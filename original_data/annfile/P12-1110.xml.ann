T1	Reference 17674 17873	The list of the features used in our joint model is presented in Table 1, where S01 S05, W01  W21, and T01 05 are taken from Zhang and Clark (2010), and P01 P28 are taken from Huang and Sagae (2010).
A1	RefType T1 Direct
A2	Type T1 Table
A3	Num T1 1
T2	Reference 21992 22024	Table 2: Statistics of datasets.
A4	RefType T2 Direct
A5	Type T2 Table
A6	Num T2 2
T3	Reference 25426 25478	Table 1: Feature templates for the full joint model.
A7	RefType T3 Direct
A8	Type T3 Table
A9	Num T3 1
T4	Reference 27358 27413	The statistics of 96 these splits are shown in Table 2.
A10	RefType T4 Direct
A11	Type T4 Table
A12	Num T4 2
T5	Reference 28963 29059	Table 5 shows that this reimplementation almost reproduces the accuracy of their implementation.
A13	RefType T5 Direct
A14	Type T5 Table
A15	Num T5 5
T6	Reference 32271 32398	Table 3 shows the performance and speed of the full joint model (with no dictionaries) on CTB5c1 with respect to the beam size.
A16	RefType T6 Direct
A17	Type T6 Table
A18	Num T6 3
T7	Reference 32649 32814	Based on this experiment, we set the beam size of SegTagDep to 64 throughout the exper 64 96.28 92.37 74.96 0.48 Table 3: F1 scores and speed (in sentences per sec.)
A19	RefType T7 Direct
A20	Type T7 Table
A21	Num T7 3
T8	Reference 33202 33435	Ta SegTag 97.66 93.61 SegTagDep 97.73 94.46 SegTag(d) 98.18 94.08 SegTagDep(d) 98.26 94.64 Table 5: Final results on CTB5j 76 75 74 ble 4 shows the segmentation, POS tagging, and dependency parsing F1 scores of these models on CTB5c.
A22	RefType T8 Direct
A23	Type T8 Table
A24	Num T8 5
T9	Reference 38468 38587	Table 4: Segmentation, POS tagging, and (unlabeled attachment) dependency F1 scores averaged over five trials on CTB5c.
A25	RefType T9 Direct
A26	Type T9 Table
A27	Num T9 4
T10	Reference 38968 38975	Table 5
A28	RefType T10 Direct
A29	Type T10 Table
A30	Num T10 5
T11	Reference 38976 39088	and Table 6 show a comparison of the segmentation and POS tagging accuracies with other state-of-the-art models.
A31	RefType T11 Direct
A32	Type T11 Table
A33	Num T11 6
T12	Reference 41349 41542	Table 6: Final results on CTB6 and CTB7 accuracies of POS tagging and dependency parsing were remarkably improved by 0.6% and 2.4%, respectively corresponding to 8.3% and 10.2% error reduction.
A34	RefType T12 Direct
A35	Type T12 Table
A36	Num T12 6
T13	Reference 15166 15319	Figure 1 portrays how the states are aligned using the proposed scheme, where a subtree is denoted as a rectangle with its partial index shown inside it.
A37	RefType T13 Direct
A38	Type T13 Figure
A39	Num T13 1
T14	Reference 16451 16598	We also propose to use the features U01 U03, which we found are effective to adjust the character Figure 1: Illustration of the alignment of steps.
A40	RefType T14 Direct
A41	Type T14 Figure
A42	Num T14 1
T15	Reference 30418 30673	(2011), we confirmed that omission of the look-ahead features results in a 0.26% decrease in the parsing accuracy on CTB5d (dev).Figure 2: F1 scores (in %) of SegTagDep on CTB 5c1 w.r.t. the training epoch (x-axis) and parsing feature weights (in legend).
A43	RefType T15 Direct
A44	Type T15 Figure
A45	Num T15 2
T16	Reference 31404 31673	Figure 2 shows the F1 scores of the proposed model (SegTagDep) on CTB5c1 with respect to the training epoch and different parsing feature weights, where  Seg ,  Tag , and  Dep  respectively denote the F1 scores of word segmentation, POS tagging, and dependency parsing.
A46	RefType T16 Direct
A47	Type T16 Figure
A48	Num T16 2
T17	Reference 35584 35679	Figure 3: Performance of baseline and joint models w.r.t. the average processing time (in sec.)
A49	RefType T17 Direct
A50	Type T17 Figure
A51	Num T17 3
T18	Reference 36602 36705	Figure 3 shows the performance and processing time comparison of various models and their combinations.
A52	RefType T18 Direct
A53	Type T18 Figure
A54	Num T18 3
