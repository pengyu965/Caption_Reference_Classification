[
    {
        "Text": "\nFoma: a finite-state compiler and library\n\t\n\t\tFoma is a compiler, programming language, and C library for constructing finite-state automata and transducers for various uses.",
        "Entity": "Normal"
    },
    {
        "Text": "It has specific support for many natural language processing applications such as producing morphological and phonological analyzers.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is largely compatible with the Xerox/PARC finite-state toolkit.",
        "Entity": "Normal"
    },
    {
        "Text": "It also embraces Unicode fully and supports various different formats for specifying regular expressions: the Xerox/PARC format, a Perl-like format, and a mathematical format that takes advantage of the \u2018Mathematical Operators\u2019 Unicode block.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is a finite-state compiler, programming language, and regular expression/finite-state library designed for multipurpose use with explicit support for automata theoretic research, constructing lexical analyzers for programming languages, and building morphological/phonological analyzers, as well as spellchecking applications.",
        "Entity": "Normal"
    },
    {
        "Text": "The compiler allows users to specify finite-state automata and transducers incrementally in a similar fashion to AT&T\u2019s fsm (Mohri et al., 1997) and Lextools (Sproat, 2003), the Xerox/PARC finite- state toolkit (Beesley and Karttunen, 2003) and the SFST toolkit (Schmid, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "One of Foma\u2019s design goals has been compatibility with the Xerox/PARC toolkit.",
        "Entity": "Normal"
    },
    {
        "Text": "Another goal has been to allow for the ability to work with n-tape automata and a formalism for expressing first-order logical constraints over regular languages and n-tape- transductions.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is licensed under the GNU general public license: in keeping with traditions of free software, the distribution that includes the source code comes with a user manual and a library of examples.",
        "Entity": "Normal"
    },
    {
        "Text": "The compiler and library are implemented in C and an API is available.",
        "Entity": "Normal"
    },
    {
        "Text": "The API is in many ways similar to the standard C library <regex.h>, and has similar calling conventions.",
        "Entity": "Normal"
    },
    {
        "Text": "However, all the low-level functions that operate directly on automata/transducers are also available (some 50+ functions), including regular expression primitives and extended functions as well as automata deter- minization and minimization algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "These may be useful for someone wanting to build a separate GUI or interface using just the existing low- level functions.",
        "Entity": "Normal"
    },
    {
        "Text": "The API also contains, mainly for spell-checking purposes, functionality for finding words that match most closely (but not exactly) a path in an automaton.",
        "Entity": "Normal"
    },
    {
        "Text": "This makes it straightforward to build spell-checkers from morphological transducers by simply extracting the range of the transduction and matching words approximately.",
        "Entity": "Normal"
    },
    {
        "Text": "Unicode (UTF8) is fully supported and is in fact the only encoding accepted by Foma.",
        "Entity": "Normal"
    },
    {
        "Text": "It has been successfully compiled on Linux, Mac OS X, and Win32 operating systems, and is likely to be portable to other systems without much effort.",
        "Entity": "Normal"
    },
    {
        "Text": "Retaining backwards compatibility with Xerox/PARC and at the same time extending the formalism means that one is often able to construct finite-state networks in equivalent various ways, either through ASCII-based operators or through the Unicode-based extensions.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, one can either say: ContainsX = \u03a3* X \u03a3*; MyWords = {cat}|{dog}|{mouse}; MyRule = n -> m || p; ShortWords = [MyLex1]1 \u2229 \u03a3\u02c6<6; or: Proceedings of the EACL 2009 Demonstrations Session, pages 29\u201332, Athens, Greece, 3 April 2009.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2009 Association for Computational Linguistics Operators Compatibility variant Function [ ] () [ ] () grouping parentheses, optionality \u2200 \u2203 N/A quantifiers \\ \u2018 term negation, substitution/homomorphism : : cross-product + \u2217 + \u2217 Kleene closures \u02c6<n \u02c6>n \u02c6{m,n} \u02c6<n \u02c6>n \u02c6{m,n} iterations 1 2 .1 .2 .u .l domain & range .f N/A eliminate all unification flags $ $.",
        "Entity": "Normal"
    },
    {
        "Text": "\u02dc $ $.",
        "Entity": "Normal"
    },
    {
        "Text": "complement, containment operators / ./.",
        "Entity": "Normal"
    },
    {
        "Text": "N/A N/A \u2018ignores\u2019, left quotient, right quotient, \u2018inside\u2019 quotient \u2208 \u2208/ = /= N/A language membership, position equivalence \u227a < > precedes, follows \u2228 \u222a \u2227 \u2229 - .P.",
        "Entity": "Normal"
    },
    {
        "Text": ".p.",
        "Entity": "Normal"
    },
    {
        "Text": "| & \u2212 .P.",
        "Entity": "Normal"
    },
    {
        "Text": ".p.",
        "Entity": "Normal"
    },
    {
        "Text": "union, intersection, set minus, priority unions => -> (->) @-> => -> (->) @-> context restriction, replacement rules <> shuffle (asynchronous product) \u00d7 \u25e6 .x.",
        "Entity": "Normal"
    },
    {
        "Text": ".o.",
        "Entity": "Normal"
    },
    {
        "Text": "cross-product, composition Table 1:                                                                            \n\t\t\tHorizontal lines separate precedence classes.",
        "Entity": "Normal"
    },
    {
        "Text": "define ContainsX ?",
        "Entity": "Normal"
    },
    {
        "Text": "* X ?",
        "Entity": "Normal"
    },
    {
        "Text": "*; define MyWords {cat}|{dog}|{mouse}; define MyRule n -> m || _ p; define ShortWords Mylex.i.l & ?\u02c6<6;                                                                                                                   \n\t\t\tOne such extension is the ability to use of a form of first-order logic to make existential statements over languages and transductions (Hulden, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, suppose we have defined an arbitrary regular language L, and want to further define a language that contains only one factor of L, we can do so by: OneL = (\u2203x)(x \u2208 L \u2227 (\u2203y)(y \u2208 L \u2227 (x = y))); Here, quantifiers apply to substrings, and we attribute the usual meaning to \u2208 and \u2227, and a kind of concatenative meaning to the predicate S(t1, t2).",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, in the above example, OneL defines the language where there exists a string x such that x is a member of the language L and there does not exist a string y, also in L, such that y would occur in a different position than x.",
        "Entity": "Normal"
    },
    {
        "Text": "This kind of logical specification of regular languages can be very useful for building some languages that would be quite cumbersome to express with other regular expression operators.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, many of the internally complex operations of Foma are built through a reduction to this type of logical expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "As mentioned, Foma supports reading and writing of the LEXC file format, where morphological categories are divided into so-called continuation classes.",
        "Entity": "Normal"
    },
    {
        "Text": "This practice stems back from the earliest two-level compilers (Karttunen et al., 1987).",
        "Entity": "Normal"
    },
    {
        "Text": "Below is a simple example of the format: Multichar_Symbols +Pl +Sing LEXICON Root Nouns; LEXICON Nouns cat Plural; church Plural; LEXICON Plural +Pl:%\u02c6s #; +Sing #;\n\t\n\t\n\t\t\tThe Foma API gives access to basic functions, such as constructing a finite-state machine from a regular expression provided as a string, performing a transduction, and exhaustively matching against a given string starting from every position.",
        "Entity": "Normal"
    },
    {
        "Text": "The following basic snippet illustrates how to use the C API instead of the main interface of Foma to construct a finite-state machine encoding the language a+b+ and check whether a string matches it: 1.\n\t\t\tvoid check_word(char *s) { 2.\n\t\t\tfsm_t *network; 3.\n\t\t\tfsm_match_result *result; 4.",
        "Entity": "Normal"
    },
    {
        "Text": "5. network = fsm_regex(\"a+ b+\"); 6.\n\t\t\tresult = fsm_match(fsm, s); 7.\n\t\t\tif (result->num_matches > 0) 8.\n\t\t\tprintf(\"Regex matches\"); 9.",
        "Entity": "Normal"
    },
    {
        "Text": "10 } Here, instead of calling the fsm regex() function to construct the machine from a regular expressions, we could instead have accessed the beforementioned low-level routines and built the network entirely without regular expressions by combining low-level primitives, as follows, replacing line 5 in the above: network = fsm_concat( fsm_kleene_plus( fsm_symbol(\"a\")), fsm_kleene_plus( fsm_symbol(\"b\"))); The API is currently under active development and future functionality is likely to include conversion of networks to 8-bit letter transducers/automata for maximum speed in regular expression matching and transduction.",
        "Entity": "Normal"
    },
    {
        "Text": "educational use Foma has support for visualization of the machines it builds through the AT&T Graphviz library.",
        "Entity": "Normal"
    },
    {
        "Text": "For educational purposes and to illustrate automata construction methods, there is some support for changing the behavior of the algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, by default, for efficiency reasons, Foma determinizes and minimizes automata between nearly every incremental operation.",
        "Entity": "Normal"
    },
    {
        "Text": "Operations such as unions of automata are also constructed by default with the product construction method that directly produces deterministic automata.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this on-the-fly minimization and determinization can be relaxed, and a Thompson construction method chosen in the interface so that automata remain non-deterministic and non- minimized whenever possible\u2014non-deterministic automata naturally being easier to inspect and analyze.",
        "Entity": "Normal"
    },
    {
        "Text": "Though the main concern with Foma has not been that of efficiency, but of compatibility and extendibility, from a usefulness perspective it is important to avoid bottlenecks in the underlying algorithms that can cause compilation times to skyrocket, especially when constructing and combining large lexical transducers.",
        "Entity": "Normal"
    },
    {
        "Text": "With this in mind, some care has been taken to attempt to optimize the underlying primitive algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "One the whole, Foma seems to perform particularly well with pathological cases that involve exponential growth in the number of states when determinizing non- deterministic machines.",
        "Entity": "Normal"
    },
    {
        "Text": "For general usage patterns, this advantage is not quite as dramatic, and for average use Foma seems to perform comparably with e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the Xerox/PARC toolkit, perhaps with the exception of certain types of very large lexicon descriptions (>100,000 words).",
        "Entity": "Normal"
    },
    {
        "Text": "The Foma project is multipurpose multi-mode finite-state compiler geared toward practical construction of large-scale finite-state machines such as may be needed in natural language processing as well as providing a framework for research in finite-state automata.",
        "Entity": "Normal"
    },
    {
        "Text": "Several wide- coverage morphological analyzers specified in the LEXC/xfst format have been compiled successfully with Foma.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is free software and will remain under the GNU General Public License.",
        "Entity": "Normal"
    },
    {
        "Text": "As the source code is available, collaboration is encouraged.",
        "Entity": "Normal"
    },
    {
        "Text": "GNU AT&T Foma xfst flex fsm 4 \u03a3\u2217a\u03a315 0.216s 16.23s 17.17s 1.884s \u03a3\u2217a\u03a320 8.605s nf nf 153.7s North Sami 14.23s 4.264s N/A N/A 8queens 0.188s 1.200s N/A N/A sudoku2x3 5.040s 5.232s N/A N/A lexicon.lex 1.224s 1.428s N/A N/A 3sat30 0.572s 0.648s N/A N/A Table 2:                                                                                                                     \n\t\t\tThe first and second entries are short regular expressions that exhibit exponential behavior.",
        "Entity": "Normal"
    },
    {
        "Text": "The second results in a FSM with 221 states and 222 arcs.",
        "Entity": "Normal"
    },
    {
        "Text": "The others are scripts that can be run on both Xerox/PARC and Foma.",
        "Entity": "Normal"
    },
    {
        "Text": "The file lexicon.lex is a LEXC format English dictionary with 38418 entries.",
        "Entity": "Normal"
    },
    {
        "Text": "North Sami is a large lexicon (lexc file) for the North Sami language available from http://divvun.no.",
        "Entity": "Normal"
    }
]