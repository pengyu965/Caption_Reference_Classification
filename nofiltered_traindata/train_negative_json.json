[
    {
        "Text": "\n\t\n\t\tWe present a statistical model of Japanese unknown words consisting of a set of length and spelling models classified by the character types that con  stitute a word.",
        "Entity": "Normal"
    },
    {
        "Text": "The point is quite simple: differ  ent character sets should be treated differently and the changes between character types are very im  portant because Japanese script has both ideograms like Chinese (kanji) and phonograms like English (katakana).",
        "Entity": "Normal"
    },
    {
        "Text": "Both word segmentation accuracy and part of speech tagging accuracy are improved by the proposed model.",
        "Entity": "Normal"
    },
    {
        "Text": "The model can achieve 96.6% tag  ging accuracy if unknown words are correctly seg  mented.",
        "Entity": "Normal"
    },
    {
        "Text": "In Japanese, around 95% word segmentation ac  curacy is reported by using a word-based lan  guage model and the Viterbi-like dynamic program  ming procedures (Nagata, 1994; Yamamoto, 1996; Takeuchi and Matsumoto, 1997; Haruno and Mat  sumoto, 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "About the same accuracy is reported in Chinese by statistical methods (Sproat et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "But there has been relatively little improve  ment in recent years because most of the remaining errors are due to unknown words.",
        "Entity": "Normal"
    },
    {
        "Text": "There are two approaches to solve this problem: to increase the coverage of the dictionary (Fung and Wu, 1994; Chang et al., 1995; Mori and Nagao, 1996) and to design a better model for unknown words (Nagata, 1996; Sproat et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "We take the latter approach.",
        "Entity": "Normal"
    },
    {
        "Text": "To improve word segmenta  tion accuracy, (Nagata, 1996) used a single general purpose unknown word model, while (Sproat et al., 1996) used a set of specific word models such as for plurals, personal names, and transliterated foreign words.\n\t\t\t'",
        "Entity": "Normal"
    },
    {
        "Text": "The goal of our research is to assign a correct part of speech to unknown word as well as identifying it correctly.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we present a novel statistical model for Japanese unknown words.",
        "Entity": "Normal"
    },
    {
        "Text": "It consists of a set of word models for each part of speech and word type.",
        "Entity": "Normal"
    },
    {
        "Text": "We classified Japanese words into nine orthographic types based on the character types that constitute a word.",
        "Entity": "Normal"
    },
    {
        "Text": "We find that by making different models for each word type, we can better model the length and spelling of unknown words.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following sections, we first describe the lan  guage model used for Japanese word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "We then describe a series of unknown word mod  els, from the baseline model to the one we propose.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we prove the effectiveness of the proposed model by experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 Baseline Language Model and Search.",
        "Entity": "Normal"
    },
    {
        "Text": "Algorithm Let the input Japanese character sequence be C = c1 ... em, and segment it into word sequence W = w1 ...Wn 1   The word segmentation task can be defined as finding the word segmentation W that max  imize the joint probability of word sequence given character sequence P(WIC).",
        "Entity": "Normal"
    },
    {
        "Text": "Since the maximiza  tion is carried out with fixed character sequence C, the word segmenter only has to maximize the joint probability of word sequence P(W).",
        "Entity": "Normal"
    },
    {
        "Text": "W = argmaxP(WIC) = argmaxP(W) (1) w w We call P(W) the segmentation model.",
        "Entity": "Normal"
    },
    {
        "Text": "We can use any type of word-based language model for P(W), such as word ngram and class-based ngram.",
        "Entity": "Normal"
    },
    {
        "Text": "We used the word bigram model in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "So, P(W) is approximated by the product of word hi  gram probabilities P(wilwi1)  P(W) P(w1l<bos>) fr=2 P(wilwi-l)P( <eos>lwn) (2) Here, the special symbols <bos> and <eos> indi  cate the beginning and the end of a sentence, re  spectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Basically, word bigram probabilities of the word segmentation model is estimated by computing the 1 In this paper, we define a word as a combination of its surface form and part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "Two words are considered to be equal only if they have the same surface form and part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "277                                                                         \"(J)/no/particle <U-noun>\" will appear in the most frequent form of Japanese noun phrases \"A (J) B\", which corresponds to \"B of A\" in English.",
        "Entity": "Normal"
    },
    {
        "Text": "(f)/no/particle <U-noun> <U-verb> \\..., /shi/inflection <U-number> fil/yen/suffix <U-adjectival-verb> f.t Ina/inflection <U-adjective> It '/i/inflection <U-adverb> c /to/particle frequency 6783 1052 407 405 182 139 words are replaced with their corresponding part of speech-based unknown word tags are very important information source of the contexts where unknown words appears.",
        "Entity": "Normal"
    },
    {
        "Text": "Word Model 3.1 Baseline Model The simplest unknown word model depends only on relative frequencies of the corresponding events in the word segmented training corpus, with appropri  ate smoothing techniques.",
        "Entity": "Normal"
    },
    {
        "Text": "The maximization search can be efficiently implemented by using the Viterbi  like dynamic programming procedure described in (Nagata, 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 Modification to Handle Unknown.",
        "Entity": "Normal"
    },
    {
        "Text": "Words To handle unknown words, we made a slight modi  fication in the above word segmentation model.",
        "Entity": "Normal"
    },
    {
        "Text": "We have introduced unknown word tags <U-t> for each part of speech t. For example, <U-noun> and <U  verb> represents an unknown noun and an unknown verb, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "If Wi is an unknown word whose part of speech is t, the word bigram probability P(wilwi1) is ap  proximated as the product of word bigram probabil  ity P( <U-t>lwi_I) and the probability of Wi given it is an unknown word whose part of speech is t, P(wii<U-t> ).",
        "Entity": "Normal"
    },
    {
        "Text": "P(wdwi1) = P( <U-t>lwi_I)P(wii<U-t>,Wi1) P( <U-t>lwi1)P(wii<U-t>) (3) the spelling.",
        "Entity": "Normal"
    },
    {
        "Text": "We think of an unknown word as a word having a special part of speech <UNK>.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, the unknown word model is formally defined as the joint probability of the character sequence wi = c1 ... ck if it is an unknown word.",
        "Entity": "Normal"
    },
    {
        "Text": "Without loss of generality, we decompose it into the product of word length probability and word spelling probability given its length, P(wii<UNK>) = P(c1 ... cki<UNK>) = P(ki<UNK>)P(c1 ... cklk, <UNK>) (4) where k is the length of the character sequence.",
        "Entity": "Normal"
    },
    {
        "Text": "We call P(ki<UNK>) the word length model, and P( c1 ...\n\t\t\tCk Ik, <UNK >) the word spelling model.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to estimate the entropy of English, (Brown et al., 1992) approximated P(ki<UNK>) by a Poisson distribution whose parameter is the average word length A in the training corpus, and P(c1 ...\n\t\t\tCk lk, <UNK>) by the product of character zerogram probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "This means all characters in the character set are considered to be selected inde  pendently and uniformly.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we made an assumption that the spelling P (c1 ..\n\t\t\t.ck I<UNK> ) k!",
        "Entity": "Normal"
    },
    {
        "Text": "Ak ->.",
        "Entity": "Normal"
    },
    {
        "Text": "k (5) of an unknown word solely depends on its part of speech and is independent of the previous word.",
        "Entity": "Normal"
    },
    {
        "Text": "This is the same assumption made in the hidden Markov model, which is called output independence.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, a word is represented by a list of surface form, pronunciation, and part of speech, which are delimited by a slash '/'.",
        "Entity": "Normal"
    },
    {
        "Text": "The first 2 Throughout in this paper, we use the term \"infrequent words\" to represent words that appeared only once in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "They are also called \"hapax legomena\" or \"hapax words\".",
        "Entity": "Normal"
    },
    {
        "Text": "It is well known that the characteristics of hapax where p is the inverse of the number of characters in the character set.",
        "Entity": "Normal"
    },
    {
        "Text": "If we assume JIS-X-0208 is used as the Japanese character set, p = 1/6879.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the Poisson distribution is a single parame  ter distribution with lower bound, it is appropriate to use it as a first order approximation to the word length distribution.",
        "Entity": "Normal"
    },
    {
        "Text": "But the Brown model has two problems.",
        "Entity": "Normal"
    },
    {
        "Text": "It assigns a certain amount of probability mass to zero-length words, and it is too simple to express morphology.",
        "Entity": "Normal"
    },
    {
        "Text": "For Japanese word segmentation and OCR error correction, (Nagata, 1996) proposed a modified ver  sion of the Brown model.",
        "Entity": "Normal"
    },
    {
        "Text": "Nagata also assumed the word length probability obeys the Poisson distribu  tion.",
        "Entity": "Normal"
    },
    {
        "Text": "But he moved the lower bound from zero to one.",
        "Entity": "Normal"
    },
    {
        "Text": "legomena are similar to those of unknown words (Baayen and Sproat, 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "P(ki<UNK>) (A 1)k-1 - e-<>.- ) (6) (k- 1)!",
        "Entity": "Normal"
    },
    {
        "Text": "Instead of zerogram, He approximated the word spelling probability P(c1 ..\n\t\t\t.ckJk, <UNK>) by the product of word-based character bigram probabili  ties, regardless of word length.",
        "Entity": "Normal"
    },
    {
        "Text": "P(cl   ckJk,<VNK>) P(cd<bow>) f1 =2 P(ciJci-l)P( <eow>Jck) (7) where <bow> and <eow> are special symbols that indicate the beginning and the end of a word.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Correction of Word Spelling.",
        "Entity": "Normal"
    },
    {
        "Text": "... ck in the set of all strings whose length are k, while the righthand side 0..\n\t\t\t0.5 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0 0 Word Length Distribution Probs from Raw Counts (hapax words) _..,_ EsUmates by Poisson (hapax words) -+-- \n\t\n\t\n\t\t\tWor Character represents the probability of the string in the set of all possible strings (from length zero to infinity).",
        "Entity": "Normal"
    },
    {
        "Text": "Let Pb (c1 ...Ck I<UNK>) be the probability of character string c1 ...Ck estimated from the char  acter bigram model.",
        "Entity": "Normal"
    },
    {
        "Text": "d Length                                                                                              Pb(cl ... cki<UNK>) = 0.5 UnknoWn Word Length Distribution kanji-+  P(c1 J<bow>) f1 =2 P(ciJci-l)P( <eow>Jck) (8) Let Pb(kJ<VNK>) be the sum of the probabilities of all strings which are generated by the character bigram model and whose length are k. More appro  priate estimate for P(c1 ..\n\t\t\t.ckJk, <UNK>) is, Pb(c1 ... ckJ<UNK>) P(cl   ckJk,<VNK>) Pb(kJ<VNK>) (9) But how can we estimate Pb(kl<VNK>)?",
        "Entity": "Normal"
    },
    {
        "Text": "It is difficult to compute it directly, but we can get a rea  sonable estimate by considering the unigram case.",
        "Entity": "Normal"
    },
    {
        "Text": "If strings are generated by the character unigram model, the sum of the probabilities of all length k strings equals to the probability of the event that the end of word symbol <eow> is selected after a 0..\n\t\t\t0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0 0 2 4 6 Word Character Length katakana -+--  10 character other than <eow> is selected k - 1 times.",
        "Entity": "Normal"
    },
    {
        "Text": "Pb(kl<VNK>)(1- P( <eow> ))k-l P( <eow>) (10)                                                                                           \n\t\t\t3.3 Japanese Orthography and Word.",
        "Entity": "Normal"
    },
    {
        "Text": "When a substring of an unknown word coincides with other word in the dic  tionary, it is very likely to be decomposed into the dictionary word and the remaining substring.",
        "Entity": "Normal"
    },
    {
        "Text": "We find the reason of the decomposition is that the word                                                                                                                                                                                          \n\t\t\t                                                                                                                                                                                                                           \n\t\t\tThe empirical and the estimated distributions agree fairly well.",
        "Entity": "Normal"
    },
    {
        "Text": "But the estimates by Poisson are smaller than empirical probabilities for shorter words ( <= 4 characters), and larger for longer words (>characters).",
        "Entity": "Normal"
    },
    {
        "Text": "This is because we rep                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n\t\t\t                                                                                                                                      \n\t\t\tIt shows that the length of kanji words distributes around 3 char  acters, while that of katakana words distributes around 5 characters.",
        "Entity": "Normal"
    },
    {
        "Text": "The empirical word length dis  tribution of                                                                 \n\t\t\tIn the Japanese writing system, there are at least five different types of characters other than punc  tuation marks: kanji, hiragana, katakana, Roman alphabet, and Arabic numeral.",
        "Entity": "Normal"
    },
    {
        "Text": "Kanji which means 'Chinese character' is used for both Chinese origin words and Japanese words semantically equivalent to Chinese characters.",
        "Entity": "Normal"
    },
    {
        "Text": "Hiragana and katakana are syllabaries: The former is used primarily for gram  matical function words, such as particles and inflec  tional endings, while the latter is used primarily to transliterate Western origin words.",
        "Entity": "Normal"
    },
    {
        "Text": "Roman alphabet is also used for Western origin words and acronyms.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic numeral is used for numbers.",
        "Entity": "Normal"
    },
    {
        "Text": "Most Japanese words are written in kanji, while more recent loan words are written in katakana.",
        "Entity": "Normal"
    },
    {
        "Text": "K atakana words are likely to be used for techni  cal terms, especially in relatively new fields like computer science.",
        "Entity": "Normal"
    },
    {
        "Text": "Kanji words are shorter than katakana words because kanji is based on a large (> 6,000) alphabet of ideograms while katakana is based on a small ( < 100) alphabet of phonograms.",
        "Entity": "Normal"
    },
    {
        "Text": "It shows approximately 65% of words are constituted by a single character type.",
        "Entity": "Normal"
    },
    {
        "Text": "Among the words that are constituted by more than two character types, only the kanjihiragana and hiraganakanji sequences are morphemes and others are compound words in a strict sense although they are identified as words in the EDR corpus 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we classified Japanese words into 9 word types based on the character types that consti  tute a word: <sym>, <num>, <alpha>, <hira>, <kata>, and <kan> represent a sequence of sym  bols, numbers, alphabets, hiraganas, katakanas, and kanjis, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "<kanhira> and <hirakan> represent a sequence of kanjis followed by hiraganas and that of hiraganas followed by kanjis, respec  tively.",
        "Entity": "Normal"
    },
    {
        "Text": "The rest are classified as <mise>.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting unknown word model is as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "We first select the word type, then we select the length and spelling.",
        "Entity": "Normal"
    },
    {
        "Text": "P(c1 ... cki<UNK>) = P( <WT>I<UNK> )P(ki<WT>, <UNK>) P(c1 ... ckik, <WT>, <UNK>) (11 ) 3.4 Part of Speech and Word.",
        "Entity": "Normal"
    },
    {
        "Text": "Morphology It is obvious that the beginnings and endings of words play an important role in tagging part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "This symbol typically appears at the end of transliterated Western origin words written in katakana.",
        "Entity": "Normal"
    },
    {
        "Text": "It is natural to make a model for each part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting unknown word model is as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "P(c1 ... cki<U-t>) = P(ki<U-t> )P(c1 ... ckik, <U-t>) (12)                                                                                                                                                                                                                                                                                                                                                       \n\t\t\tThis results in kanjihiragana sequence.",
        "Entity": "Normal"
    },
    {
        "Text": "When a Chinese character is too difficult to read, it is transliterated in hiragana.",
        "Entity": "Normal"
    },
    {
        "Text": "This results in either hiraganakanji or kanji  hiragana sequence.",
        "Entity": "Normal"
    },
    {
        "Text": "type and part of speech information.",
        "Entity": "Normal"
    },
    {
        "Text": "This is the un  known word model we propose in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "It first selects the word type given the part of speech, then the word length and spelling.",
        "Entity": "Normal"
    },
    {
        "Text": "P(c1 ... cki<U-t>) = P( <WT>I<U-t> )P(ki<WT>, <U-t>) P(c1 ... ckik, <WT>, <U-t>) (13)                                                                                                                                                                                                     \n\t\t\t- ) = C( <WT>, <U-t>) t> C(<U-t>) (14) Where ad(c;, <WT>, <U-t>) +ad(c;ic;-1, <WT>, <U-t>) +a3f(ci) + a4f(cilci1) + as(1/V) (17) Here, C ( ) represents the counts in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "To estimate the probabilities of the combinations of word type and part of speech that did not appeared in the training corpus, we used the Witten-Bell method (Witten and Bell, 1991) to obtain an esti  mate for the sum of the probabilities of unobserved events.",
        "Entity": "Normal"
    },
    {
        "Text": "We then redistributed this evenly among all unobserved events 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "A<WT>,<U-t> is the average length of words whose word type is <WT> and part of speech is <U-t>.",
        "Entity": "Normal"
    },
    {
        "Text": "P(ki<WT>, <U-t>) = (.>.<WT>.<U-t> -1)k-t e-(>.<WT> <U-t> -1) (k-1)!\n\t\t\t'",
        "Entity": "Normal"
    },
    {
        "Text": "If the combinations of word type and part of speech that did not appeared in the training corpus, we used the average word length of all words.",
        "Entity": "Normal"
    },
    {
        "Text": "Basically, they are estimated from the relative fre  quency of the character bigrams for each word type and part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "f(c;ic;_1, <WT>, <U-t>) = C(<WT>,<U-t>,c;-t,c;) C( <WT>,<U-t>,c;-t) However, if we divide the corpus by the combina  tion of word type and part of speech, the amount of each training data becomes very small.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we linearly interpolated the following five probabili  ties (Jelinek and Mercer, 1980).",
        "Entity": "Normal"
    },
    {
        "Text": "P(e;ic;-1,<WT>,<U-t>) = 4 The Witten-Bell method estimates the probability of ob  serving novel events to be r/(n+r), where n is the total num  ber of events seen previously, and r is the number of symbols that are distinct.",
        "Entity": "Normal"
    },
    {
        "Text": "The probability of the event observed c times is cf(n + r).",
        "Entity": "Normal"
    },
    {
        "Text": "a1 +a2+a3+a4+as = 1.\n\t\t\tf(ci, <WT>, <U-t>) and f(c;lc;-1, <WT>, <U-t>) are the relative frequen  cies of the character unigram and bigram for each word type and part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "f(c;) and f(c;jc;_1) are the relative frequencies of the character unigram and bigram.",
        "Entity": "Normal"
    },
    {
        "Text": "V is the number of characters (not to  kens but types) appeared in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "4 Experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Training and Test Data for the.",
        "Entity": "Normal"
    },
    {
        "Text": "Language Model We used the EDR Japanese Corpus Version 1.0 (EDR, 1991) to train the language model.",
        "Entity": "Normal"
    },
    {
        "Text": "It is a manually word segmented and tagged corpus of ap  proximately 5.1 million words (208 thousand sen  tences).",
        "Entity": "Normal"
    },
    {
        "Text": "It contains a variety of Japanese sentences taken from newspapers, magazines, dictionaries, en  cyclopedias, textbooks, etc..",
        "Entity": "Normal"
    },
    {
        "Text": "In this experiment, we randomly selected two sets of 100 thousand sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "The first 100 thousand sentences are used for training the language model.",
        "Entity": "Normal"
    },
    {
        "Text": "The second 100 thousand sentences are used for test  ing.",
        "Entity": "Normal"
    },
    {
        "Text": "The remaining 8 thousand sentences are used as a heldout set for smoothing the parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "For the evaluation of the word segmentation ac  curacy, we randomly selected 5 thousand sentences from the test set of 100 thousand sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "We call the first test set (100 thousand sentences) \"test set-1\" and the second test set (5 thousand sentences) \"test set-2\".",
        "Entity": "Normal"
    },
    {
        "Text": "There were 94,680 distinct words in the training test.",
        "Entity": "Normal"
    },
    {
        "Text": "We discarded the words whose frequency was one, and made a dictionary of 45,027 words.",
        "Entity": "Normal"
    },
    {
        "Text": "Af  ter replacing the words whose frequency was one with the corresponding unknown word tags, there were 474,155 distinct word bigrams.",
        "Entity": "Normal"
    },
    {
        "Text": "We discarded the bigrams with frequency one, and the remaining 175,527 bigrams were used in the word segmentation model.",
        "Entity": "Normal"
    },
    {
        "Text": "There were 3,120 dis  tinct character unigrams and 55,486 distinct char  acter bigrams.",
        "Entity": "Normal"
    },
    {
        "Text": "We discarded the bigram with fre  quency one and remaining 20,775 bigrams were used.",
        "Entity": "Normal"
    },
    {
        "Text": "There were 12,633 distinct character unigrams and 80,058 distinct character bigrams when we classified them for each word type and part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "We discarded the bigrams with frequency one and re  0.85 0.7 POS + WT + Poisson + bigram -+  POS + Poisson + bigram -+--  maining 26,633 bigrams were used in the unknown word model.",
        "Entity": "Normal"
    },
    {
        "Text": "Average word lengths for each word type and part of speech were also computed from the words with frequency one in the training set.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Cross Entropy and Perplexity.",
        "Entity": "Normal"
    },
    {
        "Text": "(Poisson + zerogram).",
        "Entity": "Normal"
    },
    {
        "Text": "Cross entropy was computed over the words in test set-1 that were not found in the dictionary of the word segmentation model (56,121 words).",
        "Entity": "Normal"
    },
    {
        "Text": "Character perplexity is more intu  itive than cross entropy because it shows the average number of equally probable characters out of 6,879 characters in JIS-X-0208.",
        "Entity": "Normal"
    },
    {
        "Text": "It also shows that by making a separate model for each word type, character per  plexity is reduced by an additional 45% (128 --+ 71).",
        "Entity": "Normal"
    },
    {
        "Text": "This shows that the word type information is useful for modeling the morphology of Japanese words.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Part of Speech Prediction Accuracy.",
        "Entity": "Normal"
    },
    {
        "Text": "without Context                                                                                                   \n\t\t\tIt shows the accuracies up to the top 10 candidates.",
        "Entity": "Normal"
    },
    {
        "Text": "The first model is                                                                                                       \n\t\t\t                                                                               o.s51 ---:23 _.-J4L----'-5--6.L...----'7----'-8--9'-- J10 Rank                                                                                                                 \n\t\t\tThe test words are the same 56,121 words used to compute the cross entropy.",
        "Entity": "Normal"
    },
    {
        "Text": "Since these unknown word models give the prob  ability of spelling for each part of speech P(wit), we used the empirical part of speech probability P(t) to compute the joint probability P(w, t).",
        "Entity": "Normal"
    },
    {
        "Text": "The part of speech t that gives the highest joint probability is selected.",
        "Entity": "Normal"
    },
    {
        "Text": "i = argmp.xP(w, t) = P(t)P(wit) (18) The part of speech prediction accuracy of the first and the second model was 67.5% and 74.4%, respec  tively.",
        "Entity": "Normal"
    },
    {
        "Text": "4.4 Word Segmentation Accuracy.",
        "Entity": "Normal"
    },
    {
        "Text": "Word segmentation accuracy is expressed in terms of recall and precision as is done in the previous research (Sproat et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "Let the number of words in the manually segmented corpus be Std, the number of words in the output of the word segmenter be Sys, and the number of matched words be M. Recall is defined as M/Std, and precision is defined as M/Sys.",
        "Entity": "Normal"
    },
    {
        "Text": "Since it is inconvenient to use both recall and precision all the time, we also use the F-measure to indicate the overall performance.",
        "Entity": "Normal"
    },
    {
        "Text": "It is calculated by F = (!3 2 + 1.0) X p X R (32 X p + R (19) where Pis precision, R is recall, and (3 is the relative importance given to recall over precision.",
        "Entity": "Normal"
    },
    {
        "Text": "0 65 .0 62 .0 61 .5 66 .4 42.",
        "Entity": "Normal"
    },
    {
        "Text": "7 52 .5 48 .3 51.",
        "Entity": "Normal"
    },
    {
        "Text": "4 f3 = 1.0 throughout this experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "That is, we put equal importance on recall and precision.",
        "Entity": "Normal"
    },
    {
        "Text": "Com  pared to the baseline model (Poisson+ bigram), by using word type and part of speech information, the precision of the proposed model (POS + WT + Pois  son + bigram) is improved by a modest 0.6%.",
        "Entity": "Normal"
    },
    {
        "Text": "The impact of the proposed model is small because the out-of-vocabulary rate of test set-2 is only 3.1%.",
        "Entity": "Normal"
    },
    {
        "Text": "To closely investigate the effect of the proposed unknown word model, we computed the word seg  mentation accuracy of unknown words.",
        "Entity": "Normal"
    },
    {
        "Text": "The accuracy of the proposed model (POS + WT + Poisson + bigram) is signif  icantly higher than the baseline model (Poisson + bigram).",
        "Entity": "Normal"
    },
    {
        "Text": "Recall is improved from 31.8% to 42.0% and precision is improved from 65.0% to 66.4%.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, recall is the percentage of correctly seg  mented unknown words in the system output to the all unknown words in the test sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Precision is the percentage of correctly segmented unknown words in the system's output to the all words that system identified as unknown words.",
        "Entity": "Normal"
    },
    {
        "Text": "Notice that the baseline model (Poisson + bigram) cannot predict part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "To roughly estimate the amount of improvement brought by the proposed model, we applied a simple tagging strat  egy to the output of the baseline model.",
        "Entity": "Normal"
    },
    {
        "Text": "That is, words that include numbers are tagged as numbers, and others are tagged as nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "Other than the usual recall/precision measures, we defined another precision                   , which roughly correspond to the tagging accuracy in English where word segmentation is trivial.",
        "Entity": "Normal"
    },
    {
        "Text": "Prec2 is defined as the percentage of correctly tagged un  known words to the correctly segmented unknown words.",
        "Entity": "Normal"
    },
    {
        "Text": "The tagging accuracy in context (96.6%) is significantly higher than that without context (74.4%).",
        "Entity": "Normal"
    },
    {
        "Text": "This shows that the word bigrams using unknown word tags for each part of speech are useful to predict the part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "Since English uses spaces between words, unknown words can be identified by simple dictionary lookup.",
        "Entity": "Normal"
    },
    {
        "Text": "So the topic of interest is part of speech estimation.",
        "Entity": "Normal"
    },
    {
        "Text": "Some statistical model to estimate the part of speech of unknown words from the case of the first letter and the prefix and suffix is proposed (Weischedel et al., 1993; Brill, 1995; Ratnaparkhi, 1996; Mikheev, 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "On the contrary, since Asian languages like Japanese and Chinese do not put spaces between words, previous work on unknown word problem is focused on word segmentation; there are few studies estimating part of speech of unknown words in Asian languages.",
        "Entity": "Normal"
    },
    {
        "Text": "The cues used for estimating the part of speech of unknown words for Japanese in this paper are ba  sically the same for English, namely, the prefix and suffix of the unknown word as well as the previous and following part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "The contribution of this paper is in showing the fact that different char  acter sets behave differently in Japanese and a better word model can be made by using this fact.",
        "Entity": "Normal"
    },
    {
        "Text": "By introducing different length models based on character sets, the number of decomposition errors of unknown words are significantly reduced.",
        "Entity": "Normal"
    },
    {
        "Text": "In other words, the tendency of over-segmentation is cor  rected.",
        "Entity": "Normal"
    },
    {
        "Text": "This is the main reason of the remaining under-segmented and over-segmented errors.",
        "Entity": "Normal"
    },
    {
        "Text": "To improve the unknown word model, feature  based approach such as the maximum entropy method (Ratnaparkhi, 1996) might be useful, be  cause we don't have to divide the training data into several disjoint sets (like we did by part of speech and word type) and we can incorporate more lin  guistic and morphological knowledge into the same probabilistic framework.",
        "Entity": "Normal"
    },
    {
        "Text": "We are thinking of re  implementing our unknown word model using the maximum entropy method as the next step of our research.\n\t\t\t                                                                                                                                                                               )",
        "Entity": "Normal"
    },
    {
        "Text": "r e c pr ec F pr ec 2 Po iss on +b igr a m W T + P o is s o n + b i g r a m P O S + P o is s o n + b i g r a m P O S + W T + P o is s o n + b i g r a m 28 .1 37 .7 37 .5 40 .6 57 .3 51 .5 58 .1 64 .1 37 .7 43 .5 45 .6 49 .7 8 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 8 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 9 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 9 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6\n\t\n\t\n\t\t\tWe present a statistical model of Japanese unknown words using word morphology and word context.",
        "Entity": "Normal"
    },
    {
        "Text": "We find that Japanese words are better modeled by clas  sifying words based on the character sets (kanji, hi  ragana, katakana, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "and its changes.",
        "Entity": "Normal"
    },
    {
        "Text": "This is because the different character sets behave differ  ently in many ways (historical etymology, ideogram vs. phonogram, etc.).",
        "Entity": "Normal"
    },
    {
        "Text": "Both word segmentation ac  curacy and part of speech tagging accuracy are im  proved by treating them differently.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tWe present a Parameterized Action Representation (PAR) that provides a conceptual representation ofdifferent types of actions used to animate virtual human agents in a simulated 3D environment.",
        "Entity": "Normal"
    },
    {
        "Text": "These actions involve changes of state, changes of location (kinematic) and exertion of force (dynamic).",
        "Entity": "Normal"
    },
    {
        "Text": "PARSare hierarchical, parameterized structures that facilitate both visual and verbal expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to support the animation of the actions, PARShave to make explicit many details that are often underspecified in the language.",
        "Entity": "Normal"
    },
    {
        "Text": "This detailed level ofrepresentation also provides a suitable pivot representation for generation in other natural languages, i.e., a form of interlingua.",
        "Entity": "Normal"
    },
    {
        "Text": "We show examples of how certain divergences in machine translation can be solved by our approach focusing specifically on how verb-framed and satellite-framed languages can use our representation.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we describe a Parameterized Ac tion Representation (PAR) (Badler et al., 1999)that provides a conceptual representation of differ ent types of actions used to animate virtual humanagents in a simulated 3D environment.",
        "Entity": "Normal"
    },
    {
        "Text": "These ac tions involve changes of state, changes of location (kinematic) and exertion of force (dynamic).",
        "Entity": "Normal"
    },
    {
        "Text": "PARSare hierarchical, parameterized structures that fa cilitate both visual and verbal expressions (Badler et al., 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "In order to support the animation ofthe actions, PARS have to make explicit many de tails that are often underspecified in the language.",
        "Entity": "Normal"
    },
    {
        "Text": "This detailed level of representation is well suitedfor an interlingua for machine translation applications, since the animations of actions   and therefore the PARS that control them   will be equivalent for the same actions described in different lan guages.",
        "Entity": "Normal"
    },
    {
        "Text": "These representations can be incorporated into a system which uses PAR-based animations asa workbench for creating accurate conceptual representations, which can map to seeral different lan guages as well as produce faithful animations.",
        "Entity": "Normal"
    },
    {
        "Text": "The verb classes we are currently considering in this light involve explicit physical actions such asthose expressed in the motion verb class and contact verb class (Levin, 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Since we are employ ing PAR as an interlingual representation, we willshow examples of how it can handle certain diver gences in machine translation, focusing specifically on how verb-framed and satellite-framed languages (Talmy, 1991) can yield equivalent actions in this representation.",
        "Entity": "Normal"
    },
    {
        "Text": "We use parameterized action representations to ani mate the actions of virtual human agents.",
        "Entity": "Normal"
    },
    {
        "Text": "The PAR for an action includes the action&apos;s participants (its agent and objects),&apos; as well as kinematic properties such as its path, manner and duration, and dynamic properties, such as its speed and force (see Fig.",
        "Entity": "Normal"
    },
    {
        "Text": "1).The representation also allows for traditional statespace properties of actions, such as applicability conditions and preparatory actions that have to be satisfied before the action can be executed, and termina tion conditions and post assertions which determine when an action is concluded and what changes it makes to the environment state.",
        "Entity": "Normal"
    },
    {
        "Text": "We created a hierarchy of actions, exploiting the idea that verbs can be represented in a lattice that allows semantically similar verbs, such as motion verbs or verbs of contact, to be closely associatedwith each other under a common parent that cap tures the properties these verbs all share (Dang et al., 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "The highest nodes in the hierarchy areoccupied by generalized PAR schemas which represent the basic predicate-argument structures for en tire groups of subordinate actions.",
        "Entity": "Normal"
    },
    {
        "Text": "The lower nodes are occupied by progressively more specific schemas that inherit information from the generalized PARS,and can be instantiated with arguments from natu ral language to represent a specific action such asJohn hit the ball with his bat.",
        "Entity": "Normal"
    },
    {
        "Text": "The example in          is a generalized PAR schema for contact ac &apos;Objects and agents are stored in a hierarchy and have a number of properties associated with them.",
        "Entity": "Normal"
    },
    {
        "Text": "Properties of the objects may include their location and status.",
        "Entity": "Normal"
    },
    {
        "Text": "Agents have capabilities, such as the ability to walk or swim, and properties such as their strength and height.",
        "Entity": "Normal"
    },
    {
        "Text": "12 contact/(par:contact) hit/(manner:forcefully) touch/(manner:gently) kick/(OBJ2:foot) hammer/(OBJ2:hammer)         : A lexical/semantic hierarchy for actions of contact CONTACT PAR activity :[ ACTION ] participants :  agent : AGENT objects : OBJ1, OBJ2 applic cond : reachable(OBJ1) have(AGENT,OBJ2)   preparatory spec : [get(AGENT, OBJ2)] termination cond : [contact(OBJ1, OBJ2)] post assertions : [contact(OBJ1, OBJ2)] path, duration, motion, force manner :[ MANNER ]         : A PAR schema for actions of contact tions between two objects.",
        "Entity": "Normal"
    },
    {
        "Text": "This schema specifiesthat the `contact&apos; action has an agent and two ob jects, and that the action is concluded when the twoobjects come together.2 The preparatory specification of getting the second object is tested and car ried out if the object is not possessed.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to describe a specific action, say hammer, we wouldcombine all of its ancestor representations in the ac tion hierarchy, as shown in         , and add the information specific to that action.",
        "Entity": "Normal"
    },
    {
        "Text": "Since hammer inherits from the PAR for hit, and ultimately from the PAR for contact, its representation would usethe generalized `contact&apos; PAR, with a forceful man ner, and a hammer as the instrument.",
        "Entity": "Normal"
    },
    {
        "Text": "The action hit does not specify any instrument, but inherits the forceful manner and generalized contact PAR from its ancestors, and the action contact leaves both the 2In this example, the second object is the instrument with which the action is performed.instrument and the manner unspecified, and is asso ciated only with the generalized contact PAR.The PAR is intended to provide slots for information that is typically conveyed in modifiers or ad juncts in addition to internal verb arguments.",
        "Entity": "Normal"
    },
    {
        "Text": "Assuch, it is often the case that several different syn tactic realizations can all map to the same PAR schema.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, John hit the ball, John hit the ball with a bat and John swung mightily and his bat hit the ball with a resounding crack would all map to the same schema.3\n\t\n\t\n\t\t\tThe main components of our animation system are:a natural language interface, a planner and a graphi cal animation (see         ).",
        "Entity": "Normal"
    },
    {
        "Text": "The PARS are used as intermediate representations of the actions between components.An instruction in natural language starts the process.",
        "Entity": "Normal"
    },
    {
        "Text": "We use a Synchronous Tree Adjoining Gram mar (Shieber and Schabes, 1990; Shieber, 1994) forparsing natural language instructions into deriva tions containing predicate-argument dependencies (Schuler, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "The synchronous parser extractsthese predicate-argument structures by first asso ciating each word in an input sentence with one or more elementary trees, which are combined intoa single derivation tree for the entire input sentence using the constrained operations of substitu tion and adjunction in the Tree Adjoining Grammar formalism (Joshi, 1985; Joshi, 1987).",
        "Entity": "Normal"
    },
    {
        "Text": "As the parser assembles these elementary tree predicates into apredicate-argument structure, it simultaneously se lects and assembles the corresponding schemas.",
        "Entity": "Normal"
    },
    {
        "Text": "It fills in the participants and modifiers, and outputs the PAR schema for the instruction.",
        "Entity": "Normal"
    },
    {
        "Text": "These schemas may be underspecified for actions such as `enter&apos; or `put&apos; and thus not provide enough information for the animation to be produced directly.3The relationship between PARS and alternations may be come much more complicated when we consider other verb classes such as change of state verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "13 Natural Language           General architecture of the animation system The planner uses information from the general schema, such as preconditions and post-assertions,as well as information derived from the agents&apos; ca pabilities and the objects properties to fill in these gaps in several ways:  to select the way (activity) in which the instruction is performed (enter by walking, by swim ming, etc.",
        "Entity": "Normal"
    },
    {
        "Text": ");   to determine the prepartory actions that must be completed before the instruction is carried out, (for example, in order for an agent to open the door, the door has to be reachable and that may involve a locomotion process);   to decompose the action into smaller units (put the glass on the table, involves getting the glass, planning a route to the table, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "The output of the planner for the input instructionis a complete description of the actions involved, including participants, preparatory specifications, termination conditions, manner, duration, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "Partic ipants bring with them a list of inherent propertiesof the agent (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "agent capabilities) or physical objects (e.g., object configurations) and other charac teristics, such as &apos;how to open&apos; for an object such as a door.",
        "Entity": "Normal"
    },
    {
        "Text": "This complete description refers to a setof animation PARS which can be immediately ani mated.",
        "Entity": "Normal"
    },
    {
        "Text": "In this way, a PAR schema for the action enter may actually translate into an animation PAR forwalking into a certain area.",
        "Entity": "Normal"
    },
    {
        "Text": "One way to differenti ate between action PAR schemas and instantiated animation PARs is to consider what it is possible to motion capture&apos; (by attaching sensors to a moving human figure).",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the enter action and the put action are quite general and underspecifiedand could not be motion captured.",
        "Entity": "Normal"
    },
    {
        "Text": "However, char acteristic activities such as walking and swimming could be.",
        "Entity": "Normal"
    },
    {
        "Text": "For further details about the animation PARS and the animation system see (Badler et al, 1999) and (Bindiganavale at al., 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "The PAR representation for an action can be seen as a general template.",
        "Entity": "Normal"
    },
    {
        "Text": "PAR schemas include, as part of the basic sub-categorization frame, properties of 4There are several other ways to generate motions, forexample, through inverse kinematics, dynamics and key framing.",
        "Entity": "Normal"
    },
    {
        "Text": "the action that can occur linguistically either as the main verb or as adjuncts to the main verb phrase.",
        "Entity": "Normal"
    },
    {
        "Text": "This captures problems of divergences, such as theones described by Talmy (Talmy, 1991), for verb framed versus satellite-framed languages.",
        "Entity": "Normal"
    },
    {
        "Text": "New information may come from a sentence in natural language that modifies the action&apos;s inherent properties, such as in John hit the ball slowly, where &apos;slowly&apos; is not part of the initial representation of the action &apos;hit&apos;.",
        "Entity": "Normal"
    },
    {
        "Text": "This new information is added to the PAR schema.",
        "Entity": "Normal"
    },
    {
        "Text": "Verb- versus Satellite-framed languages Verb-Framed Languages (VFL) map the motion (path or path + ground location) onto the verb,and the manner either onto a satellite or an ad junct, while Satellite-Framed Languages (SFL) map the motion into the satellite, and the manner onto the main verb.English and other Germanic languages are consid ered satellite-framed languages, expressing the pathin the satellite; Spanish, among other Romance lan guages, is a verb-framed language and expresses the path in the main verb.",
        "Entity": "Normal"
    },
    {
        "Text": "The pairs of sentences (1) and (2) from Talmy (1991) show examples of thesedivergences.",
        "Entity": "Normal"
    },
    {
        "Text": "In (I), in English, the exit of the bot tle is expressed by the preposition out, in Spanish the same concept is incorporated in the main verb salir (to exit).",
        "Entity": "Normal"
    },
    {
        "Text": "In (2), the concept of blowing out the candle is represented differently in English and Spanish.",
        "Entity": "Normal"
    },
    {
        "Text": "(1) The bottle floated out La botella solid flotando (the bottle exited floating) (2) I blew out the candle Apague la vela sopldndola (I extinguish the candle blowing) 4.1 Motion.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to capture generalizations about motion actions, we have a generalized PAR schema for mo tion, and our hierarchy includes different types of motion actions such as inherently directed motion and manner of motion actions that inherit from the more general schema, as shown in         .",
        "Entity": "Normal"
    },
    {
        "Text": "Directed motion actions, such as enter and exit, don&apos;t bring with them the manner by which the action is carried out but they have a inherent termination condition.For example, &apos;enter a room&apos; may be done by walking, crawling or flying depending on the agents&apos; ca 14 motion/(par :motion) directed_motion manner_motion enterAterm: in(03J) ) exit/(term: out (OM) crawl/(act :craul) float/(act :float)         : PAR schema hierarchy for motion actions pabilities, but it should end when the agent is in the room.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, manner of motion verbs expressthe action explicitly and don&apos;t have an intrinsic ter mination condition.",
        "Entity": "Normal"
    },
    {
        "Text": "Motion is a type of framing event where the path is in the main verb for VFLs and in the satellite for SFLs.",
        "Entity": "Normal"
    },
    {
        "Text": "In (3), we see the English sentence expressing the &apos;enter&apos; idea in the preposition into whereas the Spanish sentence expresses it in the main verb entrar (to enter).",
        "Entity": "Normal"
    },
    {
        "Text": "(3) The bottle floated into the cave La botella entrci flotando a la cueva (the bottle entered floating the cave)The PAR schemas don&apos;t distinguish the representation for these sentences, because there is a sin gle schema which includes both the manner and thepath without specifying how they are reabized lin guistically.",
        "Entity": "Normal"
    },
    {
        "Text": "Mappings from the lexical items to the schemas or to constraints in the schemas can be seenin         .5 Independent of which is the source language, the PAR schema selected is motion, the activity field, which determines how the action is per formed (in this case, by floating), is filled by float(the main verb in English, or the adjunct in Span ish).",
        "Entity": "Normal"
    },
    {
        "Text": "The termination condition, which says that action ends when the agent is in the object, is added from the preposition in English and is part of the semantics of the main verb to enter in Spanish.",
        "Entity": "Normal"
    },
    {
        "Text": "EN float/rparmotion,activity:float] into/[term:in(AG,OBJ)] SP entrarAparmotion,terrn:in(AG,0111)] flotarga.ctivity:floati         : Entries for the example sentences in (3)Because all of the necessary elements for a trans lation are specified in this representation, it is up 8A lexical item may have several mappings to reflect its semantics.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, float in English can be used also in the non-motion sense, in which case there will be two entries to capture that distinction.",
        "Entity": "Normal"
    },
    {
        "Text": "MOTION PAR - activity : float [agent : bottle I object: cave _ termination_cond in(bottle, cave)        : A (simplified) PAR schema for the sen tences in (3) to the language specific component to transform itinto a surface structure that satisfies the grammati cal principles of the destination language.",
        "Entity": "Normal"
    },
    {
        "Text": "Comparison with other work Our approach now diverges considerably from the approach outlined in Palmer et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998) which discusses the use of Feature-Based Tree Adjoining Grammars, (Joshi, 1985; VijayShanker and Joshi,1991) to capture generalizations about manner-ofmotion verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "They do not propose an interlin gua but use a transfer-based mechanism expressedin Synchronous Tree Adjoining Grammars to cap ture divergences of VFL and SF% through the useof semantic features and links between the grammars.",
        "Entity": "Normal"
    },
    {
        "Text": "The problem of whether or not a preposi tional.",
        "Entity": "Normal"
    },
    {
        "Text": "phrase constitutes an argument to a verb or an adjunct (described by Palmer et al.)",
        "Entity": "Normal"
    },
    {
        "Text": "does not constitute a problem in our representation, since all the information is recovered in the same template for the action to be animated.",
        "Entity": "Normal"
    },
    {
        "Text": "The PAR approach is much more similar to the Lexical Conceptual Structures (LOS) approach,(Jacicendoff, 1972; Jackendoff, 1990), used as an in terlingua representation (Dorr, 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Based on the assumption that motion and manner of motion are conflated in a matrix verb like swim, the use of LCSallows separation of the concepts of motion, direc tion, and manner of motion in the sentence John swam across the lake.",
        "Entity": "Normal"
    },
    {
        "Text": "Each one of these concepts is participants : 15represented separately in the interlingua represen tation, as GO, PATH and MANNER, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Our approach allows for a similar representation and the end result is the same, namely that the event ofswimming across the lake is characterized by sepa rate semantic components, which can be expressedby the main schema and by the activity field.",
        "Entity": "Normal"
    },
    {
        "Text": "In ad dition, our representation also incorporates details about the action such as applicability conditions, preparatory specifications, termination conditions, and adverbial modifiers.",
        "Entity": "Normal"
    },
    {
        "Text": "It is not clear to us how the LCS approach could be used to effect the same commonality of representation.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Instrument.",
        "Entity": "Normal"
    },
    {
        "Text": "The importance of the additional information such as the termination conditions can be more clearly illustrated with a different set of examples.",
        "Entity": "Normal"
    },
    {
        "Text": "Another class of actions that presents interesting divergences involves instruments where the instrument is used as the main verb or as an adjunct depending on thelanguage.",
        "Entity": "Normal"
    },
    {
        "Text": "The sentence pair in (4) shows this divergence for English and Portuguese.",
        "Entity": "Normal"
    },
    {
        "Text": "Because Por tuguese does not have a verb for to spoon, it uses a more general verb colocar (to put) as the main verb and expresses the instrument in a prepositional phrase.",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike directed motion actions, a put withhand-held instrument action (e.g., spoon, scoop, la dle, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "leaves the activity field unspecified in both languages.",
        "Entity": "Normal"
    },
    {
        "Text": "The specific action is generated by taking the instrument into account.",
        "Entity": "Normal"
    },
    {
        "Text": "A simplified schema is shown in         .",
        "Entity": "Normal"
    },
    {
        "Text": "(4) Mary spoons chocolate over the ice cream Mary coloca chocolate sabre a sorvete corn a collier (Mary puts chocolate over the ice cream with a spoon) PUT3 PAR activity: participants: agent: Mary objects : chocolate, icecream, spoon preparatory_spec: get(Mary, spoon) termination_cond over(chocolate, icecream)         : Representation of the sentences in (4) Notice that the only connection between to spoonand its Portuguese translation would be the termination condition where the object of the verb, choco late, has a new location which is over the ice cream.",
        "Entity": "Normal"
    },
    {
        "Text": "We have discussed a parameterized representation of actions grounded by the needs of animation of instructions in a simulated environment.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to support the animation of these instructions, our representation makes explicit many details that are often underspecified in the language, such as start and end states and changes in the environment that happen as a result of the action.",
        "Entity": "Normal"
    },
    {
        "Text": "Sometimes the start and end state information provides critical information for accurate translation but it is not always necessary.",
        "Entity": "Normal"
    },
    {
        "Text": "Machine translationcan often simply preserve ambiguities in the transla tion without resolving them.",
        "Entity": "Normal"
    },
    {
        "Text": "In our application we cannot afford this luxury.",
        "Entity": "Normal"
    },
    {
        "Text": "An interesting question to pursue for future work will be whether or not we can determine which PAR slots are not needed for machine translation purposes.",
        "Entity": "Normal"
    },
    {
        "Text": "Generalizations based on action classes provide the basis for an interlingua approach that captures the semantics of actions without committing to any language-dependent specification.",
        "Entity": "Normal"
    },
    {
        "Text": "This framework offers a strong foundation for handling the range of phenomena presented by the machine translation task.The structure of our PAR schenaas incorpo rate into a single template the kind of divergencepresented in verb-framed and satellite-framed lan guages.",
        "Entity": "Normal"
    },
    {
        "Text": "Although not shown in this paper, thisrepresentation can also capture idioms and non compositional constructions since the animations of actions   and therefore the PARS that control them   must be equivalent for the same actions described in different languages.",
        "Entity": "Normal"
    },
    {
        "Text": "Currently, we are also investigating the possibilityof building these action representations from a class based verb lexicon which has explicit syntactic and semantic information (Kipper et at,, 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "The authors would like to thank the Actionarygroup, Hoa Trang Dang, and the anonymous reviewers for their valuable comments.",
        "Entity": "Normal"
    },
    {
        "Text": "This work was pax tially supported by NSF Grant 9900297.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tGiven the lack of word delimiters in written Japanese, word segmentation is generally consid  ered a crucial first step in processing Japanese texts.",
        "Entity": "Normal"
    },
    {
        "Text": "Typical Japanese segmentation algorithms rely ei  ther on a lexicon and grammar or on pre-segmented data.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, we introduce a novel statistical method utilizing unsegmentd training data, with performance on kanji sequences comparable to and sometimes surpassing that of morphological analyz  ers over a variety of error metrics.",
        "Entity": "Normal"
    },
    {
        "Text": "Because Japanese is written without delimiters be  tween words, 1 accurate word segmentation to re  cover the lexical items is a key step in Japanese text processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Proposed applications of segmentation technology include extracting new technical terms, indexing documents for information retrieval, and correcting optical character recognition (OCR) er  rors (Wu and Tseng, 1993; Nagao and Mori, 1994; Nagata, 1996a; Nagata, 1996b; Sproat et al., 1996; Fung, 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "Typically, Japanese word segmentation is per  formed by morphological analysis based on lexical and grammatical knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "This analysis is aided by the fact that there are three types of Japanese characters, kanji, hiragana, and katakana: changes in character type often indicate word boundaries, al  though using this heuristic alone achieves less than 60% accuracy (Nagata, 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "Character sequences consisting solely of kanji pose a challenge to morphologically-based seg  menters for several reasons.",
        "Entity": "Normal"
    },
    {
        "Text": "First and most importantly, kanji sequences often contain domain terms and proper nouns: Fung (1998) notes that5085% of the terms in various technical dictio 1The analogous situation in English would be if words were written without spaces between them.",
        "Entity": "Normal"
    },
    {
        "Text": "naries are composed at least partly of kanji.",
        "Entity": "Normal"
    },
    {
        "Text": "Such words tend to be missing from general-purpose lexicons, causing an unknown word problem for morphological analyzers; yet, these terms are quite important for information retrieval, information extraction, and text summarization, making correct segmentation of these terms critical.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, kanji sequences often consist of compound nouns, so grammatical constraints are not applicable.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, the sequence shachohjkenjgyoh-mujbu  choh (presidentjandjbusinessjgeneral manager = \"a president as well as a general manager of business\") could be incorrectly segmented as: sha  chohjkengyohjmujbu-choh (presidentjsubsidiary business!Tsutomu [a name]jgeneral manager); since both alternatives are four-noun sequences, they cannot be distinguished by part-of-speech information alone.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, heuristics based on changes in character type obviously do not apply to kanji-only sequences.",
        "Entity": "Normal"
    },
    {
        "Text": "Since se  quences of more than 3 kanji generally consist of more than one word, at least 21.2% of 1993 Nikkei newswire consists of kanji sequences requiring seg  mentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, accuracy on kanji sequences is an important aspect of the total segmentation process.",
        "Entity": "Normal"
    },
    {
        "Text": "As an alternative to lexica-grammatical and su pervised approaches, we propose a simple, effi cient segmentation method which learns mostly from very large amounts of unsegmented training data, thus avoiding the costs of building a lexicon or grammar or hand-segmenting large amounts of training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Some key advantages of this method are:   No Japanese-specific rules are employed, en  hancing portability to other languages.",
        "Entity": "Normal"
    },
    {
        "Text": "A very small number of pre-segmented train  ing examples (as few as 5 in our experiments) are needed for good performance, as long as large amounts of unsegmented data are avail  able.",
        "Entity": "Normal"
    },
    {
        "Text": "For long kanji strings, the method produces re  sults rivalling those produced by Juman 3.61 (Kurohashi and Nagao, 1998) and Chasen 1.0 (Matsumoto et al., 1997), two morphological analyzers in widespread use.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, we achieve 5% higher word precision and 6% bet  ter morpheme recall.",
        "Entity": "Normal"
    },
    {
        "Text": "Let I> (y, z) be an indicator function that is 1 when y > z, and 0 otherwise.2 In order to compensate for the fact that there are more n-gram questions than (n -1)-gram questions, we calculate the fraction of affirmative answers separately for each n in N: 2 n-1\n\t\n\t\n\t\t\tOur algorithm employs counts of character n-grams Vn(k) = 2(n 1 L L I>(#(8f), #(tj)) i=l j=l in an unsegmented corpus to make segmentation de  cisions.",
        "Entity": "Normal"
    },
    {
        "Text": "Let \"A B C D W X Y Z\" represent an eight-kanji   VN(k) = 1 INI L Vn(k) nEN sequence.",
        "Entity": "Normal"
    },
    {
        "Text": "To decide whether there should be a word boundary between D and W, we check whether n  grams that are adjacent to the proposed boundary, such as the 4-grams s1 =\"A B C D\" and 82 =\"W X Y Z\", tend to be more frequent than n-grams that straddle it, such as the 4-gram t 1 =\"BCD W\".",
        "Entity": "Normal"
    },
    {
        "Text": "If so, we have evidence of a word boundary between D and W, since there seems to be relatively little cohesion between the characters on opposite sides of this gap.",
        "Entity": "Normal"
    },
    {
        "Text": "The n-gram orders used as evidence in the seg  mentation decision are specified by the set N. For instance, if N = {4} in our example, then we pose the six questions of the form, \"Is #(8i) > #(tj)?",
        "Entity": "Normal"
    },
    {
        "Text": "\", where #(x) denotes the number of occurrences of x in the (unsegmented) training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "If N = {2,4}, then two more questions (Is \"#(CD) > #(D W)?\"",
        "Entity": "Normal"
    },
    {
        "Text": "and \"Is #(W X) > #(D W)?\")",
        "Entity": "Normal"
    },
    {
        "Text": "are added.",
        "Entity": "Normal"
    },
    {
        "Text": "More formally, let 8 and 8 be the non  straddling n-grams just to the left and right of lo  cation k, respectively, and let tj be the straddling n-gram with j characters to the right of location k. After vN (k) is computed for every location, bound  aries are placed at all locations f such that either:   VN(f) > VN(f- 1) and VN( ) > VN(f. + 1) (that is, R. is a local maximum), or   vN (R.)t, a threshold parameter.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that it also controls the granularity of the segmentation: low thresholds encourage shorter segments.",
        "Entity": "Normal"
    },
    {
        "Text": "Both the count acquisition and the testing phase are efficient.",
        "Entity": "Normal"
    },
    {
        "Text": "Computing n-gram statistics for all possible values of n simultaneously can be done in 0(m log m) time using suffix arrays, where m is the training corpus size (Manber and Myers, 1993; Nagao and Mori, 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "However, if the set N of n gram orders is known in advance, conceptually simpler algorithms suffice.",
        "Entity": "Normal"
    },
    {
        "Text": "Memory allocation for 2Note that we do not take into account the magnitude of the difference between the two frequencies; see section 5 for discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "v,./k) A BI C DI W XI Y1 Z the word level, a stem and its affixe s are brack eted toget her as a single unit.",
        "Entity": "Normal"
    },
    {
        "Text": "The X- Y boundary is created by the threshold criterion, the other three by the local maximum condition.",
        "Entity": "Normal"
    },
    {
        "Text": "count tables can be significantly reduced by omit  ting n-grams occurring only once and assuming the count of unseen n-grams to be one.",
        "Entity": "Normal"
    },
    {
        "Text": "In the applica  tion phase, the algorithm is clearly linear in the test corpus size if INI is treated as a constant.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we note that some pre-segmented data is necessary in order to set the parameters N and t. However, as described below, very little such data was required to get good performance; we therefore deem our algorithm to be \"mostly unsupervised\".",
        "Entity": "Normal"
    },
    {
        "Text": "Five 500-sequence held-out subsets were ob  tained from this corpus, the rest of the data serv  ing as the unsegmented corpus from which to derive character n-gram counts.",
        "Entity": "Normal"
    },
    {
        "Text": "Each held-out subset was hand-segmented and then split into a 50-sequence parameter-training set and a 450-sequence test set.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, any sequences occurring in both a test set and its corresponding parameter-training set were discarded from the parameter-training set, so that these sets were disjoint.",
        "Entity": "Normal"
    },
    {
        "Text": "(Typically no more than five sequences were removed.)",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Held-out set annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "Each held-out set contained 500 randomly-extracted kanji sequences at least ten characters long (about twelve on average), lengthy sequences being the most difficult to segment (Takeda and Fujisaki, 1987).",
        "Entity": "Normal"
    },
    {
        "Text": "To obtain the gold-standard annotations, we segmented the sequences by hand, using an observa  tion of Takeda and Fujisaki (1987) that many kanji compound words consist of two-character stem words together with one-character prefixes and suf  fixes.",
        "Entity": "Normal"
    },
    {
        "Text": "Using this terminology, our two-level bracket  serves as a suffix.",
        "Entity": "Normal"
    },
    {
        "Text": "Loosely speaking, word-level bracketing demarcates discourse entities, whereas morpheme-level brackets enclose strings that cannot be further segmented without loss of meaning.4 For instance, if one segments naga-no in naga-no-shi into naga (long) and no (field), the intended mean  ing disappears.",
        "Entity": "Normal"
    },
    {
        "Text": "Here is an example sequence from our datasets: ['J' f'.X:J [mli'JJ [[iiibJ [J J [ J Three native Japanese speakers participated in the annotation: one segmented all the held-out data based on the above rules, and the other two reviewed 350 sequences in total.",
        "Entity": "Normal"
    },
    {
        "Text": "The percentage of agree  ment with the first person's bracketing was 98.42%: only 62 out of 3927 locations were contested by a verifier.",
        "Entity": "Normal"
    },
    {
        "Text": "Interestingly, all disagreement was at the morpheme level.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Baseline algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated our segmentation method by com  paring its performance against Chasen 1.05 (Mat  sumoto et al., 1997) and Juman 3.61,6 (Kurohashi and Nagao, 1998), two state-of-the-art, publically  available, user-extensible morphological analyzers.",
        "Entity": "Normal"
    },
    {
        "Text": "In both cases, the grammars were used as distributed without modification.",
        "Entity": "Normal"
    },
    {
        "Text": "The sizes of Chasen's and Ju  man's default lexicons are approximately 115,000 and 231,000 words, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Comparison issues An important question that arose in designing our experiments was how to en  able morphological analyzers to make use of the parameter-training data, since they do not have pa  rameters to tune.",
        "Entity": "Normal"
    },
    {
        "Text": "The only significant way that they can be updated is by changing their grammars or lexicons, which is quite tedious (for instance, we had to add part-of-speech information  to new en  tries by hand).",
        "Entity": "Normal"
    },
    {
        "Text": "We took what we felt to be a rea  sonable, but not too time-consuming, course of cre  ating new lexical entries for all the bracketed words in the parameter-training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Evidence that this ing annotation may be summarized as follows.3 At 4This level of segmentation is consistent with Wu's (1998) 3A complete description of the annotation policy, including the treatment of numeric expressions, may be found in a tech  nical report (Ando and Lee, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Monotonicity Principle for segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "The three rightmost groups represent our algorithm with parameters tuned for different optimization criteria.",
        "Entity": "Normal"
    },
    {
        "Text": "was appropriate comes from the fact that these ad  ditions never degraded test set performance, and in  deed improved it by one percent in some cases (only small improvements are to be expected because the parameter-training sets were fairly small).",
        "Entity": "Normal"
    },
    {
        "Text": "It is important to note that in the end, we are com  paring algorithms with access to different sources of knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "Juman and Chasen use lexicons and grammars developed by human experts.",
        "Entity": "Normal"
    },
    {
        "Text": "Our al  gorithm, not having access to such pre-compiled knowledge bases, must of necessity draw on other information sources (in this case, a very large un  segmented corpus and a few pre-segmented exam  ples) to compensate for this lack.",
        "Entity": "Normal"
    },
    {
        "Text": "Since we are in  terested in whether using simple statistics can match the performance of labor-intensive methods, we do not view these information sources as conveying an unfair advantage, especially since the annotated training sets were small, available to the morpho  logical analyzers, and disjoint from the test sets.",
        "Entity": "Normal"
    },
    {
        "Text": "We report the average results over the five test sets using the optimal parameter settings for the corre  sponding training sets (we tried all nonempty sub  sets of {2, 3, 4, 5, 6} for the set of n-gram orders N and all values in {.05, .1, .15, ...\n\t\t\t, 1} for the thresh  old t)7.",
        "Entity": "Normal"
    },
    {
        "Text": "In all performance graphs, the \"error bars\" represent one standard deviation.",
        "Entity": "Normal"
    },
    {
        "Text": "The results for Chasen and Juman reflect the lexicon additions de 7 For simplicity, ties were deterministically broken by pre  ferring smaller sizes of N, shorter n-grams in N, and larger threshold values, in that order.",
        "Entity": "Normal"
    },
    {
        "Text": "scribed in section 3.2.",
        "Entity": "Normal"
    },
    {
        "Text": "Word and morpheme accuracy The standard metrics in word segmentation are word precision and recall.",
        "Entity": "Normal"
    },
    {
        "Text": "Treating a proposed segmentation as a non-nested bracketing (e.g., \"IABICI\" corresponds to the bracketing \"[AB][C]\"), word precision (P) is defined as the percentage of proposed brackets that exactly match word-level brackets in the annotation; word recall (R) is the percentage of word-level an  notation brackets that are proposed by the algorithm in question; and word F combines precision and re  call: F = 2PR/(P + R)..\n\t\t\tOne problem with using word metrics is that morphological analyzers are designed to produce morpheme-level segments.",
        "Entity": "Normal"
    },
    {
        "Text": "To compensate, we al  tered the segmentations produced by Juman and Chasen by concatenating stems and affixes, as iden  tified by the part-of-speech information the analyz  ers provided.",
        "Entity": "Normal"
    },
    {
        "Text": "(We also measured morpheme accu  racy, as described below.)",
        "Entity": "Normal"
    },
    {
        "Text": "Our algorithm achieves 5.27% higher preci  sion and 0.26% better F-measure accuracy than Ju  man, and does even better (8.8% and 4.22%, respec  tively) with respect to Chasen.",
        "Entity": "Normal"
    },
    {
        "Text": "The recall perfor  mance falls (barely) between that of Juman and that of Chasen.",
        "Entity": "Normal"
    },
    {
        "Text": "As noted above, Juman and Chasen were de  signed to produce morpheme-level segmentations.",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore also measured morpheme precision, recall, and F measure, all defined analogously to their word counterparts.",
        "Entity": "Normal"
    },
    {
        "Text": "We see that our algorithm can achieve better recall (by 6.51%) and F-measure (by 1.38%) than Juman, and does better than Chasen by an even wider mar  gin (11.18% and 5.39%, respectively).",
        "Entity": "Normal"
    },
    {
        "Text": "Precision was generally worse than the morphological analyz  ers.",
        "Entity": "Normal"
    },
    {
        "Text": "Compatible Brackets Although word-level accu  racy is a standard performance metric, it is clearly very sensitive to the test annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "Morpheme ac  curacy suffers the same problem.",
        "Entity": "Normal"
    },
    {
        "Text": "Indeed, the au  thors of Juman and Chasen may well have con  structed their standard dictionaries using different notions of word and morpheme than the definitions we used in annotating the data.",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore devel  oped two new, more robust metrics to measure the number of proposed brackets that would be incor [[data][base]][system](annotation brackets) Pr op os ed se g m en tat io n w o r d e rr o r s m o r p h e m e e r r o r s c o m p a t i b l e b r a c k e t e r r o r s cr os sin g m o r p h e m e d i v i d i n g [ d a t a ] [ b a s e ] [ s y s t e m ] [ d a t a ] [ b a s e s y s t e m ] [ d a t a b a s e ] [ s y s ] [ t e r n ] 2 2 2 0 1 3 0 1 0 0 0 2                                                                     \n\t\t\tThe sequence \"data base\" has been annotated as \"[[data][base]]\" because \"data base\" and \"database\" are interchangeable.",
        "Entity": "Normal"
    },
    {
        "Text": "BS , I M o r p h e m e a c c u r a c y CHASEN JUMAN opJrrlze rocal oplmlzo F p r e d l i o n Fi g ur e 5: M or p h e m e ac c ur ac y. segme ntatio ns can be count ed as correc t. W e also use the all comp atibl e brac kets rate, whic h is the fracti on of seque nces for whic h all the prop osed brack ets are comp atible .",
        "Entity": "Normal"
    },
    {
        "Text": "Intuit ively, this funct ion meas ures the ease with whic h a huma n could corre ct the outpu t of the segm entati on algo  rithm : if the all comp atible brack ets rate is high, then the error s are conc entrat ed in relati vely few seque nces; if it is low, then a huma n doing post  proce ssing woul d have to corre ct many sequ ences .",
        "Entity": "Normal"
    },
    {
        "Text": "Our algor ithm does bet  ter on both metri cs (for insta nce, when F meas ure is opti mize d, by 2.16 % and 1.9% , respe ctivel y, in rect with respect to any reasonable annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "Our novel metrics account for two types of er  rors.",
        "Entity": "Normal"
    },
    {
        "Text": "The first, a crossing bracket, is a proposed bracket that overlaps but is not contained within an annotation bracket (Grishman et al., 1992).",
        "Entity": "Normal"
    },
    {
        "Text": "Cross  ing brackets cannot coexist with annotation brack  ets, and it is unlikely that another human would create such brackets.",
        "Entity": "Normal"
    },
    {
        "Text": "The second type of er  ror, a morpheme-dividing bracket, subdivides a morpheme-level annotation bracket; by definition, such a bracket results in a loss of meaning.",
        "Entity": "Normal"
    },
    {
        "Text": "We define a compatible bracket as a proposed bracket that is neither crossing nor morpheme  dividing.",
        "Entity": "Normal"
    },
    {
        "Text": "The compatible brackets rate is simply the compatible brackets precision.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that this met  ric accounts for different levels of segmentation si  multaneously, which is beneficial because the gran  ularity of Chasen and Juman's segmentation varies from morpheme level to compound word level (by our definition).",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, well-known university names are treated as single segments by virtue of be  ing in the default lexicon, whereas other university names are divided into the name and the word \"uni  versity\".",
        "Entity": "Normal"
    },
    {
        "Text": "Using the compatible brackets rate, both comparison to Chasen, and by 3.15% and 4.96%, respectively, in comparison to Juman), regardless of training optimization function (word precision, re  call, or F -we cannot directly optimize the com  patible brackets rate because \"perfect\" performance is possible simply by making the entire sequence a single segment).",
        "Entity": "Normal"
    },
    {
        "Text": "Compatible and all-compatible bracket.s rates CHASEN JUIAAH cpWnizo Pf\"\"\"\"\" O!",
        "Entity": "Normal"
    },
    {
        "Text": ")lllnllt riCIII CJI'IINZ!",
        "Entity": "Normal"
    },
    {
        "Text": "F l!!",
        "Entity": "Normal"
    },
    {
        "Text": "conpaliblebroclr!",
        "Entity": "Normal"
    },
    {
        "Text": "!Urtlos _brad<JIUIIU                                                                                                \n\t\t\tJuman5 vs. Juman50 Our50 vs Juman50 Our5 vs. Juman5 Our5 vs. Juman50 precision recall F-measure -1.040.630.84 +5.274.39 +0.26 +6.183.73 +1.14 +5.144.36 +0.30                                                                     \n\t\t\t\"5\" and \"50\" denote training set size before discarding overlaps with the test sets.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "Minimal human effort is needed.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast to our mostly-unsupervised method, morphological analyzers need a lexicon and grammar rules built using human expertise.",
        "Entity": "Normal"
    },
    {
        "Text": "The workload in creating dictionaries on the order of hundreds of thousands of words (the size of Chasen's and Juman's de  fault lexicons) is clearly much larger than annotat  ing the small parameter-training sets for our algo  rithm.",
        "Entity": "Normal"
    },
    {
        "Text": "We also avoid the need to segment a large amount of parameter-training data because our al  gorithm draws almost all its information from an unsegmented corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Indeed, the only human effort involved in our algorithm is pre-segmenting the five 50-sequence parameter training sets, which took only 42 minutes.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, previously proposed supervised approaches have used segmented train  ing sets ranging from 10005000 sentences (Kash  ioka et al., 1998) to 190,000 sentences (Nagata, l996a).",
        "Entity": "Normal"
    },
    {
        "Text": "To test how much annotated training data is actu  ally necessary, we experimented with using minis  cule parameter-training sets: five sets of only five strings each (from which any sequences repeated in the test data were discarded).",
        "Entity": "Normal"
    },
    {
        "Text": "It took only 4 minutes to perform the hand segmentation in this case.",
        "Entity": "Normal"
    },
    {
        "Text": "Both the local maximum and threshold condi  tions contribute.",
        "Entity": "Normal"
    },
    {
        "Text": "In our algorithm, a location k is deemed a word boundary if vN (k) is either (1) a local maximum or (2) at least as big as the thresh  old t. It is natural to ask whether we really need two conditions, or whether just one would suffice.",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore studied whether optimal perfor  mance could be achieved using only one of the con  ditions.",
        "Entity": "Normal"
    },
    {
        "Text": "Indeed, in some cases, both are needed to achieve the best perfor  mance; also, each condition when used in isolation yields suboptimal performance with respect to some performance metrics.",
        "Entity": "Normal"
    },
    {
        "Text": "a c c ur a c y o p ti m i z e p r e c i s i o n o p t i m i z e r e c a l l o p ti m iz eF m ea su re w or d M M & T M m or p h e m e M & T T T                                                                                                                                             \n\t\n\t\n\t\t\tJapanese Many previously proposed segmenta  tion methods for Japanese text make use of either a pre existing lexicon (Yamron et al., 1993; Mat  sumoto and Nagao, 1994; Takeuchi and Matsumoto, 1995; Nagata, 1997; Fuchi and Takagi, 1998) or pre-segmented training data (Nagata, 1994; Papa georgiou, 1994; Nagata, 1996a; Kashioka et al., 1998; Mori and Nagao, 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "Other approaches bootstrap from an initial segmentation provided by a baseline algorithm such as Juman (Matsukawa et al., 1993; Yamamoto, 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "Unsupervised, non-lexicon-based methods for Japanese segmentation do exist, but they often have limited applicability.",
        "Entity": "Normal"
    },
    {
        "Text": "Both Tomokiyo and Ries (1997) and Teller and Batchelder (1994) explicitly avoid working with kanji charactes.",
        "Entity": "Normal"
    },
    {
        "Text": "Takeda and Fujisaki (1987) propose the short unit model, a type of Hidden Markov Model with linguistically  determined topology, to segment kanji compound words.",
        "Entity": "Normal"
    },
    {
        "Text": "However, their method does not handle three-character stem words or single-character stem words with affixes, both of which often occur in proper nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "In our five test datasets, we found that 13.56% of the kanji sequences contain words that cannot be handled by the short unit model.Nagao and Mori (1994) propose using the heuris tic that high-frequency character n-grams may rep  resent (portions of) new collocations and terms, but the results are not experimentally evaluated, nor is a general segmentation algorithm proposed.",
        "Entity": "Normal"
    },
    {
        "Text": "The work of Ito and Kohda (1995) similarly relies on high-frequency character n-grams, but again, is more concerned with using these frequent n-grams as pseudo-lexicon entries; a standard segmentation algorithm is then used on the basis of the induced lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "Our algorithm, on the hand, is fundamen  tally different in that it incorporates no explicit no  tion of word, but only \"sees\" locations between characters.",
        "Entity": "Normal"
    },
    {
        "Text": "Chinese According to Sproat et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996), most prior work in Chinese segmentation has exploited lexical knowledge bases; indeed, the authors assert that they were aware of only one previously pub  lished instance (the mutual-information method of Sproat and Shih (1990)) of a purely statistical ap  proach.",
        "Entity": "Normal"
    },
    {
        "Text": "In a later paper, Palmer (1997) presents a transformation-based algorithm, which requires pre-segmented training data.",
        "Entity": "Normal"
    },
    {
        "Text": "To our knowledge, the Chinese segmenter most similar to ours is that of Sun et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998).",
        "Entity": "Normal"
    },
    {
        "Text": "They also avoid using a lexicon, determining whether a given location constitutes a word boundary in part by deciding whether the two characters on either side tend to occur together; also, they use thresholds and several types of local minima and maxima to make segmentation decisions.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the statis  tics they use (mutual information and t-score) are more complex than the simple n-gram counts that we employ.",
        "Entity": "Normal"
    },
    {
        "Text": "Our preliminary reimplementation of their method shows that it does not perform as well as the morphological analyzers on our datasets, al  though we do not want to draw definite conclusions because some aspects of Sun et al's method seem incomparable to ours.",
        "Entity": "Normal"
    },
    {
        "Text": "We do note, however, that their method incorporates numerical differences between statistics, whereas we only use indicator functions; for example, once we know that one trigram is more common than another, we do not take into account the difference between the two frequencies.",
        "Entity": "Normal"
    },
    {
        "Text": "We conjecture that using absolute differences may have an adverse effect on rare sequences.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we have presented a simple, mostly unsupervised algorithm that segments Japanese se quences into words based on statistics drawn from a large unsegmented corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated per  formance on kanji with respect to several metrics, including the novel compatible brackets and all  compatible brackets rates, and found that our al  gorithm could yield performances rivaling that of lexicon-based morphological analyzers.",
        "Entity": "Normal"
    },
    {
        "Text": "In future work, we plan to experiment on Japanese sentences with mixtures of character types, possibly in combination with morphologi  cal analyzers in order to balance the strengths and weaknesses of the two types of methods.",
        "Entity": "Normal"
    },
    {
        "Text": "Since our method does not use any Japanese-dependent heuristics, we also hope to test it on Chinese or other languages as well.",
        "Entity": "Normal"
    },
    {
        "Text": "We thank Minoru Shindoh and Takashi Ando for reviewing the annotations, and the anonymous re  viewers for their comments.",
        "Entity": "Normal"
    },
    {
        "Text": "This material was sup  ported in part by a grant from the GE Foundation.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tMost previous research on verb clustering has focussed on acquiring flat classifications from corpus data, although many manually built classifications are taxonomic in nature.",
        "Entity": "Normal"
    },
    {
        "Text": "Also Natural Language Processing (NLP) applications benefit from taxonomic classifications because they vary in terms of the granularity they require from a classification.",
        "Entity": "Normal"
    },
    {
        "Text": "We introduce a new clustering method called Hierarchical Graph Factorization Clustering (HGFC) and extend it so that it is optimal for the task.",
        "Entity": "Normal"
    },
    {
        "Text": "Our results show that HGFC outperforms the frequently used agglomerative clustering on a hierarchical test set extracted from VerbNet, and that it yields state-of-the-art performance also on a flat test set.",
        "Entity": "Normal"
    },
    {
        "Text": "We demonstrate how the method can be used to acquire novel classifications as well as to extend existing ones on the basis of some prior knowledge about the classification.",
        "Entity": "Normal"
    },
    {
        "Text": "A variety of verb classifications have been built to support NLP tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "These include syntactic and semantic classifications, as well as ones which integrate aspects of both (Grishman et al., 1994; Miller, 1995; Baker et al., 1998; Palmer et al., 2005; Kipper, 2005; Hovy et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "Classifications which integrate a wide range of linguistic properties can be particularly useful for tasks suffering from data sparseness.",
        "Entity": "Normal"
    },
    {
        "Text": "One such classification is the taxonomy of English verbs proposed by Levin (1993) which is based on shared (morpho-)syntactic 1023 and semantic properties of verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "Levin s taxonomy or its extended version in VerbNet (Kipper, 2005) has proved helpful for various NLP application tasks, including e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "parsing, word sense disambiguation, semantic role labeling, information extraction, question-answering, and machine translation (Swier and Stevenson, 2004; Dang, 2004; Shi and Mihalcea, 2005; Zapirain et al., 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "Because verbs change their meaning and be- haviour across domains, it is important to be able to tune existing classifications as well to build novel ones in a cost-effective manner, when required.",
        "Entity": "Normal"
    },
    {
        "Text": "In recent years, a variety of approaches have been proposed for automatic induction of Levin style classes from corpus data which could be used for this purpose (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O  Se aghdha and Copestake, 2008; Vlachos et al., 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "The best of such approaches have yielded promising results.",
        "Entity": "Normal"
    },
    {
        "Text": "However, they have mostly focussed on acquiring and evaluating flat classifications.",
        "Entity": "Normal"
    },
    {
        "Text": "Levin s classification is not flat, but taxonomic in nature, which is practical for NLP purposes since applications differ in terms of the granularity they require from a classification.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we experiment with hierarchical Levin-style clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "We adopt as our baseline method a well-known hierarchical method   agglomerative clustering (AGG)   which has been previously used to acquire flat Levin-style classifications (Stevenson and Joanis, 2003) as well as hierarchical verb classifications not based on Levin (Fer- rer, 2004; Schulte im Walde, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "The method has also been popular in the related task of noun clus Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1023 1033, Edinburgh, Scotland, UK, July 27 31, 2011.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2011 Association for Computational Linguistics tering (Ushioda, 1996; Matsuo et al., 2006; Bassiou and Kotropoulos, 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "We introduce then a new method called Hierarchical Graph Factorization Clustering (HGFC) (Yu et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "This graph-based, probabilistic clustering algorithm has some clear advantages over AGG (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "it delays the decision on a verb s cluster membership at any level until a full graph is available, minimising the problem of error propagation) and it has been shown to perform better than several other hierarchical clustering methods in recent comparisons (Yu et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "The method has been applied to the identification of social network communities (Lin et al., 2008), but has not been used (to the best of our knowledge) in NLP before.",
        "Entity": "Normal"
    },
    {
        "Text": "We modify HGFC with a new tree extraction algorithm which ensures a more consistent result, and we propose two novel extensions to it.",
        "Entity": "Normal"
    },
    {
        "Text": "The first is a method for automatically determining the tree structure (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "number of clusters to be produced for each level of the hierarchy).",
        "Entity": "Normal"
    },
    {
        "Text": "This avoids the need to predetermine the number of clusters manually.",
        "Entity": "Normal"
    },
    {
        "Text": "The second is addition of soft constraints to guide the clustering performance (Vlachos et al., 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "This is useful for situations where a partial (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "a flat) verb classification is available and the goal is to extend it.",
        "Entity": "Normal"
    },
    {
        "Text": "Adopting a set of lexical and syntactic features which have performed well in previous works, we compare the performance of the two methods on test sets extracted from Levin and VerbNet.",
        "Entity": "Normal"
    },
    {
        "Text": "When evaluated on a flat clustering task, HGFC outperforms AGG and performs very similarly with the best flat clustering method reported on the same test set (Sun and Korhonen, 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "When evaluated on a hierarchical task, HGFC performs considerably better than AGG at all levels of gold standard classification.",
        "Entity": "Normal"
    },
    {
        "Text": "The constrained version of HGFC performs the best, as expected, demonstrating the usefulness of soft constraints for extending partial classifications.",
        "Entity": "Normal"
    },
    {
        "Text": "Our qualitative analysis shows that HGFC is capable of detecting novel information not included in our gold standards.",
        "Entity": "Normal"
    },
    {
        "Text": "The unconstrained version can be used to acquire novel classifications from scratch while the constrained version can be used to extend existing ones with additional class members, classes and levels of hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "The taxonomy of Levin (1993) groups English verbs (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "break, fracture, rip) into classes (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "45.1 Break verbs) on the basis of their shared meaning components and (morpho-)syntactic behaviour, defined in terms of diathesis alternations (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the causative/inchoative alternation, where an NP frame alternates with an intransitive frame: Tony broke the window   The window broke).",
        "Entity": "Normal"
    },
    {
        "Text": "It classifies over 3000 verbs in 57 top level classes, some of which divide further into subclasses.",
        "Entity": "Normal"
    },
    {
        "Text": "The extended version of the taxonomy in VerbNet (Kipper, 2005) classifies 5757 verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "Its 5 level taxonomy includes 101 top level and 369 subclasses.",
        "Entity": "Normal"
    },
    {
        "Text": "We used three gold standards (and corresponding test sets) extracted from these resources in our experiments: T1: The first gold standard is a flat gold standard which includes 13 classes appearing in Levin s original taxonomy (Stevenson and Joanis, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "We included this small gold standard in our experiments so that we could compare the flat version of our method against previously published methods.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Stevenson and Joanis (2003), we selected 20 verbs from each class which occur at least 100 times in our corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "This gave us 260 verbs in total.",
        "Entity": "Normal"
    },
    {
        "Text": "T2: The second gold standard is a large, hierarchical gold standard which we extracted from VerbNet as follows: 1) We removed all the verbs that have less than 1000 occurrences in our corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "2) In order to minimise the problem of pol- ysemy, we assigned each verb to the class which, according to VerbNet, corresponds to its predominant sense in WordNet (Miller, 1995).",
        "Entity": "Normal"
    },
    {
        "Text": "3) In order to minimise the sparse data problem with very fine- grained classes, we converted the resulting classification into a 3-level representation so that the classes at the 4th and 5th level were combined.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the sub-classes of Declare verbs (numbered as 29.4.1.1.",
        "Entity": "Normal"
    },
    {
        "Text": "{1,2,3}) were combined into 29.4.1.",
        "Entity": "Normal"
    },
    {
        "Text": "4) Theclasses that have fewer than 5 members were dis carded.",
        "Entity": "Normal"
    },
    {
        "Text": "The total number of verb senses in the resulting gold standard is 1750, which is 33.2% of the verbs in VerbNet.",
        "Entity": "Normal"
    },
    {
        "Text": "T2 has 51 top level, 117 second level, and 133 third level classes.",
        "Entity": "Normal"
    },
    {
        "Text": "T3: The third gold standard is a subset of T2 where singular classes (top level classes which do not divide into subclasses) are removed.",
        "Entity": "Normal"
    },
    {
        "Text": "This gold standard was constructed to enable proper evaluation of the constrained version of HGFC (introduced in the following section) where we want to compare the impact of constraints across several levels of classification.",
        "Entity": "Normal"
    },
    {
        "Text": "T3 provides classification of 357 verbs into 11 top level, 14 second level, and 32 third level classes.",
        "Entity": "Normal"
    },
    {
        "Text": "For each verb appearing in T1T3, we extracted all the occurrences (up to 10,000) from the British National Corpus (Leech, 1992) and North American News Text Corpus (Graff, 1995).",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Features and feature extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous works on Levin style verb classification have investigated optimal features for this task (Stevenson and Joanis, 2003; Li and Brew, 2008; Sun and Korhonen, 2009)).",
        "Entity": "Normal"
    },
    {
        "Text": "We adopt for our experiments a set of features which have performed well in recent verb clustering works: A: Subcategorization frames (SCFs) and their relative frequencies with individual verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "B: A with SCFs parameterized for prepositions.",
        "Entity": "Normal"
    },
    {
        "Text": "C: B with SCFs parameterized for subjects appearing in grammatical relations associated with the verb in parsed data.",
        "Entity": "Normal"
    },
    {
        "Text": "D: B with SCFs parameterized for objects appearing in grammatical relations associated with the verb in parsed data.",
        "Entity": "Normal"
    },
    {
        "Text": "These features are purely syntactic.",
        "Entity": "Normal"
    },
    {
        "Text": "Although semantic features   verb selectional preferences   proved the best (when used in combination with syntactic features) in the recent work of Sun and Korhonen (2009), we left such features for future work because we noticed that different levels of classification are likely to require semantic features at different granularities.",
        "Entity": "Normal"
    },
    {
        "Text": "We extracted the syntactic features using the system of Preiss et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007).",
        "Entity": "Normal"
    },
    {
        "Text": "The system tags, lemma- tizes and parses corpus data using the RASP (Robust Accurate Statistical Parsing toolkit (Briscoe et al., 2006)), and on the basis of the resulting grammatical relations, assigns each occurrence of a verb as a member of one of the 168 verbal SCFs.",
        "Entity": "Normal"
    },
    {
        "Text": "We pa- rameterized the SCFs as described above using the information provided by the system.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "We introduce the agglomerative clustering (AGG) and Hierarchical Graph Factorization Clustering (HGFC) methods in the following two subsections, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "The subsequent two subsections present our extensions to HGFC: (i) automatically determining the cluster structure and (ii) adding soft constraints to guide clustering performance.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2.1 Agglomerative clustering AGG is a method which treats each verb as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one.",
        "Entity": "Normal"
    },
    {
        "Text": "We used the SciPy s implementation (Oliphant, 2007) of the algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The cluster distance is measured using linkage criteria.",
        "Entity": "Normal"
    },
    {
        "Text": "We experimented with four commonly used linkage criteria: Single, Average, Complete and Ward s (Ward Jr., 1963).",
        "Entity": "Normal"
    },
    {
        "Text": "Ward s criterion performed the best and was used in all the experiments in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "It measures the increase in variance after two clusters are merged.",
        "Entity": "Normal"
    },
    {
        "Text": "The output of AGG tends to have excessive number of levels.",
        "Entity": "Normal"
    },
    {
        "Text": "Cut-based methods (Wu and Leahy, 1993; Shi and Malik, 2000) are frequently applied to extract a simplified view.",
        "Entity": "Normal"
    },
    {
        "Text": "We followed previous verb clustering works and cut the AGG hierarchy manually.",
        "Entity": "Normal"
    },
    {
        "Text": "AGG suffers from two problems.",
        "Entity": "Normal"
    },
    {
        "Text": "The first is error propagation.",
        "Entity": "Normal"
    },
    {
        "Text": "When a verb is misclassified at a lower level, the error propagates to all the upper levels.",
        "Entity": "Normal"
    },
    {
        "Text": "The second is local pairwise merging, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "the fact that only two clusters can be combined at any level.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in order to group clusters representing Levin classes 9.1, 9.2 and 9.3 into a single cluster representing class 9, the method has to produce intermediate clusters, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "9.",
        "Entity": "Normal"
    },
    {
        "Text": "{1,2} and 9.3.Such clusters do not always have a semantic inter pretation.",
        "Entity": "Normal"
    },
    {
        "Text": "Although they can be removed using a cut-based method, this requires a predefined cutoff value which is difficult to set (Stevenson and Joanis, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, a significant amount of information is lost in pairwise clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "In the above example, only the clusters 9.",
        "Entity": "Normal"
    },
    {
        "Text": "{1,2} and 9.3 are consid ered, while alternative clusters 9.",
        "Entity": "Normal"
    },
    {
        "Text": "{1,3} and 9.2 are ignored.",
        "Entity": "Normal"
    },
    {
        "Text": "Ideally, information about all the possible intermediate clusters should be aggregated, but this is intractable in practice.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2.2 Hierarchical Graph Factorization We use the divergence distance:   (X, Y ) = xij Clustering ij (xij log yij  xij + yij ).",
        "Entity": "Normal"
    },
    {
        "Text": "Yu et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) showed Our new method HGFC derives a probabilistic bipartite graph from the similarity matrix (Yu et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "The local and global clustering structures are that this cost function is non-increasing under the update rule: wi j learned via the random walk properties of the graph.The method does not suffer from the above prob h ip   hip j (H  H T )ij  p hjp s.t.",
        "Entity": "Normal"
    },
    {
        "Text": "h ip = 1 (2) i lems with AGG.",
        "Entity": "Normal"
    },
    {
        "Text": "Firstly, there is no error propagation   p    p wij (H  H T )ij hip hjp s.t.",
        "Entity": "Normal"
    },
    {
        "Text": "p = wij (3) because the decision on a verb s membership at any j p ij level is delayed until the full bipartite graph is available and until a tree structure can be extracted from it by aggregating probabilistic information from all the levels.",
        "Entity": "Normal"
    },
    {
        "Text": "Secondly, the bipartite graph enables the wij can be interpreted as the probability of the direct transition between vi and vj : wij = p(vi, vj ), when L;ij wij = 1.\n\t\t\tbip can be interpreted as: construction of a hierarchical structure without any intermediate classes.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, we can group classes 9.",
        "Entity": "Normal"
    },
    {
        "Text": "{1,2,3} directly into class 9.",
        "Entity": "Normal"
    },
    {
        "Text": "We use HGFC with the distributional similarity bip biq di pq m (4) measure JensenShannon Divergence (djs(v, v )).",
        "Entity": "Normal"
    },
    {
        "Text": "D = diag(d1 , ..., dn ) where di = bip Given a set of verbs, V = {vn}N , we p=0 compute a similarity matrix W where Wij =exp( djs(v1, v2)).",
        "Entity": "Normal"
    },
    {
        "Text": "The graph G and the cluster structure can be represented by a bipartite graph K (V, U ).",
        "Entity": "Normal"
    },
    {
        "Text": "V are the p(up, uq ) is the similarity between the clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "It takes into account of a weighted average of contributions from all the data.",
        "Entity": "Normal"
    },
    {
        "Text": "This is different from the linkage method where only the data from two clusters are considered.Given the cluster similarity p(up, uq ), we can con vertices on G.                                                                                                      \n\t\t\tThe cluster algorithm can be applied clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "The matrix B denotes the n   m adjacency matrix, with bip being the connection weight between the vertex vi and the cluster up.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, B represents the connections between clusters at an upper and lower level of clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "A flat clustering algorithm can be induced by computing B.",
        "Entity": "Normal"
    },
    {
        "Text": "This process can go on itera tively, leading to a hierarchical graph.",
        "Entity": "Normal"
    },
    {
        "Text": "Algorithm 1 HGFC algorithm (Yu et al., 2006) Require: N verbs V , number of clusters ml for L levels Compute the similarity matrix W0 from V Build the graph G0 from W0 , and m0   n for l = 1, 2 to L do Factorize Gl 1 to obtain bipartite graph Kl with the (W ) between vi and vj : w L;m p=1 bip bjp  p adjacency matrix Bl (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "1, 2 and 3) Build a graph Gl with similarity matrix Wl =(B  1BT )ij where   = diag( 1, ...,  m).",
        "Entity": "Normal"
    },
    {
        "Text": "There fore, B can be found by approximating the similarity matrix W of G using W derived from K .",
        "Entity": "Normal"
    },
    {
        "Text": "Given a distance function   between two similarity matrices, B approximates W by minimizing the cost function   (W, B  1BT ).",
        "Entity": "Normal"
    },
    {
        "Text": "Yu et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) performs the extraction via a propagation of probabilities from the bottom level clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "For a verb vi, the probability of assigning it to cluster v(l) at level l is given by: v 1 u 1 2 v v v v 1 2 1 2 1 v v v v v 3 7 3 7 4 v v u v 8 v 8 5 2 9 9 v 1 v 2 u 1 v u u 3 q 1 2 v 1 4 u 5 2 v 2 6 6 6 v 3 6 v v 5 v 5 7 4 7 4 u 3 u 2 v 3 v 3 8 8 v v 9 9 (a) (b) (c) (d) (e)                                                                                                                                                                                                                                                        \n\t\t\tV1 p(v(l) |v (l 1) )...p(v (1) |vi ) 3.2.3 Aut oma tical ly dete rmin ing the num ber of clust ers for HG FC HGFC needs the number of levels and clusters at = (D( 1)  1  1 2 B2 D3 B3 ...Dl Bl )ip (5) This method might not extract a consistent tree structure, because the cluster membership at the lower level does not constrain the upper level membership.",
        "Entity": "Normal"
    },
    {
        "Text": "This prevented us from extracting a Levin style hierarchical classification in our initial experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, where two verbs were grouped together at a lower level, they could belong to separate clusters at an upper level.",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore propose a new tree extraction algorithm (Algorithm 2).",
        "Entity": "Normal"
    },
    {
        "Text": "The new algorithm starts from the top level bipartite graph, and generates consistent labels for each level by taking into account of the tree constraints set at upper levels.",
        "Entity": "Normal"
    },
    {
        "Text": "each level as input.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this information is not always available (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "when the goal is to actually learn this information automatically).",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore propose a method for inferring the cluster structure from data.",
        "Entity": "Normal"
    },
    {
        "Text": "A walker can also go to other vertices via multi-hop transitions.",
        "Entity": "Normal"
    },
    {
        "Text": "According to the chain rule of the Markov process, the multi-hop transitions indicate a decaying similarity function on the graph (Yu et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "After t transitions, the similarity matrix (Wt) becomes: Wt = Wt 1 D0 W0Yu et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) proved the correspondence be tween the HGFC levels (l) and the random walk time: A lgorithm 2 Tree extraction algorithm for HGFC Require: Given N , (Bl , ml ) on each level for L levels On the top level L, collect the labels T L (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "5) Define C to be a (mL 1   mL ) zero matrix, Cij   1, where i, j = arg maxi,j {BL } t = 2l 1.",
        "Entity": "Normal"
    },
    {
        "Text": "So the vertices at level l induce a similarity matrix of verbs after t-hop transitions.",
        "Entity": "Normal"
    },
    {
        "Text": "The decaying similarity function captures the different scales of clustering structure in the data (Azran and Ghahramani, 2006b).",
        "Entity": "Normal"
    },
    {
        "Text": "The upper levels would have for l = L   1 to 1 do i = 1 to N do a smalle r numb er of cluster s which repres ent a more for Compute p(vl |vi ) for each cluster p (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "5) global structure.",
        "Entity": "Normal"
    },
    {
        "Text": "After several levels, all the verbs l l are expected to be grouped into one cluster.",
        "Entity": "Normal"
    },
    {
        "Text": "The ti = argmaxp {p(vp |vi )|p = 1...ml , Cptl+1 = 0} end for Redefine C to be a (ml 1   ml ) zero matrix, Cij   1, where i, j = arg maxi,j {Bl } number of levels and clusters at each level can thus be learned automatically.We therefore propose a method that uses the de end for return Tree consistent labels T L , T L 1 ...T 1 caying similarity function to learn the hierarchical clustering structure.",
        "Entity": "Normal"
    },
    {
        "Text": "One simple modification to algorithm 1 is to set the number of clusters at level l (ml ) to be ml 1   1.\n\t\t\tm is denoted as the number of clusters that have at least one member according to eq.",
        "Entity": "Normal"
    },
    {
        "Text": "5.",
        "Entity": "Normal"
    },
    {
        "Text": "We start by treating each verb as a cluster at the bottom level.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm stops when all the data points are merged into one cluster.",
        "Entity": "Normal"
    },
    {
        "Text": "The increasingly decaying similarity causes many clusters to have 0 members especially at lower levels, which are pruned in the tree extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2.4 Adding constraints to HGFCThe basic version of HGFC makes no prior as where nij is the size of the intersection between class i and cluster j.",
        "Entity": "Normal"
    },
    {
        "Text": "We used normalized mutual information (NMI) and F-Score (F) to evaluate hierarchical clustering results on T2 and T3.",
        "Entity": "Normal"
    },
    {
        "Text": "NMI measures the amount of statistical information shared by two random variables representing the clustering result and the gold- standard labels.",
        "Entity": "Normal"
    },
    {
        "Text": "Given random variables A and B: NMI(A, B) = I (A; B) [H (A) + H (B)]/2 sumptions about the classification.",
        "Entity": "Normal"
    },
    {
        "Text": "It is useful I(A, B) = |(vk   cj | log N |vk   cj | for learning novel verb classifications from scratch.",
        "Entity": "Normal"
    },
    {
        "Text": "However, when wishing to extend an existing classification (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "VerbNet) it may be desirable to guide the clustering performance on the basis of information that is already known.",
        "Entity": "Normal"
    },
    {
        "Text": "We propose a constrained version of HGFC which makes uses of labels at the bottom level to learn upper level classifications.",
        "Entity": "Normal"
    },
    {
        "Text": "We do this by adding soft constraints to clustering, following Vlachos et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2009).",
        "Entity": "Normal"
    },
    {
        "Text": "We modify the similarity matrix W as follows: If two verbs have different labels (li = lj ), the similarity between them is decreased by a factor a, and a < 1.",
        "Entity": "Normal"
    },
    {
        "Text": "We set a to 0.5 in the experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "The re k j N |vk ||cj | where |vk   cj | is the number of shared membership between cluster vk and gold-standard class cj .",
        "Entity": "Normal"
    },
    {
        "Text": "The normalized variant of mutual information (MI) enables the comparison of clustering with different cluster numbers (Manning et al., 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "F is the harmonic mean of precision (P) and recall (R).",
        "Entity": "Normal"
    },
    {
        "Text": "P is calculated using modified purity   a global measure which evaluates the mean precision of clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "Each cluster is associated with its prevalent class.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of verbs in a cluster K that take this class is denoted by nprevalent(K).",
        "Entity": "Normal"
    },
    {
        "Text": "sulting tree is generally consistent with the original L; nprevalent(ki )>2 nprevalent(ki ) classification.",
        "Entity": "Normal"
    },
    {
        "Text": "The influence of the underlying data mPUR = number of verbs (domain or features) is reduced according to a.",
        "Entity": "Normal"
    },
    {
        "Text": "We applied the clustering methods introduced in section 3 to the test sets described in section 2 and evaluated them both quantitatively and qualitatively, as described in the subsequent sections.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Evaluation methods.",
        "Entity": "Normal"
    },
    {
        "Text": "We used class based accuracy (ACC) and adjusted rand index (Radj ) to evaluate the results on the flat test set T1 (see section 2 for details of T1T3).",
        "Entity": "Normal"
    },
    {
        "Text": "ACC is the proportion of members of dominant clusters DOMCLUSTi within all classes ci.",
        "Entity": "Normal"
    },
    {
        "Text": "ACC = i=1 verbs in DOMCLUSTi number of verbs The formula of Radj is (Hubert and Arabie, 1985): R is calculated using ACC.",
        "Entity": "Normal"
    },
    {
        "Text": "F = 2   mPUR   ACC mPUR + ACC F is not suitable for comparing results with different cluster numbers (Rosenberg and Hirschberg, 2007).",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we only report NMI when the number of classes in clustering and gold-standard is substantially different.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we supplemented quantitative evaluation with qualitative evaluation of clusters produced by different methods.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Quantitative evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "We first evaluated AGG and the basic (unconstrained) HGFC on the small flat test set T1.",
        "Entity": "Normal"
    },
    {
        "Text": "The main purpose of this evaluation was to compare the results of our methods against previously published results on the same test set.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of clus L; (nij   L; (ni  L; (n j /(n ters (K ) and levels (L) were inferred automatically Radj = i,j 2 i 2 j 2 2 2 [L;i ( 2 + L;j ( 2 ]   L;i ( 2 L;j ( 2 /(2 for HGFC as described in section 3.2.3.",
        "Entity": "Normal"
    },
    {
        "Text": "However, to 1 ni  n j ni  n j n make the results comparable with previously published ones, we cut the resulting hierarchy at the level of closest match (12 clusters) to the K (13) in the gold-standard.",
        "Entity": "Normal"
    },
    {
        "Text": "For AGG, we cut the hierarchy at 13 clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "In this experiment, we used the same feature set as Stevenson and Joanis (2003) (set B, see section 3.1) and were therefore able to reproduce their AGG result with a difference smaller than 2%.",
        "Entity": "Normal"
    },
    {
        "Text": "When using this simple feature set, HGFC outperforms the best performing AGG clearly: 8.5% in ACC and 7.3% in Radj .",
        "Entity": "Normal"
    },
    {
        "Text": "We also compared HGFC against the best reported clustering method on T1 to date   that of spectral clustering by Sun and Korhonen (2009).",
        "Entity": "Normal"
    },
    {
        "Text": "We used the feature sets C and D which are similar to the features (SCF parameterized by lexical prefences) in their experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "HGFC obtains F of 49.93% on T1 which is 5% lower than the result of Sun and Korhonen (2009).",
        "Entity": "Normal"
    },
    {
        "Text": "The difference comes from the tree consistency requirement.",
        "Entity": "Normal"
    },
    {
        "Text": "When the HGFC is forced to produce a flat clustering (a one level tree only), it achieves the F of 52.55% which is very close to the performance of spectral clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "We then evaluated our methods on the hierarchical test sets T2 and T3.",
        "Entity": "Normal"
    },
    {
        "Text": "In the first set of experiments, we predefined the tree structure for HGFC by setting L to 3 and K at each level to be the K in the hierarchical gold standard.",
        "Entity": "Normal"
    },
    {
        "Text": "The hierarchy produced by AGG was cut into 3 levels according to K s in the gold standard.",
        "Entity": "Normal"
    },
    {
        "Text": "This enabled direct evaluation of the results against the 3 level gold standards using both NMI and F. The results are reported in               .",
        "Entity": "Normal"
    },
    {
        "Text": "In these tables, Nc is the number of clusters in HGFC clustering while Nl is the number of classes in the gold standard (the two do not always correspond perfectly because a few clusters have zero members).",
        "Entity": "Normal"
    },
    {
        "Text": "As with T1, HGFC outperforms AGG clearly.",
        "Entity": "Normal"
    },
    {
        "Text": "The benefit can now be seen at 3 different levels of hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "On average, the HGFC outperforms AGG 3.5% in NMI and 4.8% in F. The difference between the methods becomes clearer when moving towards the upper levels of the hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "The results are generally generally better on this test set than on T2   which is to be expected since T3 is a refined subset of T21.",
        "Entity": "Normal"
    },
    {
        "Text": "Recall that the constrained version of HGFC learns the upper levels of classification on the basis of soft constraints set at the bottom level, as described earlier in section 3.2.4.",
        "Entity": "Normal"
    },
    {
        "Text": "As a consequence, NMI and F are both greater than 90% at the bottom level and the results at the top level are notably lower because the impact of the constraints degrades the further away one moves from the bottom level.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet, the relatively high result across all levels shows that the constrained version of HGFC can be employed a useful method to extend the hierarchical structure of known classifications.",
        "Entity": "Normal"
    },
    {
        "Text": "1 NMI is higher on T2, however, because NMI has a higher baseline for larger number of clusters (Vinh et al., 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "NMI is not ideal for comparing the results of T2 and T3.",
        "Entity": "Normal"
    },
    {
        "Text": "T 2 T 3 Nc Nl H GF C Nc Nl H GF C 14 8 13 3 53 .2 6 64 32 54 .9 1 97 11 7 49 .8 5 35 32 50 .8 3 46 51 33 .5 5 20 14 44 .0 2 19 51 25 .8 0 10 14 34 .4 1 9 51 19 .1 7 6 11 32 .2 7 3 51 13 .0 6                                                                                        \n\t\t\t                                                                                                                                                                                  \n\t\t\t6 levels are learned for T2 and 5 for T3.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of clusters produced ranges from 3 to 148 for T2 and from 6 to 64 for T3.",
        "Entity": "Normal"
    },
    {
        "Text": "We can see that the automatically detected cluster numbers distribute evenly across different levels.",
        "Entity": "Normal"
    },
    {
        "Text": "The scale of the clustering structure is more complete here than in the gold standards.",
        "Entity": "Normal"
    },
    {
        "Text": "This evaluation is not fully reliable because the match between the gold standard and the clustering is poor at some levels of hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "However, it is encouraging to see that the results do not drop dramatically until the match between the two is really poor.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Qualitative evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "To gain a better insight into the performance of HGFC, we conducted further qualitative analysis of the clusters the two versions of this method produced for T3.",
        "Entity": "Normal"
    },
    {
        "Text": "We focussed on the top level of 11 clusters (in the evaluation against the hierarchical gold standard,                                                                                                        \n\t\t\tAs expected, the constrained HGFC kept many individual verbs belonging to same Verbnet subclass together (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "verbs enjoy, hate, disdain, regret, love, despise, detest, dislike, fear for the class 31.2.1) so that most clusters simply group lower level classes and their members together.",
        "Entity": "Normal"
    },
    {
        "Text": "Three nearly clean clusters were produced which only include sub-classes of the same class (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "31.2.0 and 31.2.1 which both belong to 31.2 Admire verbs).",
        "Entity": "Normal"
    },
    {
        "Text": "However, the remaining 8 clusters group together sub-classes (and their members) belonging to unrelated parent classes.",
        "Entity": "Normal"
    },
    {
        "Text": "Interestingly, 6 of these make both syntactic and semantic sense.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, several such 37.7 Say verbs and 29.5 Conjencture verbs are found together which share the meaning of communication and which take similar sentential complements.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, none of the clusters produced by the unconstrained HGFC represent a single VerbNet class.",
        "Entity": "Normal"
    },
    {
        "Text": "The majority represent a high number of classes and fewer members per class.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet many of the clusters make syntactic and semantic sense.",
        "Entity": "Normal"
    },
    {
        "Text": "A good example is a cluster which includes member verbs from 9.7 Spray/Load verbs, 21.2 Carve verbs, 51.3.1 Roll verbs, and 10.4 Wipe verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "The verbs included in this cluster share the meaning of specific type of motion and show similar syntactic behaviour.",
        "Entity": "Normal"
    },
    {
        "Text": "Thorough Levin style investigation of especially the unconstrained method would require looking at shared diathesis alternations between cluster members.",
        "Entity": "Normal"
    },
    {
        "Text": "We left this for future work.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the analysis we conducted confirmed that the constrained method could indeed be used for extending known classifications, while the unconstrained method is more suitable for acquiring novel classifications from scratch.",
        "Entity": "Normal"
    },
    {
        "Text": "The errors in clusters produced by both methods were mostly due to syntactic idiosyncracy and the lack of semantic information in clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "We plan to address the latter problem in our future work.",
        "Entity": "Normal"
    },
    {
        "Text": "We have introduced a new graph-based method   HGFC   to hierarchical verb clustering which avoids some of the problems (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "error propagation, pairwise cluster merging) reported with the frequently used AGG method.",
        "Entity": "Normal"
    },
    {
        "Text": "We modified HGFC so that it can be used to automatically determine the tree structure for clustering, and proposed two extensions to it which make it even more suitable for our task.",
        "Entity": "Normal"
    },
    {
        "Text": "The first involves automatically determining the number of clusters to be produced, which is useful when this is not known in advance.",
        "Entity": "Normal"
    },
    {
        "Text": "The second involves adding soft constraints to guide the clustering performance, which is useful when aiming to extend existing classification.",
        "Entity": "Normal"
    },
    {
        "Text": "The results reported in the previous section are promising.",
        "Entity": "Normal"
    },
    {
        "Text": "On a flat test set (T1), the unconstrained version of HGFC outperforms AGG and performs very similarly with the best current flat clustering method (spectral clustering) evaluated on the same dataset.",
        "Entity": "Normal"
    },
    {
        "Text": "On the hierarchical test sets (T2 and T3), the unconstrained and constrained versions of HGFC outperform AGG clearly at all levels of classification.",
        "Entity": "Normal"
    },
    {
        "Text": "The constrained version of HGFC detects the missing hierarchy from the existing gold standards with high accuracy.",
        "Entity": "Normal"
    },
    {
        "Text": "When the number of clusters and levels is learned automatically, the unconstrained method produces a multi-level hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "Our evaluation against a 3-level gold standard shows that such a hierarchy is fairly accurate.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the results from our qualitative evaluation show that both constrained and unconstrained versions of HGFC are capable of learning valuable novel information not included in the gold standards.",
        "Entity": "Normal"
    },
    {
        "Text": "The previous work on Levin style verb classification has mostly focussed on flat classifications using methods suitable for flat clustering (Schulte im Walde, 2006; Joanis et al., 2008; Sun et al., 2008; Li and Brew, 2008; Korhonen et al., 2008; O  Se aghdha and Copestake, 2008; Vlachos et al., 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "However, some works have employed hierarchical clustering as a method to infer flat clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, Schulte im Walde and Brew (2002) employed AGG to initialize the KMeans clustering for German verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "This gave better results than random initialization.",
        "Entity": "Normal"
    },
    {
        "Text": "Stevenson and Joanis (2003) used AGG for flat clustering on T1.",
        "Entity": "Normal"
    },
    {
        "Text": "They cut the hierarchy at the number of classes in the gold standard and found that it is difficult to automatically determine a good cutoff.",
        "Entity": "Normal"
    },
    {
        "Text": "Our evaluation in the previous section shows that HGFC outperforms their implementation of AGG.",
        "Entity": "Normal"
    },
    {
        "Text": "AGG was also used by Ferrer (2004) who performed hierarchical clustering of 514 Spanish verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "The results were evaluated against a hierarchical gold standard resembling that of Levin s classification in English (Va zquez et al., 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "Radj of 0.07 was reported for a 15-way classification which is comparable to the result of Stevenson and Joanis (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "Hierarchical clustering has also been performed for the related task of semantic verb classification.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, Basili et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) identified the prob lems of AGG, and applied a conceptual clustering algorithm (Fisher, 1987) to Italian verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "They used semi-automatically acquired semantic roles and the concept types as features.",
        "Entity": "Normal"
    },
    {
        "Text": "No quantitative results were reported.",
        "Entity": "Normal"
    },
    {
        "Text": "The qualitative evaluation shows that the resulting clusters are very fine-grained.",
        "Entity": "Normal"
    },
    {
        "Text": "Schulte im Walde (2008) performed hierarchical clustering of German verbs using human verb association as features and AGG as a method.",
        "Entity": "Normal"
    },
    {
        "Text": "They focussed on two small collections of 56 and 104 verbs and evaluated the result against flat gold standard extracted from GermaNet (Kunze and Lemnitzer, 2002) and German FrameNet (Erk et al., 2003), respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "They reported F of 62.69% for the 56 verbs, and F of 34.68% for the 104 verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "In the future, we plan to extend this research line in several directions.",
        "Entity": "Normal"
    },
    {
        "Text": "First, we will try to determine optimal features for different levels of clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the general syntactic features (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "SCF) may perform the best at top levels of a hierarchy while more specific or refined features (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "SCF+pp) may be optimal at lower levels.",
        "Entity": "Normal"
    },
    {
        "Text": "We also plan to investigate incorporating semantic features, like verb selectional preferences, in our feature set.",
        "Entity": "Normal"
    },
    {
        "Text": "It is likely that different levels of clustering require more or less specific selectional preferences.",
        "Entity": "Normal"
    },
    {
        "Text": "One way to obtain the latter is hierarchical clustering of relevant noun data.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we plan to apply the unconstrained HGFC to specific domains to investigate its capability to learn novel, previously unknown classifications.",
        "Entity": "Normal"
    },
    {
        "Text": "As for the constrained version of HGFC, we will conduct a larger scale experiment on the Verb- Net data to investigate what kind of upper level hierarchy it can propose for this resource (which currently has over 100 top level classes).",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we plan to compare HGFC to other hierarchical clustering methods that are relatively new to NLP but have proved promising in other fields, including Bayesian Hierarchical Clustering (Heller and Ghahramani, 2005; Teh et al., 2008) and the method of Azran and Ghahramani (2006a) based on spectral clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "Our work was funded by the Royal Society University Research Fellowship (AK), the Dorothy Hodgkin Postgraduate Award (LS), the EPSRC grants EP/F030061/1 and EP/G051070/1 (UK) and the EU FP7 project  PANACEA .",
        "Entity": "Normal"
    },
    {
        "Text": "\nFoma: a finite-state compiler and library\n\t\n\t\tFoma is a compiler, programming language, and C library for constructing finite-state automata and transducers for various uses.",
        "Entity": "Normal"
    },
    {
        "Text": "It has specific support for many natural language processing applications such as producing morphological and phonological analyzers.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is largely compatible with the Xerox/PARC finite-state toolkit.",
        "Entity": "Normal"
    },
    {
        "Text": "It also embraces Unicode fully and supports various different formats for specifying regular expressions: the Xerox/PARC format, a Perl-like format, and a mathematical format that takes advantage of the \u2018Mathematical Operators\u2019 Unicode block.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is a finite-state compiler, programming language, and regular expression/finite-state library designed for multipurpose use with explicit support for automata theoretic research, constructing lexical analyzers for programming languages, and building morphological/phonological analyzers, as well as spellchecking applications.",
        "Entity": "Normal"
    },
    {
        "Text": "The compiler allows users to specify finite-state automata and transducers incrementally in a similar fashion to AT&T\u2019s fsm (Mohri et al., 1997) and Lextools (Sproat, 2003), the Xerox/PARC finite- state toolkit (Beesley and Karttunen, 2003) and the SFST toolkit (Schmid, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "One of Foma\u2019s design goals has been compatibility with the Xerox/PARC toolkit.",
        "Entity": "Normal"
    },
    {
        "Text": "Another goal has been to allow for the ability to work with n-tape automata and a formalism for expressing first-order logical constraints over regular languages and n-tape- transductions.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is licensed under the GNU general public license: in keeping with traditions of free software, the distribution that includes the source code comes with a user manual and a library of examples.",
        "Entity": "Normal"
    },
    {
        "Text": "The compiler and library are implemented in C and an API is available.",
        "Entity": "Normal"
    },
    {
        "Text": "The API is in many ways similar to the standard C library <regex.h>, and has similar calling conventions.",
        "Entity": "Normal"
    },
    {
        "Text": "However, all the low-level functions that operate directly on automata/transducers are also available (some 50+ functions), including regular expression primitives and extended functions as well as automata deter- minization and minimization algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "These may be useful for someone wanting to build a separate GUI or interface using just the existing low- level functions.",
        "Entity": "Normal"
    },
    {
        "Text": "The API also contains, mainly for spell-checking purposes, functionality for finding words that match most closely (but not exactly) a path in an automaton.",
        "Entity": "Normal"
    },
    {
        "Text": "This makes it straightforward to build spell-checkers from morphological transducers by simply extracting the range of the transduction and matching words approximately.",
        "Entity": "Normal"
    },
    {
        "Text": "Unicode (UTF8) is fully supported and is in fact the only encoding accepted by Foma.",
        "Entity": "Normal"
    },
    {
        "Text": "It has been successfully compiled on Linux, Mac OS X, and Win32 operating systems, and is likely to be portable to other systems without much effort.",
        "Entity": "Normal"
    },
    {
        "Text": "Retaining backwards compatibility with Xerox/PARC and at the same time extending the formalism means that one is often able to construct finite-state networks in equivalent various ways, either through ASCII-based operators or through the Unicode-based extensions.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, one can either say: ContainsX = \u03a3* X \u03a3*; MyWords = {cat}|{dog}|{mouse}; MyRule = n -> m || p; ShortWords = [MyLex1]1 \u2229 \u03a3\u02c6<6; or: Proceedings of the EACL 2009 Demonstrations Session, pages 29\u201332, Athens, Greece, 3 April 2009.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2009 Association for Computational Linguistics Operators Compatibility variant Function [ ] () [ ] () grouping parentheses, optionality \u2200 \u2203 N/A quantifiers \\ \u2018 term negation, substitution/homomorphism : : cross-product + \u2217 + \u2217 Kleene closures \u02c6<n \u02c6>n \u02c6{m,n} \u02c6<n \u02c6>n \u02c6{m,n} iterations 1 2 .1 .2 .u .l domain & range .f N/A eliminate all unification flags $ $.",
        "Entity": "Normal"
    },
    {
        "Text": "\u02dc $ $.",
        "Entity": "Normal"
    },
    {
        "Text": "complement, containment operators / ./.",
        "Entity": "Normal"
    },
    {
        "Text": "N/A N/A \u2018ignores\u2019, left quotient, right quotient, \u2018inside\u2019 quotient \u2208 \u2208/ = /= N/A language membership, position equivalence \u227a < > precedes, follows \u2228 \u222a \u2227 \u2229 - .P.",
        "Entity": "Normal"
    },
    {
        "Text": ".p.",
        "Entity": "Normal"
    },
    {
        "Text": "| & \u2212 .P.",
        "Entity": "Normal"
    },
    {
        "Text": ".p.",
        "Entity": "Normal"
    },
    {
        "Text": "union, intersection, set minus, priority unions => -> (->) @-> => -> (->) @-> context restriction, replacement rules <> shuffle (asynchronous product) \u00d7 \u25e6 .x.",
        "Entity": "Normal"
    },
    {
        "Text": ".o.",
        "Entity": "Normal"
    },
    {
        "Text": "cross-product, composition Table 1:                                                                            \n\t\t\tHorizontal lines separate precedence classes.",
        "Entity": "Normal"
    },
    {
        "Text": "define ContainsX ?",
        "Entity": "Normal"
    },
    {
        "Text": "* X ?",
        "Entity": "Normal"
    },
    {
        "Text": "*; define MyWords {cat}|{dog}|{mouse}; define MyRule n -> m || _ p; define ShortWords Mylex.i.l & ?\u02c6<6;                                                                                                                   \n\t\t\tOne such extension is the ability to use of a form of first-order logic to make existential statements over languages and transductions (Hulden, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, suppose we have defined an arbitrary regular language L, and want to further define a language that contains only one factor of L, we can do so by: OneL = (\u2203x)(x \u2208 L \u2227 (\u2203y)(y \u2208 L \u2227 (x = y))); Here, quantifiers apply to substrings, and we attribute the usual meaning to \u2208 and \u2227, and a kind of concatenative meaning to the predicate S(t1, t2).",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, in the above example, OneL defines the language where there exists a string x such that x is a member of the language L and there does not exist a string y, also in L, such that y would occur in a different position than x.",
        "Entity": "Normal"
    },
    {
        "Text": "This kind of logical specification of regular languages can be very useful for building some languages that would be quite cumbersome to express with other regular expression operators.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, many of the internally complex operations of Foma are built through a reduction to this type of logical expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "As mentioned, Foma supports reading and writing of the LEXC file format, where morphological categories are divided into so-called continuation classes.",
        "Entity": "Normal"
    },
    {
        "Text": "This practice stems back from the earliest two-level compilers (Karttunen et al., 1987).",
        "Entity": "Normal"
    },
    {
        "Text": "Below is a simple example of the format: Multichar_Symbols +Pl +Sing LEXICON Root Nouns; LEXICON Nouns cat Plural; church Plural; LEXICON Plural +Pl:%\u02c6s #; +Sing #;\n\t\n\t\n\t\t\tThe Foma API gives access to basic functions, such as constructing a finite-state machine from a regular expression provided as a string, performing a transduction, and exhaustively matching against a given string starting from every position.",
        "Entity": "Normal"
    },
    {
        "Text": "The following basic snippet illustrates how to use the C API instead of the main interface of Foma to construct a finite-state machine encoding the language a+b+ and check whether a string matches it: 1.\n\t\t\tvoid check_word(char *s) { 2.\n\t\t\tfsm_t *network; 3.\n\t\t\tfsm_match_result *result; 4.",
        "Entity": "Normal"
    },
    {
        "Text": "5. network = fsm_regex(\"a+ b+\"); 6.\n\t\t\tresult = fsm_match(fsm, s); 7.\n\t\t\tif (result->num_matches > 0) 8.\n\t\t\tprintf(\"Regex matches\"); 9.",
        "Entity": "Normal"
    },
    {
        "Text": "10 } Here, instead of calling the fsm regex() function to construct the machine from a regular expressions, we could instead have accessed the beforementioned low-level routines and built the network entirely without regular expressions by combining low-level primitives, as follows, replacing line 5 in the above: network = fsm_concat( fsm_kleene_plus( fsm_symbol(\"a\")), fsm_kleene_plus( fsm_symbol(\"b\"))); The API is currently under active development and future functionality is likely to include conversion of networks to 8-bit letter transducers/automata for maximum speed in regular expression matching and transduction.",
        "Entity": "Normal"
    },
    {
        "Text": "educational use Foma has support for visualization of the machines it builds through the AT&T Graphviz library.",
        "Entity": "Normal"
    },
    {
        "Text": "For educational purposes and to illustrate automata construction methods, there is some support for changing the behavior of the algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, by default, for efficiency reasons, Foma determinizes and minimizes automata between nearly every incremental operation.",
        "Entity": "Normal"
    },
    {
        "Text": "Operations such as unions of automata are also constructed by default with the product construction method that directly produces deterministic automata.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this on-the-fly minimization and determinization can be relaxed, and a Thompson construction method chosen in the interface so that automata remain non-deterministic and non- minimized whenever possible\u2014non-deterministic automata naturally being easier to inspect and analyze.",
        "Entity": "Normal"
    },
    {
        "Text": "Though the main concern with Foma has not been that of efficiency, but of compatibility and extendibility, from a usefulness perspective it is important to avoid bottlenecks in the underlying algorithms that can cause compilation times to skyrocket, especially when constructing and combining large lexical transducers.",
        "Entity": "Normal"
    },
    {
        "Text": "With this in mind, some care has been taken to attempt to optimize the underlying primitive algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "One the whole, Foma seems to perform particularly well with pathological cases that involve exponential growth in the number of states when determinizing non- deterministic machines.",
        "Entity": "Normal"
    },
    {
        "Text": "For general usage patterns, this advantage is not quite as dramatic, and for average use Foma seems to perform comparably with e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the Xerox/PARC toolkit, perhaps with the exception of certain types of very large lexicon descriptions (>100,000 words).",
        "Entity": "Normal"
    },
    {
        "Text": "The Foma project is multipurpose multi-mode finite-state compiler geared toward practical construction of large-scale finite-state machines such as may be needed in natural language processing as well as providing a framework for research in finite-state automata.",
        "Entity": "Normal"
    },
    {
        "Text": "Several wide- coverage morphological analyzers specified in the LEXC/xfst format have been compiled successfully with Foma.",
        "Entity": "Normal"
    },
    {
        "Text": "Foma is free software and will remain under the GNU General Public License.",
        "Entity": "Normal"
    },
    {
        "Text": "As the source code is available, collaboration is encouraged.",
        "Entity": "Normal"
    },
    {
        "Text": "GNU AT&T Foma xfst flex fsm 4 \u03a3\u2217a\u03a315 0.216s 16.23s 17.17s 1.884s \u03a3\u2217a\u03a320 8.605s nf nf 153.7s North Sami 14.23s 4.264s N/A N/A 8queens 0.188s 1.200s N/A N/A sudoku2x3 5.040s 5.232s N/A N/A lexicon.lex 1.224s 1.428s N/A N/A 3sat30 0.572s 0.648s N/A N/A Table 2:                                                                                                                     \n\t\t\tThe first and second entries are short regular expressions that exhibit exponential behavior.",
        "Entity": "Normal"
    },
    {
        "Text": "The second results in a FSM with 221 states and 222 arcs.",
        "Entity": "Normal"
    },
    {
        "Text": "The others are scripts that can be run on both Xerox/PARC and Foma.",
        "Entity": "Normal"
    },
    {
        "Text": "The file lexicon.lex is a LEXC format English dictionary with 38418 entries.",
        "Entity": "Normal"
    },
    {
        "Text": "North Sami is a large lexicon (lexc file) for the North Sami language available from http://divvun.no.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\t Lightweight  semantic annotation of textcalls for a simple representation, ideally without requiring a semantic lexicon to achieve good coverage in the language and domain.In this paper, we repurpose WordNet s super- sense tags for annotation, developing specificguidelines for nominal expressions and applying them to Arabic Wikipedia articles in four topical domains.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting corpus has high coverage and was completed quickly with reasonable inter-annotator agreement.",
        "Entity": "Normal"
    },
    {
        "Text": "The goal of  lightweight  semantic annotation of text, particularly in scenarios with limited resources and expertise, presents several requirements for arepresentation: simplicity; adaptability to new lan guages, topics, and genres; and coverage.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper describes coarse lexical semantic annotationof Arabic Wikipedia articles subject to these con straints.",
        "Entity": "Normal"
    },
    {
        "Text": "Traditional lexical semantic representations are either narrow in scope, like named entities,1 or make reference to a full-fledged lexicon/ontology, which may insufficiently cover the language/domainof interest or require prohibitive expertise and ef fort to apply.2 We therefore turn to supersense tags (SSTs), 40 coarse lexical semantic classes (25 fornouns, 15 for verbs) originating in WordNet.",
        "Entity": "Normal"
    },
    {
        "Text": "Previ ously these served as groupings of English lexicon 1Some ontologies like those in Sekine et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names.",
        "Entity": "Normal"
    },
    {
        "Text": "2E.g., a WordNet (Fellbaum, 1998) sense annotation effortreported by Passonneau et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) found considerable inter annotator variability for some lexemes; FrameNet (Baker etal., 1998) is limited in coverage, even for English; and Prop Bank (Kingsbury and Palmer, 2002) does not capture semanticrelationships across lexemes.",
        "Entity": "Normal"
    },
    {
        "Text": "We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained cross lingual annotation (Hovy et al., 2006; Dorr et al., 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "COMMUNICATION GROUP 859   XCJ   .",
        "Entity": "Normal"
    },
    {
        "Text": "AD ACT TIME  The Guinness Book of World Records considers the University of AlKaraouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.",
        "Entity": "Normal"
    },
    {
        "Text": "The Arabic is shown left-to-right.",
        "Entity": "Normal"
    },
    {
        "Text": "entries, but here we have repurposed them as target labels for direct human annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "Part of the earliest versions of WordNet, the supersense categories (originally,  lexicographer classes ) were intended to partition all English noun and verb senses into broad groupings, or semanticfields (Miller, 1990; Fellbaum, 1990).",
        "Entity": "Normal"
    },
    {
        "Text": "SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand e.g.,3Note that work in supersense tagging used text with fine grained sense annotations that were then coarsened to SSTs.",
        "Entity": "Normal"
    },
    {
        "Text": "4The noun/verb distinction might prove problematic in some languages.",
        "Entity": "Normal"
    },
    {
        "Text": "Q .J K    considers  ~ JJ k. Guinness H. A~J  book   C   J   AJ  @  A;P     @ that for-records the-standard    Ag.",
        "Entity": "Normal"
    },
    {
        "Text": "university  @ Q     @ AlKaraouine  Ai in Fez H. Q    @   Morocco    Ag.",
        "Entity": "Normal"
    },
    {
        "Text": "oldest university    Y ~@           in ARTIFACT LOCATION   A  @ the-world   A D J  A K established   J ~ in year IJ   ~    k was where      LOCATION 253 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 253 258, Jeju, Republic of Korea, 814 July 2012.\n\t\t\tc 2012 Association for Computational Linguistics Crusades   Damascus   Ibn Tolun Mosque   Imam Hussein Shrine   Islamic Golden Age   Islamic History   Ummayad Mosque 434s 16,185t 5,859m Atom   Enrico Fermi   Light   Nuclear power   Periodic Table   Physics   Muhammad alRazi 777s 18,559t 6,477m 2004 Summer Olympics   Christiano Ronaldo   Football   FIFA World Cup   Portugal football team   Ra ul Gonz ales   Real Madrid 390s 13,716t 5,149m.",
        "Entity": "Normal"
    },
    {
        "Text": "Computer   Computer Software   Internet   Linux   Richard Stallman   Solaris   X Window System 618s 16,992t 5,754m                                                    \n\t\t\tThe 7 article titles (translated) in each domain, with total counts of sentences, tokens, and supersense mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "Overall, there are 2,219 sentences with 65,452 tokens and 23,239 mentions (1.3 tokens/mention on average).",
        "Entity": "Normal"
    },
    {
        "Text": "Counts exclude sentences marked as problematic and mentions marked ?.",
        "Entity": "Normal"
    },
    {
        "Text": "disambiguating PERSON vs.",
        "Entity": "Normal"
    },
    {
        "Text": "POSSESSION for the noun principal and generalize across lexemes on the other e.g., principal, teacher, and student can all be PERSONs.",
        "Entity": "Normal"
    },
    {
        "Text": "This lumping property might be expected to give too much latitude to annotators; yetwe find that in practice, it is possible to elicit reason able inter-annotator agreement, even for a languageother than English.",
        "Entity": "Normal"
    },
    {
        "Text": "We encapsulate our interpreta tion of the tags in a set of brief guidelines that aims to be usable by anyone who can read and understand a text in the target language; our annotators had no prior expertise in linguistics or linguistic annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we note that ad hoc categorization schemes not unlike SSTs have been developed for purposes ranging from question answering (Li and Roth, 2002) to animacy hierarchy representation for corpus linguistics (Zaenen et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "We believe the interpretation of the SSTs adopted here can serveas a single starting point for diverse resource en gineering efforts and applications, especially when fine-grained sense annotation is not feasible.",
        "Entity": "Normal"
    },
    {
        "Text": "WordNet s definitions of the supersenses are terse, and we could find little explicit discussion of the specific rationales behind each category.",
        "Entity": "Normal"
    },
    {
        "Text": "English examples are given, but the guidelines are intended to be language-neutral.",
        "Entity": "Normal"
    },
    {
        "Text": "A more systematic breakdown, formulated as a 43-rule decision list, is included with the corpus.5 In developing these guidelines we consulted English WordNet (Fellbaum, 1998) and SemCor (Miller et al., 1993) for examples and synset definitions, occasionally making simplifying decisions where we found distinctions that seemed esoteric or internally inconsistent.",
        "Entity": "Normal"
    },
    {
        "Text": "Special cases (e.g., multiword expressions, anaphora, figurative 5For example, one rule states that all man-made structures (buildings, rooms, bridges, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "are to be tagged as ARTIFACTs.",
        "Entity": "Normal"
    },
    {
        "Text": "language) are addressed with additional rules.",
        "Entity": "Normal"
    },
    {
        "Text": "The annotation in this work was on top of a smallcorpus of Arabic Wikipedia articles that had al ready been annotated for named entities (Mohit et al., 2012).",
        "Entity": "Normal"
    },
    {
        "Text": "Here we use two different annotators, both native speakers of Arabic attending a university with English as the language of instruction.",
        "Entity": "Normal"
    },
    {
        "Text": "Data &amp; procedure.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The annotation task was to identify and categorize mentions, i.e., occurrences of terms belonging tonoun supersenses.",
        "Entity": "Normal"
    },
    {
        "Text": "Working in a custom, browser based interface, annotators were to tag each relevanttoken with a supersense category by selecting the to ken and typing a tag symbol.",
        "Entity": "Normal"
    },
    {
        "Text": "Any token could be marked as continuing a multiword unit by typing &lt;.",
        "Entity": "Normal"
    },
    {
        "Text": "If the annotator was ambivalent about a token they were to mark it with the ?",
        "Entity": "Normal"
    },
    {
        "Text": "symbol.",
        "Entity": "Normal"
    },
    {
        "Text": "Sentences werepre-tagged with suggestions where possible.6 Anno tators noted obvious errors in sentence splitting and grammar so ill-formed sentences could be excluded.Training.",
        "Entity": "Normal"
    },
    {
        "Text": "Over several months, annotators alternately annotated sentences from 2 designated arti cles of each domain, and reviewed the annotationsfor consistency.",
        "Entity": "Normal"
    },
    {
        "Text": "All tagging conventions were deve loped collaboratively by the author(s) and annotators during this period, informed by points of confusionand disagreement.",
        "Entity": "Normal"
    },
    {
        "Text": "WordNet and SemCor were con sulted as part of developing the guidelines, but not during annotation itself so as to avoid complicating the annotation process or overfitting to WordNet sidiosyncracies.",
        "Entity": "Normal"
    },
    {
        "Text": "The training phase ended once inter annotator mention FI had reached 75%.6Suggestions came from the previous named entity annota tion of PERSONs, organizations (GROUP), and LOCATIONs, as well as heuristic lookup in lexical resources Arabic WordNet entries (Elkateb et al., 2006) mapped to English WordNet, and named entities in OntoNotes (Hovy et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "254 O NATURAL OBJECT natural feature or nonliving object in nature barrier reef nest neutron star planet sky fishpond metamorphic rock Mediterranean cave stepping stone boulder Orion ember universe A ARTIFACT man-made structures and objects bridge restaurant bedroom stage cabinet toaster antidote aspirin L LOCATION any name of a geopolitical entity, as well as other nouns functioning as locations or regions Cote d Ivoire New York City downtown stage left India Newark interior airspace P PERSON humans or personified beings; names of socialgroups (ethnic, political, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "that can refer to an individ ual in the singular Persian deity glasscutter mother kibbutznik firstborn worshiper Roosevelt Arab consumer appellant guardsman Muslim American communistG GROUP groupings of people or objects, including: orga nizations/institutions; followers of social movements collection flock army meeting clergy Mennonite Church trumpet section health profession peasantry People s Party U.S. State Department University of California population consulting firm communism Islam (= set of Muslims) $ SUBSTANCE a material or substance krypton mocha atom hydrochloric acid aluminum sand cardboard DNA H POSSESSION term for an entity involved in ownership or payment birthday present tax shelter money loan T TIME a temporal point, period, amount, or measurement 10 seconds day Eastern Time leap year 2nd millenium BC 2011 (=year) velocity frequency runtime latency/delay middle age half life basketball season words per minute curfew industrial revolution instant/moment August = RELATION relations between entities or quantities ratio scale reverse personal relation exponential function angular position unconnectedness transitivity Q QUANTITY quantities and units of measure, including cardinal numbers and fractional amounts 7 cm 1.8 million 12 percent/12% volume (= spatial extent) volt real number square root digit 90 degrees handful ounce half F FEELING subjective emotions indifference wonder murderousness grudge desperation astonishment suffering M MOTIVE an abstract external force that causes someone to intend to do something reason incentiveC COMMUNICATION information encoding and transmis sion, except in the sense of a physical object grave accent Book of Common Prayer alphabet Cree language onomatopoeia reference concert hotel bill broadcast television program discussion contract proposal equation denial sarcasm concerto software   COGNITION aspects of mind/thought/knowledge/belief/ perception; techniques and abilities; fields of academic study; social or philosophical movements referring to the system of beliefs Platonism hypothesis logic biomedical science necromancy hierarchical structure democracy innovativeness vocational program woodcraft reference visual image Islam (= Islamic belief system) dream scientific method consciousness puzzlement skepticism reasoning design intuition inspiration muscle memory skill aptitude/talent method sense of touch awarenessS STATE stable states of affairs; diseases and their symp toms symptom reprieve potency poverty altitude sickness tumor fever measles bankruptcy infamy opulence hunger opportunity darkness (= lack of light) @ ATTRIBUTE characteristics of people/objects that can be judged resilience buxomness virtue immateriality admissibility coincidence valence sophistication simplicity temperature (= degree of hotness) darkness (= dark coloring)I ACT things people do or cause to happen; learned pro fessions meddling malpractice faith healing dismount carnival football game acquisition engineering (=profession) E EVENT things that happens at a given place and time bomb blast ordeal miracle upheaval accident tide R PROCESS a sustained phenomenon or one marked by gradual changes through a series of states oscillation distillation overheating aging accretion/growth extinction evaporationX PHENOMENON a physical force or something that hap pens/occurs electricity suction tailwind tornado effect + SHAPE two and three dimensional shapes D FOOD things used as food or drink B BODY human body parts, excluding diseases and their symptoms Y PLANT a plant or fungus N ANIMAL nonhuman, non-plant life Science chemicals, molecules, atoms, and subatomic particles are tagged as SUBSTANCE Sports championships/tournaments are EVENTs (Information) Technology Software names, kinds, and components are tagged as COMMUNICATION (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "kernel,version, distribution, environment).",
        "Entity": "Normal"
    },
    {
        "Text": "A connection is a RE LATION; project, support, and a configuration are tagged as COGNITION; development and collaboration are ACTs.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic conventions Masdar constructions (verbal nouns) are treated as nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "Anaphora are not tagged.",
        "Entity": "Normal"
    },
    {
        "Text": "Some examples and longer descriptions have been omitted due to space constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Below: A few domain- and language-specific elaborations of the general guidelines.",
        "Entity": "Normal"
    },
    {
        "Text": "255                                                                                                                      \n\t\t\t(Counts are of the union of the annotators  choices, even when they disagree.)",
        "Entity": "Normal"
    },
    {
        "Text": "tag num tag num ACT (!)",
        "Entity": "Normal"
    },
    {
        "Text": "3473 LOCATION (G) 1583 COMMUNICATION (C) 3007 GROUP (L) 1501 PERSON (P) 2650 TIME (T) 1407 ARTIFACT (A) 2164 SUBSTANCE ($) 1291 COGNITION ( ) 1672 QUANTITY (Q) 1022Main annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "After training, the two annota tors proceeded on a per-document basis: first they worked together to annotate several sentences fromthe beginning of the article, then each was independently assigned about half of the remaining sentences (typically with 5 10 shared to measure agreement).",
        "Entity": "Normal"
    },
    {
        "Text": "Throughout the process, annotators were en couraged to discuss points of confusion with each other, but each sentence was annotated in its entiretyand never revisited.",
        "Entity": "Normal"
    },
    {
        "Text": "Annotation of 28 articles re quired approximately 100 annotator-hours.",
        "Entity": "Normal"
    },
    {
        "Text": "Articles used in pilot rounds were re-annotated from scratch.",
        "Entity": "Normal"
    },
    {
        "Text": "Analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "Some of the most concrete tags BODY, ANIMAL, PLANT, NATURAL OBJECT, and FOOD  were barely present, but would likely be frequent in life sciences domains.",
        "Entity": "Normal"
    },
    {
        "Text": "Others, such as MOTIVE, POSSESSION, and SHAPE, are limited in scope.To measure inter-annotator agreement, 87 sentences (2,774 tokens) distributed across 19 of the ar ticles (not including those used in pilot rounds) wereannotated independently by each annotator.",
        "Entity": "Normal"
    },
    {
        "Text": "Interannotator mention Fl (counting agreement over en tire mentions and their labels) was 70%.",
        "Entity": "Normal"
    },
    {
        "Text": "Excluding the 1,397 tokens left blank by both annotators, the token-level agreement rate was 71%, with Cohen s n = 0.69, and token-level Fl was 83%.7We also measured agreement on a tag-by-tag basis.",
        "Entity": "Normal"
    },
    {
        "Text": "For 8 of the 10 most frequent SSTs (fig ure 3), inter-annotator mention Fl ranged from 73% to 80%.",
        "Entity": "Normal"
    },
    {
        "Text": "The two exceptions were QUANTITY at63%, and COGNITION (probably the most heterogeneous category) at 49%.",
        "Entity": "Normal"
    },
    {
        "Text": "An examination of the confusion matrix reveals four pairs of supersense cate gories that tended to provoke the most disagreement: COMMUNICATION/COGNITION, ACT/COGNITION, ACT/PROCESS, and ARTIFACT/COMMUNICATION.",
        "Entity": "Normal"
    },
    {
        "Text": "7Token-level measures consider both the supersense label and whether it begins or continues the mention.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Also in that sentence, an notators disagreed on the second use of university(ARTIFACT vs. GROUP).",
        "Entity": "Normal"
    },
    {
        "Text": "As with any sense anno tation effort, some disagreements due to legitimate ambiguity and different interpretations of the tags  especially the broadest ones are unavoidable.",
        "Entity": "Normal"
    },
    {
        "Text": "A  soft  agreement measure (counting as matches any two mentions with the same label and at leastone token in common) gives an Fl of 79%, showing that boundary decisions account for a major portion of the disagreement.",
        "Entity": "Normal"
    },
    {
        "Text": "Further examples include the technical term  thin client , for which one annotator omitted the adjective; and World Cup Football Championship , where one an notator tagged the entire phrase as an EVENT while the other tagged  football  as a separate ACT.",
        "Entity": "Normal"
    },
    {
        "Text": "We have codified supersense tags as a simple an notation scheme for coarse lexical semantics, andhave shown that supersense annotation of Ara bic Wikipedia can be rapid, reliable, and robust (about half the tokens in our data are coveredby a nominal supersense).",
        "Entity": "Normal"
    },
    {
        "Text": "Our tagging guide lines and corpus are available for download at http://www.ark.cs.cmu.edu/ArabicSST/.",
        "Entity": "Normal"
    },
    {
        "Text": "We thank Nourhen Feki and Sarah Mustafa for assistance with annotation, as well as Emad Mohamed, CMU ARK members, and anonymous reviewers for their comments.This publication was made possible by grant NPRP08 4851-083 from the Qatar National Research Fund (a member of the Qatar Foundation).",
        "Entity": "Normal"
    },
    {
        "Text": "The statements made herein are solely the responsibility of the authors.",
        "Entity": "Normal"
    },
    {
        "Text": "256",
        "Entity": "Normal"
    },
    {
        "Text": "\nBetter Arabic Parsing: Baselines, Evaluations, and Analysis\n\t\n\t\tIn this paper, we offer broad insight into the underperformance of Arabic constituency parsing by analyzing the interplay of linguistic phenomena, annotation choices, and model design.",
        "Entity": "Normal"
    },
    {
        "Text": "First, we identify sources of syntactic ambiguity understudied in the existing parsing literature.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, we show that although the Penn Arabic Treebank is similar to other tree- banks in gross statistical terms, annotation consistency remains problematic.",
        "Entity": "Normal"
    },
    {
        "Text": "Third, we develop a human interpretable grammar that is competitive with a latent variable PCFG.",
        "Entity": "Normal"
    },
    {
        "Text": "Fourth, we show how to build better models for three different parsers.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2\u20135% F1.",
        "Entity": "Normal"
    },
    {
        "Text": "It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Sima\u2019an, 2008), and the effect of variable word order (Collins et al., 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Certainly these linguistic factors increase the difficulty of syntactic disambiguation.",
        "Entity": "Normal"
    },
    {
        "Text": "Less frequently studied is the interplay among language, annotation choices, and parsing model design (Levy and Manning, 2003; Ku\u00a8 bler, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "1 The apparent difficulty of adapting constituency models to non-configurational languages has been one motivation for dependency representations (Hajic\u02c7 and Zema\u00b4nek, 2004; Habash and Roth, 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply \u201cArabic\u201d) because of the unusual opportunity it presents for comparison to English parsing results.",
        "Entity": "Normal"
    },
    {
        "Text": "The Penn Arabic Treebank (ATB) syntactic guidelines (Maamouri et al., 2004) were purposefully borrowed without major modification from English (Marcus et al., 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Further, Maamouri and Bies (2004) argued that the English guidelines generalize well to other languages.",
        "Entity": "Normal"
    },
    {
        "Text": "But Arabic contains a variety of linguistic phenomena unseen in English.",
        "Entity": "Normal"
    },
    {
        "Text": "Crucially, the conventional orthographic form of MSA text is unvocalized, a property that results in a deficient graphical representation.",
        "Entity": "Normal"
    },
    {
        "Text": "For humans, this characteristic can impede the acquisition of literacy.",
        "Entity": "Normal"
    },
    {
        "Text": "How do additional ambiguities caused by devocalization affect statistical learning?",
        "Entity": "Normal"
    },
    {
        "Text": "How should the absence of vowels and syntactic markers influence annotation choices and grammar development?",
        "Entity": "Normal"
    },
    {
        "Text": "Motivated by these questions, we significantly raise baselines for three existing parsing models through better grammar engineering.",
        "Entity": "Normal"
    },
    {
        "Text": "Our analysis begins with a description of syntactic ambiguity in unvocalized MSA text (\u00a72).",
        "Entity": "Normal"
    },
    {
        "Text": "Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency remains low relative to English (\u00a73).",
        "Entity": "Normal"
    },
    {
        "Text": "We then use linguistic and annotation insights to develop a manually annotated grammar for Arabic (\u00a74).",
        "Entity": "Normal"
    },
    {
        "Text": "To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (\u00a75).",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (\u00a76).",
        "Entity": "Normal"
    },
    {
        "Text": "We quantify error categories in both evaluation settings.",
        "Entity": "Normal"
    },
    {
        "Text": "To our knowledge, ours is the first analysis of this kind for Arabic parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic is a morphologically rich language with a root-and-pattern system similar to other Semitic languages.",
        "Entity": "Normal"
    },
    {
        "Text": "The basic word order is VSO, but SVO, VOS, and VO configurations are also possible.2 Nouns and verbs are created by selecting a consonantal root (usually triliteral or quadriliteral), which bears the semantic core, and adding affixes and diacritics.",
        "Entity": "Normal"
    },
    {
        "Text": "Particles are uninflected.",
        "Entity": "Normal"
    },
    {
        "Text": "Word Head Of Complement POS 1 '01 inna \u201cIndeed, truly\u201d VP Noun VBP 2 '01 anna \u201cThat\u201d SBAR Noun IN 3 01 in \u201cIf\u201d SBAR Verb IN 4 01 an \u201cto\u201d SBAR Verb IN                                                                                                                               \n\t\t\t                                                                                 \n\t\t\t                                                                  \n\t\t\tDiacritics can also be used to specify grammatical relations such as case and gender.",
        "Entity": "Normal"
    },
    {
        "Text": "But diacritics are not present in unvocalized text, which is the standard form of, e.g., news media documents.3 VBD she added VP PUNC S VP VBP NP ...\n\t\t\tVBD she added VP PUNC \u201c SBAR IN NP 0 NN.",
        "Entity": "Normal"
    },
    {
        "Text": "Let us consider an example of ambiguity caused by devocalization.",
        "Entity": "Normal"
    },
    {
        "Text": "\u201c 0 Indeed NN Indeed Saddam                                                           \n\t\t\tWhereas Arabic linguistic theory as Saddam (a) Reference (b) Stanford signs (1) and (2) to the class of pseudo verbs 01 +i J>1\ufffd inna and her sisters since they can beinflected, the ATB conventions treat (2) as a com plementizer, which means that it must be the head of SBAR.",
        "Entity": "Normal"
    },
    {
        "Text": "Because these two words have identical complements, syntax rules are typically unhelpful for distinguishing between them.",
        "Entity": "Normal"
    },
    {
        "Text": "Even with vocalization, there are linguistic categories that are difficult to identify without semantic clues.",
        "Entity": "Normal"
    },
    {
        "Text": "Two common cases are the attribu tive adjective and the process nominal _; maSdar, which can have a verbal reading.4 At tributive adjectives are hard because they are or- thographically identical to nominals; they are inflected for gender, number, case, and definiteness.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, they are used as substantives much 2 Unlike machine translation, constituency parsing is not significantly affected by variable word order.",
        "Entity": "Normal"
    },
    {
        "Text": "However, when grammatical relations like subject and object are evaluated, parsing performance drops considerably (Green et al., 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "In particular, the decision to represent arguments in verb- initial clauses as VP internal makes VSO and VOS configurations difficult to distinguish.",
        "Entity": "Normal"
    },
    {
        "Text": "Topicalization of NP subjects in SVO configurations causes confusion with VO (pro-drop).",
        "Entity": "Normal"
    },
    {
        "Text": "3 Techniques for automatic vocalization have been studied (Zitouni et al., 2006; Habash and Rambow, 2007).",
        "Entity": "Normal"
    },
    {
        "Text": "However, the data sparsity induced by vocalization makes it difficult to train statistical models on corpora of the size of the ATB, so vocalizing and then parsing may well not help performance.",
        "Entity": "Normal"
    },
    {
        "Text": "4 Traditional Arabic linguistic theory treats both of these types as subcategories of noun \ufffd '.i .",
        "Entity": "Normal"
    },
    {
        "Text": "more frequently than is done in English.",
        "Entity": "Normal"
    },
    {
        "Text": "Process nominals name the action of the transitive or ditransitive verb from which they derive.",
        "Entity": "Normal"
    },
    {
        "Text": "The verbal reading arises when the maSdar has an NP argument which, in vocalized text, is marked in the accusative case.",
        "Entity": "Normal"
    },
    {
        "Text": "When the maSdar lacks a determiner, the constituent as a whole resem bles the ubiquitous annexation construct \ufffd ?f iDafa.",
        "Entity": "Normal"
    },
    {
        "Text": "Gabbard and Kulick (2008) show that there is significant attachment ambiguity associated with iDafa, which occurs in 84.3% of the trees in our development set.",
        "Entity": "Normal"
    },
    {
        "Text": "All three models evaluated in this paper incorrectly analyze the constituent as iDafa; none of the models attach the attributive adjectives properly.",
        "Entity": "Normal"
    },
    {
        "Text": "For parsing, the most challenging form of ambiguity occurs at the discourse level.",
        "Entity": "Normal"
    },
    {
        "Text": "A defining characteristic of MSA is the prevalence of discourse markers to connect and subordinate words and phrases (Ryding, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "Instead of offsetting new topics with punctuation, writers of MSA in sert connectives such as \ufffd wa and \ufffd fa to link new elements to both preceding clauses and the text as a whole.",
        "Entity": "Normal"
    },
    {
        "Text": "Length English (WSJ) Arabic (ATB) \u2264 20 41.9% 33.7% \u2264 40 92.4% 73.2% \u2264 63 99.7% 92.6% \u2264 70 99.9% 94.9%                                                                                                    \n\t\t\tEnglish parsing evaluations usually report results on sentences up to length 40.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic sentences of up to length 63 would need to be.",
        "Entity": "Normal"
    },
    {
        "Text": "evaluated to account for the same fraction of the data.",
        "Entity": "Normal"
    },
    {
        "Text": "We propose a limit of 70 words for Arabic parsing evaluations.",
        "Entity": "Normal"
    },
    {
        "Text": "ATB CTB6 Negra WSJ Trees 23449 28278 20602 43948 Word Typess 40972 45245 51272 46348 Tokens 738654 782541 355096 1046829 Tags 32 34 499 45 Phrasal Cats 22 26 325 27 Test OOV 16.8% 22.2% 30.5% 13.2% Per Sentence                                                           \n\t\t\tTest set OOV rate is computed using the following splits: ATB (Chiang et al., 2006); CTB6 (Huang and Harper, 2009); Negra (Dubey and Keller, 2003); English, sections 221 (train) and section 23 (test).",
        "Entity": "Normal"
    },
    {
        "Text": "The ATB gives several different analyses to these words to indicate different types of coordination.",
        "Entity": "Normal"
    },
    {
        "Text": "A better approach would be to distin guish between these cases, possibly by drawing on the vast linguistic work on Arabic connectives (AlBatal, 1990).",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Gross Statistics.",
        "Entity": "Normal"
    },
    {
        "Text": "Linguistic intuitions like those in the previous section inform language-specific annotation choices.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting structural differences between tree- banks can account for relative differences in parsing performance.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The ATB is disadvantaged by having fewer trees with longer average 5 LDC A-E catalog numbers: LDC2008E61 (ATBp1v4), LDC2008E62 (ATBp2v3), and LDC2008E22 (ATBp3v3.1).",
        "Entity": "Normal"
    },
    {
        "Text": "We map the ATB morphological analyses to the shortened \u201cBies\u201d tags for all experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "yields.6 But to its great advantage, it has a high ratio of non-terminals/terminals (\u03bc Constituents / \u03bc Length).",
        "Entity": "Normal"
    },
    {
        "Text": "Evalb, the standard parsing metric, is biased toward such corpora (Sampson and Babarczy, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "Also surprising is the low test set OOV rate given the possibility of morphological variation in Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "In general, several gross corpus statistics favor the ATB, so other factors must contribute to parsing underperformance.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Inter-annotator Agreement.",
        "Entity": "Normal"
    },
    {
        "Text": "Annotation consistency is important in any supervised learning task.",
        "Entity": "Normal"
    },
    {
        "Text": "In the initial release of the ATB, inter-annotator agreement was inferior to other LDC treebanks (Maamouri et al., 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "To improve agreement during the revision process, a dual-blind evaluation was performed in which 10% of the data was annotated by independent teams.",
        "Entity": "Normal"
    },
    {
        "Text": "Maamouri et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2008) reported agreement between the teams (measured with Evalb) at 93.8% F1, the level of the CTB.",
        "Entity": "Normal"
    },
    {
        "Text": "But Rehbein and van Genabith (2007) showed that Evalb should not be used as an indication of real difference\u2014 or similarity\u2014between treebanks.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead, we extend the variation n-gram method of Dickinson (2005) to compare annotation error rates in the WSJ and ATB.",
        "Entity": "Normal"
    },
    {
        "Text": "For a corpus C, let M be the set of tuples \u2217n, l), where n is an n-gram with bracketing label l. If any n appears 6 Generative parsing performance is known to deteriorate with sentence length.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result, Habash et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) developed a technique for splitting and chunking long sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "In application settings, this may be a profitable strategy.",
        "Entity": "Normal"
    },
    {
        "Text": "NN \ufffd .e NP NNP NP DTNNP NN \ufffd .e NP NP NNP NP                                                                    \n\t\t\tThe samples from each corpus were independently evaluated.",
        "Entity": "Normal"
    },
    {
        "Text": "The ATB has a much higher fraction of nuclei per tree, and a higher type-level error rate.",
        "Entity": "Normal"
    },
    {
        "Text": "summit Sharm (a) Al-Sheikh summit Sharm (b) DTNNP Al-Sheikh in a corpus position without a bracketing label, then we also add \u2217n, NIL) to M. We call the set of unique n-grams with multiple labels in M the variation nuclei of C. Bracketing variation can result from either annotation errors or linguistic ambiguity.",
        "Entity": "Normal"
    },
    {
        "Text": "Human evaluation is one way to distinguish between the two cases.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Dickinson (2005), we randomly sampled 100 variation nuclei from each corpus and evaluated each sample for the presence of an annotation error.",
        "Entity": "Normal"
    },
    {
        "Text": "The human evaluators were a non-native, fluent Arabic speaker (the first author) for the ATB and a native English speaker for the WSJ.7                                                                 \n\t\t\tThe 95% confidence intervals for type-level errors are (5580, 9440) for the ATB and (1400, 4610) for the WSJ.",
        "Entity": "Normal"
    },
    {
        "Text": "The results clearly indicate increased variation in the ATB relative to the WSJ, but care should be taken in assessing the magnitude of the difference.",
        "Entity": "Normal"
    },
    {
        "Text": "On the one hand, the type-level error rate is not calibrated for the number of n-grams in the sample.",
        "Entity": "Normal"
    },
    {
        "Text": "At the same time, the n-gram error rate is sensitive to samples with extreme n-gram counts.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, one of the ATB samples was the determiner -\"\" ; dhalik\u201cthat.\u201d The sample occurred in 1507 corpus po sitions, and we found that the annotations were consistent.",
        "Entity": "Normal"
    },
    {
        "Text": "If we remove this sample from the evaluation, then the ATB type-level error rises to only 37.4% while the n-gram error rate increases to 6.24%.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of ATB n-grams also falls below the WSJ sample size as the largest WSJ sample appeared in only 162 corpus positions.",
        "Entity": "Normal"
    },
    {
        "Text": "7 Unlike Dickinson (2005), we strip traces and only con-.",
        "Entity": "Normal"
    },
    {
        "Text": "We can use the preceding linguistic and annotation insights to build a manually annotated Arabic grammar in the manner of Klein and Manning (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "Manual annotation results in human in- terpretable grammars that can inform future tree- bank annotation decisions.",
        "Entity": "Normal"
    },
    {
        "Text": "In our grammar, features are realized as annotations to basic category labels.",
        "Entity": "Normal"
    },
    {
        "Text": "We start with noun features since written Arabic contains a very high proportion of NPs.",
        "Entity": "Normal"
    },
    {
        "Text": "genitiveMark indicates recursive NPs with a indefinite nominal left daughter and an NP right daughter.",
        "Entity": "Normal"
    },
    {
        "Text": "This is the form of recursive levels in iDafa constructs.",
        "Entity": "Normal"
    },
    {
        "Text": "We also add an annotation for one-level iDafa (oneLevelIdafa) constructs since they make up more than 75% of the iDafa NPs in the ATB (Gabbard and Kulick, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "For all other recursive NPs, we add a common annotation to the POS tag of the head (recursiveNPHead).",
        "Entity": "Normal"
    },
    {
        "Text": "Base NPs are the other significant category of nominal phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "markBaseNP indicates these non-recursive nominal phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "This feature includes named entities, which the ATB marks with a flat NP node dominating an arbitrary number of NNP pre-terminal daughters (Figure 2).",
        "Entity": "Normal"
    },
    {
        "Text": "For verbs we add two features.",
        "Entity": "Normal"
    },
    {
        "Text": "First we mark any node that dominates (at any level) a verb sider POS tags when pre-terminals are the only intervening nodes between the nucleus and its bracketing (e.g., unaries, base NPs).",
        "Entity": "Normal"
    },
    {
        "Text": "Since our objective is to compare distributions of bracketing discrepancies, we do not use heuristics to prune the set of nuclei.",
        "Entity": "Normal"
    },
    {
        "Text": "8 We use head-finding rules specified by a native speaker.",
        "Entity": "Normal"
    },
    {
        "Text": "of Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "This PCFG is incorporated into the Stanford Parser, a factored model that chooses a 1-best parse from the product of constituency and dependency parses.",
        "Entity": "Normal"
    },
    {
        "Text": "termined by the category of the word that follows it.",
        "Entity": "Normal"
    },
    {
        "Text": "Because conjunctions are elevated in the parse trees when they separate recursive constituents, we choose the right sister instead of the category of the next word.",
        "Entity": "Normal"
    },
    {
        "Text": "We create equivalence classes for verb, noun, and adjective POS categories.",
        "Entity": "Normal"
    },
    {
        "Text": "phrase (markContainsVerb).",
        "Entity": "Normal"
    },
    {
        "Text": "This feature has a linguistic justification.",
        "Entity": "Normal"
    },
    {
        "Text": "Historically, Arabic grammar has identified two sentences types: those that begin with a nominal (\ufffd '.i \ufffdu _..\n\t\t\t), and thosethat begin with a verb (\ufffd ub..i \ufffdu _..",
        "Entity": "Normal"
    },
    {
        "Text": "But for eign learners are often surprised by the verbless predications that are frequently used in Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "Although these are technically nominal, they have become known as \u201cequational\u201d sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "mark- ContainsVerb is especially effective for distinguishing root S nodes of equational sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "We also mark all nodes that dominate an SVO configuration (containsSVO).",
        "Entity": "Normal"
    },
    {
        "Text": "In MSA, SVO usually appears in non-matrix clauses.",
        "Entity": "Normal"
    },
    {
        "Text": "Lexicalizing several POS tags improves performance.",
        "Entity": "Normal"
    },
    {
        "Text": "splitIN captures the verb/preposition idioms that are widespread in Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "Although this feature helps, we encounter one consequence of variable word order.",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike the WSJ corpus which has a high frequency of rules like VP \u2192VB PP, Arabic verb phrases usually have lexi calized intervening nodes (e.g., NP subjects and direct objects).",
        "Entity": "Normal"
    },
    {
        "Text": "For example, we might have VP \u2192 VB NP PP, where the NP is the subject.",
        "Entity": "Normal"
    },
    {
        "Text": "This annotation choice weakens splitIN.",
        "Entity": "Normal"
    },
    {
        "Text": "We compare the manually annotated grammar, which we incorporate into the Stanford parser, to both the Berkeley (Petrov et al., 2006) and Bikel (Bikel, 2004) parsers.",
        "Entity": "Normal"
    },
    {
        "Text": "All experiments use ATB parts 1\u20133 divided according to the canonical split suggested by Chiang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006).",
        "Entity": "Normal"
    },
    {
        "Text": "Preprocessing the raw trees improves parsing performance considerably.9 We first discard all trees dominated by X, which indicates errors and non-linguistic text.",
        "Entity": "Normal"
    },
    {
        "Text": "At the phrasal level, we remove all function tags and traces.",
        "Entity": "Normal"
    },
    {
        "Text": "We also collapse unary chains withidentical basic categories like NP \u2192 NP.",
        "Entity": "Normal"
    },
    {
        "Text": "The pre terminal morphological analyses are mapped to the shortened \u201cBies\u201d tags provided with the tree- bank.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we add \u201cDT\u201d to the tags for definite nouns and adjectives (Kulick et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "The orthographic normalization strategy we use is simple.10 In addition to removing all diacritics, we strip instances of taTweel J=J4.i, collapse variants of alif to bare alif,11 and map Ara bic punctuation characters to their Latin equivalents.",
        "Entity": "Normal"
    },
    {
        "Text": "We retain segmentation markers\u2014which are consistent only in the vocalized section of the treebank\u2014to differentiate between e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "\ufffd \u201cthey\u201d and \ufffd + \u201ctheir.\u201d Because we use the vocalized section, we must remove null pronoun markers.",
        "Entity": "Normal"
    },
    {
        "Text": "Evalb is a Java re-implementation of the standard labeled precision/recall metric.12 The ATB gives all punctuation a single tag.",
        "Entity": "Normal"
    },
    {
        "Text": "For parsing, this is a mistake, especially in the case of interrogatives.",
        "Entity": "Normal"
    },
    {
        "Text": "splitPUNC restores the convention of the WSJ.",
        "Entity": "Normal"
    },
    {
        "Text": "We also mark all tags that dominate a word with the feminine ending :: taa mar buuTa (markFeminine).",
        "Entity": "Normal"
    },
    {
        "Text": "The intuition here is that the role of a discourse marker can usually be de 9 Both the corpus split and pre-processing code are avail-.",
        "Entity": "Normal"
    },
    {
        "Text": "able at http://nlp.stanford.edu/projects/arabic.shtml.",
        "Entity": "Normal"
    },
    {
        "Text": "10 Other orthographic normalization schemes have been suggested for Arabic (Habash and Sadat, 2006), but we observe negligible parsing performance differences between these and the simple scheme used in this evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "11 taTweel (-) is an elongation character used in Arabic script to justify text.",
        "Entity": "Normal"
    },
    {
        "Text": "It has no syntactic function.",
        "Entity": "Normal"
    },
    {
        "Text": "Variants of alif are inconsistently used in Arabic texts.",
        "Entity": "Normal"
    },
    {
        "Text": "For alif with hamza, normalization can be seen as another level of devocalization.",
        "Entity": "Normal"
    },
    {
        "Text": "12 For English, our Evalb implementation is identical to the most recent reference (EVALB20080701).",
        "Entity": "Normal"
    },
    {
        "Text": "For Arabic we M o d e l S y s t e m L e n g t h L e a f A n c e s t o r Co rpu s Sent Exact E v a l b L P LR F1 T a g % B a s e l i n e 7 0 St an for d (v 1.",
        "Entity": "Normal"
    },
    {
        "Text": "6.",
        "Entity": "Normal"
    },
    {
        "Text": "3) all G o l d P O S 7 0 0.7 91 0.825 358 0.7 73 0.818 358 0.8 02 0.836 452 80.",
        "Entity": "Normal"
    },
    {
        "Text": "37 79.",
        "Entity": "Normal"
    },
    {
        "Text": "36 79.",
        "Entity": "Normal"
    },
    {
        "Text": "86 78.",
        "Entity": "Normal"
    },
    {
        "Text": "92 77.",
        "Entity": "Normal"
    },
    {
        "Text": "72 78.",
        "Entity": "Normal"
    },
    {
        "Text": "32 81.",
        "Entity": "Normal"
    },
    {
        "Text": "07 80.",
        "Entity": "Normal"
    },
    {
        "Text": "27 80.",
        "Entity": "Normal"
    },
    {
        "Text": "67 95.",
        "Entity": "Normal"
    },
    {
        "Text": "58 95.",
        "Entity": "Normal"
    },
    {
        "Text": "49 99.",
        "Entity": "Normal"
    },
    {
        "Text": "95 B a s e li n e ( S e lf t a g ) 70 a l l B i k e l ( v 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 ) B a s e l i n e ( P r e t a g ) 7 0 a l l G o l d P O S 70 0.7 70 0.801 278 0.7 52 0.794 278 0.7 71 0.804 295 0.7 52 0.796 295 0.7 75 0.808 309 77.",
        "Entity": "Normal"
    },
    {
        "Text": "92 76.",
        "Entity": "Normal"
    },
    {
        "Text": "00 76.",
        "Entity": "Normal"
    },
    {
        "Text": "95 76.",
        "Entity": "Normal"
    },
    {
        "Text": "96 75.",
        "Entity": "Normal"
    },
    {
        "Text": "01 75.",
        "Entity": "Normal"
    },
    {
        "Text": "97 78.",
        "Entity": "Normal"
    },
    {
        "Text": "35 76.",
        "Entity": "Normal"
    },
    {
        "Text": "72 77.",
        "Entity": "Normal"
    },
    {
        "Text": "52 77.",
        "Entity": "Normal"
    },
    {
        "Text": "31 75.",
        "Entity": "Normal"
    },
    {
        "Text": "64 76.",
        "Entity": "Normal"
    },
    {
        "Text": "47 78.",
        "Entity": "Normal"
    },
    {
        "Text": "83 77.",
        "Entity": "Normal"
    },
    {
        "Text": "18 77.",
        "Entity": "Normal"
    },
    {
        "Text": "99 94.",
        "Entity": "Normal"
    },
    {
        "Text": "64 94.",
        "Entity": "Normal"
    },
    {
        "Text": "63 95.",
        "Entity": "Normal"
    },
    {
        "Text": "68 95.",
        "Entity": "Normal"
    },
    {
        "Text": "68 96.",
        "Entity": "Normal"
    },
    {
        "Text": "60 ( P e tr o v, 2 0 0 9 ) all B e r k e l e y ( S e p .",
        "Entity": "Normal"
    },
    {
        "Text": "0 9 ) B a s e l i n e 7 0 a l l G o l d P O S 70 \u2014 \u2014 \u2014 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 0 9 0.839 335 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 9\n\t\n\t\n\t\t\t0 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 1 0.859 496 76.",
        "Entity": "Normal"
    },
    {
        "Text": "40 75.",
        "Entity": "Normal"
    },
    {
        "Text": "30 75.",
        "Entity": "Normal"
    },
    {
        "Text": "85 82.",
        "Entity": "Normal"
    },
    {
        "Text": "32 81.",
        "Entity": "Normal"
    },
    {
        "Text": "63 81.",
        "Entity": "Normal"
    },
    {
        "Text": "97 81.",
        "Entity": "Normal"
    },
    {
        "Text": "43 80.",
        "Entity": "Normal"
    },
    {
        "Text": "73 81.",
        "Entity": "Normal"
    },
    {
        "Text": "08 84.",
        "Entity": "Normal"
    },
    {
        "Text": "37 84.",
        "Entity": "Normal"
    },
    {
        "Text": "21 84.",
        "Entity": "Normal"
    },
    {
        "Text": "29 \u2014 95.",
        "Entity": "Normal"
    },
    {
        "Text": "07 95.",
        "Entity": "Normal"
    },
    {
        "Text": "02 99.",
        "Entity": "Normal"
    },
    {
        "Text": "87                               \n\t\t\t                                             \n\t\t\t                                                                                                                                                                             \n\t\t\t                                                                                                                                        \n\t\t\t                                                                                  \n\t\t\tF1 85 Berkeley 80 Stanford.",
        "Entity": "Normal"
    },
    {
        "Text": "Bikel 75 training trees 5000 10000 15000                                                                 \n\t\t\t                                                                                                        \n\t\t\tThe Leaf Ancestor metric measures the cost of transforming guess trees to the reference (Sampson and Babarczy, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "It was developed in response to the non-terminal/terminal bias of Evalb, but Clegg and Shepherd (2005) showed that it is also a valuable diagnostic tool for trees with complex deep structures such as those found in the ATB.",
        "Entity": "Normal"
    },
    {
        "Text": "For each terminal, the Leaf Ancestor metric extracts the shortest path to the root.",
        "Entity": "Normal"
    },
    {
        "Text": "It then computes a normalized Levenshtein edit distance between the extracted chain and the reference.",
        "Entity": "Normal"
    },
    {
        "Text": "The range of the score is between 0 and 1 (higher is better).",
        "Entity": "Normal"
    },
    {
        "Text": "We report micro-averaged (whole corpus) and macro-averaged (per sentence) scores along add a constraint on the removal of punctuation, which has a single tag (PUNC) in the ATB.",
        "Entity": "Normal"
    },
    {
        "Text": "Tokens tagged as PUNC are not discarded unless they consist entirely of punctuation.",
        "Entity": "Normal"
    },
    {
        "Text": "with the number of exactly matching guess trees.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Parsing Models.",
        "Entity": "Normal"
    },
    {
        "Text": "The Stanford parser includes both the manually annotated grammar (\u00a74) and an Arabic unknown word model with the following lexical features: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Presence of the determiner J Al.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "Contains digits.",
        "Entity": "Normal"
    },
    {
        "Text": "3.",
        "Entity": "Normal"
    },
    {
        "Text": "Ends with the feminine affix :: p. 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Various verbal (e.g., \ufffd, .",
        "Entity": "Normal"
    },
    {
        "Text": "::) and adjectival.",
        "Entity": "Normal"
    },
    {
        "Text": "suffixes (e.g., \ufffd=) Other notable parameters are second order vertical Markovization and marking of unary rules.",
        "Entity": "Normal"
    },
    {
        "Text": "Modifying the Berkeley parser for Arabic is straightforward.",
        "Entity": "Normal"
    },
    {
        "Text": "After adding a ROOT node to all trees, we train a grammar using six split-and- merge cycles and no Markovization.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the default inference parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "Because the Bikel parser has been parameter- ized for Arabic by the LDC, we do not change the default model settings.",
        "Entity": "Normal"
    },
    {
        "Text": "However, when we pre- tag the input\u2014as is recommended for English\u2014 we notice a 0.57% F1 improvement.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the log-linear tagger of Toutanova et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2003), which gives 96.8% accuracy on the test set.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2 Discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "The Berkeley parser gives state-of-the-art performance for all metrics.",
        "Entity": "Normal"
    },
    {
        "Text": "Our baseline for all sentence lengths is 5.23% F1 higher than the best previous result.",
        "Entity": "Normal"
    },
    {
        "Text": "The difference is due to more careful S-NOM NP NP NP VP VBG :: b NP restoring NP ADJP NN :: b NP NN NP NP ADJP DTJJ ADJP DTJJ NN :: b NP NP NP ADJP ADJP DTJJ J ..i NN :: b NP NP NP ADJP ADJP DTJJ NN _;\ufffd NP PRP DTJJ DTJJ J ..i _;\ufffd PRP J ..i NN _;\ufffd NP PRP DTJJ NN _;\ufffd NP PRP DTJJ J ..i role its constructive effective (b) Stanford (c) Berkeley (d) Bik el (a) Reference Figure 4: The constituent Restoring of its constructive and effective role parsed by the three different models (gold segmentation).",
        "Entity": "Normal"
    },
    {
        "Text": "The ATB annotation distinguishes between verbal and nominal readings of maSdar process nominals.",
        "Entity": "Normal"
    },
    {
        "Text": "Like verbs, maSdar takes arguments and assigns case to its objects, whereas it also demonstrates nominal characteristics by, e.g., taking determiners and heading iDafa (Fassi Fehri, 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "In the ATB, :: b asta\u2019adah is tagged 48 times as a noun and 9 times as verbal noun.",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, all three parsers prefer the nominal reading.",
        "Entity": "Normal"
    },
    {
        "Text": "None of the models attach the attributive adjectives correctly.",
        "Entity": "Normal"
    },
    {
        "Text": "pre-processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, the Stanford parser achieves the most exact Leaf Ancestor matches and tagging accuracy that is only 0.1% below the Bikel model, which uses pre-tagged input.",
        "Entity": "Normal"
    },
    {
        "Text": "The errors shown are from the Berkeley parser output, but they are representative of the other two parsing models.",
        "Entity": "Normal"
    },
    {
        "Text": "6 Joint Segmentation and Parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the segmentation requirements for Arabic are not as extreme as those for Chinese, Arabic is written with certain cliticized prepositions, pronouns, and connectives connected to adjacent words.",
        "Entity": "Normal"
    },
    {
        "Text": "Since these are distinct syntactic units, they are typically segmented.",
        "Entity": "Normal"
    },
    {
        "Text": "The ATB segmentation scheme is one of many alternatives.",
        "Entity": "Normal"
    },
    {
        "Text": "Until now, all evaluations of Arabic parsing\u2014including the experiments in the previous section\u2014have assumed gold segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "But gold segmentation is not available in application settings, so a segmenter and parser are arranged in a pipeline.",
        "Entity": "Normal"
    },
    {
        "Text": "Segmentation errors cascade into the parsing phase, placing an artificial limit on parsing performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Lattice parsing (Chappelier et al., 1999) is an alternative to a pipeline that prevents cascading errors by placing all segmentation options into the parse chart.",
        "Entity": "Normal"
    },
    {
        "Text": "Recently, lattices have been used successfully in the parsing of Hebrew (Tsarfaty, 2006; Cohen and Smith, 2007), a Semitic language with similar properties to Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "We extend the Stanford parser to accept pre-generated lattices, where each word is represented as a finite state automaton.",
        "Entity": "Normal"
    },
    {
        "Text": "To combat the proliferation of parsing edges, we prune the lattices according to a hand-constructed lexicon of 31 clitics listed in the ATB annotation guidelines (Maamouri et al., 2009a).",
        "Entity": "Normal"
    },
    {
        "Text": "Formally, for a lexicon L and segments I \u2208 L, O \u2208/ L, each word automaton accepts the language I\u2217(O + I)I\u2217.",
        "Entity": "Normal"
    },
    {
        "Text": "Aside from adding a simple rule to correct alif deletion caused by the preposition J, no other language-specific processing is performed.",
        "Entity": "Normal"
    },
    {
        "Text": "Our evaluation includes both weighted and un- weighted lattices.",
        "Entity": "Normal"
    },
    {
        "Text": "We weight edges using a unigram language model estimated with Good- Turing smoothing.",
        "Entity": "Normal"
    },
    {
        "Text": "Despite their simplicity, uni- gram weights have been shown as an effective feature in segmentation models (Dyer, 2009).13 The joint parser/segmenter is compared to a pipeline that uses MADA (v3.0), a state-of-the-art Arabic segmenter, configured to replicate ATB segmentation (Habash and Rambow, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "MADA uses an ensemble of SVMs to first re-rank the output of a deterministic morphological analyzer.",
        "Entity": "Normal"
    },
    {
        "Text": "For each 13 Of course, this weighting makes the PCFG an improper distribution.",
        "Entity": "Normal"
    },
    {
        "Text": "However, in practice, unknown word models also make the distribution improper.",
        "Entity": "Normal"
    },
    {
        "Text": "Parent Head Modif er Dir # gold F1 Label # gold F1 NP NP TAG R 946 0.54 ADJP 1216 59.45 S S S R 708 0.57 SBAR 2918 69.81 NP NP ADJ P R 803 0.64 FRAG 254 72.87 NP NP N P R 2907 0.66 VP 5507 78.83 NP NP SBA R R 1035 0.67 S 6579 78.91 NP NP P P R 2713 0.67 PP 7516 80.93 VP TAG P P R 3230 0.80 NP 34025 84.95 NP NP TAG L 805 0.85 ADVP 1093 90.64 VP TAG SBA R R 772 0.86 WHN P 787 96.00 S VP N P L 961 0.87 (a) Major phrasal categories (b) Major POS categories (c) Ten lowest scoring (Collins, 2003)-style dependencies occurring more than 700 times                                                                                                                    \n\t\t\t                                                                                                                   \n\t\t\t                                                                                                                       \n\t\t\t                                                                                                                            \n\t\t\t                                                                                                                                                                                                    \n\t\t\t                                                                                                                         \n\t\t\t                                                                                    \n\t\t\tinput token, the segmentation is then performed deterministically given the 1-best analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "Since guess and gold trees may now have different yields, the question of evaluation is complex.",
        "Entity": "Normal"
    },
    {
        "Text": "Cohen and Smith (2007) chose a metric like SParseval (Roark et al., 2006) that first aligns the trees and then penalizes segmentation errors with an edit-distance metric.",
        "Entity": "Normal"
    },
    {
        "Text": "But we follow the more direct adaptation of Evalb suggested by Tsarfaty (2006), who viewed exact segmentation as the ultimate goal.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we only score guess/gold pairs with identical character yields, a condition that allows us to measure parsing, tagging, and segmentation accuracy by ignoring whitespace.",
        "Entity": "Normal"
    },
    {
        "Text": "However, MADA is language-specific and relies on manually constructed dictionaries.",
        "Entity": "Normal"
    },
    {
        "Text": "Conversely, the lattice parser requires no linguistic resources and produces segmentations of comparable quality.",
        "Entity": "Normal"
    },
    {
        "Text": "Nonetheless, parse quality is much lower in the joint model because a lattice is effectively a long sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "A cell in the bottom row of the parse chart is required for each potential whitespace boundary.",
        "Entity": "Normal"
    },
    {
        "Text": "As we have said, parse quality decreases with sentence length.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew.",
        "Entity": "Normal"
    },
    {
        "Text": "Coverage indicates the fraction of hypotheses in which the character yield exactly matched the reference.",
        "Entity": "Normal"
    },
    {
        "Text": "Each model was able to produce hypotheses for all input sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "By establishing significantly higher parsing baselines, we have shown that Arabic parsing performance is not as poor as previously thought, but remains much lower than English.",
        "Entity": "Normal"
    },
    {
        "Text": "We have described grammar state splits that significantly improve parsing performance, catalogued parsing errors, and quantified the effect of segmentation errors.",
        "Entity": "Normal"
    },
    {
        "Text": "With a human evaluation we also showed that ATB inter-annotator agreement remains low relative to the WSJ corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Our results suggest that current parsing models would benefit from better annotation consistency and enriched annotation in certain syntactic configurations.",
        "Entity": "Normal"
    },
    {
        "Text": "Acknowledgments We thank Steven Bethard, Evan Rosen, and Karen Shiells for material contributions to this work.",
        "Entity": "Normal"
    },
    {
        "Text": "We are also grateful to Markus Dickinson, Ali Farghaly, Nizar Habash, Seth Kulick, David McCloskey, Claude Reichard, Ryan Roth, and Reut Tsarfaty for constructive discussions.",
        "Entity": "Normal"
    },
    {
        "Text": "The first author is supported by a National Defense Science and Engineering Graduate (NDSEG) fellowship.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper is based on work supported in part by DARPA through IBM.",
        "Entity": "Normal"
    },
    {
        "Text": "The content does not necessarily reflect the views of the U.S. Government, and no official endorsement should be inferred.",
        "Entity": "Normal"
    },
    {
        "Text": "\nNamed Entity Recognition: A Maximum Entropy Approach Using Global Information\n\t\n\t\tThis paper presents a maximum entropy-based named entity recognizer (NER).",
        "Entity": "Normal"
    },
    {
        "Text": "It differs from previous machine learning-based NERs in that it uses information from the whole document to classify each word, with just one classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous work that involves the gathering of information from the whole document often uses a secondary classifier, which corrects the mistakes of a primary sentence- based classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we show that the maximum entropy framework is able to make use of global information directly, and achieves performance that is comparable to the best previous machine learning-based NERs on MUC6 and MUC7 test data.",
        "Entity": "Normal"
    },
    {
        "Text": "Considerable amount of work has been done in recent years on the named entity recognition task, partly due to the Message Understanding Conferences (MUC).",
        "Entity": "Normal"
    },
    {
        "Text": "A named entity recognizer (NER) is useful in many NLP applications such as information extraction, question answering, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "On its own, a NER can also provide users who are looking for person or organization names with quick information.",
        "Entity": "Normal"
    },
    {
        "Text": "In MUC6 and MUC7, the named entity task is defined as finding the following classes of names: person, organization, location, date, time, money, and percent (Chinchor, 1998; Sundheim, 1995) Machine learning systems in MUC6 and MUC 7 achieved accuracy comparable to rule-based systems on the named entity task.",
        "Entity": "Normal"
    },
    {
        "Text": "Statistical NERs usually find the sequence of tags that maximizes the probability , where is the sequence of words in a sentence, and is the sequence of named-entity tags assigned to the words in .",
        "Entity": "Normal"
    },
    {
        "Text": "Attempts have been made to use global information (e.g., the same named entity occurring in different sentences of the same document), but they usually consist of incorporating an additional classifier, which tries to correct the errors in the output of a first NER (Mikheev et al., 1998; Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "We propose maximizing , where is the sequence of named- entity tags assigned to the words in the sentence , and is the information that can be extracted from the whole document containing .",
        "Entity": "Normal"
    },
    {
        "Text": "Our system is built on a maximum entropy classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "By making use of global context, it has achieved excellent results on both MUC6 and MUC7 official test data.",
        "Entity": "Normal"
    },
    {
        "Text": "We will refer to our system as MENERGI (Maximum Entropy Named Entity Recognizer using Global Information).",
        "Entity": "Normal"
    },
    {
        "Text": "As far as we know, no other NERs have used information from the whole document (global) as well as information within the same sentence (local) in one framework.",
        "Entity": "Normal"
    },
    {
        "Text": "The use of global features has improved the performance on MUC6 test data from 90.75% to 93.27% (27% reduction in errors), and the performance on MUC7 test data from 85.22% to 87.24% (14% reduction in errors).",
        "Entity": "Normal"
    },
    {
        "Text": "These results are achieved by training on the official MUC6 and MUC7 training data, which is much less training data than is used by other machine learning systems that worked on the MUC6 or MUC7 named entity task (Bikel et al., 1997; Bikel et al., 1999; Borth- wick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "We believe it is natural for authors to use abbreviations in subsequent mentions of a named entity (i.e., first \u201cPresident George Bush\u201d then \u201cBush\u201d).",
        "Entity": "Normal"
    },
    {
        "Text": "As such, global information from the whole context of a document is important to more accurately recognize named entities.",
        "Entity": "Normal"
    },
    {
        "Text": "Although we have not done any experiments on other languages, this way of using global features from a whole document should be applicable to other languages.",
        "Entity": "Normal"
    },
    {
        "Text": "Recently, statistical NERs have achieved results that are comparable to hand-coded systems.",
        "Entity": "Normal"
    },
    {
        "Text": "Since MUC6, BBN' s Hidden Markov Model (HMM) based IdentiFinder (Bikel et al., 1997) has achieved remarkably good performance.",
        "Entity": "Normal"
    },
    {
        "Text": "MUC7 has also seen hybrids of statistical NERs and hand-coded systems (Mikheev et al., 1998; Borthwick, 1999), notably Mikheev' s system, which achieved the best performance of 93.39% on the official NE test data.",
        "Entity": "Normal"
    },
    {
        "Text": "MENE (Maximum Entropy Named Entity) (Borth- wick, 1999) was combined with Proteus (a hand- coded system), and came in fourth among all MUC 7 participants.",
        "Entity": "Normal"
    },
    {
        "Text": "MENE without Proteus, however, did not do very well and only achieved an F measure of 84.22% (Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Among machine learning-based NERs, Identi- Finder has proven to be the best on the official MUC6 and MUC7 test data.",
        "Entity": "Normal"
    },
    {
        "Text": "MENE (without the help of hand-coded systems) has been shown to be somewhat inferior in performance.",
        "Entity": "Normal"
    },
    {
        "Text": "By using the output of a hand-coded system such as Proteus, MENE can improve its performance, and can even outperform IdentiFinder (Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Mikheev et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998) did make use of information from the whole document.",
        "Entity": "Normal"
    },
    {
        "Text": "However, their system is a hybrid of hand-coded rules and machine learning methods.",
        "Entity": "Normal"
    },
    {
        "Text": "Another attempt at using global information can be found in (Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "He used an additional maximum entropy classifier that tries to correct mistakes by using reference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Reference resolution involves finding words that co-refer to the same entity.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to train this error-correction model, he divided his training corpus into 5 portions of 20% each.",
        "Entity": "Normal"
    },
    {
        "Text": "MENE is then trained on 80% of the training corpus, and tested on the remaining 20%.",
        "Entity": "Normal"
    },
    {
        "Text": "This process is repeated 5 times by rotating the data appropriately.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the concatenated 5 * 20% output is used to train the reference resolution component.",
        "Entity": "Normal"
    },
    {
        "Text": "We will show that by giving the first model some global features, MENERGI outperforms Borthwick' s reference resolution classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "On MUC6 data, MENERGI also achieves performance comparable to IdentiFinder when trained on similar amount of training data.",
        "Entity": "Normal"
    },
    {
        "Text": "both MENE and IdentiFinder used more training data than we did (we used only the official MUC 6 and MUC7 training data).",
        "Entity": "Normal"
    },
    {
        "Text": "On the MUC6 data, Bikel et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1997; 1999) do have some statistics that show how IdentiFinder performs when the training data is reduced.",
        "Entity": "Normal"
    },
    {
        "Text": "Our results show that MENERGI performs as well as IdentiFinder when trained on comparable amount of training data.",
        "Entity": "Normal"
    },
    {
        "Text": "The system described in this paper is similar to the MENE system of (Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "It uses a maximum entropy framework and classifies each word given its features.",
        "Entity": "Normal"
    },
    {
        "Text": "Each name class is subdivided into 4 sub-classes, i.e., N begin, N continue, N end, and N unique.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, there is a total of 29 classes (7 name classes 4 sub-classes 1 not-a-name class).",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Maximum Entropy.",
        "Entity": "Normal"
    },
    {
        "Text": "The maximum entropy framework estimates probabilities based on the principle of making as few assumptions as possible, other than the constraints imposed.",
        "Entity": "Normal"
    },
    {
        "Text": "Such constraints are derived from training data, expressing some relationship between features and outcome.",
        "Entity": "Normal"
    },
    {
        "Text": "The probability distribution that satisfies the above property is the one with the highest entropy.",
        "Entity": "Normal"
    },
    {
        "Text": "It is unique, agrees with the maximum-likelihood distribution, and has the exponential form (Della Pietra et al., 1997): where refers to the outcome, the history (or context), and is a normalization function.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, each feature function is a binary function.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in predicting if a word belongs to a word class, is either true or false, and refers to the surrounding context: if = true, previous word = the otherwise The parameters are estimated by a procedure called Generalized Iterative Scaling (GIS) (Darroch and Ratcliff, 1972).",
        "Entity": "Normal"
    },
    {
        "Text": "This is an iterative method that improves the estimation of the parameters at each iteration.",
        "Entity": "Normal"
    },
    {
        "Text": "We have used the Java-based opennlp maximum entropy package1.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 5, we try to compare results of MENE, IdentiFinder, and MENERGI.",
        "Entity": "Normal"
    },
    {
        "Text": "However, 1 http://maxent.sourceforge.net 3.2 Testing.",
        "Entity": "Normal"
    },
    {
        "Text": "During testing, it is possible that the classifier produces a sequence of inadmissible classes (e.g., person begin followed by location unique).",
        "Entity": "Normal"
    },
    {
        "Text": "To eliminate such sequences, we define a transition probability between word classes to be equal to 1 if the sequence is admissible, and 0 otherwise.",
        "Entity": "Normal"
    },
    {
        "Text": "The probability of the classes assigned to the words in a sentence in a document is defined as follows: where is determined by the maximum entropy classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "A dynamic programming algorithm is then used to select the sequence of word classes with the highest probability.",
        "Entity": "Normal"
    },
    {
        "Text": "The features we used can be divided into 2 classes: local and global.",
        "Entity": "Normal"
    },
    {
        "Text": "Local features are features that are based on neighboring tokens, as well as the token itself.",
        "Entity": "Normal"
    },
    {
        "Text": "Global features are extracted from other occurrences of the same token in the whole document.",
        "Entity": "Normal"
    },
    {
        "Text": "The local features used are similar to those used in BBN' s IdentiFinder (Bikel et al., 1999) or MENE (Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "However, to classify a token , while Borthwick uses tokens from to (from two tokens before to two tokens after ), we used only the tokens , , and .",
        "Entity": "Normal"
    },
    {
        "Text": "Even with local features alone, MENERGI outperforms MENE (Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "This might be because our features are more comprehensive than those used by Borthwick.",
        "Entity": "Normal"
    },
    {
        "Text": "In IdentiFinder, there is a priority in the feature assignment, such that if one feature is used for a token, another feature lower in priority will not be used.",
        "Entity": "Normal"
    },
    {
        "Text": "In the maximum entropy framework, there is no such constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "Multiple features can be used for the same token.",
        "Entity": "Normal"
    },
    {
        "Text": "Feature selection is implemented using a feature cutoff: features seen less than a small count during training will not be used.",
        "Entity": "Normal"
    },
    {
        "Text": "We group the features used into feature groups.",
        "Entity": "Normal"
    },
    {
        "Text": "Each feature group can be made up of many binary features.",
        "Entity": "Normal"
    },
    {
        "Text": "For each token , zero, one, or more of the features in each feature group are set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Local Features.",
        "Entity": "Normal"
    },
    {
        "Text": "The local feature groups are: Non-Contextual Feature: This feature is set to 1 for all tokens.",
        "Entity": "Normal"
    },
    {
        "Text": "This feature imposes constraints                                                                                                                  \n\t\t\tZone: MUC data contains SGML tags, and a document is divided into zones (e.g., headlines and text zones).",
        "Entity": "Normal"
    },
    {
        "Text": "The zone to which a token belongs is used as a feature.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in MUC6, there are four zones (TXT, HL, DATELINE, DD).",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, for each token, one of the four features zone-TXT, zone- HL, zone-DATELINE, or zone-DD is set to 1, and the other 3 are set to 0.",
        "Entity": "Normal"
    },
    {
        "Text": "Case and Zone:                                                                                                                .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "This group consists of (3 total number of possible zones) features.",
        "Entity": "Normal"
    },
    {
        "Text": "Case and Zone of and : Similarly, if (or ) is initCaps, a feature (initCaps, zone) (or (initCaps, zone) ) is set to 1, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "Token Information:                                                                               \n\t\t\t                                                                                                                                          .",
        "Entity": "Normal"
    },
    {
        "Text": "First Word: This feature group contains only one feature firstword.",
        "Entity": "Normal"
    },
    {
        "Text": "If the token is the first word of a sentence, then this feature is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Otherwise, it is set to 0.",
        "Entity": "Normal"
    },
    {
        "Text": "Lexicon Feature: The string of the token is used as a feature.",
        "Entity": "Normal"
    },
    {
        "Text": "This group contains a large number of features (one for each token string present in the training data).",
        "Entity": "Normal"
    },
    {
        "Text": "At most one feature in this group will be set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "If is seen infrequently during training (less than a small count), then will not be selected as a feature and all features in this group are set to 0.",
        "Entity": "Normal"
    },
    {
        "Text": "Lexicon Feature of Previous and Next Token: The string of the previous token and the next token is used with the initCaps information of .",
        "Entity": "Normal"
    },
    {
        "Text": "If has initCaps, then a feature (initCaps, ) is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "If is not initCaps, then (not-initCaps, ) is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Same for .",
        "Entity": "Normal"
    },
    {
        "Text": "In the case where the next token is a hyphen, then is also used as a feature: (init- Caps, ) is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "This is because in many cases, the use of hyphens can be considered to be optional (e.g., third-quarter or third quarter).",
        "Entity": "Normal"
    },
    {
        "Text": "Out-of-Vocabulary: We derived a lexicon list from WordNet 1.6, and words that are not found in this list have a feature out-of-vocabulary set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Dictionaries: Due to the limited amount of training material, name dictionaries have been found to be useful in the named entity task.",
        "Entity": "Normal"
    },
    {
        "Text": "The importance of dictionaries in NERs has been investigated in the literature (Mikheev et al., 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "For all lists except locations, the lists are processed into a list of tokens (unigrams).",
        "Entity": "Normal"
    },
    {
        "Text": "Location list is processed into a list of unigrams and bigrams (e.g., New York).",
        "Entity": "Normal"
    },
    {
        "Text": "For locations, tokens are matched against unigrams, and sequences of two consecutive tokens are matched against bigrams.",
        "Entity": "Normal"
    },
    {
        "Text": "A list of words occurring more than 10 times in the training data is also collected (commonWords).",
        "Entity": "Normal"
    },
    {
        "Text": "If they are found in a list, then a feature for that list will be set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, if Barry is not in commonWords and is found in the list of person first names, then the feature PersonFirstName will be set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, the tokens and are tested against each list, and if found, a corresponding feature will be set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, if is found in the list of person first names, the feature PersonFirstName is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Month Names, Days of the Week, and Numbers: If is initCaps and is one of January, February, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", December, then the feature MonthName is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "If is one of Monday, Tuesday, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", Sun day, then the feature DayOfTheWeek is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "If is a number string (such as one, two, etc), then the feature NumberString is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Suffixes and Prefixes: This group contains only two features: Corporate-Suffix and Person-Prefix.",
        "Entity": "Normal"
    },
    {
        "Text": "Two lists, Corporate-Suffix-List (for corporate suffixes) and Person-Prefix-List (for person prefixes), are collected from the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "For corporate suffixes, a list of tokens cslist that occur frequently as the last token of an organization name is collected from the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Frequency is calculated by counting the number of distinct previous tokens that each token has (e.g., if Electric Corp. is seen 3 times, and Manufacturing Corp. is seen 5 times during training, and Corp. is not seen with any other preceding tokens, then the \u201cfrequency\u201d of Corp. is 2).",
        "Entity": "Normal"
    },
    {
        "Text": "The most frequently occurring last words of organization names in cslist are compiled into a list of corporate suffixes, Corporate-Suffix- List.",
        "Entity": "Normal"
    },
    {
        "Text": "A Person-Prefix-List is compiled in an analogous way.",
        "Entity": "Normal"
    },
    {
        "Text": "For MUC6, for example, Corporate- Suffix-List is made up of ltd., associates, inc., co, corp, ltd, inc, committee, institute, commission, university, plc, airlines, co., corp. and Person-Prefix- List is made up of succeeding, mr., rep., mrs., secretary, sen., says, minister, dr., chairman, ms. .",
        "Entity": "Normal"
    },
    {
        "Text": "For a token that is in a consecutive sequence of init then a feature Corporate-Suffix is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "If any of the tokens from to is in Person-Prefix- List, then another feature Person-Prefix is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that we check for , the word preceding the consecutive sequence of initCaps tokens, since person prefixes like Mr., Dr., etc are not part of person names, whereas corporate suffixes like Corp., Inc., etc are part of corporate names.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Global Features.",
        "Entity": "Normal"
    },
    {
        "Text": "Context from the whole document can be important in classifying a named entity.",
        "Entity": "Normal"
    },
    {
        "Text": "A name already mentioned previously in a document may appear in abbreviated form when it is mentioned again later.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous work deals with this problem by correcting inconsistencies between the named entity classes assigned to different occurrences of the same entity (Borthwick, 1999; Mikheev et al., 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "We often encounter sentences that are highly ambiguous in themselves, without some prior knowledge of the entities concerned.",
        "Entity": "Normal"
    },
    {
        "Text": "For example: McCann initiated a new global system.",
        "Entity": "Normal"
    },
    {
        "Text": "(1) CEO of McCann .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "(2) Description Source Location Names http://www.timeanddate.com http://www.cityguide.travel-guides.com http://www.worldtravelguide.net Corporate Names http://www.fmlx.com Person First Names http://www.census.gov/genealogy/names Person Last Names                                  The McCann family .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "(3)In sentence (1), McCann can be a person or an orga nization.",
        "Entity": "Normal"
    },
    {
        "Text": "Sentence (2) and (3) help to disambiguate one way or the other.",
        "Entity": "Normal"
    },
    {
        "Text": "If all three sentences are in the same document, then even a human will find it difficult to classify McCann in (1) into either person or organization, unless there is some other information provided.",
        "Entity": "Normal"
    },
    {
        "Text": "The global feature groups are: InitCaps of Other Occurrences (ICOC): There are 2 features in this group, checking for whether the first occurrence of the same word in an unambiguous position (non first-words in the TXT or TEXT zones) in the same document is initCaps or not-initCaps.",
        "Entity": "Normal"
    },
    {
        "Text": "For a word whose initCaps might be due to its position rather than its meaning (in headlines, first word of a sentence, etc), the case information of other occurrences might be more accurate than its own.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in the sentence that starts with \u201cBush put a freeze on .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "\u201d, because Bush is the first word, the initial caps might be due to its position (as in \u201cThey put a freeze on .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "\u201d).",
        "Entity": "Normal"
    },
    {
        "Text": "If somewhere else in the document we see \u201crestrictions put in place by President Bush\u201d, then we can be surer that Bush is a name.",
        "Entity": "Normal"
    },
    {
        "Text": "Corporate Suffixes and Person Prefixes of Other Occurrences (CSPP): If McCann has been seen as Mr. McCann somewhere else in the document, then one would like to give person a higher probability than organization.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, if it is seen as McCann Pte.",
        "Entity": "Normal"
    },
    {
        "Text": "Ltd., then organization will be more probable.",
        "Entity": "Normal"
    },
    {
        "Text": "With the same Corporate- Suffix-List and Person-Prefix-List used in local features, for a token seen elsewhere in the same document with one of these suffixes (or prefixes), another feature Other-CS (or Other-PP) is set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Acronyms (ACRO): Words made up of all capitalized letters in the text zone will be stored as acronyms (e.g., IBM).",
        "Entity": "Normal"
    },
    {
        "Text": "The system will then look for sequences of initial capitalized words that match the acronyms found in the whole document.",
        "Entity": "Normal"
    },
    {
        "Text": "Such sequences are given additional features of A begin, A continue, or A end, and the acronym is given a feature A unique.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, if FCC and Federal Communications Commission are both found in a document, then Federal has A begin set to 1, Communications has A continue set to 1, Commission has A end set to 1, and FCC has A unique set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Sequence of Initial Caps (SOIC): In the sentence Even News Broadcasting Corp., noted for its accurate reporting, made the erroneous announcement., a NER may mistake Even News Broadcasting Corp. as an organization name.",
        "Entity": "Normal"
    },
    {
        "Text": "However, it is unlikely that other occurrences of News Broadcasting Corp. in the same document also co-occur with Even.",
        "Entity": "Normal"
    },
    {
        "Text": "This group of features attempts to capture such information.",
        "Entity": "Normal"
    },
    {
        "Text": "For every sequence of initial capitalized words, its longest substring that occurs in the same document as a sequence of initCaps is identified.",
        "Entity": "Normal"
    },
    {
        "Text": "For this example, since the sequence Even News Broadcasting Corp. only appears once in the document, its longest substring that occurs in the same document is News Broadcasting Corp.",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, News has an additional feature of I begin set to 1, Broadcasting has an additional feature of I continue set to 1, and Corp. has an additional feature of I end set to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Unique Occurrences and Zone (UNIQ): This group of features indicates whether the word is unique in the whole document.",
        "Entity": "Normal"
    },
    {
        "Text": "needs to be in initCaps to be considered for this feature.",
        "Entity": "Normal"
    },
    {
        "Text": "If is unique, then a feature (Unique, Zone) is set to 1, where Zone is the document zone where appears.",
        "Entity": "Normal"
    },
    {
        "Text": "MUC6 MUC7 Baseline 90.75% 85.22% + ICOC 91.50% 86.24% + CSPP 92.89% 86.96% + ACRO 93.04% 86.99% + SOIC 93.25% 87.22% + UNIQ 93.27% 87.24%                                                                                                                   Systems MUC6 MUC7 No.",
        "Entity": "Normal"
    },
    {
        "Text": "of Articles No.",
        "Entity": "Normal"
    },
    {
        "Text": "of Tokens No.",
        "Entity": "Normal"
    },
    {
        "Text": "of Articles No.",
        "Entity": "Normal"
    },
    {
        "Text": "of Tokens MENERGI 318 160,000 200 180,000 IdentiFinder \u2013 650,000 \u2013 790,000 MENE \u2013 \u2013 350 321,000                                           2                                                                                  \n\t\t\tICOC and CSPP contributed the greatest im provements.",
        "Entity": "Normal"
    },
    {
        "Text": "The effect of UNIQ is very small on both data sets.",
        "Entity": "Normal"
    },
    {
        "Text": "All our results are obtained by using only the official training data provided by the MUC conferences.",
        "Entity": "Normal"
    },
    {
        "Text": "The reason why we did not train with both MUC6 and MUC7 training data at the same time is because the task specifications for the two tasks are not identical.",
        "Entity": "Normal"
    },
    {
        "Text": "IdentiFinder ' 99' s results are considerably better than IdentiFinder ' 97' s. IdentiFinder' s performance in MUC7 is published in (Miller et al., 1998).",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Besides size of training data, the use of dictionaries is another factor that might affect performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Bikel et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1999) did not report using any dictionaries, but mentioned in a footnote that they have added list membership features, which have helped marginally in certain domains.",
        "Entity": "Normal"
    },
    {
        "Text": "Borth 2MUC data can be obtained from the Linguistic Data Consortium: http://www.ldc.upenn.edu 3Training data for IdentiFinder is actually given in words (i.e., 650K & 790K words), rather than tokens                                         wick (1999) reported using dictionaries of person first names, corporate names and suffixes, colleges and universities, dates and times, state abbreviations, and world regions.",
        "Entity": "Normal"
    },
    {
        "Text": "In (Bikel et al., 1997) and (Bikel et al., 1999), performance was plotted against training data size to show how performance improves with training data size.",
        "Entity": "Normal"
    },
    {
        "Text": "We have estimated the performance of IdentiFinder ' 99 at 200K words of training data from the graphs.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, training on the official training data is not suitable as the articles in this data set are entirely about aviation disasters, and the test data is about air vehicle launching.",
        "Entity": "Normal"
    },
    {
        "Text": "Both BBN and NYU have tagged their own data to supplement the official training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Even with less training data, MENERGI outperforms Borthwick' s MENE + reference resolution (Borthwick, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "The effect of a second reference resolution classifier is not entirely the same as that of global features.",
        "Entity": "Normal"
    },
    {
        "Text": "A secondary reference resolution classifier has information on the class assigned by the primary classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "Such a classification can be seen as a not-always-correct summary of global features.",
        "Entity": "Normal"
    },
    {
        "Text": "The secondary classifier in (Borthwick, 1999) uses information not just from the current article, but also from the whole test corpus, with an additional feature that indicates if the information comes from the same document or from another document.",
        "Entity": "Normal"
    },
    {
        "Text": "We feel that information from a whole corpus might turn out to be noisy if the documents in the corpus are not of the same genre.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, if we want to test on a huge test corpus, indexing the whole corpus might prove computationally expensive.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence we decided to restrict ourselves to only information from the same document.",
        "Entity": "Normal"
    },
    {
        "Text": "Mikheev et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998) have also used a maximum entropy classifier that uses already tagged entities to help tag other entities.",
        "Entity": "Normal"
    },
    {
        "Text": "The overall performance of the LTG system was outstanding, but the system consists of a sequence of many hand-coded rules and machine-learning modules.",
        "Entity": "Normal"
    },
    {
        "Text": "We have shown that the maximum entropy framework is able to use global information directly.",
        "Entity": "Normal"
    },
    {
        "Text": "This enables us to build a high performance NER without using separate classifiers to take care of global consistency or complex formulation on smoothing and backoff models (Bikel et al., 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "Using less training data than other systems, our NER is able to perform as well as other state-of-the-art NERs.",
        "Entity": "Normal"
    },
    {
        "Text": "Information from a sentence is sometimes insufficient to classify a name correctly.",
        "Entity": "Normal"
    },
    {
        "Text": "Global context from the whole document is available and can be exploited in a natural manner with a maximum entropy classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "We believe that the underlying principles of the maximum entropy framework are suitable for exploiting information from diverse sources.",
        "Entity": "Normal"
    },
    {
        "Text": "Borth- wick (1999) successfully made use of other hand- coded systems as input for his MENE system, and achieved excellent results.",
        "Entity": "Normal"
    },
    {
        "Text": "However, such an approach requires a number of hand-coded systems, which may not be available in languages other than English.",
        "Entity": "Normal"
    },
    {
        "Text": "We believe that global context is useful in most languages, as it is a natural tendency for authors to use abbreviations on entities already mentioned previously.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tText prediction is a form of interactive machine translation that is well suited to skilled translators.",
        "Entity": "Normal"
    },
    {
        "Text": "In principle it can assist in the production of a target text with minimal disruption to a translator s normal routine.",
        "Entity": "Normal"
    },
    {
        "Text": "However, recent evaluations of a prototype prediction system showed that it significantly decreased the productivity of most translators who used it.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we analyze the reasons for this and propose a solution which consists in seeking predictions that maximize the expected benefit to the translator, rather than just trying to anticipate some amount of upcoming text.",
        "Entity": "Normal"
    },
    {
        "Text": "Using a model of a  typical translator  constructed from data collected in the evaluations of the prediction prototype, we show that this approach has the potential to turn text prediction into a help rather than a hindrance to a translator.",
        "Entity": "Normal"
    },
    {
        "Text": "The idea of using text prediction as a tool for translators was first introduced by Church and Hovy as one of many possible applications for  crummy  machine translation technology (Church and Hovy, 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Text prediction can be seen as a form of interactive MT that is well suited to skilled translators.",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to the traditional form of IMT based on Kay s original work (Kay, 1973) in which the user s role is to help disambiguate the source text  prediction is less obtrusive and more natural, allowing the translator to focus on and directly control the contents of the target text.",
        "Entity": "Normal"
    },
    {
        "Text": "Predictions can benefit a translator in several ways: by accelerating typing, by suggesting translations, and by serving as an implicit check against errors.",
        "Entity": "Normal"
    },
    {
        "Text": "The first implementation of a predictive tool for translators was described in (Foster et al., 1997), in the form of a simple word-completion system based on statistical models.",
        "Entity": "Normal"
    },
    {
        "Text": "Various enhancements to this were carried out as part of the TransType project (Langlais et al., 2000), including the addition of a realistic user interface, better models, and the capability of predicting multi-word lexical units.",
        "Entity": "Normal"
    },
    {
        "Text": "In the final TransType prototype for English to French translation, the translator is presented with a short pop- up menu of predictions after each character typed.",
        "Entity": "Normal"
    },
    {
        "Text": "These may be incorporated into the text with a special command or rejected by continuing to type normally.",
        "Entity": "Normal"
    },
    {
        "Text": "Although TransType is capable of correctly anticipating over 70% of the characters in a freely-typed translation (within the domain of its training corpus), this does not mean that users can translate in 70% less time when using the tool.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, in a trial with skilled translators, the users  rate of text production declined by an average of 17% as a result of using TransType (Langlais et al., 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "There are two main reasons for this.",
        "Entity": "Normal"
    },
    {
        "Text": "First, it takes time to read the system s proposals, so that in cases where they are wrong or too short, the net effect will be to slow the translator down.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, translators do not always act  rationally  when confronted with a proposal; that is, they do not always accept correct proposals and they occasionally accept incorrect ones.",
        "Entity": "Normal"
    },
    {
        "Text": "Many of the former cases correspond to translators simply ignoring proposals altogether, which is understandable behaviour given the first point.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper describes a new approach to text prediction intended to address these problems.",
        "Entity": "Normal"
    },
    {
        "Text": "The main idea is to make predictions that maximize the expected benefit to the user in each context, rather than systematically proposing a fixed amount of text after each character typed.",
        "Entity": "Normal"
    },
    {
        "Text": "The expected benefit is estimated from two components: a statistical translation model that gives the probability that a candidate prediction will be correct or incorrect, and a user model that determines the benefit to the translator in either case.",
        "Entity": "Normal"
    },
    {
        "Text": "The user model takes into account the cost of reading a proposal, as well as the random nature of the decision to accept it or not.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach can be characterized as making fewer but better predictions: in general, predictions will be longer in contexts where the translation model is confident, shorter where it is less so, and absent in contexts where it is very uncertain.",
        "Entity": "Normal"
    },
    {
        "Text": "Other novel aspects of the work we describe here are the use of a more accurate statistical translation model than has previously been employed for text prediction, and the use of a decoder to generate predictions of arbitrary length, rather than just single words or lexicalized units as in the TransType prototype.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation model is based on the maximum entropy principle and is designed specifically for this application.",
        "Entity": "Normal"
    },
    {
        "Text": "To evaluate our approach to prediction, we simulated the actions of a translator over a large corpus of previously-translated text.",
        "Entity": "Normal"
    },
    {
        "Text": "The result is an increase of over 10% in translator productivity when using the predictive tool.",
        "Entity": "Normal"
    },
    {
        "Text": "This is a considerable improvement over the -17% observed in the TransType trials.",
        "Entity": "Normal"
    },
    {
        "Text": "In the basic prediction task, the input to the predictor is a source sentence s and a prefix h of its translation (ie, the target text before the current cursor position); the output is a proposed extension x to h. F                         \n\t\t\tUnlike the TransType prototype, which proposes a set of single-word (or single-unit) suggestions, we assume that each prediction consists of only a single proposal, but one that may span an arbitrary number of words.",
        "Entity": "Normal"
    },
    {
        "Text": "As described above, the goal of the predictor is to find the prediction x  that maximizes the expected s: Let us return to serious matters.",
        "Entity": "Normal"
    },
    {
        "Text": "h x  t: O n v a r e venir aux ch o ses se rieuses.",
        "Entity": "Normal"
    },
    {
        "Text": "x: evenir a`                                                                     \n\t\t\ts is the source sentence, h is the part of its translation that has already been typed, x  is what the translator wants to type, and x is the prediction.",
        "Entity": "Normal"
    },
    {
        "Text": "benefit to the user: x  = argmax B(x, h, s), (1) x where B(x, h, s) measures typing time saved.",
        "Entity": "Normal"
    },
    {
        "Text": "This obviously depends on how much of x is correct, and how long it would take to edit it into the desired text.",
        "Entity": "Normal"
    },
    {
        "Text": "A major simplifying assumption we make is that the user edits only by erasing wrong characters from the end of a proposal.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a TransType-style interface where acceptance places the cursor at the end of a proposal, this is the most common editing method, and it gives a conservative estimate of the cost attainable by other methods.",
        "Entity": "Normal"
    },
    {
        "Text": "With this assumption, the key determinant of edit cost is the length of the correct prefix of x, so the expected benefit can be written as: l B(x, h, s) = ) p(k|x, h, s) B(x, h, s, k), (2) k=0 where p(k|x, h, s) is the probability that exactly k characters from the beginning of x will be correct, l is the length of x, and B(x, h, s, k) is the benefit to the user given that the first k characters of x are correct.",
        "Entity": "Normal"
    },
    {
        "Text": "Equations (1) and (2) define three main problems: estimating the prefix probabilities p(k|x, h, s), estimating the user benefit function B(x, h, s, k), and searching for x .",
        "Entity": "Normal"
    },
    {
        "Text": "The following three sections describe our solutions to these.",
        "Entity": "Normal"
    },
    {
        "Text": "The correct-prefix probabilities p(k|x, h, s) are derived from a word-based statistical translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "The first step in the derivation is to convert these into a form that deals explicitly with character strings.",
        "Entity": "Normal"
    },
    {
        "Text": "This is accomplished by noting that p(k|x, h, s) is the probability that the first k characters of x are correct and that the k + 1th character (if there is one) is incorrect.",
        "Entity": "Normal"
    },
    {
        "Text": "For k < l: p(k|x, h, s) = p(xk |h, s)   p(xk+1|h, s) likelihood that a word w will follow a previous sequence of words h in the translation of s.1 This is the family of distributions we have concentrated on modeling.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model for p(w|h, s) is a log-linear combination of a trigram language model for p(w|h) and a maximum-entropy translation model for p(w|s), de1 1 scribed in (Foster, 2000a; Foster, 2000b).",
        "Entity": "Normal"
    },
    {
        "Text": "The trans lation component is an analog of the IBM model 2 where xk = x1 .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "xk .",
        "Entity": "Normal"
    },
    {
        "Text": "If k =.",
        "Entity": "Normal"
    },
    {
        "Text": "l, p(k|x, h, s) = (Brown et al., 1993), with parameters that are op p(x |h, s).",
        "Entity": "Normal"
    },
    {
        "Text": "Also, p(x0)   1.\n\t\t\ttimiz ed for use with the trigr am.",
        "Entity": "Normal"
    },
    {
        "Text": "The com bine d The next step is to convert string probabilities into word probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "To do this, we assume that strings map one-to-one into token sequences, so that: model is shown in (Foster, 2000a) to have significantly lower test corpus perplexity than the linear combination of a trigram and IBM 2 used in the TransType experiments (Langlais et al., 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "Both models support O(mJ V 3) Viterbi-style searches for p(xk |h, s)   p(v1, w2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", wm  1, um |h, s), the most likely sequence of m words that follows h, where v1 is a possibly-empty word suffix, each wi is a complete word, and um is a possibly empty word prefix.",
        "Entity": "Normal"
    },
    {
        "Text": "The one-to-one assumption is reasonable given that entries in our lexicon contain neither whitespace nor internal punctuation.",
        "Entity": "Normal"
    },
    {
        "Text": "To model word-sequence probabilities, we apply the chain rule: where J is the number of tokens in s and V is the size of the target-language vocabulary.",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to an equivalent noisy-channel combination of the form p(t)p(s|t), where t is the target sentence, our model is faster but less accurate.",
        "Entity": "Normal"
    },
    {
        "Text": "It is faster because the search problem for noisy- channel models is NP-complete (Knight, 1999), and even the fastest dynamic-programming heuristics used in statistical MT (Niessen et al., 1998; Till- mann and Ney, 2000), are polynomial in J  for in p(v1, w2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", wm 1, um|h, s) = stance O(mJ 4V 3) in (Tillmann and Ney, 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "It m 1 p(v1|h, s) n p(wi|h, v1, wi 1, s)   i=2 p(um|h, v1, wm 1, s).",
        "Entity": "Normal"
    },
    {
        "Text": "(3) The probabilities of v1 and um can be expressed in terms of word probabilities as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model is therefore suitable for making predictions in real time, but not for establishing complete translations unassisted by a human.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Implementation.",
        "Entity": "Normal"
    },
    {
        "Text": "The most expensive part of the calculation in              is the sum in (4) over all words in the vo p(v1|h, s) = p(w1|ht, s)/ ) p(w|ht, s), cabulary, which according to (2) must be carried out w:w=u1 v where the sum is over all words that start with u1.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly: p(um|ht, wm 1, s) = ) p(w|ht, wm 1, s).",
        "Entity": "Normal"
    },
    {
        "Text": "(4) 1 1 w:w=um v Thus all factors in (3) can be calculated from probabilities of the form p(w|h, s) which give the for every character position k in a given prediction x.",
        "Entity": "Normal"
    },
    {
        "Text": "We reduce the cost of this by performing sums only at the end of each sequence of complete tokens in x (eg, after revenir and revenir aux in the above example).",
        "Entity": "Normal"
    },
    {
        "Text": "At these points, probabilities for all possible prefixes of the next word are calculated in a 1 Here we ignore the distinction between previous words that have been sanctioned by the translator and those that are hypothesized as part of the current prediction.",
        "Entity": "Normal"
    },
    {
        "Text": "single recursive pass over the vocabulary and stored in a trie for later access.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition to the exact calculation, we also experimented with establishing exact probabilities via p(w|h, s) only at the end of each token in x, and assuming that the probabilities of the intervening characters vary linearly between these points.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result of this assumption, p(k|x, h, s) = p(xk |h, s)   1 0.9 0.8 0.7 0.6 0.5 0.4 raw smoothed model 1 |h, s) is constant for all k between the end of one word and the next, and therefore can be factored out of the sum in              between these points.",
        "Entity": "Normal"
    },
    {
        "Text": "The purpose of the user model is to determine the expected benefit B(x, h, s, k) to the translator of a prediction x whose first k characters match the text that the translator wishes to type.",
        "Entity": "Normal"
    },
    {
        "Text": "This will depend on whether the translator decides to accept or reject the prediction, so the first step in our model is the following expansion: B(x, h, s, k) = ) p(a|x, h, s, k) B(x, h, s, k, a), a {0,1} where p(a|x, h, s, k) is the probability that the translator accepts or rejects x, B(x, h, s, k, a) is the benefit they derive from doing so, and a is a random variable that takes on the values 1 for acceptance and 0 for rejection.",
        "Entity": "Normal"
    },
    {
        "Text": "The first two quantities are the main elements in the user model, and are described in following sections.",
        "Entity": "Normal"
    },
    {
        "Text": "The parameters of both were estimated from data collected during the TransType trial described in (Langlais et al., 2002), which involved nine accomplished translators using a prototype prediction tool for approximately half an hour each.",
        "Entity": "Normal"
    },
    {
        "Text": "In all cases, estimates were made by pooling the data for all nine translators.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Acceptance Probability.",
        "Entity": "Normal"
    },
    {
        "Text": "Ideally, a model for p(a|x, h, s, k) would take into account whether the user actually reads the proposal before accepting or rejecting it, eg: p(a|x, h, s, k) = ) p(a|r, x, h, s, k)p(r|x, h, s, k) r {0,1} where r is a boolean  read  variable.",
        "Entity": "Normal"
    },
    {
        "Text": "factors which influence whether a user is likely to read a proposal such as a record of how many previous predictions have been accepted are not available to the predictor in our formulation.",
        "Entity": "Normal"
    },
    {
        "Text": "We thus model p(a|x, h, s, k) directly.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model is based on the assumption that the probability of accepting x depends only on what the user stands to gain from it, defined according to the editing scenario given in section 2 as the amount by which the length of the correct prefix of x exceeds the length of the incorrect suffix: p(a|x, h, s, k)   p(a|2k   l), where k   (l   k) = 2k   l is called the gain.",
        "Entity": "Normal"
    },
    {
        "Text": "The strongest part of this assumption is dropping the dependence on h, because there is some evidence from the data that users are more likely to accept at the beginnings of words.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this does not appear to have a severe effect on the quality of the model.",
        "Entity": "Normal"
    },
    {
        "Text": "There is a certain amount of noise intrinsic to the estimation procedure, since it is difficult to determine x , and there fore k, reliably from the data in some cases (when the user is editing the text heavily).",
        "Entity": "Normal"
    },
    {
        "Text": "Nonetheless, it is apparent from the plot that gain is a useful abstrac 4000 3500 3000 raw least squ ares fit 4000 3500 3000 r a w l e a s t   s q u a r e s f i t 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 0                                                                                                                                                                                                         \n\t\t\tThis relatively clean separation supports the basic assumption in section 2 that benefit depends on k.                                                                                                                                                                                                                                           \n\t\t\tThe model probabilities are taken from the curve at integral values.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Benefit.",
        "Entity": "Normal"
    },
    {
        "Text": "This is straightforward in the case of T (x, k) and E(x, k), which are estimated as k and l   k + 1 respectively for E(x, k), this corresponds to one keystroke for the command to accept a prediction, and one to erase each wrong character.",
        "Entity": "Normal"
    },
    {
        "Text": "This is likely to slightly underestimate the true benefit, because it is usually harder to type n characters than to erase them.",
        "Entity": "Normal"
    },
    {
        "Text": "As in the previous section, read costs are interpreted as expected values with respect to the probability that the user actually does read x, eg, assuming 0 cost for not reading, R0(x) = p(r = 1|x)Rt (x), where Rt (x ) is the unknown true cost of reading The benefit B(x, h, s, k, a) is defined as the typing time the translator saves by accepting or rejecting a prediction x whose first k characters are correct.",
        "Entity": "Normal"
    },
    {
        "Text": "To determine this, we assume that the translator first reads x, then, if he or she decides to accept, uses a special command to place the cursor at the end of x and erases its last l   k characters.",
        "Entity": "Normal"
    },
    {
        "Text": "Assuming independence from h, s as before, our model is: r and rejecting x.",
        "Entity": "Normal"
    },
    {
        "Text": "To determine Ra(x), we measured the average elapsed time in the TransType data from the point at which a proposal was displayed to the point at which the next user action occurred either an acceptance or some other command signalling a rejection.",
        "Entity": "Normal"
    },
    {
        "Text": "Times greater than 5 seconds were treated as indicating that the translator was distracted and were filtered out.",
        "Entity": "Normal"
    },
    {
        "Text": "2 Here the number of characters read was assumed to include.",
        "Entity": "Normal"
    },
    {
        "Text": "the whole contents of the TransType menu in the case of rejections, and only the proposal that was ultimately accepted in the case of acceptances.",
        "Entity": "Normal"
    },
    {
        "Text": "tionship between the number of characters read and the time taken to read them, so we used the least- squares lines shown as our models.",
        "Entity": "Normal"
    },
    {
        "Text": "Both plots are noisy and would benefit from a more sophisticated psycholinguistic analysis, but they are plausible and empirically-grounded first approximations.",
        "Entity": "Normal"
    },
    {
        "Text": "To convert reading times to keystrokes for the benefit function we calculated an average time per keystroke (304 milliseconds) based on sections of the trial where translators were rapidly typing and when predictions were not displayed.",
        "Entity": "Normal"
    },
    {
        "Text": "This gives an upper bound for the per-keystroke cost of reading  compare to, for instance, simply dividing the total time required to produce a text by the number of characters in it and therefore results in a conservative estimate of benefit.",
        "Entity": "Normal"
    },
    {
        "Text": "Combining these with the acceptance probability of .25 gives an overall expected benefit B(x, h, s, k = 7) for this proposal of 0.05 keystrokes.",
        "Entity": "Normal"
    },
    {
        "Text": "Searching directly through all character strings x in order to find x  according to              would be very expensive.",
        "Entity": "Normal"
    },
    {
        "Text": "The fact that B(x, h, s) is non- monotonic in the length of x makes it difficult to organize efficient dynamic-programming search techniques or use heuristics to prune partial hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "Because of this, we adopted a fairly radical search strategy that involves first finding the most likely sequence of words of each length, then calculating the benefit of each of these sequences to determine the best proposal.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm is: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "For each length m = 1 .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "M , find the best.",
        "Entity": "Normal"
    },
    {
        "Text": "word sequence: M average time maximum time 1 2 3 4 5 0.0012 0.0038 0.0097 0.0184 0.0285 0.01 0.23 0.51 0.55 0.57                                                                                                                                             \n\t\t\tIn all experiments reported below, M was set to a maximum of 5 to allow for convenient testing.",
        "Entity": "Normal"
    },
    {
        "Text": "Step 1 is carried out using a Viterbi beam search.",
        "Entity": "Normal"
    },
    {
        "Text": "To speed this up, the search is limited to an active vocabulary of target words likely to appear in translations of s, defined as the set of all words connected by some word-pair feature in our translation model to some word in s. Step 2 is a trivial deterministic procedure that mainly involves deciding whether or not to introduce blanks between adjacent words (eg yes in the case of la + vie, no in the case of l  + an).",
        "Entity": "Normal"
    },
    {
        "Text": "This also removes the prefix u1 from the proposal.",
        "Entity": "Normal"
    },
    {
        "Text": "Step 3 involves a straightforward evaluation of m strings according to             .",
        "Entity": "Normal"
    },
    {
        "Text": "Times for the linear model are similar.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the maximum times shown would cause perceptible delays for M > 1, these occur very rarely, and in practice typing is usually not noticeably impeded when using the TransType interface, even at M = 5.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated the predictor for English to French translation on a section of the Canadian Hansard corpus, after training the model on a chronologi w  m = argmax w1 :(w1 =u1 v), wm p(wm|ht, s), cally earlier section.",
        "Entity": "Normal"
    },
    {
        "Text": "The test corpus consisted of 5,020 sentence pairs and approximately 100k words where u1 and ht are as defined in section 3.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "Convert each w  m to a corresponding character.",
        "Entity": "Normal"
    },
    {
        "Text": "string x m. in each language; details of the training corpus are given in (Foster, 2000b).",
        "Entity": "Normal"
    },
    {
        "Text": "To simulate a translator s responses to predictions, we relied on the user model, accepting prob 3.",
        "Entity": "Normal"
    },
    {
        "Text": "Output x .",
        "Entity": "Normal"
    },
    {
        "Text": "= argmaxm B(x m, h, s), or the abilistically according to p(a|x, h, s, k), determinempty string if all B(x m, h, s) are non positive.",
        "Entity": "Normal"
    },
    {
        "Text": "ing the associated benefit using B(x, h, s, k, a), and advancing the cursor k characters in the case of an config M 1 2 3 4 5 fixed linear exact corr best -8.50.43.6011.620.8 6.1 9.40 8.8 8.1 7.8 5.3 10.10 10.7 10.0 9.7 5.8 10.7 12.0 12.5 12.6 7.9 17.90 24.5 27.7 29.2 fixed exact best -11.59.315.122.028.2 3.0 4.3 5.0 5.2 5.2 6.2 12.1 15.4 16.7 17.3                                                         \n\t\t\tNumbers give % reductions in keystrokes.",
        "Entity": "Normal"
    },
    {
        "Text": "user M 1 2 3 4 5 superman rational real 48.6 53.5 51.8 51.1 50.9 11.7 17.8 17.2 16.4 16.1 5.3 10.10 10.7 10.0 9.7                                                 \n\t\t\tNumbers give % reductions in keystrokes.",
        "Entity": "Normal"
    },
    {
        "Text": "acceptance, 1 otherwise.",
        "Entity": "Normal"
    },
    {
        "Text": "Here k was obtained by comparing x to the known x  from the test corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "It may seem artificial to measure performance according to the objective function for the predictor, but this is biased only to the extent that it misrepresents an actual user s characteristics.",
        "Entity": "Normal"
    },
    {
        "Text": "There are two cases: either the user is a better candidate types more slowly, reacts more quickly and rationally  than assumed by the model, or a worse one.",
        "Entity": "Normal"
    },
    {
        "Text": "The predictor will not be optimized in either case, but the simulation will only overestimate the benefit in the second case.",
        "Entity": "Normal"
    },
    {
        "Text": "By being conservative in estimating the parameters of the user model, we feel we have minimized the number of translators who would fall into this category, and thus can hope to obtain realistic lower bounds for the average benefit across all translators.",
        "Entity": "Normal"
    },
    {
        "Text": "The top portion corresponds to the MEMD2B maximum entropy model described in (Foster, 2000a); the bottom portion corresponds to the linear combination of a trigram and IBM 2 used in the TransType experiments (Langlais et al., 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "Columns give the maximum permitted number of words in predictions.",
        "Entity": "Normal"
    },
    {
        "Text": "Rows show different predic tor configurations: fixed ignores the user model and makes fixed M -word predictions; linear uses the linear character-probability estimates described in section 3.1; exact uses the exact character-probability calculation; corr is described below; and best gives an upper bound on performance by choosing m in step 3 of the search algorithm so as to maximize B(x, h, s, k) using the true value of k.                                                                                                                                                                                                                                                                                                               \n\t\t\tFor each simulation, the predictor optimized benefits for the corresponding user model.",
        "Entity": "Normal"
    },
    {
        "Text": "Several conclusions can be drawn from these results.",
        "Entity": "Normal"
    },
    {
        "Text": "First, it is clear that estimating expected benefit is a much better strategy than making fixed-word- length proposals, since the latter causes an increase in time for all values of M .",
        "Entity": "Normal"
    },
    {
        "Text": "In general, making  exact  estimates of string prefix probabilities works better than a linear approximation, but the difference is fairly small.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, the MEMD2B model significantly outperforms the trigram+IBM2 combination, producing better results for every predictor configuration tested.",
        "Entity": "Normal"
    },
    {
        "Text": "The figure of -11.5% in bold corresponds to the TransType configuration, and corroborates the validity of the simulation.3 Third, there are large drops in benefit due to reading times and probabilistic acceptance.",
        "Entity": "Normal"
    },
    {
        "Text": "The biggest cost is due to reading, which lowers the best possible keystroke reduction by almost 50% for M = 5.",
        "Entity": "Normal"
    },
    {
        "Text": "Probabilistic acceptance causes a further drop of about 15% for M = 5.",
        "Entity": "Normal"
    },
    {
        "Text": "The main disappointment in these results is that performance peaks at M = 3 rather than continuing to improve as the predictor is allowed to consider longer word sequences.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the predictor knows B(x, h, s, k), the most likely cause for this is that the estimates for p(w  m|h, s) become worse with increasing m. Significantly, performance lev 3 Although the drop observed with real users was greater at about 20% (= 17% reduction in speed), there are many differences between experimental setups that could account for the discrepancy.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, part of the corpus used for the TransType trials was drawn from a different domain, which would adversely affect predictor performance.",
        "Entity": "Normal"
    },
    {
        "Text": "els off at three words, just as the search loses direct contact with h through the trigram.",
        "Entity": "Normal"
    },
    {
        "Text": "To correct for this, we used modified probabilities of the form  m p(w  m|h, s), where  m is a length-specific correction factor, tuned so as to optimize benefit on a cross-validation corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, performance improves with M , reaching a maximum keystroke reduction of 12.6% at M = 5.",
        "Entity": "Normal"
    },
    {
        "Text": "We have described an approach to text prediction for translators that is based on maximizing the benefit to the translator according to an explicit user model whose parameters were set from data collected in user evaluations of an existing text prediction prototype.",
        "Entity": "Normal"
    },
    {
        "Text": "Using this approach, we demonstrate in simulated results that our current predictor can reduce the time required for an average user to type a text in the domain of our training corpus by over 10%.",
        "Entity": "Normal"
    },
    {
        "Text": "We look forward to corroborating this result in tests with real translators.",
        "Entity": "Normal"
    },
    {
        "Text": "There are many ways to build on the work described here.",
        "Entity": "Normal"
    },
    {
        "Text": "The statistical models which are the backbone of the predictor could be improved by making them adaptive taking advantage of the user s input and by adding features to capture the alignment relation between h and s in such a way as to preserve the efficient search properties.",
        "Entity": "Normal"
    },
    {
        "Text": "The user model could also be made adaptive, and it could be enriched in many other ways, for instance so as to capture the propensity of translators to accept at the beginnings of words.",
        "Entity": "Normal"
    },
    {
        "Text": "We feel that the idea of creating explicit user models to guide the behaviour of interactive systems is likely to have applications in areas of NLP apart from translators  tools.",
        "Entity": "Normal"
    },
    {
        "Text": "For one thing, most of the approach described here carries over more or less directly to monolingual text prediction, which is an important tool for the handicapped (Carlberger et al., 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "Other possibilities include virtually any application where a human and a machine communicate through a language-rich interface.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tThe paper aims at a deeper understanding of several well-known algorithms and proposes ways to optimize them.",
        "Entity": "Normal"
    },
    {
        "Text": "It describes and discusses factors and strategies of factor interaction used in the algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "The factors used in the algorithms and the algorithms themselves are evaluated on a German corpus annotated with syntactic and coreference information (Negra) (Skut et al., 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "A common format for pronoun resolution algorithms with several open parameters is proposed, and the parameter settings optimal on the evaluation data are given.",
        "Entity": "Normal"
    },
    {
        "Text": "In recent years, a variety of approaches to pronoun resolution have been proposed.",
        "Entity": "Normal"
    },
    {
        "Text": "Some of them are based on centering theory (Strube, 1998; Strube and Hahn, 1999; Tetreault, 2001), others on Machine Learning (Aone and Bennett, 1995; Ge et al., 1998; Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "They supplement older heuristic approaches (Hobbs, 1978; Lappin and Leass, 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Unfortunately, most of these approaches were evaluated on different corpora making different assumptions so that direct comparison is not possible.",
        "Entity": "Normal"
    },
    {
        "Text": "Appreciation of the new insights is quite hard.",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation differs not only with regard to size and genre of corpora but also along the following lines.",
        "Entity": "Normal"
    },
    {
        "Text": "Scope of application: Some approaches only deal with personal and possessive pronouns (centering and heuristic), while others consider coreference links in general (Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "A drawback of this latter view is that it mixes problems on different lev els of difficulty.",
        "Entity": "Normal"
    },
    {
        "Text": "It remains unclear how much of the success is due to the virtues of the approach and how much is due to the distribution of hard and easy problems in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we will only deal with coreferential pronouns (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "possessive, demonstrative, and third person pronouns).",
        "Entity": "Normal"
    },
    {
        "Text": "My thanks go to Melvin Wurster for help in annotation and to Ciprian Gerstenberger for discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "Quality of linguistic input: Some proposals were evaluated on hand annotated (Strube and Hahn, 1999) or tree bank input (Ge et al., 1998; Tetreault, 2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Other proposals provide a more realistic picture in that they work as a backend to a parser (Lappin and Leass, 1994) or noun chunker (Mitkov, 1998; Soon et al., 2001; Ng and Cardie, 2002)).",
        "Entity": "Normal"
    },
    {
        "Text": "In evaluation of applications presupposing parsing, it is helpful to separate errors due to parsing from intrinsic errors.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, one would also like to gauge the end-to-end performance of a system.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus we will provide performance figures for both ideal (hand-annotated) input and realistic (automatically generated) input.",
        "Entity": "Normal"
    },
    {
        "Text": "Language: Most approaches were evaluated on English where large resources are available, both in terms of pre-annotated data (MUC6 and MUC7 data) and lexical information (WordNet).",
        "Entity": "Normal"
    },
    {
        "Text": "This paper deals with German.",
        "Entity": "Normal"
    },
    {
        "Text": "Arguably, the free word-order of German arguably leads to a clearer distinction between grammatical function, surface order, and information status (Strube and Hahn, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "The paper is organized as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 2 describes the evaluation corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 3 describes several factors relevant to pronoun resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "It assesses these factors against the corpus, measuring their precision and restrictiveness.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4 describes and evaluates six algorithms on the basis of these factors.",
        "Entity": "Normal"
    },
    {
        "Text": "It also captures the algorithms as para- metric systems and proposes parameter settings optimal on the evaluation data.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 5 concludes.",
        "Entity": "Normal"
    },
    {
        "Text": "We chose as an evaluation base the NEGRA tree bank, which contains about 350,000 tokens of German newspaper text.",
        "Entity": "Normal"
    },
    {
        "Text": "The same corpus was also processed with a finite-state parser, performing at 80% dependency f-score (Schiehlen, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "All personal pronouns (PPER), possessive pronouns (PPOSAT), and demonstrative pronouns (PDS) in Negra were annotated in a format geared to the MUC7 guidelines (MUC7, 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "Proper names were annotated automatically by a named entity recognizer.",
        "Entity": "Normal"
    },
    {
        "Text": "In a small portion of the corpus (6.7%), all coreference links were annotated.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus the size of the annotated data (3,115 personal pronouns1 , 2,198 possessive pronouns, 928 demonstrative pronouns) compares favourably with the size of evaluation data in other proposals (619 German pronouns in (Strube and Hahn, 1999), 2,477 English pronouns in (Ge et al., 1998), about 5,400 English coreferential expressions in (Ng and Cardie, 2002)).",
        "Entity": "Normal"
    },
    {
        "Text": "In the experiments, systems only looked for single NP antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, propositional or predicative antecedents (8.4% of the pronouns annotated) and split antecedents (0.2%) were inaccessible, which reduced optimal success rate to 91.4%.",
        "Entity": "Normal"
    },
    {
        "Text": "Pronoun resolution is conditioned by a wide range of factors.",
        "Entity": "Normal"
    },
    {
        "Text": "Two questions arise: Which factors are the most effective?",
        "Entity": "Normal"
    },
    {
        "Text": "How is interaction of the factors modelled?",
        "Entity": "Normal"
    },
    {
        "Text": "The present section deals with the first question, while the second question is postponed to section 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Many approaches distinguish two classes of resolution factors: filters and preferences.",
        "Entity": "Normal"
    },
    {
        "Text": "Filters express linguistic rules, while preferences are merely tendencies in interpretation.",
        "Entity": "Normal"
    },
    {
        "Text": "Logically, filters are monotonic inferences that select a certain subset of possible antecedents, while preferences are non- monotonic inferences that partition the set of antecedents and impose an order on the cells.",
        "Entity": "Normal"
    },
    {
        "Text": "In the sequel, factors proposed in the literature are discussed and their value is appraised on evaluation data.",
        "Entity": "Normal"
    },
    {
        "Text": "Every factor narrows the set of antecedents and potentially discards correct antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "Figures are also given for parsed input.",
        "Entity": "Normal"
    },
    {
        "Text": "Preferences are evaluated on filtered sets of antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Filters.",
        "Entity": "Normal"
    },
    {
        "Text": "Agreement.",
        "Entity": "Normal"
    },
    {
        "Text": "An important filter comes from morphology: Agreement in gender and number is generally regarded as a prerequisite for coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Exceptions are existant but few (2.5%): abstract pronouns (such as that in English) referring to non- neuter or plural NPs, plural pronouns co-referring with singular collective NPs (Ge et al., 1998), antecedent and anaphor matching in natural gender 1 Here, we only count anaphoric pronouns, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "third person pronouns not used expletively.",
        "Entity": "Normal"
    },
    {
        "Text": "rather than grammatical gender.",
        "Entity": "Normal"
    },
    {
        "Text": "All in all, a maximal performance of 88.9% is maintained.",
        "Entity": "Normal"
    },
    {
        "Text": "The filter is very restrictive, and cuts the set of possible antecedents in half.",
        "Entity": "Normal"
    },
    {
        "Text": "Binding.",
        "Entity": "Normal"
    },
    {
        "Text": "Binding constraints have been in the focus of linguistic research for more than thirty years.",
        "Entity": "Normal"
    },
    {
        "Text": "They provide restrictions on coindexation of pronouns with clause siblings, and therefore can only be applied with systems that determine clause boundaries, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "parsers (Mitkov, 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "Empirically, binding constraints are rules without exceptions, hence they do not lead to any loss in achievable performance.",
        "Entity": "Normal"
    },
    {
        "Text": "The downside is that their restrictive power is quite bad as well (0.3% in our corpus, cf.",
        "Entity": "Normal"
    },
    {
        "Text": "Sortal Constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "More controversial are sortal constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Intuitively, they also provide a hard filter: The correct antecedent must fit into the environment of the pronoun (Carbonell and Brown, 1988).",
        "Entity": "Normal"
    },
    {
        "Text": "In general, however, the required knowledge sources are lacking, so they must be hand-coded and can only be applied in restricted domains (Strube and Hahn, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Selectional restrictions can also be modelled by collocational data extracted by a parser, which have, however, only a very small impact on overall performance (Kehler et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "We will neglect sortal constraints in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Preferences.",
        "Entity": "Normal"
    },
    {
        "Text": "Preferences can be classified according to their requirements on linguistic processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Sentence Re- cency and Surface Order can be read directly off the surface.",
        "Entity": "Normal"
    },
    {
        "Text": "NP Form presupposes at least tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "A range of preferences (Grammatical Roles, Role Parallelism, Depth of Embedding, Common Path), as well as all filters, presuppose full syntactic analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "Mention Count and Information Status are based on previous decisions of the anaphora resolution module.",
        "Entity": "Normal"
    },
    {
        "Text": "Sentence Recency (SR).",
        "Entity": "Normal"
    },
    {
        "Text": "The most important criterion in pronoun resolution (Lappin and Leass, 1994) is the textual distance between anaphor and antecedent measured in sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Lappin and Le ass (1994) motivate this preference as a dynamic expression of the attentional state of the human hearer:Memory capability for storage of discourse refer ents degrades rapidly.",
        "Entity": "Normal"
    },
    {
        "Text": "Several implementations are possible.",
        "Entity": "Normal"
    },
    {
        "Text": "Perhaps most obvious is the strategy implicit in Lappin and Leass (1994) s algorithm: The antecedent issearched in a sentence that is as recent as possi ble, beginning with the already uttered part of the current sentence, continuing in the last sentence, in the one but last sentence, and so forth.",
        "Entity": "Normal"
    },
    {
        "Text": "In case no Co nst rai nt Uppe r Boun d n u m b e r o f a nt e c. P a r s e r tot al PP E R PP O S A T P D S U pp er B an tec .",
        "Entity": "Normal"
    },
    {
        "Text": "no V P 91 .6 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 1 0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 48 .5 1 2 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 8 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 12 8.",
        "Entity": "Normal"
    },
    {
        "Text": "4 no spl it 91 .4 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 1 0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 47 .8 1 2 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 ag re e m en t 88 .9 9 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 9 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 37 .6 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 7 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 6 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 bi nd in g 88 .9 5 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 7 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 6 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 se nt en ce re ce nc y SR 78 .8 8 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 9 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 32 .3 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 6 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 gr a m m ati cal rol e GR 74 .0 82 .3 2 8 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 13 .0 1 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 5 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 rol e pa ral lel is m RP 64 .3 7 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "4   20 .0 1 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 4 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 su rfa ce or de r LR 53 .5 6 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 15 .3 1 4 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 1 su rfa ce or de r RL 45 .9 4 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 22 .7 1 3 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 1 de pt h of e m be dd in g DE 51 .6 5 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 6 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 14 .1 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 4 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 co m m on pa th CP 51 .7 5 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 19 .9 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 4 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 1 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 eq ui va le nc e cla ss es EQ 63 .6 6 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 7 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 15 .7 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 5 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 m en tio n co un t MC 32 .9 4 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 3 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 inf or m ati on sta tus IS 65 .3 7 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 7 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 16 .7 1 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 1 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 N P for m NF 42 .4 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 12 .8 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 2 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 N P for m (pr on ou n) NP 73 .7 8 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 7 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 30 .2 2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 3 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6                                                                                                                                                                  \n\t\t\t10000 all PPER age only 2.4 such antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the benefit also comes at a cost: The upper ceiling of performance is lowered to 82.0% in our corpus: In many cases an incorrect antecedent is found in a more recent sentence.Similarly, we can assess other strategies of sen 1000 100 10 1 P P O S A T P D S -2-1 0 1 2 3 4 5 6 7 8 9 12 19 Fi gu re 1: Se nte nc e Re ce nc y tence orderi ng that have been propo sed in the litera ture.",
        "Entity": "Normal"
    },
    {
        "Text": "Hard core center ing appro aches only deal with the last senten ce (Bren nan et al., 1987).",
        "Entity": "Normal"
    },
    {
        "Text": "In Negra, these appro aches can conse quentl y have at most a succes s rate of 44.2% .",
        "Entity": "Normal"
    },
    {
        "Text": "Perfor mance is partic ularly low with posses sive prono uns which often only have antece dents in the curren t senten ce.",
        "Entity": "Normal"
    },
    {
        "Text": "Strube and Hahn (1999) extend the contex t to more than the last senten ce, but switch prefer ence order betwe en the last and the curren t senten ce so that an antece dent is deter mined in the last senten ce, whene ver possi                                                                                                                                                  \n\t\t\tIn Negra, 55.3% of all pronominal anaphora can be resolved intrasententially, and 97.6% within the last three sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Since only 1.6% of all pronouns are cataphoric, it seems reasonable to neglect cat- aphora, as is mostly done (Strube and Hahn, 1999; Hobbs, 1978).",
        "Entity": "Normal"
    },
    {
        "Text": "In Negra, this ordering imposes an upper limit of 51.2%.",
        "Entity": "Normal"
    },
    {
        "Text": "Grammatical Roles (GR).",
        "Entity": "Normal"
    },
    {
        "Text": "Another important factor in pronoun resolution is the grammatical role of the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "The role hierarchy used in centering (Brennan et al., 1987; Grosz et al., 1995) ranks subjects over direct objects over indirect objects over others.",
        "Entity": "Normal"
    },
    {
        "Text": "Lappin and Leass (1994) provide a more elaborate model which ranks NP complements and NP adjuncts lowest.",
        "Entity": "Normal"
    },
    {
        "Text": "Two other distinctions in their model express a preference of rhematic2 over thematic arguments: Existential subjects, which follow the verb, rank very high, between subjects and direct objects.",
        "Entity": "Normal"
    },
    {
        "Text": "Topic adjuncts in pre-subject position separated by a comma rank very low, between adjuncts and NP complements.",
        "Entity": "Normal"
    },
    {
        "Text": "Both positions are not clearly demarcated in German.",
        "Entity": "Normal"
    },
    {
        "Text": "When the Lap- pin&Leass hierarchy is adopted to German without changes, a small drop in performance results as compared with the obliqueness hierarchy used in centering.",
        "Entity": "Normal"
    },
    {
        "Text": "So we will use the centering hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "The factor is both less restrictive and less precise than sentence recency.",
        "Entity": "Normal"
    },
    {
        "Text": "The definition of a grammatical role hierarchy is more involved in case of automatically derived input, as the parser cannot always decide on the grammatical role (determining grammatical roles in German may require world knowledge).",
        "Entity": "Normal"
    },
    {
        "Text": "It proposes a syntactically preferred role, however, which we will adopt.",
        "Entity": "Normal"
    },
    {
        "Text": "Role Parallelism (RP).",
        "Entity": "Normal"
    },
    {
        "Text": "Carbonell and Brown (1988) argue that pronouns prefer antecedents in the same grammatical roles.",
        "Entity": "Normal"
    },
    {
        "Text": "Lappin and Leass (1994) also adopt such a principle.",
        "Entity": "Normal"
    },
    {
        "Text": "The factor is, however, not applicable to possessive pronouns.",
        "Entity": "Normal"
    },
    {
        "Text": "Again, role ambiguities make this factor slightly problematic.",
        "Entity": "Normal"
    },
    {
        "Text": "Several approaches are conceivable: Antecedent and pronoun are required to have a common role in one reading (weak match).",
        "Entity": "Normal"
    },
    {
        "Text": "Antecedent and pronoun are required to have the same role in the reading preferred by surface order (strong match).",
        "Entity": "Normal"
    },
    {
        "Text": "Antecedent and pronoun must display the same role ambiguity (strongest match).",
        "Entity": "Normal"
    },
    {
        "Text": "Weak match restricted performance to 49.9% with 12.1 antecedents on average.",
        "Entity": "Normal"
    },
    {
        "Text": "Strong match gave an upper limit of 47.0% but with only 10.3 antecedents on average.",
        "Entity": "Normal"
    },
    {
        "Text": "Strongest match lowered the upper limit to 43.1% but yielded only 9.3 antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "In interaction, strong match performed best, so we adopt it.",
        "Entity": "Normal"
    },
    {
        "Text": "Surface Order (LR, RL).",
        "Entity": "Normal"
    },
    {
        "Text": "Surface Order is usually used to bring down the number of available antecedents to one, since it is the only factor that produces a unique discourse referent.",
        "Entity": "Normal"
    },
    {
        "Text": "There is less consensus on the preference order: (sentence-wise) left-to-right (Hobbs, 1978; Strube, 1998; Strube and Hahn, 1999; Tetreault, 1999) or right-to-left (recency) (Lappin and Leass, 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, something has to be said about antecedents which embed other antecedents (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "conjoined NPs and their conjuncts).",
        "Entity": "Normal"
    },
    {
        "Text": "We registered performance gains 2 Carbonell and Brown (1988) also argue that clefted or fronted arguments should be preferred.",
        "Entity": "Normal"
    },
    {
        "Text": "(of up to 3%) by ranking embedding antecedents higher than embedded ones (Tetreault, 2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Left-to-right order is often used as a surrogate for grammatical role hierarchy in English.",
        "Entity": "Normal"
    },
    {
        "Text": "The most notable exception to this equivalence are fronting constructions, where grammatical roles outperform surface order (Tetreault, 2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Left-to-right order performs better (upper limit 56.8%) than right-to-left order (upper limit 49.2%).",
        "Entity": "Normal"
    },
    {
        "Text": "The gain is largely due to personal pronouns; demonstrative pronouns are better modelled by right-to-left order.",
        "Entity": "Normal"
    },
    {
        "Text": "It is well-known that German demonstrative pronouns contrast with personal pronouns in that they function as topic-shifting devices.",
        "Entity": "Normal"
    },
    {
        "Text": "Another effect of this phenomenon is the poor performance of the role preferences in connection with demonstrative pronouns.",
        "Entity": "Normal"
    },
    {
        "Text": "Depth of Embedding (DE).",
        "Entity": "Normal"
    },
    {
        "Text": "A prominent factor in Hobbs (1978) s algorithm is the level of phrasal embedding: Hobbs s algorithm performs a breadth- first search, so antecedents at higher levels of embedding are preferred.",
        "Entity": "Normal"
    },
    {
        "Text": "Common Path (CP).",
        "Entity": "Normal"
    },
    {
        "Text": "The syntactic version of Hobbs (1978) s algorithm also assumes maximization of the common path between antecedents and anaphors as measured in NP and S nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "Accordingly, intrasentential antecedents that are syntactically nearer to the pronoun are preferred.",
        "Entity": "Normal"
    },
    {
        "Text": "The factor only applies to intrasentential anaphora.",
        "Entity": "Normal"
    },
    {
        "Text": "The anaphora resolution module itself generates potentially useful information when processing a text.",
        "Entity": "Normal"
    },
    {
        "Text": "Arguably, discourse entities that have been often referred to in the previous context are topical and more likely to serve as antecedents again.",
        "Entity": "Normal"
    },
    {
        "Text": "This principle can be captured in different ways.",
        "Entity": "Normal"
    },
    {
        "Text": "Equivalence Classes (EQ).",
        "Entity": "Normal"
    },
    {
        "Text": "Lappin and Leass (1994) make use of a mechanism based on equivalence classes of discourse referents which manages the attentional properties of the individual entities referred to.",
        "Entity": "Normal"
    },
    {
        "Text": "The mechanism stores and provides information on how recently and in which grammatical role the entities were realized in the discourse.",
        "Entity": "Normal"
    },
    {
        "Text": "The net effect of the storage mechanism is that discourse entities are preferred as antecedents if they recently came up in the discourse.",
        "Entity": "Normal"
    },
    {
        "Text": "But the mechanism also integrates the preferences Role Hierarchy and Role Parallelism.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, it is one of the best- performing factors on our data.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the equivalence class scheme is tightly integrated in the parser, the problem of ideal anaphora resolution data does not arise.",
        "Entity": "Normal"
    },
    {
        "Text": "Mention Count (MC).",
        "Entity": "Normal"
    },
    {
        "Text": "Ge et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998) try to factorize the same principle by counting the number of times a discourse entities has been mentioned in the discourse already.",
        "Entity": "Normal"
    },
    {
        "Text": "However, they do not only train but also test on the manually annotated counts, and hence presuppose an optimal anaphora resolution system.",
        "Entity": "Normal"
    },
    {
        "Text": "In our implementation, we did not bother with intrasentential mention count, which depends on the exact traversal.",
        "Entity": "Normal"
    },
    {
        "Text": "Rather, mention count was computed only from previous sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Information Status (IS).",
        "Entity": "Normal"
    },
    {
        "Text": "Strube (1998) and Strube and Hahn (1999) argue that the information status of an antecedent is more important than the grammatical role in which it occurs.",
        "Entity": "Normal"
    },
    {
        "Text": "They distinguish three levels of information status: entities known to the hearer (as expressed by coreferential NPs, unmodified proper names, appositions, relative pronouns, and NPs in titles), entities related to such hearer-old entities (either overtly via modifiers or by bridging), and entities new to the hearer.",
        "Entity": "Normal"
    },
    {
        "Text": "Like (Ge et al., 1998), Strube (1998) evaluates on ideal hand annotated data.",
        "Entity": "Normal"
    },
    {
        "Text": "NP Form (NF, NP).",
        "Entity": "Normal"
    },
    {
        "Text": "A cheap way to model information status is to consider the form of an antecedent (Tetreault, 2001; Soon et al., 2001; Strube and M ller, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "Personal and demonstrative pronouns are necessarily context-dependent, and proper nouns are nearly always known to the hearer.",
        "Entity": "Normal"
    },
    {
        "Text": "Definite NPs may be coreferential or interpreted by bridging, while indefinite NPs are in their vast majority new to the hearer.",
        "Entity": "Normal"
    },
    {
        "Text": "We considered two proposals for orderings of form: preferring pronouns and proper names over other NPs over indefinite NPs (Tetreault, 2001) (NF) or preferring pronouns over all other NPs (Tetreault, 2001) (NP).",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we consider the individual approaches in more detail, in particular we will look at their choice of factors and their strategy to model factor interaction.",
        "Entity": "Normal"
    },
    {
        "Text": "According to interaction potential, we distinguish three classes of approaches: Serialization, Weighting, and Machine Learning.",
        "Entity": "Normal"
    },
    {
        "Text": "We re-implemented some of the algorithms described in the literature and evaluated them on syntactically ideal and realistic German3 input.",
        "Entity": "Normal"
    },
    {
        "Text": "With the ideal treebank input, we also assumed ideal input for the factors dependent on previous 3 A reviewer points out that most of the algorithms were proposed for English, where they most likely perform better.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the algorithms also incorporate a theory of saliency, which should be language-independent.",
        "Entity": "Normal"
    },
    {
        "Text": "anaphora resolution results.",
        "Entity": "Normal"
    },
    {
        "Text": "With realistic parsed input, we fed the results of the actual system back into the computation of such factors.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Serialization Approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "Algorithmical approaches first apply filters unconditionally; possible exceptions are deemed non- existant or negligible.",
        "Entity": "Normal"
    },
    {
        "Text": "With regard to interaction of preferences, many algorithms (Hobbs, 1978; Strube, 1998; Tetreault, 2001) subscribe to a scheme, which, though completely rigid, performs surprisingly well: The chosen preferences are applied one after the other in a certain predefined order.",
        "Entity": "Normal"
    },
    {
        "Text": "Application of a preference consists in selecting those of the antecedents still available that are ranked highest in the preference order.",
        "Entity": "Normal"
    },
    {
        "Text": "Hobbs (1978) s algorithm essentially is a concatenation of the preferences Sentence Recency (without cataphora), Common Path, Depth of Embedding, and left-to-right Surface Order.",
        "Entity": "Normal"
    },
    {
        "Text": "It also implements the binding constraints by disallowing sibling to the anaphor in a clause or NP as antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "Like Lappin and Leass (1994), we replaced this implementation by our own mechanism to check binding constraints, which raised the success rate.",
        "Entity": "Normal"
    },
    {
        "Text": "The Left-Right Centering algorithm of Tetreault (1999) is similar to Hobbs s algorithm, and is composed of the preferences Sentence Recency (without cataphora), Depth of Embedding, and left-to-right Surface Order.",
        "Entity": "Normal"
    },
    {
        "Text": "Since it is a centering approach, it only inspects the current and last sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Strube (1998) s S-list algorithm is also restricted to the current and last sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Predicative complements and NPs in direct speech are excluded as antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "The primary ordering criterion is Information Status, followed by Sentence Recency (without cataphora) and left-to-right Surface Order.",
        "Entity": "Normal"
    },
    {
        "Text": "Since serialization provides a quite rigid frame, we conducted an experiment to find the best performing combination of pronoun resolution factors on the treebank and the best combination on the parsed input.",
        "Entity": "Normal"
    },
    {
        "Text": "For this purpose, we checked all permutations of preferences and subtracted preferences from the best-performing combinations until performance degraded (greedy descent).",
        "Entity": "Normal"
    },
    {
        "Text": "Greedy descent outperformed hill-climbing.",
        "Entity": "Normal"
    },
    {
        "Text": "The completely annotated 6.7% of the corpus were used as development set, the rest as test set.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Weighting Approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "Compared with the serialization approaches, the algorithm of Lappin and Leass (1994) is more sophisticated: It uses a system of hand-selected weights to control interaction among preferences, so that in principle the order of preference application can Al go rit h m D e f i n i t i o n F-Scores   treebankF Sc or e P ar se r tot al PP ER PP OS AT P D S (H ob bs, 19 78 ) ( T e t r e a u l t , 1 9 9 9 ) ( S t r u b e , 1 9 9 8 ) op ti m al al go r.\n\t\t\t(tr ee ba nk ) op ti m al al go r.\n\t\t\t(p ars ed ) S R C P D E L R S R 2 D E L R I S S R 2 L R S R C P I S D E M C R P G R R L S R C P G R I S D E L R 59 .9 57 .0 57 .9 70 .4 67 .7 6 5.",
        "Entity": "Normal"
    },
    {
        "Text": "1 6 4.",
        "Entity": "Normal"
    },
    {
        "Text": "1 6 5.",
        "Entity": "Normal"
    },
    {
        "Text": "9 7 5.",
        "Entity": "Normal"
    },
    {
        "Text": "6 7 4.",
        "Entity": "Normal"
    },
    {
        "Text": "3 7 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 6 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 6 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 8 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 8 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 17 .4 17 .2 12 .0 22 .7 10 .6 4 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 4 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 3 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 4 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 (L ap pi n an d Le as s, 19 94 ) E Q S R R L 65 .4 7 1.",
        "Entity": "Normal"
    },
    {
        "Text": "0 7 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 16 .6 5 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 (G e et al.",
        "Entity": "Normal"
    },
    {
        "Text": ", 19 98 ) (S oo n et al.",
        "Entity": "Normal"
    },
    {
        "Text": ", 20 01 ) op ti m al al go r.\n\t\t\t(C 4.",
        "Entity": "Normal"
    },
    {
        "Text": "5) H ob bs +M C (S R+ N P) R L (S R/ R L+ G R+ N F/ I S) R L 43 .4 24 .8 71 .1 4 5.",
        "Entity": "Normal"
    },
    {
        "Text": "7 3 0.",
        "Entity": "Normal"
    },
    {
        "Text": "8 7 8.",
        "Entity": "Normal"
    },
    {
        "Text": "2 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 2 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 7 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 2.",
        "Entity": "Normal"
    },
    {
        "Text": "1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "7                                                                      \n\t\t\tIn the actual realization, however, the weights of factors lie so much apart that in the majority of cases interaction boils down to serialization.",
        "Entity": "Normal"
    },
    {
        "Text": "The weighting scheme includes Sentence Recency, Grammatical Roles, Role Parallelism, on the basis of the equivalence class approach described in section 3.2.",
        "Entity": "Normal"
    },
    {
        "Text": "Final choice of antecedents is relegated to right-to-left Surface Order.",
        "Entity": "Normal"
    },
    {
        "Text": "Interestingly, the Lappin&Leass algorithm outperforms even the best serialization algorithm on parsed input.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Machine Learning Approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "Machine Learning approaches (Ge et al., 1998; Soon et al., 2001; Ng and Cardie, 2002) do not distinguish between filters and preferences.",
        "Entity": "Normal"
    },
    {
        "Text": "They submit all factors as features to the learner.",
        "Entity": "Normal"
    },
    {
        "Text": "For every combination of feature values the learner has the freedom to choose different factors and to assign different strength to them.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus the main problem is not choice and interaction of factors, but rather the formulation of anaphora resolution as a classification problem.",
        "Entity": "Normal"
    },
    {
        "Text": "Two proposals emerge from the literature.",
        "Entity": "Normal"
    },
    {
        "Text": "(1) Given an anaphor and an antecedent, decide if the antecedent is the correct one (Ge et al., 1998; Soon et al., 2001; Ng and Cardie, 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "(2) Given an anaphor and two antecedents, decide which antecedent is more likely to be the correct one (Yang et al., 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "In case (1), the lopsidedness of the distribution is problematic: There are much more negative than positive training examples.",
        "Entity": "Normal"
    },
    {
        "Text": "Machine Learning tools have to surpass a very high baseline: The strategy of never proposing an antecedent typically already yields an f-score of over 90%.",
        "Entity": "Normal"
    },
    {
        "Text": "In case (2), many more correct decisions have to be made before a correct antecedent is found.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus it is important in this scenario, that the set of antecedents is subjected to a strict filtering process in advance so that the system only has to choose among the best candidates and errors are less dangerous.",
        "Entity": "Normal"
    },
    {
        "Text": "Ge et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998) s probabilistic approach combines three factors (aside from the agreement filter): the result of the Hobbs algorithm, Mention Count dependent on the position of the sentence in the article, and the probability of the antecedent occurring in the local context of the pronoun.",
        "Entity": "Normal"
    },
    {
        "Text": "In our re-implementation, we neglected the last factor (see section 3.1).",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation was performed using 10- fold cross validation.",
        "Entity": "Normal"
    },
    {
        "Text": "Other Machine Learning approaches (Soon et al., 2001; Ng and Cardie, 2002; Yang et al., 2003) make use of decision tree learning4 ; we used C4.5 (Quinlan, 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "To construct the training set, Soon et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2001) take the nearest correct antecedent in the previous context as a positive example, while all possible antecedents between this antecedent and the pronoun serve as negative examples.",
        "Entity": "Normal"
    },
    {
        "Text": "For testing, potential antecedents are presented to the classifier in Right-to-Left order; the first one classified positive is chosen.",
        "Entity": "Normal"
    },
    {
        "Text": "Apart from agreement, only two of Soon et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2001) s features apply to pronominal anaphora: Sentence Recency, and NP Form (with personal pronouns only).",
        "Entity": "Normal"
    },
    {
        "Text": "We used every 10th sentence in Negra for testing, all other sentences for training.",
        "Entity": "Normal"
    },
    {
        "Text": "On parsed input, a very simple decision tree is generated: For every personal and possessive pronoun, the nearest agreeing pronoun is chosen as antecedent; demonstrative pronouns never get an antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "This tree performs better than the more complicated tree generated from treebank input, where also non-pronouns in previous sentences can serve as antecedents to a personal pronoun.",
        "Entity": "Normal"
    },
    {
        "Text": "Soon et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2001) s algorithm performs below its potential.",
        "Entity": "Normal"
    },
    {
        "Text": "We modified it somewhat to get better results.",
        "Entity": "Normal"
    },
    {
        "Text": "For one, we used every possible antecedent 4 On our data, Maximum Entropy (Kehler et al., 2004) had problems with the high baseline, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "proposed no antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "in the training set, which improved performance on the treebank set (by 1.8%) but degraded performance on the parsed data (by 2%).",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, we used additional features, viz.",
        "Entity": "Normal"
    },
    {
        "Text": "the grammatical role of antecedent and pronoun, the NP form of the antecedent, and its information status.",
        "Entity": "Normal"
    },
    {
        "Text": "The latter two features were combined to a single feature with very many values, so that they were always chosen first in the decision tree.",
        "Entity": "Normal"
    },
    {
        "Text": "We also used fractional numbers to express intrasentential word distance in addition to Soon et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2001) s sentential distance.",
        "Entity": "Normal"
    },
    {
        "Text": "Role Parallelism (Ng and Cardie, 2002) degraded performance (by 0.3% F-value).",
        "Entity": "Normal"
    },
    {
        "Text": "Introducing agreement as a feature had no effect, since the learner always determined that mismatches in agreement preclude coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Mention Count, Depth of Embedding, and Common Path did not affect performance either.",
        "Entity": "Normal"
    },
    {
        "Text": "The paper has presented a survey of pronoun resolution factors and algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "Two questions were investigated: Which factors should be chosen, and how should they interact?",
        "Entity": "Normal"
    },
    {
        "Text": "Two types of factors,  filters  and  preferences , were discussed in detail.",
        "Entity": "Normal"
    },
    {
        "Text": "In particular, their restrictive potential and effect on success rate were assessed on the evaluation corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "To address the second question, several well-known algorithms were grouped into three classes according to their solution to factor interaction: Serialization, Weighting, and Machine Learning.",
        "Entity": "Normal"
    },
    {
        "Text": "Six algorithms were evaluated against a common evaluation set so as to facilitate direct comparison.",
        "Entity": "Normal"
    },
    {
        "Text": "Different algorithms have different strengths, in particular as regards their robustness to parsing errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Two of the interaction strategies (Serialization and Machine Learning) allow data-driven optimization.",
        "Entity": "Normal"
    },
    {
        "Text": "Optimal algorithms could be proposed for these strategies.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tThis article presents empirical evaluations of aspects of annotation for the linguistic property of animacy in Swedish, ranging from manual human annotation, automatic classification and, finally, an external evaluation in the task of syntactic parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "We show that a treatment of animacy as a lexical semantic property of noun types enables generalization over distributional properties of these nouns which proves beneficial in automatic classification and furthermore gives significant improvements in terms of parsing accuracy for Swedish, compared to a state-of-the- art baseline parser with gold standard ani- macy information.",
        "Entity": "Normal"
    },
    {
        "Text": "The property of animacy influences linguistic phenomena in a range of different languages, such as case marking (Aissen, 2003) and argument realization (Bresnan et al., 2005; de Swart et al., 2008), and has been shown to constitute an important factor in the production and comprehension of syntactic structure (Branigan et al., 2008; Weckerly and Kutas, 1999).1 In computational linguistic work, animacy has been shown to provide important information in anaphora resolution (Ora san and Evans, 2007), argument disambiguation (Dell Orletta et al., 2005) and syntactic parsing in general ( vrelid and Nivre, 2007).The dimension of animacy roughly distin guishes between entities which are alive and entities which are not, however, other distinctions 1 Parts of the research reported in this paper has been supported by the Deutsche Forschungsgemeinschaft (DFG, Son- derforschungsbereich 632, project D4).",
        "Entity": "Normal"
    },
    {
        "Text": "are also relevant and the animacy dimension is often viewed as a continuum ranging from humans to inanimate objects.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Silverstein (1976) several animacy hierarchies have been proposed in typological studies, focusing on the linguistic category of animacy, i.e., the distinctions which are relevant for linguistic phenomena.",
        "Entity": "Normal"
    },
    {
        "Text": "An example of an animacy hierarchy, taken from (Aissen, 2003), is provided in (1): (1) Human > Animate > Inanimate Clearly, nonhuman animates, like animals, are not less animate than humans in a biological sense, however, humans and animals show differing linguistic behaviour.Empirical studies of animacy require human an notation efforts, and, in particular, a well-defined annotation task.",
        "Entity": "Normal"
    },
    {
        "Text": "However, annotation studies of animacy differ distinctly in their treatment of ani- macy as a type or token-level phenomenon, as well as in terms of granularity of categories.",
        "Entity": "Normal"
    },
    {
        "Text": "The use of the annotated data as a computational resource furthermore poses requirements on the annotation which do not necessarily agree with more theoretical considerations.",
        "Entity": "Normal"
    },
    {
        "Text": "Methods for the induction of animacy information for use in practical applications require the resolution of issues of level of representation, as well as granularity.This article addresses these issues through em pirical and experimental evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "We present an in-depth study of a manually annotated data set which indicates that animacy may be treated as a lexical semantic property at the type level.",
        "Entity": "Normal"
    },
    {
        "Text": "We then evaluate this proposal through supervised machine learning of animacy information and focus on an in-depth error analysis of the resulting classifier, addressing issues of granularity of the animacy dimension.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the automatically an Proceedings of the 12th Conference of the European Chapter of the ACL, pages 630 638, Athens, Greece, 30 March   3 April 2009.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2009 Association for Computational Linguistics notated data set is employed in order to train a syntactic parser and we investigate the effect of the an- imacy information and contrast the automatically acquired features with gold standard ones.",
        "Entity": "Normal"
    },
    {
        "Text": "The rest of the article is structured as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "In section 2, we briefly discuss annotation schemes for animacy, the annotation strategies and categories proposed there.",
        "Entity": "Normal"
    },
    {
        "Text": "We go on to describe annotation for the binary distinction of  human reference  found in a Swedish dependency treebank in section 3 and we perform an evaluation of the consistency of the human annotation in terms of linguistic level.",
        "Entity": "Normal"
    },
    {
        "Text": "In section 4, we present experiments in lexical acquisition of animacy based on morphosyntactic features extracted from a considerably larger corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 5 presents experiments with the acquired animacy information applied in the data-driven dependency parsing of Swedish.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, section 6 concludes the article and provides some suggestions for future research.",
        "Entity": "Normal"
    },
    {
        "Text": "Annotation for animacy is not a common component of corpora or treebanks.",
        "Entity": "Normal"
    },
    {
        "Text": "However, following from the theoretical interest in the property of an- imacy, there have been some initiatives directed at the animacy of their referent in the particular context.",
        "Entity": "Normal"
    },
    {
        "Text": "Animacy is thus treated as a token level property, however, has also been proposed as a lexical semantic property of nouns (Yamamoto, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "The indirect encoding of animacy in lexical resources, such as WordNet (Fellbaum, 1998) can also be seen as treating animacy as a type- level property.",
        "Entity": "Normal"
    },
    {
        "Text": "We may thus distinguish between a purely type level annotation strategy and a purely token level one.",
        "Entity": "Normal"
    },
    {
        "Text": "Type level properties hold for lexemes and are context-independent, i.e., independent of the particular linguistic context, whereas token-level properties are determined in context and hold for referring expressions, rather than lexemes.",
        "Entity": "Normal"
    },
    {
        "Text": "Talbanken05 is a Swedish treebank which was created in the 1970 s and which has recently been converted to dependency format (Nivre et al., 2006b) and made freely available.",
        "Entity": "Normal"
    },
    {
        "Text": "The written sections of the treebank consist of professional prose and student essays and amount to 197,123 running tokens, spread over 11,431 sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "animacy annotation of corpus data.",
        "Entity": "Normal"
    },
    {
        "Text": "Corpus studies of animacy (Yamamoto, 1999; (2) Samma same erfarenhet experience gjorde made engelsma  nnen englishmen-D E FDahl and Fraurud, 1996) have made use of an notated data, however they differ in the extent to which the annotation has been explicitly formulated as an annotation scheme.",
        "Entity": "Normal"
    },
    {
        "Text": "The annotation  The same experience, the Englishmen had  DT OO ROOT SS study presented in Zaenen et.",
        "Entity": "Normal"
    },
    {
        "Text": "al.",
        "Entity": "Normal"
    },
    {
        "Text": "The main class distinction for animacy is three-way, distinguishing Human, Other animate and Inanimate, with sub- classes under two of the main classes.",
        "Entity": "Normal"
    },
    {
        "Text": "The  Other animate  class further distinguishes Organizations and Animals.",
        "Entity": "Normal"
    },
    {
        "Text": "Within the group of inanimates, further distinctions are made between concrete and non-concrete inanimate, as well as time and place nominals.2 The annotation scheme described in Zaenen et.",
        "Entity": "Normal"
    },
    {
        "Text": "al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2004) annotates the markables according to 2 The fact that the study focuses on genitival modification has clearly influenced the categories distinguished, as these are all distinctions which have been claimed to influence the choice of genitive construction.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, temporal nouns are frequent in genitive constructions, unlike the other inanimate nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition to information on part-of-speech, dependency head and relation, and various morphosyntactic properties such as definiteness, the annotation expresses a distinction for nominal elements between reference to human and nonhuman.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "above.",
        "Entity": "Normal"
    },
    {
        "Text": "The human/nonhuman contrast forms the central distinction in the animacy dimension and, in this respect, the annotation schemes do not conflict.",
        "Entity": "Normal"
    },
    {
        "Text": "If we compare the annotation found in Talbanken05 with the annotation proposed in Zaenen et.",
        "Entity": "Normal"
    },
    {
        "Text": "al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2004), we find that the schemes differ primarily in the granularity of classes distinguished.",
        "Entity": "Normal"
    },
    {
        "Text": "The main source of variation in class distinctions consists in the annotation of collective nouns, including organizations, as well as animals.",
        "Entity": "Normal"
    },
    {
        "Text": "tic contexts, we may group the nouns which were assigned to both classes, into the following categories:that  H H  is the tag for Abstract nouns Nouns with underspecified or vague type level properties with respect to ani- macy, such as quantifying nouns, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "ha  lft  half , miljon  million , as well as nouns which may be employed with varying animacy, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "element  element , part  party , as in (3) and (4): 3.1 Level of annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "(3) .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "ocksa  .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "also den the andra other partenH H party-D E F sta  r stands utanfo  r outside We distinguished above between type and token  .",
        "Entity": "Normal"
    },
    {
        "Text": "also the other party is left outside  level annotation strategies, where a type level annotation strategy entails that an element consistently be assigned to only one class.",
        "Entity": "Normal"
    },
    {
        "Text": "A token level (4) I in lika ett a fo  rha  llande relationship starka a  r are aldrig never ba  gge both parter parties same strongstrategy, in contrast, does not impose this restric tion on the annotation and class assignment may vary depending on the specific context.",
        "Entity": "Normal"
    },
    {
        "Text": "Garretson et.",
        "Entity": "Normal"
    },
    {
        "Text": "al (2004) propose a token level annotation strategy and state that  when coding for animacy [.\n\t\t\t]",
        "Entity": "Normal"
    },
    {
        "Text": "we are not considering the nominal per se (e.g., the word  church ), but rather the entity that is the referent of that nominal (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "some particular thing in the real world) .",
        "Entity": "Normal"
    },
    {
        "Text": "This indicates that for all possible markables, a referent should be determinable.",
        "Entity": "Normal"
    },
    {
        "Text": "The brief instruction with respect to annotation for human reference in the annotation manual for Talbanken05 (Teleman, 1974, 223) gives leeway for interpretation in the annotation and does not clearly state that it should be based on token level reference in context.",
        "Entity": "Normal"
    },
    {
        "Text": "It may thus be interesting  In a relationship, both parties are never equally strong  We also find that nouns which denote abstract concepts regarding humans show variable annotation, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "individ  individual , adressat  addressee , medlem  member , kandidat  candidate , representant  representative , auktoritet  authority  Reference shifting contexts These are nouns whose type level animacy is clear but which are employed in a specific context which shifts their reference.",
        "Entity": "Normal"
    },
    {
        "Text": "Examples include metonymic usage of nouns, as in (5) and nouns occurring in dereferencing constructions, such as predicative constructions (6), titles (7) and idioms (8):to examine the extent to which this manual an (5) .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "daghemmensH H .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "kindergarten-D E F.G E N otillra  ckliga inadequate resurser resources notation is consistent across lexemes or whether we observe variation.",
        "Entity": "Normal"
    },
    {
        "Text": "We manually examine the  .",
        "Entity": "Normal"
    },
    {
        "Text": "the kindergarten s inadequate resources  intersection of the two classes of noun lemmas (6) .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "fo  r .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "for att to bli become en bra a good soldat soldier in the written sections of Talbanken, i.e., the set of nouns which have been assigned both classes  .",
        "Entity": "Normal"
    },
    {
        "Text": "in order to become a good soldier  by the annotators.",
        "Entity": "Normal"
    },
    {
        "Text": "It contains 82 noun lemmas, (7) .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "menar .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "thinks biskop bishop Hellsten Hellstenwhich corresponds to only 1.1% of the total number of noun lemmas in the treebank (7554 lem  thinks bishop Hellsten  mas all together).",
        "Entity": "Normal"
    },
    {
        "Text": "After a manual inspection of the intersective elements along with their linguis (8) ta take studenten student-D E F  graduate from highschool (lit.",
        "Entity": "Normal"
    },
    {
        "Text": "take the student)  It is interesting to note that the main variation in annotation stems precisely from difficulties in determining reference, either due to bleak type level properties such as for the abstract nouns, or due to properties of the context, as in the reference shifting constructions.",
        "Entity": "Normal"
    },
    {
        "Text": "The small amount of variation in the human annotation for animacy clearly supports a type-level approach to animacy, however, underline the influence of the linguistic context on the conception of animacy, as noted in the literature (Zaenen et al., 2004; Rosenbach, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "Even though knowledge about the animacy of a noun clearly has some interesting implications, little work has been done within the field of lexical acquisition in order to automatically acquire ani- macy information.",
        "Entity": "Normal"
    },
    {
        "Text": "Ora san and Evans (2007) make use of hyponym-relations taken from the Word- Net resource in order to classify animate referents.",
        "Entity": "Normal"
    },
    {
        "Text": "However, such a method is clearly restricted to languages for which large scale lexical resources, such as the WordNet, are available.",
        "Entity": "Normal"
    },
    {
        "Text": "The task of animacy classification bears some resemblance to the task of named entity recognition (NER) which usually makes reference to a  person  class.",
        "Entity": "Normal"
    },
    {
        "Text": "However, whereas most NER systems make extensive use of orthographic, morphological or contextual clues (titles, suffixes) and gazetteers, animacy for nouns is not signaled overtly in the same way.",
        "Entity": "Normal"
    },
    {
        "Text": "Following a strategy in line with work on verb classification (Merlo and Stevenson, 2001; Stevenson and Joanis, 2003), we set out to classify common noun lemmas based on their morphosyntactic distribution in a considerably larger corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "This is thus equivalent to treatment of animacy as a lexical semantic property and the classification strategy is based on generalization of morphosyntactic behaviour of common nouns over large quantities of data.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to the small size of the Talbanken05 treebank and the small amount of variation, this strategy was pursued for the acquisition of animacy information.",
        "Entity": "Normal"
    },
    {
        "Text": "In the animacy classification of common nouns we exploit well-documented correlations between morphosyntactic realization and semantic properties of nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, animate nouns tend to be realized as agentive subjects, inanimate nouns do not (Dahl and Fraurud, 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "Animate nouns make good  possessors , whereas inanimate nouns are more likely  possessees  (Rosenbach, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "for common nouns in Talbanken05.",
        "Entity": "Normal"
    },
    {
        "Text": "It is clear that the data is highly skewed towards the nonhuman class, which accounts for 91.5% of the type instances.",
        "Entity": "Normal"
    },
    {
        "Text": "For classification we organize the data into accumulated frequency bins, which include all nouns with frequencies above a certain threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "We here approximate the class of  animate  to  human  and the class of  inanimate  to  nonhuman .",
        "Entity": "Normal"
    },
    {
        "Text": "Intersective elements, see section 3.1, are assigned to their majority class.3 4.1 Features for animacy classification.",
        "Entity": "Normal"
    },
    {
        "Text": "We define a feature space, which makes use of distributional data regarding the general syntactic properties of a noun, as well as various morphological properties.",
        "Entity": "Normal"
    },
    {
        "Text": "It is clear that in order for a syntactic environment to be relevant for animacy classification it must be, at least potentially, nominal.",
        "Entity": "Normal"
    },
    {
        "Text": "We define the nominal potential of a dependency relation as the frequency with which it is realized by a nominal element (noun or pronoun) and determine empirically a threshold of .10.",
        "Entity": "Normal"
    },
    {
        "Text": "The syntactic and morphological features in the feature space are presented below: Syntactic features A feature for each dependency relation with nominal potential: (transitive) subject (SU B J), object (O B J), prepositional complement (PA), root (RO OT)4 , apposition (A PP), conjunct (C C), determiner (D ET), predicative (PR D), complement of comparative subjunction (U K).",
        "Entity": "Normal"
    },
    {
        "Text": "We also include a feature for the head of a genitive modifier, the so-called  possessee , (G EN H D).",
        "Entity": "Normal"
    },
    {
        "Text": "Morphological features A feature for each morphological distinction relevant for a noun 3 When there is no majority class, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "in the case of ties, the noun is removed from the data set.",
        "Entity": "Normal"
    },
    {
        "Text": "12 lemmas were consequently removed.",
        "Entity": "Normal"
    },
    {
        "Text": "4 Nominal elements may be assigned the root relation of the dependency graph in sentence fragments which do not contain a finite verb.",
        "Entity": "Normal"
    },
    {
        "Text": "in Swedish: gender (N EU /U TR), number (SIN/PLU), definiteness (D EF/IN D), case (N O M/G EN).",
        "Entity": "Normal"
    },
    {
        "Text": "Also, the part-of-speech tags distinguish dates (DAT) and quantifying nouns (SET), e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "del, rad  part, row , so these are also included as features.",
        "Entity": "Normal"
    },
    {
        "Text": "For extraction of distributional data for the set of Swedish nouns we make use of the Swedish Parole corpus of 21.5M tokens.5 To facilitate feature extraction, we part-of-speech tag the corpus and parse it with MaltParser6 , which assigns a dependency analysis.7 4.2 Experimental methodology.",
        "Entity": "Normal"
    },
    {
        "Text": "For machine learning, we make use of the Tilburg Memory-Based Learner (TiMBL) (Daelemans et al., 2004).8 Memory-based learning is a supervised machine learning method characterized by a lazy learning algorithm which postpones learning until classification time, using the k-nearest neighbor algorithm for the classification of unseen instances.",
        "Entity": "Normal"
    },
    {
        "Text": "For animacy classification, the TiMBL parameters are optimized on a subset of the full data set.9 For training and testing of the classifiers, we make use of leave-one-out cross-validation.",
        "Entity": "Normal"
    },
    {
        "Text": "The baseline represents assignment of the majority class (inanimate) to all nouns in the data set.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to the skewed distribution of classes, as noted above, the baseline accuracy is very high, usually around 90%.Clearly, however, the class-based measures of precision and recall, as well as the combined F-score measure are more informative for these results.",
        "Entity": "Normal"
    },
    {
        "Text": "The baseline F-score for the animate class is thus 0, and a main goal is to improve on the rate of true positives for animates, while limiting the trade-off in terms of performance for\n\t\n\t\n\t\t\t6 http://www.maltparser.org 7 For part-of-speech tagging, we employ the MaltTagger.",
        "Entity": "Normal"
    },
    {
        "Text": "a HMM part-of-speech tagger for Swedish (Hall, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "For parsing, we employ MaltParser (Nivre et al., 2006a), a language-independent system for data-driven dependency parsing , with the pretrained model for Swedish, which has been trained on the tags output by the tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "8 http://ilk.uvt.nl/software.html 9 For parameter optimization we employ the paramsearch tool, supplied with TiMBL, see http://ilk.uvt.nl/software.html.",
        "Entity": "Normal"
    },
    {
        "Text": "Paramsearch implements a hill climbing search for the optimal settings on iteratively larger parts of the supplied data.",
        "Entity": "Normal"
    },
    {
        "Text": "We performed parameter optimization on 20% of the total data set, where we balanced the data with respect to frequency.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting settings are k = 11, GainRatio feature weighting and Inverse Linear (IL) class voting weights.",
        "Entity": "Normal"
    },
    {
        "Text": "Bin Instances Baseline MBL SVM >1000 291 89.3 97.3 95.2 >500 597 88.9 97.3 97.1 >100 1668 90.5 96.8 96.9 >50 2278 90.6 96.1 96.0 >10 3786 90.8 95.4 95.1 >0 5481 91.3 93.9 93.7                                                                                                                      \n\t\t\tthe majority class of inanimates, which start out with F-scores approaching 100.",
        "Entity": "Normal"
    },
    {
        "Text": "For calculation of the statistical significance of differences in the performance of classifiers tested on the same data set, McNemar s test (Dietterich, 1998) is employed.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Results.",
        "Entity": "Normal"
    },
    {
        "Text": "We observe a clear improvement on all data sets (p<.0001), compared to the respective baselines.",
        "Entity": "Normal"
    },
    {
        "Text": "As we recall, the data sets are successively larger, hence it seems fair to conclude that the size of the data set partially counteracts the lower frequency of the test nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "It is not surprising, however, that a method based on dis- tributional features suffers when the absolute frequencies approach 1.",
        "Entity": "Normal"
    },
    {
        "Text": "We obtain results for ani- macy classification, ranging from 97.3% accuracy to 93.9% depending on the sparsity of the data.",
        "Entity": "Normal"
    },
    {
        "Text": "We find that classification of the inanimate class is quite stable throughout the experiments, whereas the classification of the minority class of animate nouns suffers from sparse data.",
        "Entity": "Normal"
    },
    {
        "Text": "It is an important point, however, that it is largely recall for the animate class which goes down with increased sparseness, whereas precision remains quite stable.",
        "Entity": "Normal"
    },
    {
        "Text": "All of these properties are clearly advantageous in the application to realistic data sets, where a more conservative classifier is to be preferred.",
        "Entity": "Normal"
    },
    {
        "Text": "4.4 Error analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "The human reference annotation of the Talbanken05 nouns distinguishes only the classes corresponding to  human  and  inanimate  along the A n i m a t e Inanimate Prec isio n Rec all Fsc ore Prec isio n Rec all Fsco re >10 00 >50 0 >10 0 >50 >10 >0 8 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 8 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 8 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 8 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 8 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 8 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 8 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 7 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 8 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 8 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 7 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 7 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 8 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 7 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 7 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 4 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 9 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 9 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 9 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 9 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 9 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 9 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 9 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 9 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 Table 3: Precision, recall and F-scores for the two classes in MBL-experiments with a general feature space.",
        "Entity": "Normal"
    },
    {
        "Text": "animacy dimension.",
        "Entity": "Normal"
    },
    {
        "Text": "An interesting question is whether the errors show evidence of the gradience in categories discussed earlier and explicitly expressed in the annotation scheme by Zaenen et.al.",
        "Entity": "Normal"
    },
    {
        "Text": "If so, we would expect erroneously classified inanimate nouns to contain nouns of intermediate animacy, such as animals and organizations.",
        "Entity": "Normal"
    },
    {
        "Text": "The error analysis examines the performance of the MBLclassifier employing all features on the > 10 data set in order to abstract away from the most serious effects of data sparseness.",
        "Entity": "Normal"
    },
    {
        "Text": "If we examine the errors for the inanimate class we indeed find evidence of gradience within this category.",
        "Entity": "Normal"
    },
    {
        "Text": "The errors contain a group of nouns referring to animals and other living beings (bacteria, algae), as listed in (9), as well as one noun referring to an  intelligent machine , included in the intermediate animacy category in Zaenen et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2004).",
        "Entity": "Normal"
    },
    {
        "Text": "Collective nouns with human reference and organizations are also found among the errors, listed in (11).",
        "Entity": "Normal"
    },
    {
        "Text": "We also find some nouns among the errors with human denotation, listed in (12).",
        "Entity": "Normal"
    },
    {
        "Text": "These are nouns which typically occur in dereferencing contexts, such as titles, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "herr  mister , biskop  bishop  and which were annotated as nonhuman referring by the human an- notators.10 Finally, a group of abstract, human 10In fact, both of these showed variable annotation in the treebank and were assigned their majority class   inanimate denoting nouns are also found among the errors, as listed in (13).",
        "Entity": "Normal"
    },
    {
        "Text": "In summary, we find that nouns with gradient animacy properties account for 53.1% of the errors for the inanimate class.",
        "Entity": "Normal"
    },
    {
        "Text": "(9) Animals/living beings: alg  algae , apa  monkey , bakterie  bacteria , bjo  rn  bear , djur  animal , fa  gel  bird , fladdermo  ss  bat , myra  ant , ma  s  seagull , parasit  parasite  (10) Intelligent machines: robot  robot  (11) Collective nouns, organizations: myndighet  authority , nation  nation , fo  retagsledning  corporate-board , personal  personell , stiftelse  foundation , idrottsklubb  sport-club  (12) Human-denoting nouns: biskop  bishop , herr  mister , nationalist  nationalist , tolk  interpreter  (13) Abstract, human nouns: fo  rlorare  loser , huvudpart  main-party , konkurrent  competitor , majoritet  majority , va  rd  host  It is interesting to note that both the human and automatic annotation showed difficulties in ascertaining class for a group of abstract, human-denoting nouns, like individ  individual , motsta  ndare  opponent , kandidat  candidate , representant  representative .",
        "Entity": "Normal"
    },
    {
        "Text": "These were all assigned to the animate majority class during extraction, but were misclassified as inanimate during classification.",
        "Entity": "Normal"
    },
    {
        "Text": "4.5 SVM classifiers.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to evaluate whether the classification method generalizes to a different machine learning algorithm, we design an identical set of experiments to the ones presented above, but where classification is performed with Support Vector Machines (SVMs) instead of MBL.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the LIB- SVM package (Chang and Lin, 2001) with a RBF kernel (C = 8.0,   = 0.5).11   in the extraction of training data.",
        "Entity": "Normal"
    },
    {
        "Text": "11 As in the MBL-experiment, parameter optimization, i.e., choice of kernel function, C and   values, is performed on 20% of the total data set with the easy.py tool, supplied with LIBSVM.",
        "Entity": "Normal"
    },
    {
        "Text": "5 Parsing with animacy information.",
        "Entity": "Normal"
    },
    {
        "Text": "As an external evaluation of our animacy classifier, we apply the induced information to the task of syntactic parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "Seeing that we have a tree- bank with gold standard syntactic information and gold standard as well as induced animacy information, it should be possible to study the direct effect of the added animacy information in the assignment of syntactic structure.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Experimental methodology.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the freely available MaltParser system, which is a language-independent system for data- driven dependency parsing (Nivre, 2006; Nivre et al., 2006c).",
        "Entity": "Normal"
    },
    {
        "Text": "A set of parsers are trained on Talbanken05, both with and without additional an- imacy information, the origin of which is either the manual annotation described in section 3 or the automatic animacy classifier described in section 4.24.4 (MBL).",
        "Entity": "Normal"
    },
    {
        "Text": "The common nouns in the treebank are classified for animacy using leave- one-out training and testing.",
        "Entity": "Normal"
    },
    {
        "Text": "This ensures that the training and test instances are disjoint at all times.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, the fact that the distributional data is taken from a separate data set ensures non- circularity since we are not basing the classification on gold standard parses.",
        "Entity": "Normal"
    },
    {
        "Text": "All parsing experiments are performed using 10-fold cross-validation for training and testing on the entire written part of Talbanken05.",
        "Entity": "Normal"
    },
    {
        "Text": "Overall parsing accuracy will be reported using the standard metrics of labeled attachment score (LAS) and unlabeled attachment score (UAS).13 Statistical significance is checked using Dan Bikel s randomized parsing evaluation comparator.14 As our baseline, we use the settings optimized for Swedish in the CoNLL-X shared task (Buchholz 12The SVMclassifiers generally show slightly lower results, however, only performance on the >1000 data set is significantly lower (p<.05).",
        "Entity": "Normal"
    },
    {
        "Text": "13LAS and UAS report the percentage of tokens that are assigned the correct head with (labeled) or without (unlabeled) the correct dependency label.",
        "Entity": "Normal"
    },
    {
        "Text": "and Marsi, 2006), where this parser was the best performing parser for Swedish.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2 Results.",
        "Entity": "Normal"
    },
    {
        "Text": "The addition of automatically assigned animacy information for common nouns (Anim) causes a small, but significant improvement in overall results (p<.04) compared to the baseline, as well as the corresponding gold standard experiment (p<.04).",
        "Entity": "Normal"
    },
    {
        "Text": "In the gold standard experiment, the results are not significantly better than the baseline and the main, overall, improvement from the gold standard animacy information reported in  vrelid and Nivre (2007) and  vrelid (2008) stems largely from the animacy annotation of pronouns.15 This indicates that the animacy information for common nouns, which has been automatically acquired from a considerably larger corpus, captures distributional distinctions which are important for the general effect of animacy and furthermore that the differences from the gold standard annotation prove beneficial for the results.",
        "Entity": "Normal"
    },
    {
        "Text": "A closer error analysis shows that the performance of the two parsers employing gold and automatic animacy information is very similar with respect to dependency relations and we observe an improved analysis for subjects, (direct and indirect) objects and subject predicatives with only minor variations.",
        "Entity": "Normal"
    },
    {
        "Text": "This in itself is remarkable, since the covered set of animate instances is notably smaller in the automatically annotated data set.",
        "Entity": "Normal"
    },
    {
        "Text": "We furthermore find that the main difference between the gold standard and automatic Anim-experiments 15 Recall that the Talbanken05 treebank contains animacy information for all nominal elements   pronouns, proper and common nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "When the totality of this information is added the overall parse results are significantly improved (p<.0002) ( vrelid and Nivre, 2007;  vrelid, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "does not reside in the analysis of syntactic arguments, but rather of non-arguments.",
        "Entity": "Normal"
    },
    {
        "Text": "One relation for which performance deteriorates with the added information in the gold Anim-experiment is the nominal postmodifier relation (ET) which is employed for relative clauses and nominal PP- attachment.",
        "Entity": "Normal"
    },
    {
        "Text": "With the automatically assigned feature, in contrast, we observe an improvement in the performance for the ET relation, compared to the gold standard experiment, from a F-score in the latter of 76.14 to 76.40 in the former.",
        "Entity": "Normal"
    },
    {
        "Text": "Since this is a quite common relation, with a frequency of 5% in the treebank as a whole, the improvement has a clear effect on the results.The parser s analysis of postnominal modifica tion is influenced by the differences in the added animacy annotation for the nominal head, as well as the internal dependent.",
        "Entity": "Normal"
    },
    {
        "Text": "If we examine the corrected errors in the automatic experiment, compared to the gold standard experiment, we find elements with differing annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "Preferences with respect to the animacy of prepositional complements vary.",
        "Entity": "Normal"
    },
    {
        "Text": "In (14), the automatic annotation of the noun djur  animal  as animate results in correct assignment of the ET relation to the preposition hos  among , as well as correct nominal, as opposed to verbal, attachment.",
        "Entity": "Normal"
    },
    {
        "Text": "This preposition is one of the few with a preference for animate complements in the treebank.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, the example in (15) illustrates an error where the automatic classification of barn  children  as inanimate causes a correct analysis of the head preposition om  about .16\n\t\n\t\n\t\t\tThis article has dealt with an empirical evaluation of animacy annotation in Swedish, where the main focus has been on the use of such annotation for computational purposes.We have seen that human annotation for ani macy shows little variation at the type-level for a binary animacy distinction.",
        "Entity": "Normal"
    },
    {
        "Text": "Following from this observation, we have shown how a type- level induction strategy based on morphosyntac- tic distributional features enables automatic ani- macy classification for noun lemmas which furthermore generalizes to different machine learning algorithms (MBL, SVM).",
        "Entity": "Normal"
    },
    {
        "Text": "We obtain results for an- imacy classification, ranging from 97.3% accuracy to 93.9% depending on the sparsity of the data.",
        "Entity": "Normal"
    },
    {
        "Text": "With an absolute frequency threshold of 10, we obtain an accuracy of 95.4%, which constitutes a50% reduction of error rate.",
        "Entity": "Normal"
    },
    {
        "Text": "A detailed error anal ysis revealed some interesting results and we saw that more than half of the errors performed by the animacy classifier for the large class of inanimate nouns actually included elements which have been assigned an intermediate animacy status in theoretical work, such as animals and collective nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "The application of animacy annotation in the task of syntactic parsing provided a test bed for the applicability of the annotation, where we could contrast the manually assigned classes with the automatically acquired ones.",
        "Entity": "Normal"
    },
    {
        "Text": "The results showed that the automatically acquired information gives a slight, but significant improvement of overall parse results where the gold standard annotation (14) .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "samha  llsbildningar .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "societies hos among olika different djur animals does not, despite a considerably lower coverage.",
        "Entity": "Normal"
    },
    {
        "Text": "This is a suprising result which highlights impor  .",
        "Entity": "Normal"
    },
    {
        "Text": "social organizations among different animals  tant properties of the annotation.",
        "Entity": "Normal"
    },
    {
        "Text": "First of all, the (15) Fo  ra  ldrar parents har have va  rdnaden custody-D E F om sina of their barn children automatic annotation is completely consistent at the type level.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, the automatic animacy  Parents have the custody of their children  A more thorough analysis of the different factors involved in PP-attachment is a complex task which is clearly beyond the scope of the present study.",
        "Entity": "Normal"
    },
    {
        "Text": "We may note, however, that the distinctions induced by the animacy classifier based purely on linguistic evidence proves useful for the analysis of both arguments and non-arguments.",
        "Entity": "Normal"
    },
    {
        "Text": "16Recall that the classification is based purely on linguistic evidence and in this respect children largely pattern with the inanimate nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "A child is probably more like a physical object in the sense that it is something one possesses and otherwise reacts to, rather than being an agent that acts upon its surroundings.",
        "Entity": "Normal"
    },
    {
        "Text": "classifier captures important distributional properties of the nouns, exemplified by the case of nominal postmodifiers in PP-attachment.",
        "Entity": "Normal"
    },
    {
        "Text": "The automatic annotation thus captures a purely linguistic notion of animacy and abstracts over contextual influence in particular instances.",
        "Entity": "Normal"
    },
    {
        "Text": "Animacy has been shown to be an important property in a range of languages, hence animacy classification of other languages constitutes an interesting line of work for the future, where empirical evaluations may point to similarities and differences in the linguistic expression of animacy.",
        "Entity": "Normal"
    },
    {
        "Text": "\nA Stochastic Finite-State Word-Segmentation Algorithm for Chinese\n\nThe initial stage of text analysis for any NLP task usually involves the tokenization of the input into words.",
        "Entity": "Normal"
    },
    {
        "Text": "For languages like English one can assume, to a first approximation, that word boundaries are given by whitespace or punctuation.",
        "Entity": "Normal"
    },
    {
        "Text": "In various Asian languages, including Chinese, on the other hand, whitespace is never used to delimit words, so one must resort to lexical information to \"reconstruct\" the word-boundary information.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we present a stochastic finite-state model wherein the basic workhorse is the weighted finite-state transducer.",
        "Entity": "Normal"
    },
    {
        "Text": "The model segments Chinese text into dictionary entries and words derived by various productive lexical processes, and--since the primary intended application of this model is to text-to-speech synthesis--provides pronunciations for these words.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluate the system's performance by comparing its segmentation 'Tudgments\" with the judgments of a pool of human segmenters, and the system is shown to perform quite well.",
        "Entity": "Normal"
    },
    {
        "Text": "Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).",
        "Entity": "Normal"
    },
    {
        "Text": "An initial step of any text  analysis task is the tokenization of the input into words.",
        "Entity": "Normal"
    },
    {
        "Text": "For a language like English, this problem is generally regarded as trivial since words are delimited in English text by whitespace or marks of punctuation.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus in an English sentence such as I'm going to show up at the ACL one would reasonably conjecture that there are eight words separated by seven spaces.",
        "Entity": "Normal"
    },
    {
        "Text": "A moment's reflection will reveal that things are not quite that simple.",
        "Entity": "Normal"
    },
    {
        "Text": "There are clearly eight orthographic words in the example given, but if one were doing syntactic analysis one would probably want to consider I'm to consist of two syntactic words, namely I and am.",
        "Entity": "Normal"
    },
    {
        "Text": "If one is interested in translation, one would probably want to consider show up as a single dictionary word since its semantic interpretation is not trivially derivable from the meanings of show and up.",
        "Entity": "Normal"
    },
    {
        "Text": "And if one is interested in TIS, one would probably consider the single orthographic word ACL to consist of three phonological words-lei s'i d/-corresponding to the pronunciation of each of the letters in the acronym.",
        "Entity": "Normal"
    },
    {
        "Text": "Space- or punctuation-delimited * 700 Mountain Avenue, 2d451, Murray Hill, NJ 07974, USA.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: rlls@bell-labs.",
        "Entity": "Normal"
    },
    {
        "Text": "com t 700 Mountain Avenue, 2d451, Murray Hill, NJ 07974, USA.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: cls@bell-labs.",
        "Entity": "Normal"
    },
    {
        "Text": "com t 600 Mountain Avenue, 2c278, Murray Hill, NJ 07974, USA.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: gale@research.",
        "Entity": "Normal"
    },
    {
        "Text": "att.",
        "Entity": "Normal"
    },
    {
        "Text": "com  Cambridge, UK Email: nc201@eng.cam.ac.uk   1996 Association for Computational Linguistics (a) B ) ( , : & ; ? '",
        "Entity": "Normal"
    },
    {
        "Text": "H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? '",
        "Entity": "Normal"
    },
    {
        "Text": "(b) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : & I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l ' J a p a n e s e ' ' o c t o p u s ' ' h o w ' ' s a y ' (c) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [ ] lxI 1:&I ri4 wen2 zhangl yu2zen3 me0 shuol 'Japan' 'essay' 'fish' 'how' 'say' A Chinese sentence in (a) illustrating the lack of word boundaries.",
        "Entity": "Normal"
    },
    {
        "Text": "In (b) is a plausible segmentation for this sentence; in (c) is an implausible segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "orthographic words are thus only a starting point for further analysis and can only be regarded as a useful hint at the desired division of the sentence into words.",
        "Entity": "Normal"
    },
    {
        "Text": "Whether a language even has orthographic words is largely dependent on the writing system used to represent the language (rather than the language itself); the notion \"orthographic word\" is not universal.",
        "Entity": "Normal"
    },
    {
        "Text": "Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ  ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.",
        "Entity": "Normal"
    },
    {
        "Text": "In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion \"word\" has never played a role in Chinese philological tradition, and the idea that Chinese lacks any  thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).",
        "Entity": "Normal"
    },
    {
        "Text": "Twentieth-century linguistic work on Chinese (Chao 1968; Li and Thompson 1981; Tang 1988,1989, inter alia) has revealed the incorrectness of this traditional view.",
        "Entity": "Normal"
    },
    {
        "Text": "All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..\n\t\t\t2 Chinese ?l* han4zi4 'Chinese character'; this is the same word as Japanese kanji..\n\t\t\t3 Throughout this paper we shall give Chinese examples in traditional orthography, followed.",
        "Entity": "Normal"
    },
    {
        "Text": "immediately by a Romanization into the pinyin transliteration scheme; numerals following each pinyin syllable represent tones.",
        "Entity": "Normal"
    },
    {
        "Text": "Examples will usually be accompanied by a translation, plus a morpheme-by-morpheme gloss given in parentheses whenever the translation does not adequately serve this purpose.",
        "Entity": "Normal"
    },
    {
        "Text": "In the pinyin transliterations a dash(-) separates syllables that may be considered part of the same phonological word; spaces are used to separate plausible phonological words; and a plus sign (+) is used, where relevant, to indicate morpheme boundaries of interest.",
        "Entity": "Normal"
    },
    {
        "Text": "raphy: A ren2 'person' is a fairly uncontroversial case of a monographemic word, and rplil zhong1guo2 (middle country) 'China' a fairly uncontroversial case of a di  graphernic word.",
        "Entity": "Normal"
    },
    {
        "Text": "The relevance of the distinction between, say, phonological words and, say, dictionary words is shown by an example like rpftl_A :;!",
        "Entity": "Normal"
    },
    {
        "Text": ":Hfllil zhong1hua2 ren2min2 gong4he2-guo2 (China people republic) 'People's Republic of China.'",
        "Entity": "Normal"
    },
    {
        "Text": "Arguably this consists of about three phonological words.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, in a translation system one probably wants to treat this string as a single dictionary word since it has a conventional and somewhat unpredictable translation into English.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, suppose one is building a ITS system for Mandarin Chinese.",
        "Entity": "Normal"
    },
    {
        "Text": "For that application, at a minimum, one would want to know the phonological word boundaries.",
        "Entity": "Normal"
    },
    {
        "Text": "Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.",
        "Entity": "Normal"
    },
    {
        "Text": "However, there are several reasons why this approach will not in general work: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Many hanzi have more than one pronunciation, where the correct.",
        "Entity": "Normal"
    },
    {
        "Text": "pronunciation depends upon word affiliation: tfJ is pronounced deO when it is a prenominal modification marker, but di4 in the word  tfJ mu4di4 'goal'; fl; is normally ganl 'dry,' but qian2 in a person's given name.",
        "Entity": "Normal"
    },
    {
        "Text": "including Third Tone Sandhi (Shih 1986), which changes a 3 (low) tone into a 2 (rising) tone before another 3 tone: 'j\";gil, xiao3 [lao3 shu3] 'little rat,' becomes xiao3 { lao2shu3 ], rather than xiao2 { lao2shu3 ], because the rule first applies within the word lao3shu3 'rat,' blocking its phrasal application.",
        "Entity": "Normal"
    },
    {
        "Text": "3.",
        "Entity": "Normal"
    },
    {
        "Text": "In various dialects of Mandarin certain phonetic rules apply at the word.",
        "Entity": "Normal"
    },
    {
        "Text": "level.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in Northern dialects (such as Beijing), a full tone (1, 2, 3, or 4) is changed to a neutral tone (0) in the final syllable of many words: Jll donglgual 'winter melon' is often pronounced donglguaO.",
        "Entity": "Normal"
    },
    {
        "Text": "The high 1 tone of J1l would not normally neutralize in this fashion if it were functioning as a word on its own.",
        "Entity": "Normal"
    },
    {
        "Text": "4.",
        "Entity": "Normal"
    },
    {
        "Text": "TIS systems in general need to do more than simply compute the.",
        "Entity": "Normal"
    },
    {
        "Text": "pronunciations of individual words; they also need to compute intonational phrase boundaries in long utterances and assign relative prominence to words in those utterances.",
        "Entity": "Normal"
    },
    {
        "Text": "It has been shown for English (Wang and Hirschberg 1992; Hirschberg 1993; Sproat 1994, inter alia) that grammatical part of speech provides useful information for these tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "Given that part-of-speech labels are properties of words rather than morphemes, it follows that one cannot do part-of-speech assignment without having access to word-boundary information.",
        "Entity": "Normal"
    },
    {
        "Text": "Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.",
        "Entity": "Normal"
    },
    {
        "Text": "There are thus some very good reasons why segmentation into words is an important task.",
        "Entity": "Normal"
    },
    {
        "Text": "A minimal requirement for building a Chinese word segmenter is obviously a dictionary; furthermore, as has been argued persuasively by Fung and Wu (1994), one will perform much better at segmenting text by using a dictionary constructed with text of the same genre as the text to be segmented.",
        "Entity": "Normal"
    },
    {
        "Text": "For novel texts, no lexicon that consists simply of a list of word entries will ever be entirely satisfactory, since the list will inevitably omit many constructions that should be considered words.",
        "Entity": "Normal"
    },
    {
        "Text": "Among these are words derived by various productive processes, including: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Morphologically derived words such as, xue2shengl+men0.",
        "Entity": "Normal"
    },
    {
        "Text": "(student+plural) 'students,' which is derived by the affixation of the plural affix f, menD to the nounxue2shengl.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "Personal names such as 00, 3R; zhoulenl-lai2 'Zhou Enlai.'",
        "Entity": "Normal"
    },
    {
        "Text": "Of course, we.",
        "Entity": "Normal"
    },
    {
        "Text": "can expect famous names like Zhou Enlai's to be in many dictionaries, but names such as :fi lf;f; shi2jil-lin2, the name of the second author of this paper, will not be found in any dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "'Malaysia.'",
        "Entity": "Normal"
    },
    {
        "Text": "Again, famous place names will most likely be found in the dictionary, but less well-known names, such as 1PM  R; bu4lang3-shi4wei2-ke4 'Brunswick' (as in the New Jersey town name 'New Brunswick') will not generally be found.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we present a stochastic finite-state model for segmenting Chinese text into words, both words found in a (static) lexicon as well as words derived via the above-mentioned productive processes.",
        "Entity": "Normal"
    },
    {
        "Text": "The segmenter handles the grouping of hanzi into words and outputs word pronunciations, with default pronunciations for hanzi it cannot group; we focus here primarily on the system's ability to segment text appropriately (rather than on its pronunciation abilities).",
        "Entity": "Normal"
    },
    {
        "Text": "The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.",
        "Entity": "Normal"
    },
    {
        "Text": "It also incorporates the Good-Turing method (Baayen 1989; Church and Gale 1991) in estimating the likelihoods of previously unseen con  structions, including morphological derivatives and personal names.",
        "Entity": "Normal"
    },
    {
        "Text": "We will evaluate various specific aspects of the segmentation, as well as the overall segmentation per  formance.",
        "Entity": "Normal"
    },
    {
        "Text": "This latter evaluation compares the performance of the system with that of several human judges since, as we shall show, even people do not agree on a single correct way to segment a text.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, this effort is part of a much larger program that we are undertaking to develop stochastic finite-state methods for text analysis with applications to TIS and other areas; in the final section of this paper we will briefly discuss this larger program so as to situate the work discussed here in a broader context.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "A Brief Introduction to the Chinese Writing System Most readers will undoubtedly be at least somewhat familiar with the nature of the Chinese writing system, but there are enough common misunderstandings that it is as well to spend a few paragraphs on properties of the Chinese script that will be relevant to topics discussed in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "The first point we need to address is what type of linguistic object a hanzi repre  sents.",
        "Entity": "Normal"
    },
    {
        "Text": "Much confusion has been sown about Chinese writing by the use of the term ideograph, suggesting that hanzi somehow directly represent ideas.",
        "Entity": "Normal"
    },
    {
        "Text": "The most accurate characterization of Chinese writing is that it is morphosyllabic (DeFrancis 1984): each hanzi represents one morpheme lexically and semantically, and one syllable phonologi  cally.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus in a two-hanzi word like lflli?J zhong1guo2 (middle country) 'China' there are two syllables, and at the same time two morphemes.",
        "Entity": "Normal"
    },
    {
        "Text": "Of course, since the number of attested (phonemic) Mandarin syllables (roughly 1400, including tonal distinctions) is far smaller than the number of morphemes, it follows that a given syllable could in principle be written with any of several different hanzi, depending upon which morpheme is intended: the syllable zhongl could be lfl 'middle,''clock,''end,' or ,'loyal.'",
        "Entity": "Normal"
    },
    {
        "Text": "A morpheme, on the other hand, usually corresponds to a unique hanzi, though there are a few cases where variant forms are found.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, quite a few hanzi are homographs, meaning that they may be pronounced in several different ways, and in extreme cases apparently represent different morphemes: The prenominal modifi  cation marker eg deO is presumably a different morpheme from the second morpheme of  eg mu4di4, even though they are written the same way.4 The second point, which will be relevant in the discussion of personal names in Section 4.4, relates to the internal structure of hanzi.",
        "Entity": "Normal"
    },
    {
        "Text": "Following the system devised under the Qing emperor Kang Xi, hanzi have traditionally been classified according to a set of approximately 200 semantic radicals; members of a radical class share a particular structural component, and often also share a common meaning (hence the term 'semantic').",
        "Entity": "Normal"
    },
    {
        "Text": "For example, hanzi containing the INSECT radical !R tend to denote insects and other crawling animals; examples include tr wal 'frog,' feng1 'wasp,' and !Itt she2 'snake.'",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, hanzi sharing the GHOST radical _m tend to denote spirits and demons, such as _m gui3 'ghost' itself, II: mo2 'demon,' and yan3 'nightmare.'",
        "Entity": "Normal"
    },
    {
        "Text": "While the semantic aspect of radicals is by no means completely predictive, the semantic homogeneity of many classes is quite striking: for example 254 out of the 263 examples (97%) of the INSECT class listed by Wieger (1965, 77376) denote crawling or invertebrate animals; similarly 21 out of the 22 examples (95%) of the GHOST class (page 808) denote ghosts or spirits.",
        "Entity": "Normal"
    },
    {
        "Text": "As we shall argue, the semantic class affiliation of a hanzi constitutes useful information in predicting its properties.",
        "Entity": "Normal"
    },
    {
        "Text": "3.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous Work.",
        "Entity": "Normal"
    },
    {
        "Text": "There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexi  cal rule-based approaches, and approaches that combine lexical information with sta  tistical information.",
        "Entity": "Normal"
    },
    {
        "Text": "The present proposal falls into the last group.",
        "Entity": "Normal"
    },
    {
        "Text": "Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.",
        "Entity": "Normal"
    },
    {
        "Text": "In that work, mutual information was used to decide whether to group adjacent hanzi into two-hanzi words.",
        "Entity": "Normal"
    },
    {
        "Text": "Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "A related point is that mutual information is helpful in augmenting existing electronic dictionaries, (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "4 To be sure, it is not always true that a hanzi represents a syllable or that it represents a morpheme.",
        "Entity": "Normal"
    },
    {
        "Text": "For.",
        "Entity": "Normal"
    },
    {
        "Text": "example, in Northern Mandarin dialects there is a morpheme -r that attaches mostly to nouns, and which is phonologically incorporated into the syllable to which it attaches: thus men2+r (door+R) 'door' is realized as mer2.",
        "Entity": "Normal"
    },
    {
        "Text": "This is orthographically represented as 7C.",
        "Entity": "Normal"
    },
    {
        "Text": "so that 'door' would be and in this case the hanzi 7C, does not represent a syllable.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, there is no compelling evidence that either of the syllables of f.ifflll binllang2 'betelnut' represents a morpheme, since neither can occur in any context without the other: more likely fjfflll binllang2 is a disyllabic morpheme.",
        "Entity": "Normal"
    },
    {
        "Text": "(See Sproat and Shih 1995.)",
        "Entity": "Normal"
    },
    {
        "Text": "However, the characterization given in the main body of the text is correct sufficiently often to be useful.",
        "Entity": "Normal"
    },
    {
        "Text": "Church and Hanks [1989]), and we have used lists of character pairs ranked by mutual information to expand our own dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "Nonstochastic lexical-knowledge-based approaches have been much more numer  ous.",
        "Entity": "Normal"
    },
    {
        "Text": "Two issues distinguish the various proposals.",
        "Entity": "Normal"
    },
    {
        "Text": "The first concerns how to deal with ambiguities in segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "The second concerns the methods used (if any) to ex  tend the lexicon beyond the static list of entries provided by the machine-readable dictionary upon which it is based.",
        "Entity": "Normal"
    },
    {
        "Text": "The most popular approach to dealing with seg  mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.",
        "Entity": "Normal"
    },
    {
        "Text": "This method, one instance of which we term the \"greedy algorithm\" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin  ning) of the sentence is reached.",
        "Entity": "Normal"
    },
    {
        "Text": "Papers that use this method or minor variants thereof include Liang (1986), Li et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1991}, Gu and Mao (1994), and Nie, Jin, and Hannan (1994).",
        "Entity": "Normal"
    },
    {
        "Text": "The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Some approaches depend upon some form of con  straint satisfaction based on syntactic or semantic features (e.g., Yeh and Lee [1991], which uses a unification-based approach).",
        "Entity": "Normal"
    },
    {
        "Text": "Others depend upon various lexical heuris  tics: for example Chen and Liu (1992) attempt to balance the length of words in a three-word window, favoring segmentations that give approximately equal length for each word.",
        "Entity": "Normal"
    },
    {
        "Text": "Methods for expanding the dictionary include, of course, morphological rules, rules for segmenting personal names, as well as numeral sequences, expressions for dates, and so forth (Chen and Liu 1992; Wang, Li, and Chang 1992; Chang and Chen 1993; Nie, Jin, and Hannan 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost  based scoring mechanism.",
        "Entity": "Normal"
    },
    {
        "Text": "Approaches differ in the algorithms used for scoring and selecting the best path, as well as in the amount of contextual information used in the scoring process.",
        "Entity": "Normal"
    },
    {
        "Text": "The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).",
        "Entity": "Normal"
    },
    {
        "Text": "More complex approaches such as the relaxation technique have been applied to this problem Fan and Tsai (1988}.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that Chang, Chen, and Chen (1991), in addition to word-frequency information, include a constraint-satisfication model, so their method is really a hybrid approach.",
        "Entity": "Normal"
    },
    {
        "Text": "Several papers report the use of part-of-speech information to rank segmentations (Lin, Chiang, and Su 1993; Peng and Chang 1993; Chang and Chen 1993); typically, the probability of a segmentation is multiplied by the probability of the tagging(s) for that segmentation to yield an estimate of the total probability for the analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "Statistical methods seem particularly applicable to the problem of unknown-word identification, especially for constructions like names, where the linguistic constraints are minimal, and where one therefore wants to know not only that a particular se  quence of hanzi might be a name, but that it is likely to be a name with some probabil  ity.",
        "Entity": "Normal"
    },
    {
        "Text": "Several systems propose statistical methods for handling unknown words (Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac  tually tag the words as belonging to one or another class of expression.",
        "Entity": "Normal"
    },
    {
        "Text": "This is not ideal for some applications, however.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, for TTS it is necessary to know that a particular sequence of hanzi is of a particular category because that knowl  edge could affect the pronunciation; consider, for example the issues surrounding the pronunciation of ganl I qian2 discussed in Section 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.",
        "Entity": "Normal"
    },
    {
        "Text": "However, it is almost universally the case that no clear definition of what constitutes a \"correct\" segmentation is given, so these performance measures are hard to evaluate.",
        "Entity": "Normal"
    },
    {
        "Text": "Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.",
        "Entity": "Normal"
    },
    {
        "Text": "In a few cases, the criteria for correctness are made more explicit.",
        "Entity": "Normal"
    },
    {
        "Text": "For example Chen and Liu (1992) report precision and recall rates of over 99%, but this counts only the words that occur in the test corpus that also occur in their dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.",
        "Entity": "Normal"
    },
    {
        "Text": "The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.",
        "Entity": "Normal"
    },
    {
        "Text": "The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus: as Fung and Wu (1994) have shown, one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented.",
        "Entity": "Normal"
    },
    {
        "Text": "Chinese word segmentation can be viewed as a stochastic transduction problem.",
        "Entity": "Normal"
    },
    {
        "Text": "More formally, we start by representing the dictionary D as a Weighted Finite State Trans  ducer (WFST) (Pereira, Riley, and Sproat 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Let H be the set of hanzi, p be the set of pinyin syllables with tone marks, and P be the set of grammatical part-of-speech labels.",
        "Entity": "Normal"
    },
    {
        "Text": "Then each arc of D maps either from an element of H to an element of p, or from E-i.e., the empty string-to an element of P. More specifically, each word is represented in the dictionary as a sequence of arcs, starting from the initial state of D and labeled with an element 5 of Hxp, which is terminated with a weighted arc labeled with an element of Ex P. The weight represents the estimated cost (negative log probability) of the word.",
        "Entity": "Normal"
    },
    {
        "Text": "Next, we represent the input sentence as an unweighted finite-state acceptor (FSA) I over H. Let us assume the existence of a function Id, which takes as input an FSA A, and produces as output a transducer that maps all and only the strings of symbols accepted by A to themselves (Kaplan and Kay 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "We can 5 Recall that precision is defined to be the number of correct hits divided by the total number of items.",
        "Entity": "Normal"
    },
    {
        "Text": "selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.",
        "Entity": "Normal"
    },
    {
        "Text": "then define the best segmentation to be the cheapest or best path in Id(I) o D* (i.e., Id(I) composed with the transitive closure of 0).6 Consider the abstract example illustrated in Figure 2.",
        "Entity": "Normal"
    },
    {
        "Text": "In this example there are four \"input characters,\" A, B, C and D, and these map respectively to four \"pronunciations\" a, b, c and d. Furthermore, there are four \"words\" represented in the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "These are shown, with their associated costs, as follows: ABj nc 4.0 AB C/jj 6.0 CD /vb 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 D/ nc 5.0 The minimal dictionary encoding this information is represented by the WFST in Figure 2(a).",
        "Entity": "Normal"
    },
    {
        "Text": "An input ABCD can be represented as an FSA as shown in Figure 2(b).",
        "Entity": "Normal"
    },
    {
        "Text": "This FSA I can be segmented into words by composing Id(I) with D*, to form the WFST shown in Figure 2(c), then selecting the best path through this WFST to produce the WFST in Figure 2(d).",
        "Entity": "Normal"
    },
    {
        "Text": "This WFST represents the segmentation of the text into the words AB and CD, word boundaries being marked by arcs mapping between f and part-of-speech labels.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the segmentation corresponds to the sequence of words that has the lowest summed unigram cost, the segmenter under discussion here is a zeroth-order model.",
        "Entity": "Normal"
    },
    {
        "Text": "It is important to bear in mind, though, that this is not an inherent limitation of the model.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, it is well-known that one can build a finite-state bigram (word) model by simply assigning a state Si to each word Wi in the vocabulary, and having (word) arcs leaving that state weighted such that for each Wj and corresponding arc aj leaving Si, the cost on aj is the bigram cost of WiWj- (Costs for unseen bigrams in such a scheme would typically be modeled with a special backoff state.)",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 6 we dis  cuss other issues relating to how higher-order language models could be incorporated into the model.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Dictionary Representation.",
        "Entity": "Normal"
    },
    {
        "Text": "As we have seen, the lexicon of basic words and stems is represented as a WFST; most arcs in this WFST represent mappings between hanzi and pronunciations, and are costless.",
        "Entity": "Normal"
    },
    {
        "Text": "Each word is terminated by an arc that represents the transduction between f and the part of speech of that word, weighted with an estimated cost for that word.",
        "Entity": "Normal"
    },
    {
        "Text": "The cost is computed as follows, where N is the corpus size and f is the frequency: (1) Besides actual words from the base dictionary, the lexicon contains all hanzi in the Big 5 Chinese code/ with their pronunciation(s), plus entries for other characters that can be found in Chinese text, such as Roman letters, numerals, and special symbols.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that hanzi that are not grouped into dictionary words (and are not identified as single  hanzi words), or into one of the other categories of words discussed in this paper, are left unattached and tagged as unknown words.",
        "Entity": "Normal"
    },
    {
        "Text": "Other strategies could readily 6 As a reviewer has pointed out, it should be made clear that the function for computing the best path is.",
        "Entity": "Normal"
    },
    {
        "Text": "an instance of the Viterbi algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "7 Big 5 is the most popular Chinese character coding standard in use in Taiwan and Hong Kong.",
        "Entity": "Normal"
    },
    {
        "Text": "It is.",
        "Entity": "Normal"
    },
    {
        "Text": "based on the traditional character set rather than the simplified character set used in Singapore and Mainland China.",
        "Entity": "Normal"
    },
    {
        "Text": "(a) IDictionary D I D:d/0.000 B:b/0.000 B:b/0.000 ( b ) ( c ) ( d ) I B e s t P a t h ( I d ( I ) o D * ) I cps:nd4.",
        "Entity": "Normal"
    },
    {
        "Text": "!l(l() Figure 2 An abstract example illustrating the segmentation algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The transitive closure of the dictionary in (a) is composed with Id(input) (b) to form the WFST (c).",
        "Entity": "Normal"
    },
    {
        "Text": "The segmentation chosen is the best path through the WFST, shown in (d).",
        "Entity": "Normal"
    },
    {
        "Text": "(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).",
        "Entity": "Normal"
    },
    {
        "Text": "We have not to date explored these various options.",
        "Entity": "Normal"
    },
    {
        "Text": "Word frequencies are estimated by a re-estimation procedure that involves apply  ing the segmentation algorithm presented here to a corpus of 20 million words,8 using 8 Our training corpus was drawn from a larger corpus of mixed-genre text consisting mostly of.",
        "Entity": "Normal"
    },
    {
        "Text": "newspaper material, but also including kungfu fiction, Buddhist tracts, and scientific material.",
        "Entity": "Normal"
    },
    {
        "Text": "This larger corpus was kindly provided to us by United Informatics Inc., R.O.C.",
        "Entity": "Normal"
    },
    {
        "Text": "a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.",
        "Entity": "Normal"
    },
    {
        "Text": "The best analysis of the corpus is taken to be the true analysis, the frequencies are re-estimated, and the algorithm is repeated until it converges.",
        "Entity": "Normal"
    },
    {
        "Text": "Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic  ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.",
        "Entity": "Normal"
    },
    {
        "Text": "In any event, to date, we have not compared different methods for deriving the set of initial frequency estimates.",
        "Entity": "Normal"
    },
    {
        "Text": "Note also that the costs currently used in the system are actually string costs, rather than word costs.",
        "Entity": "Normal"
    },
    {
        "Text": "This is because our corpus is not annotated, and hence does not distinguish between the various words represented by homographs, such as, which could be /adv jiangl 'be about to' orInc jiang4 '(military) general'-as in 1j\\xiao3jiang4 'little general.'",
        "Entity": "Normal"
    },
    {
        "Text": "In such cases we assign all of the estimated probability mass to the form with the most likely pronunciation (determined by inspection), and assign a very small probability (a very high cost, arbitrarily chosen to be 40) to all other variants.",
        "Entity": "Normal"
    },
    {
        "Text": "In the case of, the most common usage is as an adverb with the pronunciation jiangl, so that variant is assigned the estimated cost of 5.98, and a high cost is assigned to nominal usage with the pronunciation jiang4.",
        "Entity": "Normal"
    },
    {
        "Text": "The less favored reading may be selected in certain contexts, however; in the case of , for example, the nominal reading jiang4 will be selected if there is morphological information, such as a following plural affix ir, menD that renders the nominal reading likely, as we shall see in Section 4.3.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 3 shows a small fragment of the WFST encoding the dictionary, containing both entries forjust discussed, g:t  zhonglhua2 min2guo2 (China Republic) 'Republic of China,' and i inl.",
        "Entity": "Normal"
    },
    {
        "Text": "nan2gual 'pumpkin.'",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 A Sample Segmentation Using Only Dictionary Words Figure 4 shows two possible paths from the lattice of possible analyses of the input sentence B X:  .",
        "Entity": "Normal"
    },
    {
        "Text": ":.S:P:l 'How do you say octopus in Japanese?'",
        "Entity": "Normal"
    },
    {
        "Text": "previously shown in Figure 1.",
        "Entity": "Normal"
    },
    {
        "Text": "As noted, this sentence consists of four words, namely B X ri4wen2 'Japanese,' : , zhanglyu2 'octopus/ :&P:l zen3me0 'how,' and IDt shuol 'say.'",
        "Entity": "Normal"
    },
    {
        "Text": "As indicated in Figure 1(c), apart from this correct analysis, there is also the analysis taking B ri4 as a word (e.g., a common abbreviation for Japan), along with X:  wen2zhangl 'essay/ and f!!.",
        "Entity": "Normal"
    },
    {
        "Text": "yu2 'fish.'",
        "Entity": "Normal"
    },
    {
        "Text": "Both of these analyses are shown in Figure 4; fortunately, the correct analysis is also the one with the lowest cost, so it is this analysis that is chosen.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Morphological Analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "The method just described segments dictionary words, but as noted in Section 1, there are several classes of words that should be handled that are not found in a standard dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "One class comprises words derived by productive morphologi  cal processes, such as plural noun formation using the suffix ir, menD.",
        "Entity": "Normal"
    },
    {
        "Text": "(Other classes handled by the current system are discussed in Section 5.)",
        "Entity": "Normal"
    },
    {
        "Text": "The morphological anal ysis itself can be handled using well-known techniques from finite-state morphol 9 The initial estimates are derived from the frequencies in the corpus of the strings of hanzi making up.",
        "Entity": "Normal"
    },
    {
        "Text": "each word in the lexicon whether or not each string is actually an instance of the word in question.",
        "Entity": "Normal"
    },
    {
        "Text": ": _ADV: 5.88 If:!",
        "Entity": "Normal"
    },
    {
        "Text": ":zhong1 : 0.0 tjl :huo2 :0.0 (R:spub:/ic of Ch:ina) + .,_,...I : jlong4 :0.0 (mUifaty genG181) 0  : _NC: 40.0 Figure 3 Partial Chinese Lexicon (NC = noun; NP = proper noun).c=- - I  =- :il: .",
        "Entity": "Normal"
    },
    {
        "Text": ";ss:;zhangt   '-:.",
        "Entity": "Normal"
    },
    {
        "Text": "I   JAPANS :rl4 .",
        "Entity": "Normal"
    },
    {
        "Text": "\"\\)          \"o '       \"\\:J                   '\\; .",
        "Entity": "Normal"
    },
    {
        "Text": "'.",
        "Entity": "Normal"
    },
    {
        "Text": ":: ..........0 6.51 9.51 : jj / JAPANESE OCTOPUS 10 28i  :_nc HOW SAY f B :rl4 :il: :wen2 t '-   :zhang!",
        "Entity": "Normal"
    },
    {
        "Text": "!!",
        "Entity": "Normal"
    },
    {
        "Text": ":\\ :yu2 e:_nc [::!!",
        "Entity": "Normal"
    },
    {
        "Text": ":zen3 l!f :moO t:_adv il!",
        "Entity": "Normal"
    },
    {
        "Text": ":shuot ,:_vb i i i 1   10.03 13...\n\t\t\t7.96 5.55 1 l...................................................................................................................................................................................................J..",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.",
        "Entity": "Normal"
    },
    {
        "Text": "A non-optimal analysis is shown with dotted lines in the bottom frame.",
        "Entity": "Normal"
    },
    {
        "Text": "ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.",
        "Entity": "Normal"
    },
    {
        "Text": "However, for our purposes it is not sufficient to repre  sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.",
        "Entity": "Normal"
    },
    {
        "Text": "For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.",
        "Entity": "Normal"
    },
    {
        "Text": "So, 1: f, xue2shengl+men0 (student+PL) 'students' occurs and we estimate its cost at 11.43; similarly we estimate the cost of f, jiang4+men0 (general+PL) 'generals' (as in 'J' f, xiao3jiang4+men0 'little generals'), at 15.02.",
        "Entity": "Normal"
    },
    {
        "Text": "But we also need an estimate of the probability for a non-occurring though possible plural form like i JJ1l.f, nan2gua1-men0 'pumpkins.'",
        "Entity": "Normal"
    },
    {
        "Text": "10 Here we use the Good-Turing estimate (Baayen 1989; Church and Gale 1991), whereby the aggregate probability of previously unseen instances of a construction is estimated as ni/N, where N is the total number of observed tokens and n1 is the number of types observed only once.",
        "Entity": "Normal"
    },
    {
        "Text": "Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de  noted unseen(f,).",
        "Entity": "Normal"
    },
    {
        "Text": "For irt the Good-Turing estimate just discussed gives us an estimate of p(unseen(f,) I f,)-the probability of observing a previously unseen instance of a construction in ft given that we know that we have a construction in f,.",
        "Entity": "Normal"
    },
    {
        "Text": "This Good  Turing estimate of p(unseen(f,) If,) can then be used in the normal way to define the probability of finding a novel instance of a construction in ir, in a text: p(unseen(f,)) = p(unseen(f,) I f,) p(fn Here p(ir,) is just the probability of any construction in ft as estimated from the frequency of such constructions in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, as  suming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word i 1J1l.",
        "Entity": "Normal"
    },
    {
        "Text": "irL as the product of the probability estimate for i JJ1l., and the probability estimate just derived for unseen plurals in ir,: p(i 1J1l.ir,) p(i 1J1l.)p(unseen(f,)).",
        "Entity": "Normal"
    },
    {
        "Text": "The cost estimate, cost(i JJ1l.fn is computed in the obvious way by summing the negative log probabilities of i JJ1l.",
        "Entity": "Normal"
    },
    {
        "Text": "and f,.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 5 shows how this model is implemented as part of the dictionary WFST.",
        "Entity": "Normal"
    },
    {
        "Text": "There is a (costless) transition between the NC node and f,.",
        "Entity": "Normal"
    },
    {
        "Text": "The transition from f, to a final state transduces c to the grammatical tag PL with cost cost(unseen(f,)): cost(i JJ1l.ir,) == cost(i JJ1l.)",
        "Entity": "Normal"
    },
    {
        "Text": "+ cost(unseen(fm, as desired.",
        "Entity": "Normal"
    },
    {
        "Text": "For the seen word ir, 'gen  erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).",
        "Entity": "Normal"
    },
    {
        "Text": "This representation gives ir, an appropriate morphological decomposition, pre  serving information that would be lost by simply listing ir, as an unanalyzed form.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.",
        "Entity": "Normal"
    },
    {
        "Text": "An analysis of nouns that occur in both the singular and the plural in our database reveals that there is indeed a slight but significant positive correlation-R2 = 0.20, p < 0.005; see Figure 6.",
        "Entity": "Normal"
    },
    {
        "Text": "This suggests that the backoff model is as reasonable a model as we can use in the absence of further information about the expected cost of a plural form.",
        "Entity": "Normal"
    },
    {
        "Text": "10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.",
        "Entity": "Normal"
    },
    {
        "Text": "attaching to terms denoting human beings.",
        "Entity": "Normal"
    },
    {
        "Text": "However, it is possible to personify any noun, so in children's stories or fables, i JJ1l.",
        "Entity": "Normal"
    },
    {
        "Text": "f, nan2gual+men0 'pumpkins' is by no means impossible.",
        "Entity": "Normal"
    },
    {
        "Text": "J:j:l :zhongl :0.0 ;m,Jlong4 :0.0 (mHHaryg9tltHBI)  : _ADV: 5.98   :hua2:o.o E :_NC: 4.41 :mln2:o.o mm : guo2 : 0.0 (RopubllcofChlna) .....,.",
        "Entity": "Normal"
    },
    {
        "Text": "0 Figure 5 An example of affixation: the plural affix.",
        "Entity": "Normal"
    },
    {
        "Text": "4.4 Chinese Personal Names.",
        "Entity": "Normal"
    },
    {
        "Text": "Full Chinese personal names are in one respect simple: they are always of the form family+given.",
        "Entity": "Normal"
    },
    {
        "Text": "The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.",
        "Entity": "Normal"
    },
    {
        "Text": "Given names are most commonly two hanzi long, occasionally one hanzi long: there are thus four possible name types, which can be described by a simple set of context-free rewrite rules such as the following: 1.\n\t\t\two rd => na m e 2.\n\t\t\tna me =>1 ha nzi fa mi ly 2 ha nzi gi ve n 3.\n\t\t\tna me =>1 ha nzi fa mi ly 1 ha nzi gi ve n 4.\n\t\t\tna me =>2 ha nzi fa mi ly 2 ha nzi gi ve n 5.\n\t\t\tna me =>2 ha nzi fa mi ly 1 ha nzi gi ve n 6.1 ha nzi fa mi ly => ha nz ii 7.2 ha nzi fa mi ly => ha nzi i ha nz ij 8.1 ha nzi gi ve n => ha nz ii 9.2 ha nzi giv en => ha nzi i ha nz ij The difficulty is that given names can consist, in principle, of any hanzi or pair of hanzi, so the possible given names are limited only by the total number of hanzi, though some hanzi are certainly far more likely than others.",
        "Entity": "Normal"
    },
    {
        "Text": "For a sequence of hanzi that is a possible name, we wish to assign a probability to that sequence qua name.",
        "Entity": "Normal"
    },
    {
        "Text": "We can model this probability straightforwardly enough with a probabilistic version of the grammar just given, which would assign probabilities to the individual rules.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, given a sequence F1G1G2, where F1 is a legal single-hanzi family name, and Plural Nouns X g 0 g \"' X X 0 T!i c\"'.",
        "Entity": "Normal"
    },
    {
        "Text": "0 X u} \"' o; .2 X X><X X XX X X X X X X x X X X X X x X V X X X X .",
        "Entity": "Normal"
    },
    {
        "Text": ";t'*- XXX:OX X X X X X X 9 x X X XX XX X X X X X X X XXX:< X X>O<XX>!KXX XI<><  C X X XX :X: X X \"' X X XX >OO<X>D<XIK X X X X X X --XX : XXX X X C X X X...C:XXX X Xll< X X ><XX>IIC:liiC:oiiiiCI--8!X:liiOC!I!S8K X X X 10 100 1000 10000 log(F)_base: R\"2=0.20 (p < 0.005) X 100000 Figure 6 Plot of log frequency of base noun, against log frequency of plural nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of:   the probability that a word chosen randomly from a text will be a name-p(rule 1), and   the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and   the probability that the family name is the particular hanzi F1-p(rule 6), and   the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1992).",
        "Entity": "Normal"
    },
    {
        "Text": "The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.",
        "Entity": "Normal"
    },
    {
        "Text": "This model is easily incorporated into the segmenter by building a WFST restrict  ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.",
        "Entity": "Normal"
    },
    {
        "Text": "This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "'s Model.",
        "Entity": "Normal"
    },
    {
        "Text": "There are two weaknesses in Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "'s model, which we improve upon.",
        "Entity": "Normal"
    },
    {
        "Text": "First, the model assumes independence between the first and second hanzi of a double given name.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet, some hanzi are far more probable in women's names than they are in men's names, and there is a similar list of male-oriented hanzi: mixing hanzi from these two lists is generally less likely than would be predicted by the independence model.",
        "Entity": "Normal"
    },
    {
        "Text": "As a partial solution, for pairs of hanzi that co-occur sufficiently often in our namelists, we use the estimated bigram cost, rather than the independence-based cost.",
        "Entity": "Normal"
    },
    {
        "Text": "The second weakness is purely conceptual, and probably does not affect the per  formance of the model.",
        "Entity": "Normal"
    },
    {
        "Text": "For previously unseen hanzi in given names, Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "assign a uniform small cost; but we know that some unseen hanzi are merely acci  dentally missing, whereas others are missing for a reason-for example, because they have a bad connotation.",
        "Entity": "Normal"
    },
    {
        "Text": "As we have noted in Section 2, the general semantic class to which a hanzi belongs is often predictable from its semantic radical.",
        "Entity": "Normal"
    },
    {
        "Text": "Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.",
        "Entity": "Normal"
    },
    {
        "Text": "Other good classes include JADE and GOLD; other bad classes are DEATH and RAT.",
        "Entity": "Normal"
    },
    {
        "Text": "We can better predict the probability of an unseen hanzi occurring in a name by computing a within-class Good-Turing estimate for each radical class.",
        "Entity": "Normal"
    },
    {
        "Text": "Assuming unseen objects within each class are equiprobable, their probabilities are given by the Good-Turing theorem as: cis E( n'J.ls) Po oc N * E(N8ls) (2) where p815 is the probability of one unseen hanzi in class cls, E(n'J.15 ) is the expected number of hanzi in cls seen once, N is the total number of hanzi, and E(N(/ 5 ) is the expected number of unseen hanzi in class cls.",
        "Entity": "Normal"
    },
    {
        "Text": "The use of the Good-Turing equation presumes suitable estimates of the unknown expectations it requires.",
        "Entity": "Normal"
    },
    {
        "Text": "In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.",
        "Entity": "Normal"
    },
    {
        "Text": "hanzi in the various name positions, derived from a million names.",
        "Entity": "Normal"
    },
    {
        "Text": "12 One class of full personal names that this characterization does not cover are married women's names.",
        "Entity": "Normal"
    },
    {
        "Text": "where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.",
        "Entity": "Normal"
    },
    {
        "Text": "This style of naming is never required and seems to be losing currency.",
        "Entity": "Normal"
    },
    {
        "Text": "It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.",
        "Entity": "Normal"
    },
    {
        "Text": "We of course also fail to identify, by the methods just described, given names used without their associated family name.",
        "Entity": "Normal"
    },
    {
        "Text": "This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.",
        "Entity": "Normal"
    },
    {
        "Text": "JA DE G O L D G R AS S SI C K NE SS DE AT H R A T 14.",
        "Entity": "Normal"
    },
    {
        "Text": "98 15.",
        "Entity": "Normal"
    },
    {
        "Text": "52 15.",
        "Entity": "Normal"
    },
    {
        "Text": "76 16.",
        "Entity": "Normal"
    },
    {
        "Text": "25 16.",
        "Entity": "Normal"
    },
    {
        "Text": "30 16.",
        "Entity": "Normal"
    },
    {
        "Text": "42 nator, the N31s can be measured well by counting, and we replace the expectation by the observation.",
        "Entity": "Normal"
    },
    {
        "Text": "In the numerator, however, the counts of ni1s are quite irregular, in  cluding several zeros (e.g., RAT, none of whose members were seen).",
        "Entity": "Normal"
    },
    {
        "Text": "However, there is a strong relationship between ni1s and the number of hanzi in the class.",
        "Entity": "Normal"
    },
    {
        "Text": "For E(ni1s), then, we substitute a smooth S against the number of class elements.",
        "Entity": "Normal"
    },
    {
        "Text": "This smooth guarantees that there are no zeroes estimated.",
        "Entity": "Normal"
    },
    {
        "Text": "The final estimating equation is then: (3) Since the total of all these class estimates was about 10% off from the Turing estimate n1/N for the probability of all unseen hanzi, we renormalized the estimates so that they would sum to n 1jN.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that the good classes JADE, GOLD and GRASS have lower costs than the bad classes SICKNESS, DEATH and RAT, as desired, so the trend observed for the results of this method is in the right direction.",
        "Entity": "Normal"
    },
    {
        "Text": "4.5 Transliterations of Foreign Words.",
        "Entity": "Normal"
    },
    {
        "Text": "Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.",
        "Entity": "Normal"
    },
    {
        "Text": "Since foreign names can be of any length, and since their original pronunciation is effectively unlimited, the identi  fication of such names is tricky.",
        "Entity": "Normal"
    },
    {
        "Text": "Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !",
        "Entity": "Normal"
    },
    {
        "Text": ":i*m xia4mi3-er3 'Shamir,' which is a legal Chi  nese personal name, retains a foreign flavor because of liM.",
        "Entity": "Normal"
    },
    {
        "Text": "As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil  ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.",
        "Entity": "Normal"
    },
    {
        "Text": "As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, the common \"suffixes,\" -nia (e.g.,.",
        "Entity": "Normal"
    },
    {
        "Text": "Virginia) and -sia are normally transliterated as fbSi!",
        "Entity": "Normal"
    },
    {
        "Text": "ni2ya3 and @5:2 xilya3, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "The interdependence between fb or 1/!i, and 5:2 is not captured by our model, but this could easily be remedied.",
        "Entity": "Normal"
    },
    {
        "Text": "logical rules, and personal names; the transitive closure of the resulting machine is then computed.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section we present a partial evaluation of the current system, in three parts.",
        "Entity": "Normal"
    },
    {
        "Text": "The first is an evaluation of the system's ability to mimic humans at the task of segmenting text into word-sized units; the second evaluates the proper-name identification; the third measures the performance on morphological analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "To date we have not done a separate evaluation of foreign-name recognition.",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation of the Segmentation as a Whole.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous reports on Chinese segmentation have invariably cited performance either in terms of a single percent-correct score, or else a single precision-recall pair.",
        "Entity": "Normal"
    },
    {
        "Text": "The problem with these styles of evaluation is that, as we shall demonstrate, even human judges do not agree perfectly on how to segment a given text.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, rather than give a single evaluative score, we prefer to compare the performance of our method with the judgments of several human subjects.",
        "Entity": "Normal"
    },
    {
        "Text": "To this end, we picked 100 sentences at random containing 4,372 total hanzi from a test corpus.14 (There were 487 marks of punctuation in the test sentences, including the sentence-final periods, meaning that the average inter-punctuation distance was about 9 hanzi.)",
        "Entity": "Normal"
    },
    {
        "Text": "We asked six native speakers-three from Taiwan (TlT3), and three from the Mainland (M1M3)-to segment the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Since we could not bias the subjects towards a particular segmentation and did not presume linguistic sophistication on their part, the instructions were simple: subjects were to mark all places they might plausibly pause if they were reading the text aloud.",
        "Entity": "Normal"
    },
    {
        "Text": "An examination of the subjects' bracketings confirmed that these instructions were satisfactory in yielding plausible word-sized units.",
        "Entity": "Normal"
    },
    {
        "Text": "(See also Wu and Fung [1994].)",
        "Entity": "Normal"
    },
    {
        "Text": "Various segmentation approaches were then compared with human performance: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "A greedy algorithm (or maximum-matching algorithm), GR: proceed through the sentence, taking the longest match with a dictionary entry at each point.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "An anti-greedy algorithm, AG: instead of the longest match, take the.",
        "Entity": "Normal"
    },
    {
        "Text": "shortest match at each point.",
        "Entity": "Normal"
    },
    {
        "Text": "3.",
        "Entity": "Normal"
    },
    {
        "Text": "The method being described-henceforth ST..\n\t\t\tTwo measures that can be used to compare judgments are: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Precision.",
        "Entity": "Normal"
    },
    {
        "Text": "For each pair of judges consider one judge as the standard,.",
        "Entity": "Normal"
    },
    {
        "Text": "computing the precision of the other's judgments relative to this standard.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "Recall.",
        "Entity": "Normal"
    },
    {
        "Text": "For each pair of judges, consider one judge as the standard,.",
        "Entity": "Normal"
    },
    {
        "Text": "computing the recall of the other's judgments relative to this standard.",
        "Entity": "Normal"
    },
    {
        "Text": "Clearly, for judges h and h taking h as standard and computing the precision and recall for Jz yields the same results as taking h as the standard, and computing for h, 14 All evaluation materials, with the exception of those used for evaluating personal names were drawn.",
        "Entity": "Normal"
    },
    {
        "Text": "from the subset of the United Informatics corpus not used in the training of the models.",
        "Entity": "Normal"
    },
    {
        "Text": "Jud ges A G G R ST M 1 M 2 M 3 T1 T2 T3 AG 0.7 0 0.7 0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 3 0.4 2 0.6 0 0.6 0 0.6 2 0.5 9 GR 0.9 9 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 2 0.6 4 0.7 9 0.8 2 0.8 1 0.7 2 ST 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 4 0.6 7 0.8 0 0.8 4 0.8 2 0.7 4 M1 0.7 7 0.6 9 0.7 1 0.6 9 0.7 0 M2 0.7 2 0.7 3 0.7 1 0.7 0 M3 0.8 9 0.8 7 0.8 0 T1 0.8 8 0.8 2 T2 0.7 8 respectively, the recall and precision.",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore used the arithmetic mean of each interjudge precision-recall pair as a single measure of interjudge similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that dis  tance matrix, and plotting the first two most significant dimensions.",
        "Entity": "Normal"
    },
    {
        "Text": "The result of this is shown in Figure 7.",
        "Entity": "Normal"
    },
    {
        "Text": "The horizontal axis in this plot represents the most significant dimension, which explains 62% of the variation.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).",
        "Entity": "Normal"
    },
    {
        "Text": "This is to allow for fair comparison between the statistical method and GR, which is also purely dictionary-based.",
        "Entity": "Normal"
    },
    {
        "Text": "As can be seen, GR and this \"pared-down\" statistical method perform quite similarly, though the statistical method is still slightly better.16 AG clearly performs much less like humans than these methods, whereas the full statistical algorithm, including morphological derivatives and names, performs most closely to humans among the automatic methods.",
        "Entity": "Normal"
    },
    {
        "Text": "It can also be seen clearly in this plot that two of the Taiwan speakers cluster very closely together, and the third Tai  wan speaker is also close in the most significant dimension (the x axis).",
        "Entity": "Normal"
    },
    {
        "Text": "Two of the Mainlanders also cluster close together but, interestingly, not particularly close to the Taiwan speakers; the third Mainlander is much more similar to the Taiwan speakers.",
        "Entity": "Normal"
    },
    {
        "Text": "Clearly the percentage of productively formed words is quite small (for this particular corpus), meaning that dictionary entries are covering most of the 15 GR is .73 or 96%..\n\t\t\t16 As one reviewer points out, one problem with the unigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words.",
        "Entity": "Normal"
    },
    {
        "Text": "That is, given a choice between segmenting a sequence abc into abc and ab, c, the former will always be picked so long as its cost does not exceed the summed costs of ab and c: while; it is possible for abc to be so costly as to preclude the larger grouping, this will certainly not usually be the case.",
        "Entity": "Normal"
    },
    {
        "Text": "In this way, the method reported on here will necessarily be similar to a greedy method, though of course not identical.",
        "Entity": "Normal"
    },
    {
        "Text": "As the reviewer also points out, this is a problem that is shared by, e.g., probabilistic context-free parsers, which tend to pick trees with fewer nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "The question is how to normalize the probabilities in such a way that smaller groupings have a better shot at winning.",
        "Entity": "Normal"
    },
    {
        "Text": "This is an issue that we have not addressed at the current stage of our research.",
        "Entity": "Normal"
    },
    {
        "Text": "i..f,..\n\t\t\t\"c' 0 + 0 \"0 '   + a n t i g r e e d y x g r e e d y < > c u r r e n t m e t h o d o d i e t .",
        "Entity": "Normal"
    },
    {
        "Text": "o n l y   Taiwan 0  ;; 0 c CD E i5 0\"' 9 9   Mainland         -0.30.20.1 0.0 0.1 0.2 Dimension 1 (62%) Figure 7 Classical metric multidimensional scaling of distance matrix, showing the two most significant dimensions.",
        "Entity": "Normal"
    },
    {
        "Text": "The percentage scores on the axis labels represent the amount of variation in the data explained by the dimension in question.",
        "Entity": "Normal"
    },
    {
        "Text": "Word type N % Dic tion ary entr ies 2 , 5 4 3 9 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 7 Mor pho logi call y deri ved wor ds 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 1 Fore ign tran slite rati ons 9 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 4 Per son al na mes 5 4 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 7 cases.",
        "Entity": "Normal"
    },
    {
        "Text": "Nonetheless, the results of the comparison with human judges demonstrates that there is mileage being gained by incorporating models of these types of words.",
        "Entity": "Normal"
    },
    {
        "Text": "It may seem surprising to some readers that the interhuman agreement scores reported here are so low.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this result is consistent with the results of ex  periments discussed in Wu and Fung (1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Wu and Fung introduce an evaluation method they call nk-blind.",
        "Entity": "Normal"
    },
    {
        "Text": "Under this scheme, n human judges are asked independently to segment a text.",
        "Entity": "Normal"
    },
    {
        "Text": "Their results are then compared with the results of an automatic segmenter.",
        "Entity": "Normal"
    },
    {
        "Text": "For a given \"word\" in the automatic segmentation, if at least k of the hu  man judges agree that this is a word, then that word is considered to be correct.",
        "Entity": "Normal"
    },
    {
        "Text": "For eight judges, ranging k between 1 and 8 corresponded to a precision score range of 90% to 30%, meaning that there were relatively few words (30% of those found by the automatic segmenter) on which all judges agreed, whereas most of the words found by the segmenter were such that one human judge agreed.",
        "Entity": "Normal"
    },
    {
        "Text": "Proper-Name Identification.",
        "Entity": "Normal"
    },
    {
        "Text": "To evaluate proper-name identification, we randomly se  lected 186 sentences containing 12,000 hanzi from our test corpus and segmented the text automatically, tagging personal names; note that for names, there is always a sin  gle unambiguous answer, unlike the more general question of which segmentation is correct.",
        "Entity": "Normal"
    },
    {
        "Text": "The performance was 80.99% recall and 61.83% precision.",
        "Entity": "Normal"
    },
    {
        "Text": "Interestingly, Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "report 80.67% recall and 91.87% precision on an 11,000 word corpus: seemingly, our system finds as many names as their system, but with four times as many false hits.",
        "Entity": "Normal"
    },
    {
        "Text": "However, we have reason to doubt Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "'s performance claims.",
        "Entity": "Normal"
    },
    {
        "Text": "Without using the same test corpus, direct comparison is obviously difficult; fortunately, Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "include a list of about 60 sentence fragments that exemplify various categories of performance for their system.",
        "Entity": "Normal"
    },
    {
        "Text": "The performance of our system on those sentences ap  peared rather better than theirs.",
        "Entity": "Normal"
    },
    {
        "Text": "On a set of 11 sentence fragments-the A set-where they reported 100% recall and precision for name identification, we had 73% recall and 80% precision.",
        "Entity": "Normal"
    },
    {
        "Text": "However, they list two sets, one consisting of 28 fragments and the other of 22 fragments, in which they had 0% recall and precision.",
        "Entity": "Normal"
    },
    {
        "Text": "On the first of these-the B set-our system had 64% recall and 86% precision; on the second-the C set-it had 33% recall and 19% precision.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that it is in precision that our over  all performance would appear to be poorer than the reported performance of Chang et al., yet based on their published examples, our system appears to be doing better precisionwise.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus we have some confidence that our own performance is at least as good as that of Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1992).",
        "Entity": "Normal"
    },
    {
        "Text": "In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "'s system.",
        "Entity": "Normal"
    },
    {
        "Text": "Fortunately, we were able to obtain a copy of the full set of sentences from Chang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "on which Wang, Li, and Chang tested their system, along with the output of their system.18 In what follows we will discuss all cases from this set where our performance on names differs from that of Wang, Li, and Chang.",
        "Entity": "Normal"
    },
    {
        "Text": "In these examples, the names identified by the two systems (if any) are underlined; the sentence with the correct segmentation is boxed.19 The differences in performance between the two systems relate directly to three issues, which can be seen as differences in the tuning of the models, rather than repre  senting differences in the capabilities of the model per se.",
        "Entity": "Normal"
    },
    {
        "Text": "The first issue relates to the completeness of the base lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "The Wang, Li, and Chang system fails on fragment (b) because their system lacks the word youlyoul 'soberly' and misinterpreted the thus isolated first youl as being the final hanzi of the preceding name; similarly our system failed in fragment (h) since it is missing the abbreviation i:lJI!",
        "Entity": "Normal"
    },
    {
        "Text": "tai2du2 'Taiwan Independence.'",
        "Entity": "Normal"
    },
    {
        "Text": "This is a rather important source of errors in name identifi  cation, and it is not really possible to objectively evaluate a name recognition system without considering the main lexicon with which it is used.",
        "Entity": "Normal"
    },
    {
        "Text": "17 They also provide a set of title-driven rules to identify names when they occur before titles such as $t.",
        "Entity": "Normal"
    },
    {
        "Text": "1: xianlshengl 'Mr.'",
        "Entity": "Normal"
    },
    {
        "Text": "or i:l:itr!J tai2bei3 shi4zhang3 'Taipei Mayor.'",
        "Entity": "Normal"
    },
    {
        "Text": "Obviously, the presence of a title after a potential name N increases the probability that N is in fact a name.",
        "Entity": "Normal"
    },
    {
        "Text": "Our system does not currently make use of titles, but it would be straightforward to do so within the finite-state framework that we propose.",
        "Entity": "Normal"
    },
    {
        "Text": "18 We are grateful to ChaoHuang Chang for providing us with this set.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that Wang, Li, and Chang's.",
        "Entity": "Normal"
    },
    {
        "Text": "set was based on an earlier version of the Chang et a!.",
        "Entity": "Normal"
    },
    {
        "Text": "paper, and is missing 6 examples from the A set.",
        "Entity": "Normal"
    },
    {
        "Text": "19 We note that it is not always clear in Wang, Li, and Chang's examples which segmented words.",
        "Entity": "Normal"
    },
    {
        "Text": "constitute names, since we have only their segmentation, not the actual classification of the segmented words.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore in cases where the segmentation is identical between the two systems we assume that tagging is also identical.",
        "Entity": "Normal"
    },
    {
        "Text": "Our System Wang, Li, and Chang a.",
        "Entity": "Normal"
    },
    {
        "Text": "1\\!f!IP Eflltii /1\\!f!J:P $1til I b. agm: I a m: c. 5 Bf is Bf 1 d. \"*:t: w _t ff 1 \"* :t: w_tff 1 g., , Transliteration/Translation chen2zhongl-shenl qu3 'music by Chen Zhongshen ' huang2rong2 youlyoul de dao4 'Huang Rong said soberly' zhangl qun2 Zhang Qun xian4zhang3 you2qingl shang4ren2 hou4 'after the county president You Qing had assumed the position' lin2 quan2 'Lin Quan' wang2jian4 'Wang Jian' oulyang2-ke4 'Ouyang Ke' yinl qi2 bu4 ke2neng2 rong2xu3 tai2du2 er2 'because it cannot permit Taiwan Independence so' silfa3-yuan4zhang3 lin2yang2-gang3 'president of the Judicial Yuan, Lin Yanggang' lin2zhangl-hu2 jiangl zuo4 xian4chang3 jie3shuol 'Lin Zhanghu will give an ex  planation live' jin4/iang3 nian2 nei4 sa3 xia4 de jinlqian2 hui4 ting2zhi3 'in two years the distributed money will stop' gaoltangl da4chi2 ye1zi0 fen3 'chicken stock, a tablespoon of coconut flakes' you2qingl ru4zhu3 xian4fu3 lwu4 'after You Qing headed the county government'                                               \n\t\t\tAffix Pron Base category N found N missed (recall) N correct (precision) t,-,7 The second issue is that rare family names can be responsible for overgeneration, especially if these names are otherwise common as single-hanzi words.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the Wang, Li, and Chang system fails on the sequence 1:f:p:]nian2 nei4 sa3 in (k) since 1F nian2 is a possible, but rare, family name, which also happens to be written the same as the very common word meaning 'year.'",
        "Entity": "Normal"
    },
    {
        "Text": "Our system fails in (a) because of$ shenl, a rare family name; the system identifies it as a family name, whereas it should be analyzed as part of the given name.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the statistical method fails to correctly group hanzi in cases where the individual hanzi comprising the name are listed in the dictionary as being relatively high-frequency single-hanzi words.",
        "Entity": "Normal"
    },
    {
        "Text": "An example is in (i), where the system fails to group t;,f;?\"$?t!",
        "Entity": "Normal"
    },
    {
        "Text": ": lin2yang2gang3 as a name, because all three hanzi can in principle be separate words (t;,f; lin2 'wood';?",
        "Entity": "Normal"
    },
    {
        "Text": "\"$ yang2 'ocean'; ?t!",
        "Entity": "Normal"
    },
    {
        "Text": "; gang3 'harbor').",
        "Entity": "Normal"
    },
    {
        "Text": "In many cases these failures in recall would be fixed by having better estimates of the actual prob  abilities of single-hanzi words, since our estimates are often inflated.",
        "Entity": "Normal"
    },
    {
        "Text": "A totally non  stochastic rule-based system such as Wang, Li, and Chang's will generally succeed in such cases, but of course runs the risk of overgeneration wherever the single-hanzi word is really intended.",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation of Morphological Analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "The first four affixes are so-called resultative affixes: they denote some prop  erty of the resultant state of a verb, as in E7 wang4bu4-liao3 (forget-not-attain) 'cannot forget.'",
        "Entity": "Normal"
    },
    {
        "Text": "The last affix in the list is the nominal plural f, men0.20 In the       are the (typical) classes of words to which the affix attaches, the number found in the test corpus by the method, the number correct (with a precision measure), and the number missed (with a recall measure).",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we have argued that Chinese word segmentation can be modeled ef  fectively using weighted finite-state transducers.",
        "Entity": "Normal"
    },
    {
        "Text": "This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.",
        "Entity": "Normal"
    },
    {
        "Text": "Other kinds of productive word classes, such as company names, abbreviations (termed fijsuolxie3 in Mandarin), and place names can easily be 20 Note that 7 in E 7 is normally pronounced as leO, but as part of a resultative it is liao3..\n\t\t\thandled given appropriate models.",
        "Entity": "Normal"
    },
    {
        "Text": "(For some recent corpus-based work on Chinese abbreviations, see Huang, Ahrens, and Chen [1993].)",
        "Entity": "Normal"
    },
    {
        "Text": "We have argued that the proposed method performs well.",
        "Entity": "Normal"
    },
    {
        "Text": "However, some caveats are in order in comparing this method (or any method) with other approaches to seg  mentation reported in the literature.",
        "Entity": "Normal"
    },
    {
        "Text": "First of all, most previous articles report perfor  mance in terms of a single percent-correct score, or else in terms of the paired measures of precision and recall.",
        "Entity": "Normal"
    },
    {
        "Text": "What both of these approaches presume is that there is a sin  gle correct segmentation for a sentence, against which an automatic algorithm can be compared.",
        "Entity": "Normal"
    },
    {
        "Text": "We have shown that, at least given independent human judgments, this is not the case, and that therefore such simplistic measures should be mistrusted.",
        "Entity": "Normal"
    },
    {
        "Text": "This is not to say that a set of standards by which a particular segmentation would count as correct and another incorrect could not be devised; indeed, such standards have been proposed and include the published PRCNSC (1994) and ROCLING (1993), as well as the unpublished Linguistic Data Consortium standards (ca.",
        "Entity": "Normal"
    },
    {
        "Text": "May 1995).",
        "Entity": "Normal"
    },
    {
        "Text": "However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, comparisons of different methods are not meaningful unless one can eval  uate them on the same corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Unfortunately, there is no standard corpus of Chinese texts, tagged with either single or multiple human judgments, with which one can compare performance of various methods.",
        "Entity": "Normal"
    },
    {
        "Text": "One hopes that such a corpus will be forth  coming.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we wish to reiterate an important point.",
        "Entity": "Normal"
    },
    {
        "Text": "The major problem for our seg  menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).",
        "Entity": "Normal"
    },
    {
        "Text": "We have provided methods for handling certain classes of unknown words, and models for other classes could be provided, as we have noted.",
        "Entity": "Normal"
    },
    {
        "Text": "However, there will remain a large number of words that are not readily adduced to any produc  tive pattern and that would simply have to be added to the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "This implies, therefore, that a major factor in the performance of a Chinese segmenter is the quality of the base dictionary, and this is probably a more important factor-from the point of view of performance alone-than the particular computational methods used.",
        "Entity": "Normal"
    },
    {
        "Text": "The method reported in this paper makes use solely of unigram probabilities, and is therefore a zeroeth-order model: the cost of a particular segmentation is estimated as the sum of the costs of the individual words in the segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "However, as we have noted, nothing inherent in the approach precludes incorporating higher-order constraints, provided they can be effectively modeled within a finite-state framework.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, as Gan (1994) has noted, one can construct examples where the segmen  tation is locally ambiguous but can be determined on the basis of sentential or even discourse context.",
        "Entity": "Normal"
    },
    {
        "Text": "Two sets of examples from Gan are given in (1) and (2) (:::::: Gan's Appendix B, exx.",
        "Entity": "Normal"
    },
    {
        "Text": "lla/llb and 14a/14b respectively).",
        "Entity": "Normal"
    },
    {
        "Text": "In (1) the sequencema3lu4 cannot be resolved locally, but depends instead upon broader context; similarly in (2), the sequence :::tcai2neng2 cannot be resolved locally: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "(a) 1   .",
        "Entity": "Normal"
    },
    {
        "Text": ";m t 7 leO z h e 4 pil m a 3 lu 4 sh an g4 bi ng 4 t h i s CL (assi fier) horse w ay on sic k A SP (ec t) 'This horse got sick on the way' (b) 1 : .",
        "Entity": "Normal"
    },
    {
        "Text": "til y zhe4 tiao2 ma3lu4 hen3 shao3 this CL road very few 'Very few cars pass by this road' :$ chel jinglguo4 car pass by 2.",
        "Entity": "Normal"
    },
    {
        "Text": "(a) I f f fi * fi :1 }'l ij 1 : {1M m m s h e n 3 m e 0 shi2 ho u4 wo 3 cai2 ne ng 2 ke4 fu 2 zh e4 ge 4 ku n4 w h a t ti m e I just be abl e ov er co m e thi s C L dif fic 'When will I be able to overcome this difficulty?'",
        "Entity": "Normal"
    },
    {
        "Text": "(b) 89 :1 t& tal de cai2neng2 hen3 he DE talent very 'He has great talent' f.b ga ol hig h While the current algorithm correctly handles the (b) sentences, it fails to handle the (a) sentences, since it does not have enough information to know not to group the sequences.ma3lu4 and?",
        "Entity": "Normal"
    },
    {
        "Text": "]cai2neng2 respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Gan's solution depends upon a fairly sophisticated language model that attempts to find valid syntactic, semantic, and lexical relations between objects of various linguistic types (hanzi, words, phrases).",
        "Entity": "Normal"
    },
    {
        "Text": "An example of a fairly low-level relation is the affix relation, which holds between a stem morpheme and an affix morpheme, such as f1 -menD (PL).",
        "Entity": "Normal"
    },
    {
        "Text": "A high-level relation is agent, which relates an animate nominal to a predicate.",
        "Entity": "Normal"
    },
    {
        "Text": "Particular instances of relations are associated with goodness scores.",
        "Entity": "Normal"
    },
    {
        "Text": "Particular relations are also consistent with particular hypotheses about the segmentation of a given sentence, and the scores for particular relations can be incremented or decremented depending upon whether the segmentations with which they are consistent are \"popular\" or not.",
        "Entity": "Normal"
    },
    {
        "Text": "While Gan's system incorporates fairly sophisticated models of various linguistic information, it has the drawback that it has only been tested with a very small lexicon (a few hundred words) and on a very small test set (thirty sentences); there is therefore serious concern as to whether the methods that he discusses are scalable.",
        "Entity": "Normal"
    },
    {
        "Text": "Another question that remains unanswered is to what extent the linguistic information he considers can be handled-or at least approximated-by finite-state language models, and therefore could be directly interfaced with the segmentation model that we have presented in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "For the examples given in (1) and (2) this certainly seems possible.",
        "Entity": "Normal"
    },
    {
        "Text": "Consider first the examples in (2).",
        "Entity": "Normal"
    },
    {
        "Text": "The segmenter will give both analyses :1 cai2 neng2 'just be able,' and ?",
        "Entity": "Normal"
    },
    {
        "Text": "]cai2neng2 'talent,' but the latter analysis is preferred since splitting these two morphemes is generally more costly than grouping them.",
        "Entity": "Normal"
    },
    {
        "Text": "In (2a), we want to split the two morphemes since the correct analysis is that we have the adverb :1 cai2 'just,' the modal verb neng2 'be able' and the main verb R: Hke4fu2 'overcome'; the competing analysis is, of course, that we have the noun :1 cai2neng2 'talent,' followed by }'lijke4fu2 'overcome.'",
        "Entity": "Normal"
    },
    {
        "Text": "Clearly it is possible to write a rule that states that if an analysis Modal+ Verb is available, then that is to be preferred over Noun+ Verb: such a rule could be stated in terms of (finite-state) local grammars in the sense of Mohri (1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Turning now to (1), we have the similar problem that splitting.into.ma3 'horse' andlu4 'way' is more costly than retaining this as one word .ma3lu4 'road.'",
        "Entity": "Normal"
    },
    {
        "Text": "However, there is again local grammatical information that should favor the split in the case of (1a): both .ma3 'horse' and .ma3 lu4 are nouns, but only .ma3 is consistent with the classifier pil, the classifier for horses.21 By a similar argument, the preference for not splitting , lm could be strengthened in (lb) by the observation that the classifier 1'1* tiao2 is consistent with long or winding objects like , lm ma3lu4 'road' but not with,ma3 'horse.'",
        "Entity": "Normal"
    },
    {
        "Text": "Note that the sets of possible classifiers for a given noun can easily be encoded on that noun by grammatical features, which can be referred to by finite-state grammatical rules.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, we feel fairly confident that for the examples we have considered from Gan's study a solution can be incorporated, or at least approximated, within a finite-state framework.",
        "Entity": "Normal"
    },
    {
        "Text": "With regard to purely morphological phenomena, certain processes are not han  dled elegantly within the current framework Any process involving reduplication, for instance, does not lend itself to modeling by finite-state techniques, since there is no way that finite-state networks can directly implement the copying operations required.",
        "Entity": "Normal"
    },
    {
        "Text": "Mandarin exhibits several such processes, including A-not-A question formation, il  lustrated in (3a), and adverbial reduplication, illustrated in (3b): 3.",
        "Entity": "Normal"
    },
    {
        "Text": "(a) ;IE shi4 'be' => ;IE;IE shi4bu2-shi4 (be-not-be) 'is it?'",
        "Entity": "Normal"
    },
    {
        "Text": "JI!",
        "Entity": "Normal"
    },
    {
        "Text": "gaolxing4 'happy' => F.i'JF.i'J Jl!",
        "Entity": "Normal"
    },
    {
        "Text": "gaolbu4-gaolxing4 (hap-not-happy) 'happy?'",
        "Entity": "Normal"
    },
    {
        "Text": "(b) F.i'JJI!",
        "Entity": "Normal"
    },
    {
        "Text": "gaolxing4 'happy'=> F.i'JF.i'JJI!JI!",
        "Entity": "Normal"
    },
    {
        "Text": "gaolgaolxing4xing4 'happily' In the particular form of A-not-A reduplication illustrated in (3a), the first syllable of the verb is copied, and the negative markerbu4 'not' is inserted between the copy and the full verb.",
        "Entity": "Normal"
    },
    {
        "Text": "In the case of adverbial reduplication illustrated in (3b) an adjective of the form AB is reduplicated as AABB.",
        "Entity": "Normal"
    },
    {
        "Text": "The only way to handle such phenomena within the framework described here is simply to expand out the reduplicated forms beforehand, and incorporate the expanded forms into the lexical transducer.",
        "Entity": "Normal"
    },
    {
        "Text": "Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.",
        "Entity": "Normal"
    },
    {
        "Text": "The model we use provides a simple framework in which to incorporate a wide variety of lexical information in a uniform way.",
        "Entity": "Normal"
    },
    {
        "Text": "The use of weighted transducers in particular has the attractive property that the model, as it stands, can be straightforwardly interfaced to other modules of a larger speech or natural language system: presumably one does not want to segment Chinese text for its own sake but instead with a larger purpose in mind.",
        "Entity": "Normal"
    },
    {
        "Text": "As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, by inverting the transducer so that it maps from phonemic transcriptions to hanzi sequences, one can apply the segmenter to other problems, such as speech recognition (Pereira, Riley, and Sproat 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.",
        "Entity": "Normal"
    },
    {
        "Text": "While size of the resulting transducers may seem daunting-the segmenter described here, as it is used in the Bell Labs Mandarin TTS system has about 32,000 states and 209,000 arcs-recent work on minimization of weighted machines and transducers (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "21 In Chinese, numerals and demonstratives cannot modify nouns directly, and must be accompanied by.",
        "Entity": "Normal"
    },
    {
        "Text": "a classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "The particular classifier used depends upon the noun.",
        "Entity": "Normal"
    },
    {
        "Text": "Mohri [1995]) shows promise for improving this situation.",
        "Entity": "Normal"
    },
    {
        "Text": "The model described here thus demonstrates great potential for use in widespread applications.",
        "Entity": "Normal"
    },
    {
        "Text": "This flexibility, along with the simplicity of implementation and expansion, makes this framework an attractive base for continued research.",
        "Entity": "Normal"
    },
    {
        "Text": "We thank United Informatics for providing us with our corpus of Chinese text, and BDC for the 'Behavior ChineseEnglish Electronic Dictionary.'",
        "Entity": "Normal"
    },
    {
        "Text": "We further thank Dr. J.-S.\n\t\t\tChang of Tsinghua University, Taiwan, R.O.C., for kindly providing us with the name corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "We also thank ChaoHuang Chang, reviewers for the 1994 ACL conference, and four anonymous reviewers for Computational Linguistics for useful comments.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tAt present, adapting an Information Extraction system to new topics is an expensive and slow process, requiring some knowledge engineering for each new topic.",
        "Entity": "Normal"
    },
    {
        "Text": "We propose a new paradigm of Information Extraction which operates 'on demand' in response to a user's query.",
        "Entity": "Normal"
    },
    {
        "Text": "On-demand Information Extraction (ODIE) aims to completely eliminate the customization effort.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a user s query, the system will automatically create patterns to extract salient relations in the text of the topic, and build tables from the extracted information using paraphrase discovery technology.",
        "Entity": "Normal"
    },
    {
        "Text": "It relies on recent advances in pattern discovery, paraphrase discovery, and extended named entity tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "We report on experimental results in which the system created useful tables for many topics, demonstrating the feasibility of this approach.",
        "Entity": "Normal"
    },
    {
        "Text": "Most of the world s information is recorded, passed down, and transmitted between people in text form.",
        "Entity": "Normal"
    },
    {
        "Text": "Implicit in most types of text are regularities of information structure - events which are reported many times, about different individuals, in different forms, such as layoffs or mergers and acquisitions in news articles.",
        "Entity": "Normal"
    },
    {
        "Text": "The goal of information extraction (IE) is to extract such information: to make these regular structures explicit, in forms such as tabular databases.",
        "Entity": "Normal"
    },
    {
        "Text": "Once the information structures are explicit, they can be processed in many ways: to mine information, to search for specific information, to generate graphical displays and other summaries.",
        "Entity": "Normal"
    },
    {
        "Text": "However, at present, a great deal of knowledge for automatic Information Extraction must be coded by hand to move a system to a new topic.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, at the later MUC evaluations, system developers spent one month for the knowledge engineering to customize the system to the given test topic.",
        "Entity": "Normal"
    },
    {
        "Text": "Research over the last decade has shown how some of this knowledge can be obtained from annotated corpora, but this still requires a large amount of annotation in preparation for a new task.",
        "Entity": "Normal"
    },
    {
        "Text": "Improving portability - being able to adapt to a new topic with minimal effort   is necessary to make Information Extraction technology useful for real users and, we be lieve, lead to a breakthrough for the application of the technology.",
        "Entity": "Normal"
    },
    {
        "Text": "We propose  On-demand information extraction (ODIE) : a system which automatically identifies the most salient structures and extracts the information on the topic the user demands.",
        "Entity": "Normal"
    },
    {
        "Text": "This new IE paradigm becomes feasible due to recent developments in machine learning for NLP, in particular unsupervised learning methods, and it is created on top of a range of basic language analysis tools, including POS taggers, dependency analyzers, and extended Named Entity taggers.",
        "Entity": "Normal"
    },
    {
        "Text": "The basic functionality of the system is the following.",
        "Entity": "Normal"
    },
    {
        "Text": "The user types a query / topic description in keywords (for example,  merge  or  merger ).",
        "Entity": "Normal"
    },
    {
        "Text": "Then tables will be created automatically in several minutes, rather than in a month of human labor.",
        "Entity": "Normal"
    },
    {
        "Text": "These tables are expected to show information about the salient relations for the topic.",
        "Entity": "Normal"
    },
    {
        "Text": "There are six major compo nents in the system.",
        "Entity": "Normal"
    },
    {
        "Text": "We will briefly describe each component and how the data is processed; then, in the next section, four important components will be described in more detail.",
        "Entity": "Normal"
    },
    {
        "Text": "731 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 731 738, Sydney, July 2006.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2006 Association for Computational Linguistics Description of task (query) 1) Relevant documents IR system 6) Extended NE tagger 5) Language Analyzer Patterns 2) Pattern discovery 3) Paraphrase discovery Pattern sets 4) Table construction P a r a p h r a s e Know ledge base Table          \n\t\t\tSystem overview 1) IR system: Based on the query given by the user, it retrieves relevant documents from the document database.",
        "Entity": "Normal"
    },
    {
        "Text": "We used a simple TF/IDF IR system we developed.",
        "Entity": "Normal"
    },
    {
        "Text": "2) Pattern discovery: First, the texts in the retrieved documents are analyzed using a POS tagger, a dependency analyzer and an Extended NE (Named Entity) tagger, which will be described later.",
        "Entity": "Normal"
    },
    {
        "Text": "Then this component extracts sub-trees of dependency trees which are relatively frequent in the retrieved documents compared to the entire corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "It counts the frequencies in the retrieved texts of all sub- trees with more than a certain number of nodes and uses TF/IDF methods to score them.",
        "Entity": "Normal"
    },
    {
        "Text": "The top-ranking sub-trees which contain NEs will be called patterns, which are expected to indicate salient relationships of the topic and will be used in the later components.",
        "Entity": "Normal"
    },
    {
        "Text": "3) Paraphrase discovery: In order to find semantic relationships between patterns, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "to find patterns which should be used to build the same table, we use paraphrase discovery techniques.",
        "Entity": "Normal"
    },
    {
        "Text": "The paraphrase discovery was conducted off- line and created a paraphrase knowledge base.",
        "Entity": "Normal"
    },
    {
        "Text": "4) Table construction: In this component, the patterns created in (2) are linked based on the paraphrase knowledge base created by (3), producing sets of patterns which are semantically equivalent.",
        "Entity": "Normal"
    },
    {
        "Text": "Once the sets of patterns are created, these patterns are applied to the documents retrieved by the IR system (1).",
        "Entity": "Normal"
    },
    {
        "Text": "The matched patterns pull out the entity instances and these entities are aligned to build the final tables.",
        "Entity": "Normal"
    },
    {
        "Text": "5) Language analyzers: We use a POS tagger and a dependency analyzer to analyze the text.",
        "Entity": "Normal"
    },
    {
        "Text": "The analyzed texts are used in pattern discovery and paraphrase discovery.",
        "Entity": "Normal"
    },
    {
        "Text": "6) Extended NE tagger: Most of the participants in events are likely to be Named Entities.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the traditional NE categories are not sufficient to cover most participants of various events.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the standard MUC s 7 NE categories (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "person, location, organization, percent, money, time and date) miss product names (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Windows XP, Boeing 747),event names (Olympics, World War II), nu merical expressions other than monetary expressions, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "We used the Extended NE categories with 140 categories and a tagger based on the categories.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, four important components will be described in detail.",
        "Entity": "Normal"
    },
    {
        "Text": "Prior work related to each component is explained and the techniques used in our system are presented.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Pattern Discovery.",
        "Entity": "Normal"
    },
    {
        "Text": "The pattern discovery component is responsible for discovering salient patterns for the topic.",
        "Entity": "Normal"
    },
    {
        "Text": "The patterns will be extracted from the documents relevant to the topic which are gathered by an IR system.",
        "Entity": "Normal"
    },
    {
        "Text": "Several unsupervised pattern discovery techniques have been proposed, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "(Riloff 96), (Agichtein and Gravano 00) and (Yangarber et al.",
        "Entity": "Normal"
    },
    {
        "Text": "00).",
        "Entity": "Normal"
    },
    {
        "Text": "Most recently we (Sudo et al.",
        "Entity": "Normal"
    },
    {
        "Text": "03) proposed a method which is triggered by a user query to discover important patterns fully automatically.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work, three different representation models for IE patterns were compared, and the sub-tree model was found more effective compared to the predicate-argument model and the chain model.",
        "Entity": "Normal"
    },
    {
        "Text": "In the sub-tree model, any connected part of a dependency tree for a sentence can be considered as a pattern.",
        "Entity": "Normal"
    },
    {
        "Text": "As it counts all possible sub-trees from all sentences in the retrieved documents, the computation is very expensive.",
        "Entity": "Normal"
    },
    {
        "Text": "This problem was solved by requiring that the sub-trees contain a predicate (verb) and restricting the number of nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "It was implemented using the sub-tree counting algorithm proposed by (Abe et al.",
        "Entity": "Normal"
    },
    {
        "Text": "02).",
        "Entity": "Normal"
    },
    {
        "Text": "The patterns are scored based on the relative frequency of the pattern in the retrieved documents (fr) and in the entire corpus (fall).",
        "Entity": "Normal"
    },
    {
        "Text": "The formula uses the TF/IDF idea (Formula 1).",
        "Entity": "Normal"
    },
    {
        "Text": "The system ignores very frequent patterns, as those patterns are so common that they are not likely to be important to any particular topic, and also very rare patterns, as most of those patterns are noise.",
        "Entity": "Normal"
    },
    {
        "Text": "case words.",
        "Entity": "Normal"
    },
    {
        "Text": "(COM means  company  and MNY means  money ) <COM1> <agree to buy> <COM2> <for MNY> <COM1> <will acquire> <COM2> <for MNY> <a MNY merger> <of COM1> <and COM2>          \n\t\t\tPattern examples 3.2 Paraphrase Discovery.",
        "Entity": "Normal"
    },
    {
        "Text": "The role of the paraphrase discovery component is to link the patterns which mean the same thing for the task.",
        "Entity": "Normal"
    },
    {
        "Text": "Recently there has been a growing amount of research on automatic paraphrase discovery.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, (Barzilay 01) proposed a method to extract paraphrases from parallel translations derived from one original document.",
        "Entity": "Normal"
    },
    {
        "Text": "We proposed to find paraphrases from multiple newspapers reporting the same event, using shared Named Entities to align the phrases (Shinyama et al.",
        "Entity": "Normal"
    },
    {
        "Text": "02).",
        "Entity": "Normal"
    },
    {
        "Text": "We also proposed a method to find paraphrases in the context of two Named Entity instances in a large un-annotated corpus (Sekine 05).",
        "Entity": "Normal"
    },
    {
        "Text": "The phrases connecting two NEs are grouped based on two types of evidence.",
        "Entity": "Normal"
    },
    {
        "Text": "One is the identity of the NE instance pairs, as multiple instances of the same NE pair (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Yahoo!",
        "Entity": "Normal"
    },
    {
        "Text": "and Overture) are likely to refer to the same relationship (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "acquisition).",
        "Entity": "Normal"
    },
    {
        "Text": "The other type of evidence is the keywords in the phrase.",
        "Entity": "Normal"
    },
    {
        "Text": "If we gather a lot of phrases connecting NE's of the same two NE types (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "company and company), we can cluster score(t : subtree) = f r (t) log( f all (t) + c) (1) these phrases and find some typical expressions (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "merge, acquisition, buy).",
        "Entity": "Normal"
    },
    {
        "Text": "The phrases are clustered based on these two types of evidence The scoring function sorts all patterns which contain at least one extended NE and the top 100 patterns are selected for later processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Chunks are shown in brackets and extended NEs are shown in upper and sets of paraphrases are created.",
        "Entity": "Normal"
    },
    {
        "Text": "Basically, we used the paraphrases found by the approach mentioned above.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that there is an alternative method of paraphrase discovery, using a hand crafted synonym dictionary like WordNet (WordNet Home page).",
        "Entity": "Normal"
    },
    {
        "Text": "However, we found that the coverage of WordNet for a particular topic is not sufficient.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, even if these words are found as synonyms, there is the additional task of linking expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, if one of the expressions is  reject the merger , it shouldn t be a paraphrase of  acquire .",
        "Entity": "Normal"
    },
    {
        "Text": "3.3 Extended NE tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "Named Entities (NE) were first introduced by the MUC evaluations (Grishman and Sundheim 96).",
        "Entity": "Normal"
    },
    {
        "Text": "As the MUCs concentrated on business and mili set using discovered paraphrase knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "Once the pattern sets are built, a table is created for each pattern set.",
        "Entity": "Normal"
    },
    {
        "Text": "We gather all NE instances matched by one of the patterns in the set.",
        "Entity": "Normal"
    },
    {
        "Text": "These instances are put in the same column of the table for the pattern set.",
        "Entity": "Normal"
    },
    {
        "Text": "When creating tables, we impose some restrictions in order to reduce the number of meaningless tables and to gather the same relations in one table.",
        "Entity": "Normal"
    },
    {
        "Text": "We require columns to have at least three filled instances and delete tables with fewer than three rows.",
        "Entity": "Normal"
    },
    {
        "Text": "These thresholds are empirically determined using training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Newspaper Pattern Set ANrtiecwle1s Paper * COM1 agree to buy tary topics, the important entity types were limited to a few classes of names and numerical expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "However, along with the development of Information Extraction and Question Answering technologies, people realized that there should be more and finer categories for NE.",
        "Entity": "Normal"
    },
    {
        "Text": "We proposed one of those extended NE sets (Sekine 02).",
        "Entity": "Normal"
    },
    {
        "Text": "It includes 140 hierarchical categories.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, ABC agreed to buy CDE for $1M  .",
        "Entity": "Normal"
    },
    {
        "Text": "Article 2 a $20M merger of FGH and IJK Constructed table COM2 for MNY * COM1 will acquire COM2 for MNY * a MNY merger of COM1 and COM2 the categories include Company, Company group, Military, Government, Political party, and International Organization as subcategories of Organization.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, new categories are introduced such as Vehicle, Food, Award, Religion, Language, Offense, Art and so on as subcategories of Product, as well as Event, Natural Object, Vocation, Unit, Weight, Temperature, Number of people and so on.",
        "Entity": "Normal"
    },
    {
        "Text": "We used a rule-based tagger developed to tag the 140 categories for this experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that, in the proposed method, the slots of the final table will be filled in only with instances of these extended Named Entities.",
        "Entity": "Normal"
    },
    {
        "Text": "Most common nouns, verbs or sentences can t be entries in the table.",
        "Entity": "Normal"
    },
    {
        "Text": "This is obviously a limitation of the proposed method; however, as the categories are designed to provide good coverage for a factoid type QA system, most interesting types of entities are covered by the categories.",
        "Entity": "Normal"
    },
    {
        "Text": "3.4 Table Construction.",
        "Entity": "Normal"
    },
    {
        "Text": "Basically the table construction is done by applying the discovered patterns to the original corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The discovered patterns are grouped into pattern Article Company Money 1 ABC, CDE $1M.",
        "Entity": "Normal"
    },
    {
        "Text": "2 FGH, IJK $20M.",
        "Entity": "Normal"
    },
    {
        "Text": "Table Construction\n\t\n\t\n\t\t\t4.1 Data and Processing.",
        "Entity": "Normal"
    },
    {
        "Text": "We conducted the experiments using the 1995 New York Times as the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The queries used for system development and threshold tuning were created by the authors, while queries based on the set of event types in the ACE extraction evaluations were used for testing.",
        "Entity": "Normal"
    },
    {
        "Text": "A total of 31 test queries were used; we discarded several queries which were ambiguous or uncertain.",
        "Entity": "Normal"
    },
    {
        "Text": "The test queries were derived from the example sentences for each event type in the ACE guidelines.",
        "Entity": "Normal"
    },
    {
        "Text": "Examples of queries are shown in the Appendix.",
        "Entity": "Normal"
    },
    {
        "Text": "At the moment, the whole process takes about 15 minutes on average for each query on a Pentium 2.80GHz processor running Linux.",
        "Entity": "Normal"
    },
    {
        "Text": "The corpus was analyzed in advance by a POS tagger, NE tagger and dependency analyzer.",
        "Entity": "Normal"
    },
    {
        "Text": "The processing and counting of sub-trees takes the majority (more than 90%) of the time.",
        "Entity": "Normal"
    },
    {
        "Text": "We believe we can easily make it faster by programming techniques, for example, using distributed computing.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Result and Evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "Out of 31 queries, the system is unable to build any tables for 11 queries.",
        "Entity": "Normal"
    },
    {
        "Text": "The major reason is that the IR component can t find enough newspaper articles on the topic.",
        "Entity": "Normal"
    },
    {
        "Text": "It retrieved only a few articles for topics like  born ,  divorce  or  injure  from The New York Times.",
        "Entity": "Normal"
    },
    {
        "Text": "For the moment, we will focus on the 20 queries for which tables were built.",
        "Entity": "Normal"
    },
    {
        "Text": "The Appendix shows some examples of queries and the generated tables.",
        "Entity": "Normal"
    },
    {
        "Text": "In total, 127 tables are created for the 20 topics, with one to thirteen tables for each topic.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of columns in a table ranges from 2 to 10, including the document ID column, and the average number of columns is 3.0.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of rows in a table range from 3 to 125, and the average number of rows is 16.9.",
        "Entity": "Normal"
    },
    {
        "Text": "The created tables are usually not fully filled; the average rate is 20.0%.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to measure the potential and the usefulness of the proposed method, we evaluate the result based on three measures: usefulness, argument role coverage, and correctness.",
        "Entity": "Normal"
    },
    {
        "Text": "For the usefulness evaluation, we manually reviewed the tables to determine whether a useful table is included or not.",
        "Entity": "Normal"
    },
    {
        "Text": "This is inevitably subjective, as the user does not specify in advance what table rows and columns are expected.",
        "Entity": "Normal"
    },
    {
        "Text": "We asked a subject to judge usefulness in three grades; A) very useful   for the query, many people might want to use this table for the further investigation of the topic, B) useful   at least, for some purpose, some people might want to use this table for further investigation and C) not useful   no one will be interested in using this table for further investigation.",
        "Entity": "Normal"
    },
    {
        "Text": "The argument role coverage measures the percentage of the roles specified for each ACE event type which appeared as a column in one or more of the created tables for that event type.",
        "Entity": "Normal"
    },
    {
        "Text": "The correctness was measured based on whether a row of a table reflects the correct information.",
        "Entity": "Normal"
    },
    {
        "Text": "As it is impossible to evaluate all the data, the evaluation data are selected randomly.",
        "Entity": "Normal"
    },
    {
        "Text": "Out of 20 topics, two topics are judged very useful and twelve are judged useful.",
        "Entity": "Normal"
    },
    {
        "Text": "The very useful top ics are  fine  (Q4 in the appendix) and  acquit  (not shown in the appendix).",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to the results in the  useful  category, the tables for these two topics have more slots filled and the NE types of the fillers have fewer mistakes.",
        "Entity": "Normal"
    },
    {
        "Text": "The topics in the  not useful  category are  appeal ,  execute ,  fired ,  pardon ,  release  and  trial .",
        "Entity": "Normal"
    },
    {
        "Text": "These are again topics with very few relevant articles.",
        "Entity": "Normal"
    },
    {
        "Text": "By increasing the corpus size or improving the IR component, we may be able to improve the performance for these topics.",
        "Entity": "Normal"
    },
    {
        "Text": "The majority category,  useful , has 12 topics.",
        "Entity": "Normal"
    },
    {
        "Text": "Five of them can be found in the appendix (all those besides Q4).",
        "Entity": "Normal"
    },
    {
        "Text": "For these topics, the number of relevant articles in the corpus is relatively high and interesting relations are found.",
        "Entity": "Normal"
    },
    {
        "Text": "The examples in the appendix are selected from larger tables with many columns.",
        "Entity": "Normal"
    },
    {
        "Text": "Although there are columns that cannot be filled for every event instance, we found that the more columns that are filled in, the more useful and interesting the information is.",
        "Entity": "Normal"
    },
    {
        "Text": "Usefulness evaluation result Ev al ua tio n N u m b e r o f t o p i c s Ve ry us ef ul 2 Us ef ul 1 2 N ot us ef ul 6 For the 14  very useful  and  useful  topics, the role coverage was measured.",
        "Entity": "Normal"
    },
    {
        "Text": "Some of the roles in the ACE task can be filled by different types of Named Entities, for example, the  defendant  of a  sentence  event can be a Person, Organization or GPE.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the system creates tables based on NE types; e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "for the  sentence  event, a Person column is created, in which most of the fillers are defendants.",
        "Entity": "Normal"
    },
    {
        "Text": "In such cases, we regard the column as covering the role.",
        "Entity": "Normal"
    },
    {
        "Text": "Out of 63 roles for the 14 event types, 38 are found in the created tables, for a role coverage of 60.3%.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that, by lowering the thresholds, the coverage can be increased to as much as 90% (some roles can t be found because of Extended NE limitations or the rare appearance of roles) but with some sacrifice of precision.",
        "Entity": "Normal"
    },
    {
        "Text": "We randomly select 100 table rows among the topics which were judged  very useful  or  useful , and determine the correctness of the information by reading the newspaper articles the information was extracted from.",
        "Entity": "Normal"
    },
    {
        "Text": "Out of 100 rows, 84 rows have correct information in all slots.",
        "Entity": "Normal"
    },
    {
        "Text": "4 rows have some incorrect information in some of the columns, and 12 contain wrong information.",
        "Entity": "Normal"
    },
    {
        "Text": "Most errors are due to NE tagging errors (11 NE errors out of 16 errors).",
        "Entity": "Normal"
    },
    {
        "Text": "These errors include instances of people which are tagged as other categories, and so on.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, by looking at the actual articles, we found that co-reference resolution could help to fill in more information.",
        "Entity": "Normal"
    },
    {
        "Text": "Because the important information is repeatedly mentioned in newspaper articles, referential expressions are often used.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in a sentence  In 1968 he was elected mayor of Indianapolis.",
        "Entity": "Normal"
    },
    {
        "Text": ", we could not extract  he  at the moment.",
        "Entity": "Normal"
    },
    {
        "Text": "We plan to add coreference resolution in the near future.",
        "Entity": "Normal"
    },
    {
        "Text": "Other sources of error include:   The role of the entity is confused, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "victim and murderer   Different kinds of events are found in one table, e.g., the victory of Jack Nicklaus was found in first proposed by (Aone and RamosSantacruz 00) and the ACE evaluations of event detection follow this line (ACE Home Page).",
        "Entity": "Normal"
    },
    {
        "Text": "An unsupervised learning method has been applied to a more restricted IE task, Relation Discovery.",
        "Entity": "Normal"
    },
    {
        "Text": "(Hasegawa et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2004) used large corpora and an Extended Named Entity tagger to find novel relations and their participants.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the results are limited to a pair of participants and because of the nature of the procedure, the discovered relations are static relations like a country and its presidents rather than events.",
        "Entity": "Normal"
    },
    {
        "Text": "Topic-oriented summarization, currently pursued by the DUC evaluations (DUC Home Page), is also closely related.",
        "Entity": "Normal"
    },
    {
        "Text": "The systems are trying to create summaries based on the specified topic for a manually prepared set of documents.",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, if the result is suitable to present in table format, it can be handled by ODIE.",
        "Entity": "Normal"
    },
    {
        "Text": "Our previous study (Se the political election use terms like  win ) query (as both of them kine and Nobata 03) found that about one third of randomly constructed similar newspaper article   An unrelated but often collocate entity was included.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, Year period expressions are found in  fine  events, as there are many expressions like  He was sentenced 3 years and fined $1,000 .",
        "Entity": "Normal"
    },
    {
        "Text": "Correctness evaluation result Ev al ua tio n N u m b e r o f r o w s Co rre ct 8 4 Pa rti all y co rre ct 4 In co rre ct 1 2\n\t\n\t\n\t\t\tAs far as the authors know, there is no system similar to ODIE.",
        "Entity": "Normal"
    },
    {
        "Text": "Several methods have been proposed to produce IE patterns automatically to facilitate IE knowledge creation, as is described in Section 3.1.",
        "Entity": "Normal"
    },
    {
        "Text": "But those are not targeting the fully automatic creation of a complete IE system for a new topic.",
        "Entity": "Normal"
    },
    {
        "Text": "There exists another strategy to extend the range of IE systems.",
        "Entity": "Normal"
    },
    {
        "Text": "It involves trying to cover a wide variety of topics with a large inventory of relations and events.",
        "Entity": "Normal"
    },
    {
        "Text": "It is not certain if there are only a limited number of topics in the world, but there are a limited number of high-interest topics, so this may be a reasonable solution from an engineering point of view.",
        "Entity": "Normal"
    },
    {
        "Text": "This line of research was clusters are well-suited to be presented in table format, and another one third of the clusters can be acceptably expressed in table format.",
        "Entity": "Normal"
    },
    {
        "Text": "This suggests there is a big potential where an ODIE-type system can be beneficial.",
        "Entity": "Normal"
    },
    {
        "Text": "We demonstrated a new paradigm of Information Extraction technology and showed the potential of this method.",
        "Entity": "Normal"
    },
    {
        "Text": "However, there are problems to be solved to advance the technology.",
        "Entity": "Normal"
    },
    {
        "Text": "One of them is the coverage of the extracted information.",
        "Entity": "Normal"
    },
    {
        "Text": "Although we have created useful tables for some topics, there are event instances which are not found.",
        "Entity": "Normal"
    },
    {
        "Text": "This problem is mostly due to the inadequate performance of the language analyzers (information retrieval component, dependency analyzer or Extended NE tagger) and the lack of a coreference analyzer.",
        "Entity": "Normal"
    },
    {
        "Text": "Even though there are possible applications with limited coverage, it will be essential to enhance these components and add coreference in order to increase coverage.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, there are basic domain limitations.",
        "Entity": "Normal"
    },
    {
        "Text": "We made the system  on-demand  for any topic, but currently only within regular news domains.",
        "Entity": "Normal"
    },
    {
        "Text": "As configured, the system would not work on other domains such as a medical, legal, or patent domain, mainly due to the design of the extended NE hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "While specific hierarchies could be incorporated for new domains, it will also be desirable to integrate bootstrapping techniques for rapid incremental additions to the hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "Also at the moment, table column labels are simply Extended NE categories, and do not indicate the role.",
        "Entity": "Normal"
    },
    {
        "Text": "We would like to investigate this problem in the future.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we proposed  On-demand Information Extraction (ODIE) .",
        "Entity": "Normal"
    },
    {
        "Text": "It is a system which automatically identifies the most salient structures and extracts the information on whatever topic the user demands.",
        "Entity": "Normal"
    },
    {
        "Text": "It relies on recent advances in NLP technologies; unsupervised learning and several advanced NLP analyzers.",
        "Entity": "Normal"
    },
    {
        "Text": "Although it is at a preliminary stage, we developed a prototype system which has created useful tables for many topics and demonstrates the feasibility of this approach.",
        "Entity": "Normal"
    },
    {
        "Text": "This research was supported in part by the Defense Advanced Research Projects Agency under Contract HR001106-C-0023 and by the National Science Foundation under Grant IIS0325657.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper does not necessarily reflect the position of the U.S. Government.",
        "Entity": "Normal"
    },
    {
        "Text": "We would like to thank Prof. Ralph Grishman, Dr. Kiyoshi Sudo, Dr. Chikashi Nobata, Mr. Takaaki Hasegawa, Mr. Koji Murakami and Mr. Yusuke Shinyama for useful comments, discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tWe propose semantic role features for a Tree-to-String transducer to model the reordering/deletion of source-side semantic roles.",
        "Entity": "Normal"
    },
    {
        "Text": "These semantic features, as well as the Tree-to-String templates, are trained based on a conditional log-linear model and are shown to significantly outperform systems trained based on Max-Likelihood and EM.",
        "Entity": "Normal"
    },
    {
        "Text": "We also show significant improvement in sentence fluency by using the semantic role features in the log-linear model, based on manual evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "Syntax-based statistical machine translation (SSMT) has achieved significant progress during recent years (Galley et al., 2006; May and Knight, 2007; Liu et al., 2006; Huang et al., 2006), showing that deep linguistic knowledge, if used properly, can improve MT performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Semantics-based SMT, as a natural extension to SSMT, has begun to receive more attention from researchers (Liu and Gildea, 2008; Wu and Fung, 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "Semantic structures have two major advantages over syntactic structures in terms of helping machine translation.",
        "Entity": "Normal"
    },
    {
        "Text": "First of all, semantic roles tend to agree better between two languages than syntactic constituents (Fung et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "This property motivates the approach of using the consistency of semantic roles to select MT outputs (Wu and Fung, 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "Secondly, the set of semantic roles of a predicate models the skeleton of a sentence, which is crucial to the readability of MT output.",
        "Entity": "Normal"
    },
    {
        "Text": "By skeleton, we mean the main structure of a sentence including the verbs and their arguments.",
        "Entity": "Normal"
    },
    {
        "Text": "In spite of the theoretical potential of the semantic roles, there has not been much success in using them to improve SMT systems.",
        "Entity": "Normal"
    },
    {
        "Text": "Liu and Gildea (2008) proposed a semantic role based Tree-to-String (TTS) transducer by adding semantic roles to the TTS templates.",
        "Entity": "Normal"
    },
    {
        "Text": "Their approach did not differentiate the semantic roles of different predicates, and did not always improve the TTS transducer s performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Wu and Fung (2009) took the output of a phrase-based SMT system Moses (Koehn et al., 2007), and kept permuting the semantic roles of the MT output until they best matched the semantic roles in the source sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach shows the positive effect of applying semantic role constraints, but it requires re-tagging semantic roles for every permuted MT output and does not scale well to longer sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper explores ways of tightly integrating semantic role features (SRFs) into an MT system, rather than using them in post-processing or n- best re-ranking.",
        "Entity": "Normal"
    },
    {
        "Text": "Semantic role labeling (SRL) systems usually use sentence-wide features (Xue and Palmer, 2004; Pradhan et al., 2004; Toutanova et al., 2005); thus it is difficult to compute target- side semantic roles incrementally during decoding.",
        "Entity": "Normal"
    },
    {
        "Text": "Noticing that the source side semantic roles are easy to compute, we apply a compromise approach, where the target side semantic roles are generated by projecting the source side semantic roles using the word alignments between the source and target sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Since this approach does not perform true SRL on the target string, it cannot fully evaluate whether the source and target semantic structures are consistent.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the approach does capture the semantic-level reordering of the sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "We assume here that the MT system is capable of providing word alignment (or equivalent) information during decoding, which is generally true for current statistical MT systems.",
        "Entity": "Normal"
    },
    {
        "Text": "Specifically, two types of semantic role features are proposed in this paper: a semantic role reordering feature designed to capture the skeleton- level permutation, and a semantic role deletion fea 716 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 716 724, Beijing, August 2010 ture designed to penalize missing semantic roles in the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "To use these features during decoding, we need to keep track of the semantic role sequences (SRS) for partial translations, which can be generated based on the source-side semantic role sequence and the corresponding word alignments.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the SRL system and the MT system are separate, a translation rule (e.g., a phrase pair in phrase-based SMT) could cover two partial source-side semantic roles.",
        "Entity": "Normal"
    },
    {
        "Text": "In such cases partial SRSs must be recorded in such a way that they can be combined later with other partial SRSs.",
        "Entity": "Normal"
    },
    {
        "Text": "Dealing with this problem will increase the complexity of the decoding algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "Fortunately, Tree-to- String transducer based MT systems (Liu et al., 2006; Huang et al., 2006) can avoid this problem by using the same syntax tree for both SRL and MT.",
        "Entity": "Normal"
    },
    {
        "Text": "Such an arrangement guarantees that a TTS template either covers parts of one source-side semantic role, or a few complete semantic roles.",
        "Entity": "Normal"
    },
    {
        "Text": "This advantage motivates us to use a TTS transducer as the MT system with which to demonstrate the use of the proposed semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": "Since it is hard to design a generative model to combine both the semantic role features and the TTS templates, we use a log-linear model to estimate the feature weights, by maximizing the conditional probabilities of the target strings given the source syntax trees.",
        "Entity": "Normal"
    },
    {
        "Text": "The log-linear model with latent variables has been discussed by Blunsom et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2008); we apply this technique to combine the TTS templates and the semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": "The remainder of the paper is organized as follows: Section 2 describes the semantic role features proposed for machine translation; Section 3 describes how semantic role features are used and trained in a TTS transducer; Section 4 presents the experimental results; and Section 5 gives the conclusion.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation 2.1 Defining Semantic Roles.",
        "Entity": "Normal"
    },
    {
        "Text": "There are two semantic standards with publicly available training data: PropBank (Palmer et al., 2005) and FrameNet (Johnson et al., 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "Prop- Bank defines a set of semantic roles for the verbs in the Penn TreeBank using numbered roles.",
        "Entity": "Normal"
    },
    {
        "Text": "These roles are defined individually for each verb.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, for the verb disappoint, the role name arg1 means experiencer, but for the verb wonder, role name arg1 means cause.",
        "Entity": "Normal"
    },
    {
        "Text": "FrameNet is motivated by the idea that a certain type of verbs can be gathered together to form a frame, and in the same frame, a set of semantic roles is defined and shared among the verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the verbs boil, bake, and steam will be in frame apply heat, and they have the semantic roles of cook, food, and heating instrument.",
        "Entity": "Normal"
    },
    {
        "Text": "Of these two semantic standards, we choose PropBank over FrameNet for the following reasons: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "PropBank has a simpler semantic definition.",
        "Entity": "Normal"
    },
    {
        "Text": "than FrameNet and thus is easier for automatic labeling.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "PropBank is built upon the Penn TreeBank.",
        "Entity": "Normal"
    },
    {
        "Text": "and is more consistent with statistical parsers, most of which are trained on the Penn Tree- Bank.",
        "Entity": "Normal"
    },
    {
        "Text": "3.",
        "Entity": "Normal"
    },
    {
        "Text": "PropBank is a larger corpus than FrameNet.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that the semantic standard/corpus is not cru cial in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "Any training corpus that can be used to automatically obtain the set of semantic roles of a verb could be used in our approach.",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 Semantic Role Features.",
        "Entity": "Normal"
    },
    {
        "Text": "Ideally, we want to use features based on the true semantic roles of the MT candidates.",
        "Entity": "Normal"
    },
    {
        "Text": "Considering there is no efficient way of integrating SRL and MT, accurate target-side semantic roles can only be used in post-processing and re-ranking the MT outputs, where a limited number of MT candidates are considered.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, it is much easier to obtain reliable semantic roles for the source sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper uses a compromise approach, where the target-side semantic roles are projected from the source-side semantic roles using the word alignment derived from the translation process.",
        "Entity": "Normal"
    },
    {
        "Text": "More specifically, we define two types of semantic role features: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Semantic Role Reordering (SRR) This fea-.",
        "Entity": "Normal"
    },
    {
        "Text": "ture describes reordering of the source-side semantic roles (including the predicate) in the target side.",
        "Entity": "Normal"
    },
    {
        "Text": "It takes the following form: arg0 arg neg arg1 arg1 arg0 I did not see the book you borrowed SrcP red : SrcRole1, ..., SrcRolen   T arRole1, ..., T arRolen SRR:             where SrcP red and SrcRole denotes the central verb and semantic roles in the source side, and T arRole denotes the target-side roles.",
        "Entity": "Normal"
    },
    {
        "Text": "The source/target SRSs do not need be continuous, but there should be a one-to-one alignment between the roles in the two sides.",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to the general reordering models used in statistical MT systems, this type of feature is capable of modeling skeleton-level reordering, which is crucial to the fluency of MT output.",
        "Entity": "Normal"
    },
    {
        "Text": "Because a predicate can have different semantic role sequences in different voices, passive/active are tagged for each occurrence of the verbs based on their POS and preceding words.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "Deleted Roles (DR) are the individual source-.",
        "Entity": "Normal"
    },
    {
        "Text": "side semantic roles which are deleted in the MT outputs, taking the form of: SrcP red : SrcRole   deleted DR is meant to penalize the deletion of the semantic roles.",
        "Entity": "Normal"
    },
    {
        "Text": "Though most statistical MT systems have penalties for word deletion, it is still useful to make separate features for the deletion of semantic roles, which is considered more harmful than the deletion of non-core components (e.g., modifiers) and deserves more serious penalty.",
        "Entity": "Normal"
    },
    {
        "Text": "Both types of features can be made non-lexicalized by removing the actual verb but retaining its voice information in the features.",
        "Entity": "Normal"
    },
    {
        "Text": "Non-lexicalized features are used in the system to alleviate the problem of sparse verbs.",
        "Entity": "Normal"
    },
    {
        "Text": "see active: arg neg verb   arg neg verb borrowed active: arg1 arg0   arg0 arg1 borrowed active: arg1 verb   verb arg1 borrowed active: arg0 verb   arg0 verb borrowed active: arg1 arg0 verb   arg0 verb arg1 DR: see active: arg0   deleted                                                                                                                             \n\t\t\tWe first briefly describe the basic Tree-to-String translation model used in our experiments, and then describe how to modify it to incorporate the semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Basic Tree-to-String Transducer.",
        "Entity": "Normal"
    },
    {
        "Text": "A Tree-to-String transducer receives a syntax tree as its input and, by recursively applying TTS templates, generates the target string.",
        "Entity": "Normal"
    },
    {
        "Text": "A TTS template is composed of a left-hand side (LHS) and a right-hand side (RHS), where the LHS is a sub- tree pattern and the RHS is a sequence of variables and translated words.",
        "Entity": "Normal"
    },
    {
        "Text": "The variables in the RHS of a template correspond to the bottom level non- terminals in the LHS s subtree pattern, and their relative order indicates the permutation desired at the point where the template is applied to translate one language to another.",
        "Entity": "Normal"
    },
    {
        "Text": "The variables are further transformed, and the recursive process goes on until there are no variables left.",
        "Entity": "Normal"
    },
    {
        "Text": "The formal description of a TTS transducer is given by Graehl and Knight (2004), and our baseline approach follows the Extended Tree-to-String Transducer defined by Huang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006).",
        "Entity": "Normal"
    },
    {
        "Text": "For a given derivation (decomposition into templates) of a syntax tree, the translation probability is computed as the product of the templates which generate both the source syntax trees and the target translations.",
        "Entity": "Normal"
    },
    {
        "Text": "n\n\t\n\t\n\t\t\tMachine Translation P r(S | T , D ) = t D  P r(t) This section describes how to use the proposed semantic role features in a Tree-to-String transducer, Here, S denotes the target sentence, T denotes the source syntax tree, and D  denotes the derivation of T .",
        "Entity": "Normal"
    },
    {
        "Text": "In addition to the translation model, the function DECODE(T ) for tree node v of T in bottom-up order do for template t applicable at v do {c1 , c2 }=match(v, t); s.lef tw = c1 .lef tw; s.rightw = c2 .rightw; s.val = c1 .val   c2 .val; s.val  = P r(t); s.val  = P r(c2 .lef tw|c1 .rightw); add s to v s beam;                                                                         \n\t\t\tlef tw/rightw denote the left/right boundary word of s. c1 , c2 denote the descendants of v, ordered based on RHS of t. VBG [giving: verb] giving VBG [giving: verb] giving VP NP [giving: arg2] VP [giving: arg2 arg1] NP [giving: arg2] NP [giving: arg1] NP [giving: arg1] TTS system includes a trigram language model, a deletion penalty, and an insertion bonus.",
        "Entity": "Normal"
    },
    {
        "Text": "To incorporate the n-gram language model, states in the algorithm denote a tree node s best translations with different left and right boundary words.",
        "Entity": "Normal"
    },
    {
        "Text": "We use standard beam-pruning to narrow the search space.",
        "Entity": "Normal"
    },
    {
        "Text": "It is straightforward to generalize the algorithm for larger n-gram models and TTS templates with any number of children in the bottom using target-side binarized combination (Huang et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "TTS template: (VP (VBG giving ) NP#1 NP#2 )   NP#1 NP#2 Triggered SRR: giving active: arg2 arg1   arg2 arg1 Triggered DR: giving active: verb   deleted                                                                                           \n\t\t\tAbove/middle is the state information before/after applying the TTS template, and bottom is the used TTS template and the triggered SRFs during the combination.",
        "Entity": "Normal"
    },
    {
        "Text": "be easily derived.",
        "Entity": "Normal"
    },
    {
        "Text": "Now we show how to incorporate the two types of semantic role features into a TTS transducer.",
        "Entity": "Normal"
    },
    {
        "Text": "To use the semantic role reordering feature SRR, the states in the decoding algorithm need to be expanded to encode the target-side SRSs.",
        "Entity": "Normal"
    },
    {
        "Text": "The SRSs are initially attached to the translation states of the source tree con 3.2 Modified Tree-to-String Transducer with.",
        "Entity": "Normal"
    },
    {
        "Text": "Semantic Role Features Semantic role features can be used as an auxiliary translation model in the TTS transducer, which focuses more on the skeleton-level permutation.",
        "Entity": "Normal"
    },
    {
        "Text": "The model score, depending on not only the input source tree and the derivation of the tree, but also the semantic roles of the source tree, can be formulated as: VBZ [bring: verb] VP NP [bring: arg1] NNP NN new test PP [bring: arg3] P r(S | T , D ) = n f  F (S,T .role,D ) P r(f ) where T denotes the source syntax tree with semantic roles, T .role denotes the semantic role sequence in the source side and F (S.role, T .role, D ) denotes the set of defined semantic role features over T .role and the target side semantic role sequence S.role.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that given T .role and the derivation D , S.role can Median = 3 ar^g1 Combined SRS arg3 verb arg1                                                                                                                                    \n\t\t\tstituents which are labeled as semantic roles for some predicate.",
        "Entity": "Normal"
    },
    {
        "Text": "These semantic roles are then accumulated with reordering and deletion operations specified by the TTS templates as the decoding process goes bottom-up.",
        "Entity": "Normal"
    },
    {
        "Text": "The model component corresponding to the feature SRR is computed when combining two translation states.",
        "Entity": "Normal"
    },
    {
        "Text": "I.e., the probabilities of the SRR features composed based on the semantic roles of function DECODE(T ) for tree node v of T in bottom-up order do for template t applicable at v do {c1 , c2 }=match(v, t); s.lef tw = c1 .lef tw; s.rightw = c2 .rightw; s.role = concatenate(c1 .role, c2 .role); if v is a semantic role then set s.role to v.role; s.val = c1 .val   c2 .val; s.val  = P r(t); s.val  = P r(c2 .lef tw|c1 .rightw); t> Compute the probabilities associated with semantic roles the two combining states will be added into the = Q f  Sema(c1 .role,c2 .role,t) add s to v s beam; P r(f ); combined state.",
        "Entity": "Normal"
    },
    {
        "Text": "Sema(c1 .role, c2 .role, t) denotes the triggered semantic ity is O(N M 4(n 1)R(LC C !",
        "Entity": "Normal"
    },
    {
        "Text": ")V ),                                                                                                     \n\t\t\tthe number of nodes in the source syntax tree, M is the vocabulary size of the target language, n is the order of the n-gram language model, R is the maximum number of TTS templates which can be matched at a tree node, C is the maximum number of roles of a verb, and V is the maximum number of verbs in a sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "In this formula, LC C !",
        "Entity": "Normal"
    },
    {
        "Text": "is the number of role sequences obtained by first choosing i out of C possible roles and then permuting the i roles.",
        "Entity": "Normal"
    },
    {
        "Text": "This theoretical upper bound is not reached in practice, because the number of possible TTS templates applicable at a tree node is very limited.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, since we apply beam pruning at each tree node, the running time is controlled by the beam size, and is linear in the size of the tree.",
        "Entity": "Normal"
    },
    {
        "Text": "Since we are primarily interested in the relative order of the semantic roles, we approximate each semantic role s target side position by the median of the word positions that is aligned to.",
        "Entity": "Normal"
    },
    {
        "Text": "If more than one semantic role is mapped to the same position in the target side, their source side order will be used as their target side order, i.e., monotonic translation is assumed for those semantic roles.",
        "Entity": "Normal"
    },
    {
        "Text": "The word alignments in the TTS templates are also used to compute the deletion feature DR.",
        "Entity": "Normal"
    },
    {
        "Text": "Whenever a semantic role is deleted in a TTS template s RHS, the corresponding deletion penalty will be applied.",
        "Entity": "Normal"
    },
    {
        "Text": "3.3 Training.",
        "Entity": "Normal"
    },
    {
        "Text": "We describe two alternative methods for training the weights for the model s features, including both the individual TTS templates and the semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": "The first method maximizes data likelihood as is standard in EM, while the second method maximizes conditional likelihood for a log- linear model following Blunsom et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2008).",
        "Entity": "Normal"
    },
    {
        "Text": "3.3.1 Maximizing Data Likelihood The standard way to train a TTS translation model is to extract the minimum TTS templates using GHKM (Galley et al., 2004), and then normalize the frequency of the extracted TTS templates (Galley et al., 2004; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "The probability of the semantic features SRR and DR can be computed similarly, given that SRR and DR can be derived from the paired source/target sentences and the word alignments between them.",
        "Entity": "Normal"
    },
    {
        "Text": "We refer to this model as max-likelihood training and normalize the counts of TTS templates and semantic features based on their roots and predicates respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "We wish to overcome noisy alignments from GIZA++ and learn better TTS rule probabilities by re-aligning the data using EM within the TTS E-step: for all pair of syntax tree T and target string S do for all TTS Template t, semantic features f do PD:t D P r(S,T ,D) function COMPUTE PARTITION(T ) for tree node v of T in bottom-up order do for template t applicable at v do for {s1 , s2 }=Match(v, t) do EC (t) += P ; s.sum += s .sum   s .sum  Dt P r(S,T ,Dt ) PD:f  D P r(S,T ,D) 1 2 exp( t + P f EC (f ) += M-step: PDt P r(S,T ,Dt ) ; f  Sema(s1 ,s2 ,t)   ); s.role = concatenate(s1 .role, s2 .role); add s to v; for all TTS Template t, semantic features f do P r(t) = EC (t) ; Ptt :tt .root=t.root EC (tt ) P r(f ) = EC (f ) ; Pf t :f t .predicate=t.predicate EC (f t )                                                                                                            \n\t\t\tWe can estimate the expected counts of the TTS templates and the semantic features by formulating the probability of a pair of source tree and target string as: for state s in root do res += s.sum; return res;                                                                                     \n\t\t\tSema(s1 , s2 , t) denotes all the semantic role features generated by combining s1 and s2 using t. role features are defined makes it impossible to design a sound generative model to incorporate these features, a log-linear model is also a theoretically better choice than the EM algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The difficult part of the EM algorithm is the E- step, which computes the expected counts of the TTS templates and the semantic features by summing over all possible derivations of the source trees and target strings.",
        "Entity": "Normal"
    },
    {
        "Text": "The standard inside- outside algorithm (Graehl and Knight, 2004) can be used to compute the expected counts of the TTS templates.",
        "Entity": "Normal"
    },
    {
        "Text": "Similar to the modification made in the TTS decoder, we can add the target-side semantic where the features f include both the TTS templates and the semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": "The numerator in the formula above can be computed using the same dynamic programming algorithm used to compute the expected counts in the EM algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the partition function (denominator) requires summing over all possible source trees and target strings, and is infeasible to compute.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead of approximating the partition function using methods such as sampling, we change the objective function from the data likelihood to the conditional likelihood: role sequence to the dynamic programming states D exp i  i fi (S, T , D)of the inside-outside algorithm to compute the ex P r(S | T ) = P P exp P   f (S , T , D ) pected counts of the semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "This way St  all(T ) Dt i i i each state (associated with a source tree node) represents a target side span and the partial SRSs.",
        "Entity": "Normal"
    },
    {
        "Text": "To speed up the training, a beam is created for each target span and only the top rated SRSs in the beam are kept.",
        "Entity": "Normal"
    },
    {
        "Text": "3.3.2 Maximizing Conditional Likelihood A log-linear model is another way to combine the TTS templates and the semantic features together.",
        "Entity": "Normal"
    },
    {
        "Text": "Again, to simplify the illustration, only binary TTS templates are used.",
        "Entity": "Normal"
    },
    {
        "Text": "Using the conditional probability as the objective function not only reduces the computational cost, but also corresponds better to the TTS decoder, where the best MT output is selected only among the possible candidates which can be generated from the input source tree using TTS templates.",
        "Entity": "Normal"
    },
    {
        "Text": "The derivative of the logarithm of the objective function (over the entire training corpus) w.r.t.",
        "Entity": "Normal"
    },
    {
        "Text": "a feature weight can be computed as: (n-gram language model, TTS templates, SRR, DR) weights of the transducer are tuned based on the development set using a grid-based line search, and the translation results are evaluated based on a single Chinese reference using BLEU4 (Papineni et al., 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "Huang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) used character- based BLEU as a way of normalizing inconsistent   log Q P r(S | T ) = X EC (fi )   EC t (fi )} Chinese word segmentati on, but we avoid this prob   i { S,T D|S,T S |T lem as the training, developmen t, and test data are from the same source.",
        "Entity": "Normal"
    },
    {
        "Text": "With the objective function and its derivatives, a variety of optimization methods can be used to obtain the best feature weights; we use LBFGS (Zhu et al., 1994) in our experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "To prevent the model from overfitting the training data, a weighted Gaussian prior is used with the objective function.",
        "Entity": "Normal"
    },
    {
        "Text": "The variance of the Gaussian prior is tuned based on the development set.",
        "Entity": "Normal"
    },
    {
        "Text": "We train an English-to-Chinese translation system using the FBIS corpus, where 73,597 sentence pairs are selected as the training data, and 500 sentence pairs with no more than 25 words on the Chinese side are selected for both the development and test data.1 Charniak (2000) s parser, trained on the Penn Treebank, is used to generate the English syntax trees.",
        "Entity": "Normal"
    },
    {
        "Text": "To compute the semantic roles for the source trees, we use an in-house maxent classifier with features following Xue and Palmer (2004) and Pradhan et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2004).",
        "Entity": "Normal"
    },
    {
        "Text": "The semantic role labeler is trained and tuned based on sections 2 21 and section 24 of PropBank respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "The standard role-based F-score of our semantic role labeler is 88.70%.",
        "Entity": "Normal"
    },
    {
        "Text": "Modified KneserNey trigram models are trained using SRILM (Stolcke, 2002) on the Chinese portion of the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "s parser.",
        "Entity": "Normal"
    },
    {
        "Text": "The baseline system in our experiments uses the TTS templates generated by using GHKM and the union of the two single-direction alignments generated by GIZA++.",
        "Entity": "Normal"
    },
    {
        "Text": "Unioning the two single-direction alignments yields better performance for the SSMT systems using TTS templates (Fossum et al., 2008) than the two single-direction alignments and the heuristic diagonal combination (Koehn et al., 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "The two single-direction word alignments as well as the union are used to generate the initial TTS template set for both the EM algorithm and the log-linear model.",
        "Entity": "Normal"
    },
    {
        "Text": "The initial TTS templates  probabilities/weights are set to their normalized counts based on the root of the TTS template (Galley et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "To test semantic role features, their initial weights are set to their normalized counts for the EM algorithm and to 0 for the log-linear model.",
        "Entity": "Normal"
    },
    {
        "Text": "We can see that the EM algorithm, based only on TTS templates, is slightly better than the baseline system.",
        "Entity": "Normal"
    },
    {
        "Text": "Adding semantic role features to the EM algorithm actually hurts the performance, which is not surprising since the combination of the TTS templates and semantic role features does not yield a sound generative model.",
        "Entity": "Normal"
    },
    {
        "Text": "The log-linear model based on TTS templates achieves significantly better results than both the baseline system and the EM algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "Both improvements are significant at p < 0.05 based on 2000 iterations of paired bootstrap re- sampling of the test set (Koehn, 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "Adding semantic role features to the log-linear model further improves the BLEU score.",
        "Entity": "Normal"
    },
    {
        "Text": "One problem in our approach is the sparseness of the verbs, which makes it difficult for the log-linear model to tune the lexicalized semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": "One way to alleviate this problem is to make features based on verb classes.",
        "Entity": "Normal"
    },
    {
        "Text": "We first tried using the verb TTS Templates + SRF + Verb Class Union 15.6     EM 15.9 15.5 15.6 Log-linear 17.1 17.4 17.6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n\t\t\tUnfortu SRF On   123  4   6,7     14,15   9     11,12 SRF Off   123  4    14,15 ,   6,7     11,12   9 Source A1 gratifying2 change3 also4 occurred5 in6 the7 structure8 of9 ethnic10 minority11 cadres12 SRF On     10,11   8  4   5    2   3 nately, VerbNet only covers about 34% of the verb SRF Off           ,                tokens in our training corpus, and does not improve the system s performance.",
        "Entity": "Normal"
    },
    {
        "Text": "We then resorted 1 2 3 4 10,11 8 to automatic clustering based on the aspect model (Hofmann, 1999; Rooth et al., 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "The training corpus used in clustering is the English portion of the selected FBIS corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Though automatically obtained verb clusters lead to further improvement in BLEU score, the total improvement from the semantic role features is not statistically significant.",
        "Entity": "Normal"
    },
    {
        "Text": "Because BLEU4 is biased towards the adequacy of the MT outputs and may not effectively evaluate their fluency, it is desirable to give a more accurate evaluation of the sentence s fluency, which is the property that semantic role features are supposed to improve.",
        "Entity": "Normal"
    },
    {
        "Text": "To do this, we manually compare the outputs of the two log-linear models with and without the semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": "Our evaluation focuses on the completeness and ordering of the semantic roles, and better, equal, worse are tagged for each pair of MT outputs indicating the impact of the semantic role features.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "This paper proposes two types of semantic role features for a Tree-to-String transducer: one models the reordering of the source-side semantic role sequence, and the other penalizes the deletion of a source-side semantic role.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The first and second example shows that SRFs improve the completeness and the ordering of the MT outputs respectively, the third example shows that SRFs improve both properties.",
        "Entity": "Normal"
    },
    {
        "Text": "The subscripts of each Chinese phrase show their aligned words in English.",
        "Entity": "Normal"
    },
    {
        "Text": "and the Tree-to-String templates, trained based on a conditional log-linear model, are shown to significantly improve a basic TTS transducer s performance in terms of BLEU4.",
        "Entity": "Normal"
    },
    {
        "Text": "To avoid BLEU s bias towards the adequacy of the MT outputs, manual evaluation is conducted for sentence fluency and significant improvement is shown by using the semantic role features in the log-linear model.",
        "Entity": "Normal"
    },
    {
        "Text": "Considering our semantic features are the most basic ones, using more sophisticated features (e.g., the head words and their translations of the source- side semantic roles) provides a possible direction for further experimentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Acknowledgments This work was funded by NSF IIS0546554 and IIS0910611.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tA new hybrid approach to the coreference resolution problem is presented.",
        "Entity": "Normal"
    },
    {
        "Text": "The COR,UDISsystem (COreference R,Ules with Disambiguation Statistics) combines syntactico-semantic rules with statistics derived from an annotated corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "First, the rules and corpus annotationsare described and exemplified.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, the coreference resolution algorithm and the involved statistics are explained.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the proposed method is evaluated against a baseline modeland some directions for further research are indicated.",
        "Entity": "Normal"
    },
    {
        "Text": "Coreference resolution is a central problem innatural language understanding since coreference links play an important role for text coher ence.&apos; In sentence (1) for instance, one wants to know what the German personal pronouns sic and ihr refer to.",
        "Entity": "Normal"
    },
    {
        "Text": "Both can refer to Madchen or Zeitung because grammatical gender agreement in German can be overruled by natural gender agreement in certain cases.",
        "Entity": "Normal"
    },
    {
        "Text": "(1) [Das Mddehenji hest [die The girl+NEUT reads the Zeitungli; danach geht newspaper+FEM; afterwards goes sie mit ihTi fins she+FEM with her+FEM in the Bitralk.",
        "Entity": "Normal"
    },
    {
        "Text": "office.",
        "Entity": "Normal"
    },
    {
        "Text": "&apos;The girl reads the newspaper; afterwards she goes to the office with it.&apos;11 would like to thank Hermann Helbig, Rainer Osswald, and the anonymous reviewers for their helpful com ments and suggestions.",
        "Entity": "Normal"
    },
    {
        "Text": "The task in this paper is similar to theMUC coreference task (Hirschman and Chin chor, 1997)2:   only identity coreference is treated (and not part-whole or other complex semantic relationships);   only noun phrases (NPs) are considered asmarkables for coreference (and not situa tions expressed by clauses etc.",
        "Entity": "Normal"
    },
    {
        "Text": ").This kind of coreference is an equivalence rela tion so that coreference resolution comes down to finding the correct partition3 of markables.",
        "Entity": "Normal"
    },
    {
        "Text": "If there exists a genuine ambiguity for humanreaders (and not just a spurious one for com puters), several partitions of markables wouldbe the correct answer to the coreference prob lem.",
        "Entity": "Normal"
    },
    {
        "Text": "But since such ambiguities are rare the disambiguation method described in this paper always delivers only one partition.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, the full MUC coreference taskis tackled with a new hybrid approach combin ing syntactico-semantic rules with rule statisticsderived from an annotated corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Two ques tion might arise.",
        "Entity": "Normal"
    },
    {
        "Text": "Why not a purely statisticalapproach: first, because why throw away tradi tional linguistic knowledge, and second, becausestatistics on rules reduce the sparse data prob lem since the applicability of one rule classifies combinations of many relevant features into onefeature value.",
        "Entity": "Normal"
    },
    {
        "Text": "Why not a purely rule-based approach: because it would leave too many alter natives and would not indicate which to choose.",
        "Entity": "Normal"
    },
    {
        "Text": "2Some problems of this task definition are discussed by van Deemter and Kibble (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "3A partition of a set S is a set of pairwise disjoint subsets of S (the partition elements) that cover S.\n\t\n\t\n\t\t\tTwo kinds of data are required for the corefer ence resolution method described in section 3:handcrafted rules defining whether two mark ables can corefer or not and a corpus annotated with coreference information.",
        "Entity": "Normal"
    },
    {
        "Text": "The rules licensepossible coreferences; the corpus is used for scoring alternative coreference partitions with esti mated probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 Coreference rules.",
        "Entity": "Normal"
    },
    {
        "Text": "The coreference rules are designed to licensepossible coreference relations among two mark ables.",
        "Entity": "Normal"
    },
    {
        "Text": "Some rules are language-dependent, some are universal; in this paper, the rules (and the corpus) are for German, but the approach suits other languages as well.",
        "Entity": "Normal"
    },
    {
        "Text": "Each rule consists of a unique name, a premise, and a conclusion.",
        "Entity": "Normal"
    },
    {
        "Text": "For development and maintenance reasons, arule is accompanied by a description, some pos itive example texts, and some negative example texts.",
        "Entity": "Normal"
    },
    {
        "Text": "A positive example shows that the rule premise is satisfied and the conclusion that the two markables at hand are coreferential would be correct, whereas a negative example shows that the rule premise is not satisfied and theconclusion would indeed be incorrect for the ex ample.",
        "Entity": "Normal"
    },
    {
        "Text": "The rule premise is a conjunction of (possibly negated) constraints; these can be constituent constraints (c-constraints) referring to featurevalues of one markable and interconstituent con straints (ic-constraints) referring to feature values of both markables that are to be tested for coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Both types of constraints can be attribute-value equations.",
        "Entity": "Normal"
    },
    {
        "Text": "The features used in coreference rules are listed in        ; the feature values for markables stem from a parser using a semantically oriented lexicon currently containing 14000 German lexemes (HaGenLex).A feature value can be a single type or a disjunc tion of types.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, one can constructconstraints with predicates.",
        "Entity": "Normal"
    },
    {
        "Text": "The most important predicates are given in        : they realize concepts from Dependency Grammar (de pend/2) and Government and Binding Theory (c-command/2) or define simple relationshipsbetween constituents (e. g. compatible-gend-n gend/2).The conclusion of a rule expresses a corefer ence relation with a semantic network (basedon the MultiNet formalism defined by Hel big (2001) which has been applied in several other projects, see (Hartrumpf, 1999; Knoll etal., 1998)).",
        "Entity": "Normal"
    },
    {
        "Text": "For identity coreference, a rela tion named EQU (equivalence) leading from the anaphor (called c2 in rules)4 to the antecedent (called c1 in rules) suffices.Seven rules from the eighteen rules cur rently used are given in         .",
        "Entity": "Normal"
    },
    {
        "Text": "The rule ident.gend_conflict would license a link between das Mddchen and sic in sentence (1).",
        "Entity": "Normal"
    },
    {
        "Text": "The premise and conclusion can also be viewed as one attribute value matrix employing structure sharing for expressing ic-constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 Annotated corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "A corpus (a collection of German newspaper articles from the Sitddeutsche Zeitung) is anno tated for coreference according to the guidelinesfor the MUC coreference task adapted from En glish to German.",
        "Entity": "Normal"
    },
    {
        "Text": "The annotations are inserted as SGML tags into the corpus, which is already marked up according to the Corpus Encoding Standard (Ide et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "The annotation for sentence (1) is given as (2): (2) (s) (coref id=&amp;quot; 125t129&amp;quot; Kw) Das ( / w) (w)Madchen( /w) ( /coref) Kw) liest (/w) (coref id=&amp;quot; 143t147&amp;quot; Kw) die ( /w) (w)Zeitung( /w) ( / coref) Kw); (/w) (w)danachK/w) (w)gehtK/w) (coref ref=&amp;quot; 125t129&amp;quot; type=&amp;quot; ident&amp;quot; Kw) sie( /w) ( /coref) (w)mit ( /w) (coref ref=&amp;quot; 143t147&amp;quot; type=&amp;quot; ident&amp;quot; Kw) ihr ( /w) ( /coref) (w)insK/w) (w)BilroK/w) (w).K/w)(/s)\n\t\n\t\n\t\t\t3.1 Algorithm overview.",
        "Entity": "Normal"
    },
    {
        "Text": "To resolve coreference ambiguities, one must find the partition of markables that corresponds to the correct coreference equivalence relation.",
        "Entity": "Normal"
    },
    {
        "Text": "The search space is huge since the number of different partitions for n markables is equal to the Bell number B(n).",
        "Entity": "Normal"
    },
    {
        "Text": "These numbers are also called Exponential numbers, see (Bell, 1934); some example values are: B(1) = 1, B(2) = 2, B(3) = 5, B(4) = 15, B(5) = 52, B(10) = 4R.ules for cataphora are also among the coreference rules.",
        "Entity": "Normal"
    },
    {
        "Text": "In such rules, cl corresponds to the cataphor and c2 to the postcedent.",
        "Entity": "Normal"
    },
    {
        "Text": "feature name use* descriptionCAT syntactic category en (noun), perspro (personal pronoun), possdet (pos sessive determiner), reflpro (reflexive pronoun), etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "ENTITY ic semantic classification comprising the semantic sort (feature SORT) andsemantic Boolean features (currently 16, all defined for the MultiNet (mul tilayered extended semantic network) formalism by Helbig (2001)) ETYPE ic extension type (0 (an individual), 1 (a set), 2 (a set of sets), etc.",
        "Entity": "Normal"
    },
    {
        "Text": "), part of the complex feature LAY containing other extensional and intensional layer features like CARD (cardinality) GEND ic gender (syntactic; masculine, feminine, and neuter in German) NUM c, ic number (syntactic; singular and plural in German) PERS c, ic person (only tested jointly with the other agreement features GEND and NUM) PROPER proper noun (Boolean feature) REFER c, ic reference type (determinate, indeterminate; based on article choice) SENTENCE-ID ic sentence number in text SORT semantic sort (45 hierarchically ordered values, 15 of them for nominal concepts) *c means: feature is used in c-constraints; ic means: feature is used in ic-constraints.",
        "Entity": "Normal"
    },
    {
        "Text": ": Features in coreference rules predicate name/arity description =/2 c-command/2 compatible-gend-n-gend/2 The values are unifiable.",
        "Entity": "Normal"
    },
    {
        "Text": "The first argument (a constituent) c-commands the second.The grammatical gender value at the first argument position is compatible with the natural gender value at the second argument posi tion.",
        "Entity": "Normal"
    },
    {
        "Text": "The first argument (a possessive determiner) can refer to the second argument (a constituent).",
        "Entity": "Normal"
    },
    {
        "Text": "The arguments (two constituents) are related by a copula.",
        "Entity": "Normal"
    },
    {
        "Text": "The first argument (a constituent) depends on the second.",
        "Entity": "Normal"
    },
    {
        "Text": "Numerical difference between two feature values is greater than a third value.",
        "Entity": "Normal"
    },
    {
        "Text": "Two constituents containing (possibly complex) names match.",
        "Entity": "Normal"
    },
    {
        "Text": "The argument (a feature value) is maximal, i. e., a leaf node in the type hierarchy.",
        "Entity": "Normal"
    },
    {
        "Text": "One argument (a constituent) is a compound suffix of the other argument (a constituent) or both arguments have the same nominal head.",
        "Entity": "Normal"
    },
    {
        "Text": "compatible-possdet/2 copula-related/2 depend/2 difference&gt;/3 matching-names/2 maximal/1 similar-nouns/2        : Predicates in coreference rules 115975, B(15) 1.38x 109, B(20) 5.17x 1013, B(25) 4.64 x 1018.The evaluated algorithm for coreference resolution is implemented as the COR,UDIS sys tem (COreference R,Ules with Disambiguation Statistics) and works as follows: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "The markables in a given text are iden-.",
        "Entity": "Normal"
    },
    {
        "Text": "tified.",
        "Entity": "Normal"
    },
    {
        "Text": "For this task and for gaining thesyntactico-semantic feature values to be ac cessed by rules in step 2, each sentence inthe text is parsed independently.",
        "Entity": "Normal"
    },
    {
        "Text": "If a sentence parse fails, a chunk parse is gener desc.",
        "Entity": "Normal"
    },
    {
        "Text": "exam.",
        "Entity": "Normal"
    },
    {
        "Text": "id ident.n_perspro pre.",
        "Entity": "Normal"
    },
    {
        "Text": "(el CAT) n (e2 cm) perspro (= (el Num) (e2 NUM)) (= (C1 PERS) (C2 PERS)) (= (C1 GEND) (C2 GEND)) (= (C1 ENTITY) (C2 ENTITY)) (not (c-command el e2)) (not (c-command (2 el)) desc.",
        "Entity": "Normal"
    },
    {
        "Text": "same gender - anaphoric exam.",
        "Entity": "Normal"
    },
    {
        "Text": "Per Mann liest [das Buch]i lir versteht [es] nicht.",
        "Entity": "Normal"
    },
    {
        "Text": "id ident.perspro_n pre.",
        "Entity": "Normal"
    },
    {
        "Text": "(Ci CAT) perspro (e2 eAT) n (= (el Num) (e2 NUM)) (= (C1 PERS) (C2 PERS)) (= (C1 GEND) (C2 GEND)) (= (C1 ENTITY) (C2 ENTITY)) (not (c-command cl c2)) (not (c-command c2 Ci)) (difference&gt; (C1 SENTENCETD) (C2 SENTENCE-ID) 0) desc.",
        "Entity": "Normal"
    },
    {
        "Text": "personal pronoun - cataphoric exam.",
        "Entity": "Normal"
    },
    {
        "Text": "[Sie]i will die Welt andern; und Mie Wissenschaftlerin]i macht sich frisch ans Werk.",
        "Entity": "Normal"
    },
    {
        "Text": "id ident.perspro_perspro pre.",
        "Entity": "Normal"
    },
    {
        "Text": "(Ci CAT) perspro (C2 CAT) perspro (= (el Num) (e2 NUM)) (= (Cl PERS) (C2 PERS)) (= (C1 GEND) (C2 GEND)) (= (C1 ENTITY) (C2 ENTITY)) (not (c-command cl c2)) (not (c-command c2 Ci)) desc.",
        "Entity": "Normal"
    },
    {
        "Text": "same gender - anaphoric exam.",
        "Entity": "Normal"
    },
    {
        "Text": "[Sie]i schreiben viel.",
        "Entity": "Normal"
    },
    {
        "Text": "Und [sie] lesen viel.",
        "Entity": "Normal"
    },
    {
        "Text": "id ident.gend_conflict pre.",
        "Entity": "Normal"
    },
    {
        "Text": "(Ci CAT) n (c2 CAT) perspro (= (el Num) (e2 NUM)) (= (C1 PERS) (C2 PERS)) (not (= (C1 GEND) (C2 GEND))) (compatible-gencl-n-gencl (C2 GEND) (C1 N-GEND)) (not (c-command cl c2)) (not (c-command c2 Ci)) desc.",
        "Entity": "Normal"
    },
    {
        "Text": "A personal pronoun refers to an NY with a nominal head and conflicting grammatical gender.",
        "Entity": "Normal"
    },
    {
        "Text": "exam.",
        "Entity": "Normal"
    },
    {
        "Text": "[Das Madchen]i lacht.",
        "Entity": "Normal"
    },
    {
        "Text": "[Sie]i war stets so.",
        "Entity": "Normal"
    },
    {
        "Text": "ident.nuna_conflict (el CAT) n (Cl PROPER) noproper (C2 CAT) n (e2 PROPER) noproper (not (= (el Nem) (e2 Nem))) (= (C1 =TYE) (C2 ETYPE)) (= (C1 ENTITY) (C2 ENTITY)) (not (c-command el e2)) (not (c-command C2 el))different number values (one aggregate and one nonaggre gate but equal etype values) Per Vorstand]i entschied riber die Entlassungen.",
        "Entity": "Normal"
    },
    {
        "Text": "[these Manner ]i hatten keine Skrupel.",
        "Entity": "Normal"
    },
    {
        "Text": "ident.sinailar_sem (Ci CAT) n (Ci soul]) co (c2 CAT) n (c2 Ithrhit) det (e2 PROPER) noproper (= (el Num) (e2 Nutt)) (similar-nouns cl c2) (difference&gt; (C1 SENTENCE-ID) (C2 SENTENCE-ID) 0)two semantically similar NPs.",
        "Entity": "Normal"
    },
    {
        "Text": "Cases contained in similar nouns: compound and base noun; synonyms.",
        "Entity": "Normal"
    },
    {
        "Text": "Mer Buchautor]i ...\n\t\t\t[der Autor]i Mie Grol3stadte]i Mie Stadte]i [Krankenhaus]i [Klinik]i ident.compatible_sem (Ci CAT) n (Ci soul]) co (C1 PROPER) noproper (e2 CAT) n (e2 Ithrhit) det (e2 PROPER) noproper (= (el NUM) (C2 NUM)) (= (C1 =TYE) (C2 ETYPE)) (= (C1 ENTITY) (C2 ENTITY)) (not (similar-nouns cl c2)) (maximal (C1 ENTITY)) (maximal (c2 ENTITY)) (difference&gt; (C1 SENTENCE-ID) (C2 SENTENCE-ID) 0) two semantically compatible NPs.",
        "Entity": "Normal"
    },
    {
        "Text": "Mie Tater] Mie Manner] i [einer hollandischen Fanailie]i [die entfiihrte Deutsche]j id pre.",
        "Entity": "Normal"
    },
    {
        "Text": "desc.",
        "Entity": "Normal"
    },
    {
        "Text": "exam.",
        "Entity": "Normal"
    },
    {
        "Text": "id pre.",
        "Entity": "Normal"
    },
    {
        "Text": "desc.",
        "Entity": "Normal"
    },
    {
        "Text": "exam.",
        "Entity": "Normal"
    },
    {
        "Text": "id pre.",
        "Entity": "Normal"
    },
    {
        "Text": ": Example coreference rules ated.",
        "Entity": "Normal"
    },
    {
        "Text": "(In such cases, constraints in rule premises that involve predicates requiring full parses (e. g. c-command) are ignored instep 2.)",
        "Entity": "Normal"
    },
    {
        "Text": "For details on the parser, see (Hel big and Hartrumpf, 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "All possible coreference rule activations.",
        "Entity": "Normal"
    },
    {
        "Text": "that link an anaphor to an antecedent candidate are collected.",
        "Entity": "Normal"
    },
    {
        "Text": "This is done by test ing rule premises on all markable pairs (constituent c1 must precede constituent c2).",
        "Entity": "Normal"
    },
    {
        "Text": "For two markables, one rule (at most) is activated since the rules have disjoint premises for real text purposes.",
        "Entity": "Normal"
    },
    {
        "Text": "3.",
        "Entity": "Normal"
    },
    {
        "Text": "For each anaphor, one antecedent candi-.",
        "Entity": "Normal"
    },
    {
        "Text": "date is selected.",
        "Entity": "Normal"
    },
    {
        "Text": "This decision is based on rule statistics gained from the annotatedtraining corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The sparse data prob lem is alleviated by backed-off estimation (see for example (Katz, 1987; Collins and Brooks, 1995)).The algorithm deals with three sets of ob jects: first, the possible anaphors (all identified markables); second, the candidate antecedentsfor each possible anaphor (all preceding markables and the artificial nonreferable mark able explained below); third, the coreference rules.",
        "Entity": "Normal"
    },
    {
        "Text": "The nonreferable markable is used asthe artificial anaphor of a nonreferring markable in order to represent all alternative references for a possible anaphor as a pair.",
        "Entity": "Normal"
    },
    {
        "Text": "For first mentions, the disambiguation algorithm shouldselect a coreference with the nonreferable mark able as antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "Currently, one rule licenses the nonreferable markable as antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "But it might be useful to apply more finely grained rules and not just one rough licensing rule, asindicated by promising research results for definite descriptions referring to discourse-new en tities (see (Vieira and Poesio, 2000)).",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Disambiguating between.",
        "Entity": "Normal"
    },
    {
        "Text": "antecedent candidates Step 3 of the algorithm given in section 3.1 isthe most interesting one and needs some expla nation.",
        "Entity": "Normal"
    },
    {
        "Text": "Leaving the issue of search algorithms aside for a moment, all possible and licensed partitions of identified markables are generated,filtered, and finally scored using estimated prob abilities.",
        "Entity": "Normal"
    },
    {
        "Text": "The partitions are generated incrementallystarting with the first possible anaphor in a sin gleton partition element.",
        "Entity": "Normal"
    },
    {
        "Text": "For each antecedent candidate licensed by a coreference rule instep 2, an extended partition with this an tecedent in the same partition element as the anaphor in question is introduced.",
        "Entity": "Normal"
    },
    {
        "Text": "This process is iterated until all possible anaphors have been investigated.",
        "Entity": "Normal"
    },
    {
        "Text": "Partitions are filtered out if they violate one of the following distance and compatibility constraints: sentence distance The distance between the anaphor and the antecedent measured in sentences must be below the limit for the linking coreference rule.",
        "Entity": "Normal"
    },
    {
        "Text": "These limits have been learned from the training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "paragraph distance The distance betweenthe linked markables measured in para graphs must be below the limit learned for the licensing coreference rule.",
        "Entity": "Normal"
    },
    {
        "Text": "Typically, pronominal anaphoras can span only two paragraphs, while for example coreferences between named entities can span arbitrary distances.",
        "Entity": "Normal"
    },
    {
        "Text": "semantic compatibility All markables in apartition element must bear compatible se mantics (unifiable ENTITY and LAY feature values, see        ).Because of the huge search space (see sec tion 3.1), the generation of partitions and thefiltering is intertwined in a heuristic search al gorithm so that impossible alternatives in thesearch tree are pruned early.",
        "Entity": "Normal"
    },
    {
        "Text": "Also the scor ing described below is done during the search so that alternatives with low (bad) scores can be delayed and possibly discarded early by the search algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The score for a partition is constructed as the sum of estimated probabilities for addingthe possible anaphor in currently under inves tigation to one of the antecedent candidates C = Kei, e2, , ek).",
        "Entity": "Normal"
    },
    {
        "Text": "The candidates are orderedby distance; each ci is a feature structure rep resenting the parse result from algorithm step 1for the corresponding markable.",
        "Entity": "Normal"
    },
    {
        "Text": "Each coreference between in and ci is licensed by a coreference rule ri so that this coreference alterna tive can be represented as the triple (m, In order to generalize from the token-based representation (rn, ci,ri) and to make usefulstatistics from an annotated corpus, an ab straction function a is applied that abstracts from the given anaphor, antecedent candidate, and linking coreference rule to a type-based representation.",
        "Entity": "Normal"
    },
    {
        "Text": "The abstraction function inequation (3) turned out to be a good compro mise between limited sparseness of statistical matrices and distinctiveness for disambiguation purposes: It reduces a coreference alternative (m, ci,ri) to the candidate antecedent position i and the licensing coreference rule a(m, ci, ri) := (i,ri) (3) Let ai be the abstracted coreference alternative a(m, c, ri) and A be the list(al, a2, , ak) of abstracted coreference alter natives for the possible anaphor in.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, the probability that ai corresponds to the closestcorrect antecedent for in is estimated as the rel ative frequency rf (i, A): rf (i, A) := kf (i, A) (4) f (1, A) 1=1 The          uses the statistical values f (i, A), which count how many times in the annotatedtraining corpus the abstracted coreference alter native ai wins as the one with the closest correctantecedent in the context of abstracted corefer ence alternatives A.",
        "Entity": "Normal"
    },
    {
        "Text": "Further experiments have shown that looking at more than 5 antecedent candidates does not improve disambiguation results.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, k is reduced to 5 if necessary.",
        "Entity": "Normal"
    },
    {
        "Text": "Backed-off estimation can alleviate sparse data problems.",
        "Entity": "Normal"
    },
    {
        "Text": "The basic idea is that if for a context A no statistical values are known, they are estimated by looking at increasingly smaller parts of A until statistical values are found.",
        "Entity": "Normal"
    },
    {
        "Text": "Onemight call such a backed-off estimation backed off estimation over alternatives.",
        "Entity": "Normal"
    },
    {
        "Text": "Backed-off estimation as defined by equations (5) to (7) is applied in the coreference resolution method when all counts f (i, A) are zero and f3 (i, A) is calculated for j = 1.",
        "Entity": "Normal"
    },
    {
        "Text": "The parameter j is increased by one until one of the f3 (i, A) becomes positive (then, the rP (i, A) are used as scores for the antecedent candidates) or j reaches k   1 (in this case, allcandidates receive equal scores).",
        "Entity": "Normal"
    },
    {
        "Text": "If the backoff process stops at j = b, the relative frequencies rfb(i, A) are used as estimates for the con ditional probabilities P(i1C) that ci is the closest correct antecedent given antecedent candidates C: P(ir) rfb (i, A) (8) One could add other scores to those based on estimated probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "In the literature,syntactic parallelism between anaphor and an tecedent (based on syntactic case), semanticparallelism (based on semantic roles), and max imality of antecedent NPs are proposed among others.",
        "Entity": "Normal"
    },
    {
        "Text": "In several experiments, such additional scores have been applied for certain rules (e. g. rules involving pronouns).",
        "Entity": "Normal"
    },
    {
        "Text": "Small improvements have been achieved, but this topic has not been investigated completely yet.",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation results from 12-fold cross-validation for 502 anaphors5 are listed in        .",
        "Entity": "Normal"
    },
    {
        "Text": "The standard definitions for recall and precision used in information retrieval are as follows: #true positives true positives   #false negatives #true positives (10) true positives   #false positives For coreference resolution, true positives are correct coreference links found, false negatives are correct coreference links not reported, andfalse positives are incorrect coreference links re ported.",
        "Entity": "Normal"
    },
    {
        "Text": "Vilain et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1995) illustrate that thesedefinitions sometimes yield counter-intuitive re sults for coreference evaluations and proposemodel-theoretic definitions of recall and preci sion.",
        "Entity": "Normal"
    },
    {
        "Text": "The values in         are calculated with these modified definitions.",
        "Entity": "Normal"
    },
    {
        "Text": "There are three different evaluation results.",
        "Entity": "Normal"
    },
    {
        "Text": "The first is the full coreference task.",
        "Entity": "Normal"
    },
    {
        "Text": "The secondone could be called markable-relative evalu ation since the numbers are calculated only forthe markables that have been successfully iden tified (in some sense, this concentrates on the coreference relation aspect of the coreference task).",
        "Entity": "Normal"
    },
    {
        "Text": "And the final evaluation result comesfrom a baseline model: &amp;quot;always select the clos est antecedent candidate that is licensed by a rule and fulfills the distance and compatibility constraints from section 3.2&amp;quot;.",
        "Entity": "Normal"
    },
    {
        "Text": "There are many recent approaches to this prob lem, e. g. syntax-based approaches (Lappin and Leass, 1994), cooccurrence-based approaches(Dagan and Itai, 1990), machine-learning approaches (Connolly et al., 1994; Aone and Ben nett, 1996; Soon et al., 1999), uncertainty reasoning approaches (Mitkov, 1995; Mitkov, 1997), and robust knowledge-poor approaches (Kennedy and Boguarev, 1996; Baldwin, 1997; 5The number of markables that are coreferential with some other markable ranges from 28 to 63 for the foldsbecause the texts in the evaluation corpus were not bro ken up for cross-validation in order to yield statistical data about whole texts.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore the training corpussize varied between 439 and 474 and the test corpus be tween 28 and 63 during the cross-validation.",
        "Entity": "Normal"
    },
    {
        "Text": "fo(i, A) f (i, A) f3(i, A) := fi-&apos; ajeA/CA,011=k j for 1 &lt; j &lt; k   1 rf (i, A) := P (i, A) 1=i for 0 &lt;j&lt;k-1 := P := (9) method evaluation results in percentage coreference (incl.",
        "Entity": "Normal"
    },
    {
        "Text": "markable identification) markable-relative coreference evaluation baseline: always closest candidate recall precision F-measure 55 82 66 76 82 79 46 42 44 F-measure is calculated with equal weight to recall r and precision p as 2r         : Coreference resolution results r p   Mitkov, 1998b; Mitkov, 1999).6 The following two systems tackle the MUC coreference task and bear some similarities to COR,UDIS.",
        "Entity": "Normal"
    },
    {
        "Text": "The system described by Cardie and Wagstaff (1999) resembles the presented system in that it views coreference resolution in a text as partitioning (or clustering).",
        "Entity": "Normal"
    },
    {
        "Text": "The difference in terms of clustering is that the first system usesgreedy clustering while COR,UDIS optimizes us ing global scores.",
        "Entity": "Normal"
    },
    {
        "Text": "The fundamental difference isthat the first system partitions based on a simi larity function over markable representations as attribute value pairs, while COR,UDIS applies linguistic rules to license possible coreference links and applies corpus statistics to choose one link because typically alternatives exist.The SWIZZLE system (Harabagiu and Maiorano, 2000) applies heuristics and heuristic or dering by bootstrapping to pick one antecedent per anaphor; in the COR,UDIS system, rules license alternatives and one is selected based on a learned statistical model.",
        "Entity": "Normal"
    },
    {
        "Text": "COR,UDIS usessentence parsing, SWIZZLE as an intention ally knowledge-poor approach only approximate phrasal parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "I have presented a disambiguation methodwhich combines traditional linguistically moti vated rules and a backed-off statistical model derived form an annotated corpus in a powerfulway.",
        "Entity": "Normal"
    },
    {
        "Text": "Comparison to other approaches is diffi cult since evaluation results for German are not available for the MUC coreference task.",
        "Entity": "Normal"
    },
    {
        "Text": "But theresults presented seem to be competitive corn 6 The cited works deal only with pronominal.",
        "Entity": "Normal"
    },
    {
        "Text": "anaphors, except the approaches by Aone and Bennett (1996), Baldwin (1997), Connolly et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1994), and Soon et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1999).",
        "Entity": "Normal"
    },
    {
        "Text": "pared to the 60% F-measure results for English in MUC7.",
        "Entity": "Normal"
    },
    {
        "Text": "Additional filtering conditions, additionalscores (preferences), and features from Center ing Theory (Grosz et al., 1995) might improve the results reported in this paper significantly.",
        "Entity": "Normal"
    },
    {
        "Text": "The use of a large lexical-semantic network likeGermaNet would solve some problematic coref erence cases.",
        "Entity": "Normal"
    },
    {
        "Text": "More sophisticated evaluationscentered around different error types as recom mended by Mitkov (1998a) and larger data sets are planned for the future.",
        "Entity": "Normal"
    },
    {
        "Text": "\nSubword-based Tagging by Conditional Random Fields for Chinese Word Segmentation\n\t\n\t\tWe proposed two approaches to improve Chinese word segmentation: a subword-based tagging and a confidence measure approach.",
        "Entity": "Normal"
    },
    {
        "Text": "We found the former achieved better performance than the existing character-based tagging, and the latter improved segmentation further by combining the former with a dictionary-based segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, the latter can be used to balance out-of-vocabulary rates and in-vocabulary rates.",
        "Entity": "Normal"
    },
    {
        "Text": "By these techniques we achieved higher F-scores in CITYU, PKU and MSR corpora than the best results from Sighan Bakeoff 2005.",
        "Entity": "Normal"
    },
    {
        "Text": "The character-based  IOB  tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "Under the scheme, each character of a word is labeled as  B  if it is the first character of a multiple-character word, or  O  if the character functions as an independent word, or  I  otherwise.",
        "Entity": "Normal"
    },
    {
        "Text": "For example,   (whole) (Beijing city)  is labeled as   (whole)/O (north)/B (capital)/I (city)/I .",
        "Entity": "Normal"
    },
    {
        "Text": "We found that so far all the existing implementations were using character-based IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work we propose a subword-based IOB tagging, which assigns tags to a predefined lexicon subset consisting of the most frequent multiple-character words in addition to single Chinese characters.",
        "Entity": "Normal"
    },
    {
        "Text": "If only Chinese characters are used, the subword-based IOB tagging is downgraded into a character-based one.",
        "Entity": "Normal"
    },
    {
        "Text": "Taking the same example mentioned above,   (whole) (Beijing city)  is labeled as   (whole)/O (Beijing)/B (city)/I  in the subword-based tagging, where   (Beijing)/B  is labeled as one unit.",
        "Entity": "Normal"
    },
    {
        "Text": "We will give a detailed description of this approach in Section 2.",
        "Entity": "Normal"
    },
    {
        "Text": "Now the second author is affiliated with NTT.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we found a clear weakness with the IOB tagging approach: It yields a very low in-vocabulary (IV) rate (R-iv) in return for a higher out-of-vocabulary (OOV) rate (R-oov).",
        "Entity": "Normal"
    },
    {
        "Text": "In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.",
        "Entity": "Normal"
    },
    {
        "Text": "While OOV recognition is very important in word segmentation, a higher IV rate is also desired.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work we propose a confidence measure approach to lessen the weakness.",
        "Entity": "Normal"
    },
    {
        "Text": "By this approach we can change R-oovs and R-ivs and find an optimal tradeoff.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach will be described in Section 2.2.",
        "Entity": "Normal"
    },
    {
        "Text": "In the followings, we illustrate our word segmentation process in Section 2, where the subword-based tagging is implemented by the CRFs method.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 3 presents our experimental results.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4 describes current state- of-the-art methods for Chinese word segmentation, with which our results were compared.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 5 provides the concluding remarks.",
        "Entity": "Normal"
    },
    {
        "Text": "Our word segmentation process is illustrated in Fig.",
        "Entity": "Normal"
    },
    {
        "Text": "1.",
        "Entity": "Normal"
    },
    {
        "Text": "It is composed of three parts: a dictionary-based N-gram word segmentation for segmenting IV words, a subword- based tagging by the CRF for recognizing OOVs, and a confidence-dependent word segmentation used for merging the results of both the dictionary-based and the IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "An example exhibiting each step s results is also given in the        \n\t\t\tSince the dictionary-based approach is a well-known method, we skip its technical descriptions.",
        "Entity": "Normal"
    },
    {
        "Text": "However, keep in mind that the dictionary-based approach can produce a higher R-iv rate.",
        "Entity": "Normal"
    },
    {
        "Text": "We will use this advantage in the confidence measure approach.",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 Subword-based IOB tagging using CRFs.",
        "Entity": "Normal"
    },
    {
        "Text": "There are several steps to train a subword-based IOB tag- ger.",
        "Entity": "Normal"
    },
    {
        "Text": "First, we extracted a word list from the training data sorted in decreasing order by their counts in the training 193 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 193 196, New York, June 2006.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2006 Association for Computational Linguistics input          +XDQJ<LQJ&KXQ OLYHV LQ %HLMLQJFLW\\ Dictionary-based word segmentation               +XDQJ <LQJ &KXQ OLYHV LQ %HLMLQJFLW\\ Subword-based IOB tagging  /%  /,  /,  /2  /2   /%  /, +XDQJ/% <LQJ/, &KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\\/, Confidence-based segmentation  /%  /,  /,  /2  /2   /%  /, +XDQJ/% <LQJ/, &KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\\/, output             +XDQJ<LQJ&KXQ OLYHV LQ %HLMLQJFLW\\         : Outline of word segmentation process data.",
        "Entity": "Normal"
    },
    {
        "Text": "We chose all the single characters and the top multi- character words as a lexicon subset for the IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "If the subset consists of Chinese characters only, it is a character-based IOB tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "We regard the words in the subset as the subwords for the IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, we re-segmented the words in the training data into subwords belonging to the subset, and assigned IOB tags to them.",
        "Entity": "Normal"
    },
    {
        "Text": "For a character-based IOB tagger, there is only one possibility of re-segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "However, there are multiple choices for a subword-based IOB tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "For example,   (Beijing-city)  can be segmented as   (Beijing-city)/O,  or   (Beijing)/B (city)/I,  or   (north)/B (capital)/I (city)/I.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work we used forward maximal match (FMM) for disambiguation.",
        "Entity": "Normal"
    },
    {
        "Text": "Of course, backward maximal match (BMM) or other approaches are also applicable.",
        "Entity": "Normal"
    },
    {
        "Text": "We did not conduct comparative experiments because trivial differences of these approaches may not result in significant consequences to the subword-based ap proach.",
        "Entity": "Normal"
    },
    {
        "Text": "In the third step, we used the CRFs approach to train the IOB tagger (Lafferty et al., 2001) on the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "We downloaded and used the package  CRF++  from the site  http://www.chasen.org/ taku/software.",
        "Entity": "Normal"
    },
    {
        "Text": "According to the CRFs, the probability of an IOB tag sequence, T = t0 t1       tM , given the word sequence, W = w0 w1       wM , is defined by p(T |W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti .",
        "Entity": "Normal"
    },
    {
        "Text": "k and  k are the model parameters corresponding to feature functions fk and gk respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "The model parameters were trained by maximizing the log-likelihood of the training data using L-BFGS gradient descent optimization method.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to overcome overfitting, a gaussian prior was imposed in the training.",
        "Entity": "Normal"
    },
    {
        "Text": "The types of unigram features used in our experiments included the following types: w0 , w 1 , w1 , w 2 , w2 , w0 w 1 , w0 w1 , w 1 w1 , w 2 w 1 , w2 w0 where w stands for word.",
        "Entity": "Normal"
    },
    {
        "Text": "The subscripts are position indicators.",
        "Entity": "Normal"
    },
    {
        "Text": "0 means the current word;  1,  2, the first or second word to the left; 1, 2, the first or second word to the right.",
        "Entity": "Normal"
    },
    {
        "Text": "For the bigram features, we only used the previous and the current observations, t 1 t0 .",
        "Entity": "Normal"
    },
    {
        "Text": "As to feature selection, we simply used absolute counts for each feature in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "We defined a cutoff value for each feature type and selected the features with occurrence counts over the cutoff.",
        "Entity": "Normal"
    },
    {
        "Text": "A forward-backward algorithm was used in the training and viterbi algorithm was used in the decoding.",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 Confidence-dependent word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Before moving to this step in         , we produced two segmentation results: the one by the dictionary-based approach and the one by the IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "However, neither was perfect.",
        "Entity": "Normal"
    },
    {
        "Text": "The dictionary-based segmentation produced results with higher R-ivs but lower R-oovs while the IOB tagging yielded the contrary results.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section we introduce a confidence measure approach to combine the two results.",
        "Entity": "Normal"
    },
    {
        "Text": "We define a confidence measure, C M(tiob |w), to measure the confidence of the results produced by the IOB tagging by using the results from the dictionary-based segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "The confidence measure comes from two sources: IOB tagging and dictionary- based word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Its calculation is defined as: C M(tiob |w) =  C Miob (tiob |w) + (1    ) (tw , tiob )ng (2) where tiob is the word w s IOB tag assigned by the IOB tagging; tw , a prior IOB tag determined by the results of the dictionary-based segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "After the dictionary- based word segmentation, the words are re-segmented into subwords by FMM before being fed to IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "Each subword is given a prior IOB tag, tw .",
        "Entity": "Normal"
    },
    {
        "Text": "C Miob (t|w), a   M     confidence probability derived in the process of IOB tag exp  )'  )'  k fk (ti 1 , ti , W ) + )'  k gk (ti , W )   /Z,    i=1    k k       (1) ging, is defined as Z = )' T =t0 t1    tM p(T |W ) C Miob (t|w ) = L,T =t0 t1    tM ,ti =t P(T |W, wi ) T =t 0 t1     tM P ( T | W ) where we call fk (ti 1 , ti , W ) bigram feature functions because the features trigger the previous observation ti 1 where the numerator is a sum of all the observation sequences with word wi labeled as t.  (tw , tiob )ng denotes the contribution of the dictionary- based segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "It is a Kronecker delta function defined as  (tw , tiob )ng = { 1 if tw = tiob 0 otherwise In Eq.",
        "Entity": "Normal"
    },
    {
        "Text": "2,   is a weighting between the IOB tagging and the dictionary-based word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "We found the value 0.7 for  , empirically.",
        "Entity": "Normal"
    },
    {
        "Text": "By Eq.",
        "Entity": "Normal"
    },
    {
        "Text": "2 the results of IOB tagging were reevaluated.",
        "Entity": "Normal"
    },
    {
        "Text": "A confidence measure threshold, t, was defined for making a decision based on the value.",
        "Entity": "Normal"
    },
    {
        "Text": "If the value was lower than t, the IOB tag was rejected and the dictionary-based segmentation was used; otherwise, the IOB tagging segmentation was used.",
        "Entity": "Normal"
    },
    {
        "Text": "A new OOV was thus created.",
        "Entity": "Normal"
    },
    {
        "Text": "For the two extreme cases, t = 0 is the case of the IOB tagging while t = 1 is that of the dictionary-based approach.",
        "Entity": "Normal"
    },
    {
        "Text": "In a real application, a satisfactory tradeoff between R- ivs and R-oovs could find through tuning the confidence threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 3.2 we will present the experimental segmentation results of the confidence measure approach.",
        "Entity": "Normal"
    },
    {
        "Text": "We used the data provided by Sighan Bakeoff 2005 to test our approaches described in the previous sections.",
        "Entity": "Normal"
    },
    {
        "Text": "The data contain four corpora from different sources: Academia Sinica (AS), City University of Hong Kong (CITYU), Peking University (PKU) and Microsoft Research in Beijing (MSR).",
        "Entity": "Normal"
    },
    {
        "Text": "Since this work was to evaluate the proposed subword-based IOB tagging, we carried out the closed test only.",
        "Entity": "Normal"
    },
    {
        "Text": "Five metrics were used to evaluate segmentation results: recall(R), precision(P), F-score(F), OOV rate(R-oov) and IV rate(R-iv).",
        "Entity": "Normal"
    },
    {
        "Text": "For detailed info.",
        "Entity": "Normal"
    },
    {
        "Text": "of the corpora and these scores, refer to (Emerson, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "For the dictionary-based approach, we extracted a word list from the training data as the vocabulary.",
        "Entity": "Normal"
    },
    {
        "Text": "Tri- gram LMs were generated using the SRI LM toolkit for disambiguation.",
        "Entity": "Normal"
    },
    {
        "Text": "shows the performance of the dictionary-based segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Since there were some single-character words present in the test data but not in the training data, the R-oov rates were not zero in this experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, there were no OOV recognition.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, this approach produced lower F-scores.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the R-ivs were very high.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Effects of the Character-based and the.",
        "Entity": "Normal"
    },
    {
        "Text": "subword-based tagger The main difference between the character-based and the word-based is the contents of the lexicon subset used for re-segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "For the character-based tagging, we used all the Chinese characters.",
        "Entity": "Normal"
    },
    {
        "Text": "For the subword-based tagging, we added another 2000 most frequent multiple- character words to the lexicons for tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "The segmentation results of the dictionary-based were re-segmented        : Our segmentation results by the dictionary- based approach for the closed test of Bakeoff 2005, very low R-oov rates due to no OOV recognition applied.",
        "Entity": "Normal"
    },
    {
        "Text": "R P FR oo vR iv A S 0.9 51 0.9 53 0.9 42 0.9 40 0.9 47 0.9 47 0.",
        "Entity": "Normal"
    },
    {
        "Text": "67 8 0.",
        "Entity": "Normal"
    },
    {
        "Text": "64 7 0.9 64 0.9 67 CI TY U 0.9 39 0.9 50 0.9 43 0.9 42 0.9 41 0.9 46 0.",
        "Entity": "Normal"
    },
    {
        "Text": "70 0 0.",
        "Entity": "Normal"
    },
    {
        "Text": "73 6 0.9 58 0.9 67 P K U 0.9 40 0.9 43 0.9 50 0.9 46 0.9 45 0.9 45 0.",
        "Entity": "Normal"
    },
    {
        "Text": "78 3 0.",
        "Entity": "Normal"
    },
    {
        "Text": "75 4 0.9 49 0.9 55 M S R 0.9 57 0.9 65 0.9 60 0.9 63 0.9 59 0.9 64 0.",
        "Entity": "Normal"
    },
    {
        "Text": "71 0 0.",
        "Entity": "Normal"
    },
    {
        "Text": "71 6 0.9 64 0.9 72        : Segmentation results by a pure subword-based IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "The upper numbers are of the character- based and the lower ones, the subword-based.",
        "Entity": "Normal"
    },
    {
        "Text": "using the FMM, and then labeled with  IOB  tags by the CRFs.",
        "Entity": "Normal"
    },
    {
        "Text": "The segmentation results using CRF tagging are shown in        , where the upper numbers of each slot were produced by the character-based approach while the lower numbers were of the subword-based.",
        "Entity": "Normal"
    },
    {
        "Text": "We found that the proposed subword-based approaches were effective in CITYU and MSR corpora, raising the F-scores from 0.941 to 0.946 for CITYU corpus, 0.959 to 0.964 for MSR corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "There were no F-score changes for AS and PKU corpora, but the recall rates were improved.",
        "Entity": "Normal"
    },
    {
        "Text": "Comparing              , we found the CRF-modeled IOB tagging yielded better segmentation than the dictionary- based approach.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the R-iv rates were getting worse in return for higher R-oov rates.",
        "Entity": "Normal"
    },
    {
        "Text": "We will tackle this problem by the confidence measure approach.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Effect of the confidence measure.",
        "Entity": "Normal"
    },
    {
        "Text": "In section 2.2, we proposed a confidence measure approach to reevaluate the results of IOB tagging by combinations of the results of the dictionary-based segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "The effect of the confidence measure is shown in        , where we used   = 0.7 and confidence threshold t = 0.8.",
        "Entity": "Normal"
    },
    {
        "Text": "In each slot, the numbers on the top were of the character-based approach while the numbers on the bottom were the subword-based.",
        "Entity": "Normal"
    },
    {
        "Text": "We found the results in         were better than those in         and        , which prove that using confidence measure approach achieved the best performance over the dictionary-based segmentation and the IOB tagging approach.",
        "Entity": "Normal"
    },
    {
        "Text": "The act of confidence measure made a tradeoff between R-ivs and R- oovs, yielding higher R-oovs than         and higher R R P FR oo vR iv A S 0.9 53 0.9 56 0.9 44 0.9 47 0.9 48 0.9 51 0.",
        "Entity": "Normal"
    },
    {
        "Text": "60 7 0.",
        "Entity": "Normal"
    },
    {
        "Text": "64 9 0.9 69 0.9 69 CI TY U 0.9 43 0.9 52 0.9 48 0.9 49 0.9 46 0.9 51 0.",
        "Entity": "Normal"
    },
    {
        "Text": "68 2 0.",
        "Entity": "Normal"
    },
    {
        "Text": "74 1 0.9 64 0.9 69 P K U 0.9 42 0.9 47 0.9 57 0.9 55 0.9 49 0.9 51 0.",
        "Entity": "Normal"
    },
    {
        "Text": "77 5 0.",
        "Entity": "Normal"
    },
    {
        "Text": "74 8 0.9 52 0.9 59 M S R 0.9 60 0.9 72 0.9 66 0.9 69 0.9 63 0.9 71 0.",
        "Entity": "Normal"
    },
    {
        "Text": "67 4 0.",
        "Entity": "Normal"
    },
    {
        "Text": "71 2 0.9 67 0.9 76        : Effects of combination using the confidence measure.",
        "Entity": "Normal"
    },
    {
        "Text": "The upper numbers and the lower numbers are of the character-based and the subword-based, respectively A S CI T Y U M SR P K U Ba ke off be st 0.",
        "Entity": "Normal"
    },
    {
        "Text": "95 2 0.",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 3 0.",
        "Entity": "Normal"
    },
    {
        "Text": "96 4 0.",
        "Entity": "Normal"
    },
    {
        "Text": "95 0 O u r s 0.",
        "Entity": "Normal"
    },
    {
        "Text": "95 1 0.",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 1 0.",
        "Entity": "Normal"
    },
    {
        "Text": "97 1 0.",
        "Entity": "Normal"
    },
    {
        "Text": "95 1        : Comparison our results with the best ones from Sighan Bakeoff 2005 in terms of F-score ivs than        .",
        "Entity": "Normal"
    },
    {
        "Text": "Even with the use of confidence measure, the word- based IOB tagging still outperformed the character-based IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "It proves the proposed word-based IOB tagging was very effective.",
        "Entity": "Normal"
    },
    {
        "Text": "The IOB tagging approach adopted in this work is not a new idea.",
        "Entity": "Normal"
    },
    {
        "Text": "It was first used in Chinese word segmentation by (Xue and Shen, 2003), where maximum entropy methods were used.",
        "Entity": "Normal"
    },
    {
        "Text": "Later, this approach was implemented by the CRF-based method (Peng and McCallum, 2004), which was proved to achieve better results than the maximum entropy approach because it can solve the label bias problem (Lafferty et al., 2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Our main contribution is to extend the IOB tagging approach from being a character-based to a subword-based.",
        "Entity": "Normal"
    },
    {
        "Text": "We proved the new approach enhanced the word segmentation significantly.",
        "Entity": "Normal"
    },
    {
        "Text": "Our results are listed together with the best results from Bakeoff 2005 in         in terms of F-scores.",
        "Entity": "Normal"
    },
    {
        "Text": "We achieved the highest F-scores in CITYU, PKU and MSR corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "We think our proposed subword- based tagging played an important role for the good results.",
        "Entity": "Normal"
    },
    {
        "Text": "Since it was a closed test, some information such as Arabic and Chinese number and alphabetical letters cannot be used.",
        "Entity": "Normal"
    },
    {
        "Text": "We could yield a better results than those shown in         using such information.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, inconsistent errors of foreign names can be fixed if alphabetical characters are known.",
        "Entity": "Normal"
    },
    {
        "Text": "For AS corpus,  Adam Smith  are two words in the training but become a one- word in the test,  AdamSmith .",
        "Entity": "Normal"
    },
    {
        "Text": "Our approaches produced wrong segmentations for labeling inconsistency.",
        "Entity": "Normal"
    },
    {
        "Text": "Another advantage of the word-based IOB tagging over the character-based is its speed.",
        "Entity": "Normal"
    },
    {
        "Text": "The subword-based approach is faster because fewer words than characters were labeled.",
        "Entity": "Normal"
    },
    {
        "Text": "We found a speed up both in training and test.",
        "Entity": "Normal"
    },
    {
        "Text": "The idea of using the confidence measure has appeared in (Peng and McCallum, 2004), where it was used to recognize the OOVs.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work we used it more delicately.",
        "Entity": "Normal"
    },
    {
        "Text": "By way of the confidence measure we combined results from the dictionary-based and the IOB-tagging-based and as a result, we could achieve the optimal performance.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work, we proposed a subword-based IOB tagging method for Chinese word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Using the CRFs approaches, we prove that it outperformed the character- based method using the CRF approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "We also successfully employed the confidence measure to make a confidence-dependent word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach is effective for performing desired segmentation based on users  requirements to R-oov and R-iv.",
        "Entity": "Normal"
    },
    {
        "Text": "The authors appreciate the reviewers  effort and good advice for improving the paper.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tArabic presents an interesting challenge to natural language processing, being a highly inflected and agglutinative language.",
        "Entity": "Normal"
    },
    {
        "Text": "In particular, this paper presents an in-depth investigation of the entity detection and recognition (EDR) task for Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "We start by highlighting why segmentation is a necessary prerequisite for EDR, continue by presenting a finite-state statistical segmenter, and then examine how the resulting segments can be better included into a mention detection system and an entity recognition system; both systems are statistical, build around the maximum entropy principle.",
        "Entity": "Normal"
    },
    {
        "Text": "Experiments on a clearly stated partition of the ACE 2004 data show that stem-based features can significantly improve the performance of the EDT system by 2 absolute F-measure points.",
        "Entity": "Normal"
    },
    {
        "Text": "The system presented here had a competitive performance in the ACE 2004 evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "Information extraction is a crucial step toward understanding and processing language.",
        "Entity": "Normal"
    },
    {
        "Text": "One goal of information extraction tasks is to identify important conceptual information in a discourse.",
        "Entity": "Normal"
    },
    {
        "Text": "These tasks have applications in summarization, information retrieval (one can get all hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the fo cus of several recent investigations (Bikel et al., 1997; Miller et al., 1998; Borthwick, 1999; Mikheev et al., 1999; Soon et al., 2001; Ng and Cardie, 2002; Florian et al., 2004), and have been at the center of evaluations such as: MUC6, MUC7, and the CoNLL 02 and CoNLL 03 shared tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "John Mayor), nominal (the president) or pronominal (she, it).",
        "Entity": "Normal"
    },
    {
        "Text": "An entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, in the sentence President John Smith said he has no comments there are two mentions (named and pronomial) but only one entity, formed by the set {John Smith, he}.",
        "Entity": "Normal"
    },
    {
        "Text": "We separate the EDR task into two parts: a mention detection step, which identifies and classifies all the mentions in a text   and a coreference resolution step, which combinines the detected mentions into groups that refer to the same object.",
        "Entity": "Normal"
    },
    {
        "Text": "In its entirety, the EDR task is arguably harder than traditional named entity recognition, because of the additional complexity involved in extracting non-named mentions (nominal and pronominal) and the requirement of grouping mentions into entities.",
        "Entity": "Normal"
    },
    {
        "Text": "This is particularly true for Arabic where nominals and pronouns are also attached to the word they modify.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, most Arabic words are morphologically derived from a list of base forms or stems, to which prefixes and suffixes can be attached to form Arabic surface forms (blank-delimited words).",
        "Entity": "Normal"
    },
    {
        "Text": "In addition to the different forms of the Arabic word that result from the 63 Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 63 70, Ann Arbor, June 2005.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2005 Association for Computational Linguistics derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.",
        "Entity": "Normal"
    },
    {
        "Text": "It is these orthographic variations and complex morphological structure that make Arabic language processing challenging (Xu et al., 2001; Xu et al., 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in (Florian et al., 2004) and the coreference resolution system is similar to the one described in (Luo et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "Both systems are built around from the maximum-entropy technique (Berger et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "We formulate the mention detection task as a sequence classification problem.",
        "Entity": "Normal"
    },
    {
        "Text": "While this approach is language independent, it must be modified to accomodate the particulars of the Arabic language.",
        "Entity": "Normal"
    },
    {
        "Text": "The Arabic words may be composed of zero or more prefixes, followed by a stem and zero or more suffixes.",
        "Entity": "Normal"
    },
    {
        "Text": "We begin with a segmentation of the written text before starting the classification.",
        "Entity": "Normal"
    },
    {
        "Text": "form Arabic words.",
        "Entity": "Normal"
    },
    {
        "Text": "The Arabic alphabet consists of 28 letters that can be extended to ninety by additional shapes, marks, and vowels (Tayli and AlSalamah, 1990).",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike Latin-based alphabets, the orientation of writing in Arabic is from right to left.",
        "Entity": "Normal"
    },
    {
        "Text": "In written Arabic, short vowels are often omitted.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, because variety in expression is appreciated as part of a good writing style, the synonyms are widespread.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic nouns encode information about gender, number, and grammatical cases.",
        "Entity": "Normal"
    },
    {
        "Text": "There are two genders (masculine and feminine), three numbers (singular, dual, and plural), and three grammatical cases (nominative, genitive, and accusative).",
        "Entity": "Normal"
    },
    {
        "Text": "A noun has a nominative case when it is a subject, accusative case when it is the object of a verb, and genitive case when it is the object of a preposition.",
        "Entity": "Normal"
    },
    {
        "Text": "The form of an Arabic noun is consequently determined by its gender, number, and grammatical case.",
        "Entity": "Normal"
    },
    {
        "Text": "The definitive nouns are formed by attaching the Arabic article J to the immediate front of the This segmentation process consists of separating the nouns, such as in the word A s'_ '- (the company).normal whitespace delimited words into (hypothe Also, prepositions such as   (by), and J (to) can be sized) prefixes, stems, and suffixes, which become the attached as a prefix as in A s'_ '-l (to the company).subject of analysis (tokens).",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting granular ity of breaking words into prefixes and suffixes allows different mention type labels beyond the stem label A noun may carry a possessive pronoun as a suffix, such as in tt  s'_ '\" (their company).",
        "Entity": "Normal"
    },
    {
        "Text": "For the EDR task, in this previous example, the Arabic blank-delimited (for instance, in the case of nominal and pronominal word tt  s'_ '\" should be split into two tokens: A s'_ '\" and mentions).",
        "Entity": "Normal"
    },
    {
        "Text": "Additionally, because the prefixes and t...",
        "Entity": "Normal"
    },
    {
        "Text": "The first token A s'_ '\" is a mention that refers tosuffixes are quite frequent, directly processing unseg mented words results in significant data sparseness.",
        "Entity": "Normal"
    },
    {
        "Text": "We present in Section 2 the relevant particularities of the Arabic language for natural language processing, especially for the EDR task.",
        "Entity": "Normal"
    },
    {
        "Text": "We then describe the segmentation system we employed for this task in Section 3.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4 briefly describes our mention detection system, explaining the different feature types we use.",
        "Entity": "Normal"
    },
    {
        "Text": "We focus in particular on the stem n-gram, prefix n-gram, and suffix n-gram features that are an organization, whereas the second token t..\n\t\t\tis also a mention, but one that may refer to a person.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, the prepositions (i.e.,   and J) not be considered a part of the mention.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic has two kinds of plurals: broken plurals and sound plurals (Wightwick and Gaafar, 1998; Chen and Gey, 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "The formation of broken plurals is common, more complex and often irregular.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, the plural form of the noun J< _ (man) is J <_ (men), which is formed by inserting the infix s' (book) is __ s' specific to a morphologically rich language such as .",
        "Entity": "Normal"
    },
    {
        "Text": "The plural form of the noun   Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "We describe in Section 5 our coreferenceresolution system where we also describe the advan (books), which is formed by deleting the infix .",
        "Entity": "Normal"
    },
    {
        "Text": "Theplural form and the sing ,ular form may also be com tage of using stem based features.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 6 shows pletely different (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "_., for woman, but   - \" for and discusses the different experimental results and Section 7 concludes the paper.",
        "Entity": "Normal"
    },
    {
        "Text": "women).",
        "Entity": "Normal"
    },
    {
        "Text": "The sound plurals are formed by adding plural suffixes to singular nouns (e.g., __' > , meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,   '> , ), 0 _ for masculine Extraction difficult?",
        "Entity": "Normal"
    },
    {
        "Text": "nouns in the nominative case (e.g., 0 _' > , ), and u , The Arabic language, which is the mother tongue of for masculine nouns in the genitive and accusative cases (e.g., u ' ' > , ).",
        "Entity": "Normal"
    },
    {
        "Text": "The dual suffix is 0 for the nom more than 300 million people (Center, 2000), present inative case ' > (e.g., 0 , ), and u, for the genitive orsignificant challenges to many natural language pro cessing applications.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic is a highly inflected and accusative (e.g., u ' ' > , ).",
        "Entity": "Normal"
    },
    {
        "Text": "derived language.",
        "Entity": "Normal"
    },
    {
        "Text": "In Arabic morphology, most morphemes are comprised of a basic word form (the root or stem), to which many affixes can be attached toBecause we consider pronouns and nominals as men tions, it is essential to segment Arabic words into these subword tokens.",
        "Entity": "Normal"
    },
    {
        "Text": "We also believe that the in formation denoted by these affixes can help with the coreference resolution task1.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic verbs have perfect and imperfect tenses (Abbou and McCarus, 1983).",
        "Entity": "Normal"
    },
    {
        "Text": "Perfect tense denotes completed actions, while imperfect denotes ongoing actions.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic verbs in the perfect tense consist of a stem followed by a subject marker, denoted as a suf fix.",
        "Entity": "Normal"
    },
    {
        "Text": "The subject marker indicates the person, gender, known words based upon a character unigram model, although this model is dominated by an empirically chosen unknown word penalty.",
        "Entity": "Normal"
    },
    {
        "Text": "Using 0.5M words from the combined Arabic Treebanks 1V2, 2V2 and 3V1, the dictionary based segmenter achieves a exact word match 97.8% correct segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "and number of the subject.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, the verb J,   (to meet) has a perfect tense __l,   for the thirdperson feminine singular, and _ ,   for the third per /epsilon a/epsilon a/A# epsilon/# b/AB# b/epsilon b/B UNK/epsilon c/C epsilon/epsilon c/BC d/epsilon e/+E epsilon/+ e/+DE l son masculine plural.",
        "Entity": "Normal"
    },
    {
        "Text": "We notice also that a verb with a/epsilon b/A#B# b/epsilon c/epsilon d/BCD d/epsilon e/+D+E a subject marker and a pronoun suffix can be by itself a complete sentence, such us in the word tt l,  : it has a third-person feminine singular subject-marker   (she) and a pronoun suffix t..\n\t\t\t(them).",
        "Entity": "Normal"
    },
    {
        "Text": "It is also a complete sentence meaning  she met them.",
        "Entity": "Normal"
    },
    {
        "Text": "The subject markers are often suffixes, but we may find a subject marker as a combination of a prefix and a suffix as in t+l, A., (she meets them).",
        "Entity": "Normal"
    },
    {
        "Text": "In this example, the EDR system should be able to separate t+l, A.,, to create two mentions (   and t..).",
        "Entity": "Normal"
    },
    {
        "Text": "Because the two mentions belong to different entities, the EDR system should not chain them together.",
        "Entity": "Normal"
    },
    {
        "Text": "An Arabic word can potentially have a large number of variants, and some of the variants can be quite complex.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, consider the word t '> _ (and to her researchers) which contains two prefixes and one suffix ( ..\n\t\t\t+ u''> , + J + _).",
        "Entity": "Normal"
    },
    {
        "Text": "Segmentation Lee et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2003) demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation.",
        "Entity": "Normal"
    },
    {
        "Text": "A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules.",
        "Entity": "Normal"
    },
    {
        "Text": "In our latest implementation of this algorithm, we have recast this segmentation strategy as the composition of three distinct finite state machines.",
        "Entity": "Normal"
    },
    {
        "Text": "The second machine is a dictionary that accepts characters and produces identifiers corresponding to dictionary entries.",
        "Entity": "Normal"
    },
    {
        "Text": "The final machine is a trigram language model, specifically a KneserNey (Chen and Goodman, 1998) based back- off language model.",
        "Entity": "Normal"
    },
    {
        "Text": "Differing from (Lee et al., 2003), we have also introduced an explicit model for un 1 As an example, we do not chain mentions with different gender, number, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "For these models, both arabic characters and spaces, and the inserted prefix and suffix markers appear on the arcs of the finite state machine.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the language model is conditioned to insert prefix and suffix markers based upon the frequency of their appearance in n-gram character contexts that appear in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "The character based model alone achieves a 94.5% exact match segmentation accuracy, considerably less accurate then the dictionary based model.",
        "Entity": "Normal"
    },
    {
        "Text": "However, an analysis of the errors indicated that the character based model is more effective at segmenting words that do not appear in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "We seeked to exploit this ability to generalize to improve the dictionary based model.",
        "Entity": "Normal"
    },
    {
        "Text": "As in (Lee et al., 2003), we used unsupervised training data which is automatically segmented to discover previously unseen stems.",
        "Entity": "Normal"
    },
    {
        "Text": "In our case, the character n-gram model is used to segment a portion of the Arabic Giga- word corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "From this, we create a vocabulary of stems and affixes by requiring that tokens appear more than twice in the supervised training data or more than ten times in the unsupervised, segmented corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting vocabulary, predominately of word stems, is 53K words, or about six times the vocabulary observed in the supervised training data.",
        "Entity": "Normal"
    },
    {
        "Text": "This represents about only 18% of the total number of unique tokens observed in the aggregate training data.",
        "Entity": "Normal"
    },
    {
        "Text": "With the addition of the automatically acquired vocabulary, the segmentation accuracy achieves 98.1% exact match.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Preprocessing of Arabic Treebank Data.",
        "Entity": "Normal"
    },
    {
        "Text": "Because the Arabic treebank and the gigaword corpora are based upon news data, we apply some small amount of regular expression based preprocessing.",
        "Entity": "Normal"
    },
    {
        "Text": "Arabic specific processing include removal ofthe characters tatweel (-), and vowels.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, the fol lowing characters are treated as an equivalence class during all lookups and processing: (1) ...\n\t\t\t, ..., and , _ .",
        "Entity": "Normal"
    },
    {
        "Text": "We define a token and introduce whites-.",
        "Entity": "Normal"
    },
    {
        "Text": "pace boundaries between every span of one or more alphabetic or numeric characters.",
        "Entity": "Normal"
    },
    {
        "Text": "Each punctuation symbol is considered a separate token.",
        "Entity": "Normal"
    },
    {
        "Text": "Character classes, such as punctuation, are defined according to the Unicode Standard (Aliprand et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "The mention detection task we investigate identifies, for each mention, four pieces of information: 1.\n\t\t\tthe mention type: person (PER), organization (ORG), location (LOC), geopolitical entity (GPE), facility (FAC), vehicle (VEH), and weapon (WEA) 2.\n\t\t\tthe mention level (named, nominal, pronominal, or premodifier) 3.\n\t\t\tthe mention class (generic, specific, negatively quantified, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "4.\n\t\t\tthe mention sub-type, which is a sub-category of the mention type (ACE, 2004) (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "OrgGovernmental, FacilityPath, etc.).",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 System Description.",
        "Entity": "Normal"
    },
    {
        "Text": "We formulate the mention detection problem as a classification problem, which takes as input segmented Arabic text.",
        "Entity": "Normal"
    },
    {
        "Text": "We assign to each token in the text a label indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "We use a maximum entropy Markov model (MEMM) classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "The principle of maximum entropy states that when one searches among probability distributions that model the observed data (evidence), the preferred one is the one that maximizes the entropy (a measure of the uncertainty different second-stage classifiers to predict the sub- type, the mention level, and the mention class.",
        "Entity": "Normal"
    },
    {
        "Text": "After the first stage, when the boundary (starting, inside, or outside a mention) has been determined, the other classifiers can use this information to analyze a larger context, capturing the patterns around the entire mentions, rather than words.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, the token sequence that refers to a mention will become a single recognized unit and, consequently, lexical and syntactic features occuring inside or outside of the entire mention span can be used in prediction.",
        "Entity": "Normal"
    },
    {
        "Text": "In the first stage (entity type detection and classification), Arabic blank-delimited words, after segmenting, become a series of tokens representing prefixes, stems, and suffixes (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "section 2).",
        "Entity": "Normal"
    },
    {
        "Text": "We allow any contiguous sequence of tokens can represent a mention.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, prefixes and suffixes can be, and often are, labeled with a different mention type than the stem of the word that contains them as constituents.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Stem n-gram Features.",
        "Entity": "Normal"
    },
    {
        "Text": "We use a large set of features to improve the prediction of mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "This set can be partitioned into 4 categories: lexical, syntactic, gazetteer-based, and those obtained by running other named-entity classifiers (with different tag sets).",
        "Entity": "Normal"
    },
    {
        "Text": "We use features such as the shallow parsing information associated with the tokens in a window of 3 tokens, POS, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not (Florian et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of ti respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "For a token ti , the backward token n-gram feature will contains the previous n   1 tokens in the history (ti n+1 , .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "ti 1 ) and the forward token n-gram feature will contains the next n   1 tokens (ti+1 , .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "ti+n 1 ).",
        "Entity": "Normal"
    },
    {
        "Text": "Because we are segmenting arabic words into multiple tokens, there is some concern that tri- gram contexts will no longer convey as much contextual information.",
        "Entity": "Normal"
    },
    {
        "Text": "Consider the following sentence extracted from the development set:of the model) (Berger et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "One big advan _ l u'\" __ l_A.",
        "Entity": "Normal"
    },
    {
        "Text": "J' ..\n\t\t\t(transla tage of this approach is that it can combine arbitrary and diverse types of information in making a classification decision.",
        "Entity": "Normal"
    },
    {
        "Text": "Our mention detection system predicts the four labels types associated with a mention through a cascade approach.",
        "Entity": "Normal"
    },
    {
        "Text": "It first predicts the boundary and the main entity type for each mention.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, it uses the information regarding the type and boundary in tion  This represents the location for Political Party Office ).",
        "Entity": "Normal"
    },
    {
        "Text": "The  Political Party Office  is tagged as an organization and, as a word-for-word translation, is expressed as  to the Office of the political to the party .",
        "Entity": "Normal"
    },
    {
        "Text": "It is clear in this example that the word _A..\n\t\t\t(location for) contains crucial information in distinguishing between a location and an organization when tagging the token __ .",
        "Entity": "Normal"
    },
    {
        "Text": "(office).",
        "Entity": "Normal"
    },
    {
        "Text": "After segmentation, the sentence becomes: where mk is one mention in entity e, and the basic + __ .",
        "Entity": "Normal"
    },
    {
        "Text": "+ J + J + _A..\n\t\t\t+ J + J'.",
        "Entity": "Normal"
    },
    {
        "Text": "model building block P (L = 1|e, mk , m) is an ex  _> + J + J + u'\"   + J ponential or maximum entropy model (Berger et al., 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "When predicting if the token __ .",
        "Entity": "Normal"
    },
    {
        "Text": "(office) is the For the start model, we use the following approxima beginning of an organization or not, backward and forward token n-gram features contain only J + J (for the) and u'\"   + J (the political).",
        "Entity": "Normal"
    },
    {
        "Text": "This is most likely not enough context, and addressing the tion: PS (S = 1|e1, e2,       , et, m)   1   max PL (L = 1|ei, m) (2) 1 i t problem by increasing the size of the n-gram context quickly leads to a data sparseness problem.",
        "Entity": "Normal"
    },
    {
        "Text": "We propose in this paper the stem n-gram features as additional features to the lexical set.",
        "Entity": "Normal"
    },
    {
        "Text": "If the current token ti is a stem, the backward stem n-gram feature contains the previous n   1 stems and the forward stem n-gram feature will contain the following n   1 stems.",
        "Entity": "Normal"
    },
    {
        "Text": "We proceed similarly for prefixes and suffixes: if ti is a prefix (or suffix, respectively) we take the previous and following prefixes (or suffixes)2.",
        "Entity": "Normal"
    },
    {
        "Text": "In the sentence shown above, when the system is predict ing if the token __ .",
        "Entity": "Normal"
    },
    {
        "Text": "(office) is the beginning of an organization or not, the backward and forward stem n-gram features contain _A..\n\t\t\tJ'.",
        "Entity": "Normal"
    },
    {
        "Text": "(represent location of ) and  _> u'\"   (political office).",
        "Entity": "Normal"
    },
    {
        "Text": "The stem features contain enough information in this example to make a decision that __ .",
        "Entity": "Normal"
    },
    {
        "Text": "(office) is the beginning of an organization.",
        "Entity": "Normal"
    },
    {
        "Text": "In our experiments, n is 3, therefore we use stem trigram features.",
        "Entity": "Normal"
    },
    {
        "Text": "Coreference resolution (or entity recognition) is defined as grouping together mentions referring to the same object or entity.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in the following text, (I)  John believes Mary to be the best student  three mentions  John ,  Mary ,  student  are underlined.",
        "Entity": "Normal"
    },
    {
        "Text": "Mary  and  student  are in the same entity since both refer to the same person.",
        "Entity": "Normal"
    },
    {
        "Text": "The coreference system system is similar to the Bell tree algorithm as described by (Luo et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "In our implementation, the link model between a candidate entity e and the current mention m is comThe start model (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "The maximum-entropy model provides us with a flexible framework to encode features into the the system.",
        "Entity": "Normal"
    },
    {
        "Text": "Our Arabic entity recognition system uses many language-indepedent features such as strict and partial string match, and distance features (Luo et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, however, we focus on the addition of Arabic stem-based features.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Arabic Stem Match Feature.",
        "Entity": "Normal"
    },
    {
        "Text": "Features using the word context (left and right tokens) have been shown to be very helpful in coreference resolution (Luo et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "For Arabic, since words are morphologically derived from a list of roots (stems), we expected that a feature based on the right and left stems would lead to improvement in system accuracy.",
        "Entity": "Normal"
    },
    {
        "Text": "Let m1 and m2 be two candidate mentions where a mention is a string of tokens (prefixes, stems, and suffixes) extracted from the segmented text.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to make a decision in either linking the two mentions or not we use additional features such as: do the stems in m1 and m2 match, do stems in m1 match all stems in m2, do stems in m1 partially match stems in m2.",
        "Entity": "Normal"
    },
    {
        "Text": "We proceed similarly for prefixes and suffixes.",
        "Entity": "Normal"
    },
    {
        "Text": "Since prefixes and suffixes can belong to different mention types, we build a parse tree on the segmented text and we can explore features dealing with the gender and number of the token.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following example, between parentheses we make a word-for-word translations in order to better explain our stemming feature.",
        "Entity": "Normal"
    },
    {
        "Text": "Let us puted astake the two mentions  _ l u'\" __ l PL (L = 1|e, m)   max P  (L = 1|e, mk, m), (1) (to-the-office the-politic to-the-party) and mk  e u'_\"\" __ .",
        "Entity": "Normal"
    },
    {
        "Text": "(office the party s) segmented as 2 Thus, the difference to token n-grams is that the tokens of different type are removed from the streams, be  _> + J + J + u'\"   + J + __ .",
        "Entity": "Normal"
    },
    {
        "Text": "+ J + J fore the features are created.",
        "Entity": "Normal"
    },
    {
        "Text": "and ...\n\t\t\t+  _> + J + __ .",
        "Entity": "Normal"
    },
    {
        "Text": "respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "In our development corpus, these two mentions are chained to the same entity.",
        "Entity": "Normal"
    },
    {
        "Text": "The stemming match feature in this case will contain information such us all stems of m2 match, which is a strong indicator that these mentions should be chained together.",
        "Entity": "Normal"
    },
    {
        "Text": "Features based on the words alone would not help this specific example, because the two strings m1 and m2 do not match.",
        "Entity": "Normal"
    },
    {
        "Text": "6.1 Data.",
        "Entity": "Normal"
    },
    {
        "Text": "The system is trained on the Arabic ACE 2003 and part of the 2004 data.",
        "Entity": "Normal"
    },
    {
        "Text": "We introduce here a clearly defined and replicable split of the ACE 2004 data, so that future investigations can accurately and correctly compare against the results presented here.",
        "Entity": "Normal"
    },
    {
        "Text": "There are 689 Arabic documents in LDC s 2004 release (version 1.4) of ACE data from three sources: the Arabic Treebank, a subset of the broadcast (bnews) and newswire (nwire) TDT4 documents.",
        "Entity": "Normal"
    },
    {
        "Text": "The 178-document devtest is created by taking the last (in chronological order) 25% of documents in each of three sources: 38 Arabic tree- bank documents dating from  20000715  (i.e., July 15, 2000) to  20000815,  76 bnews documents from  20001205.1100.0489  (i.e., Dec. 05 of 2000 from 11:00pm to 04:89am) to  20001230.1100.1216,  and 64 nwire documents from  20001206.1000.0050  to  20001230.0700.0061.",
        "Entity": "Normal"
    },
    {
        "Text": "The time span of the test set is intentionally non-overlapping with that of the training set within each data source, as this models how the system will perform in the real world.",
        "Entity": "Normal"
    },
    {
        "Text": "6.2 Mention Detection.",
        "Entity": "Normal"
    },
    {
        "Text": "We want to investigate the usefulness of stem n- gram features in the mention detection system.",
        "Entity": "Normal"
    },
    {
        "Text": "As stated before, the experiments are run in the ACE 04 framework (NIST, 2004) where the system will identify mentions and will label them (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4) with a type (person, organization, etc), a sub-type (OrgCommercial, OrgGovernmental, etc), a mention level (named, nominal, etc), and a class (specific, generic, etc).",
        "Entity": "Normal"
    },
    {
        "Text": "Detecting the mention boundaries (set of consecutive tokens) and their main type is one of the important steps of our mention detection system.",
        "Entity": "Normal"
    },
    {
        "Text": "The score that the ACE community uses (ACE value) attributes a higher importance (outlined by its weight) to the main type compared to other sub- tasks, such as the mention level and the class.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, to build our mention detection system we spent a lot of effort in improving the first step: detecting the mention boundary and their main type.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we report the results in terms of precision, recall, and F-measure3.",
        "Entity": "Normal"
    },
    {
        "Text": "Lexical features Pr ec isi on ( % ) Re cal l ( % )F m ea su re ( % ) To tal 7 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 5 8.",
        "Entity": "Normal"
    },
    {
        "Text": "0 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 FA C G P E L O C O R G P E R V E H W E A 7 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 7 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 6 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 7 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 8 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 7 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 2 4.",
        "Entity": "Normal"
    },
    {
        "Text": "0 6 5.",
        "Entity": "Normal"
    },
    {
        "Text": "6 2 9.",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 6.",
        "Entity": "Normal"
    },
    {
        "Text": "6 6 3.",
        "Entity": "Normal"
    },
    {
        "Text": "5 2 9.",
        "Entity": "Normal"
    },
    {
        "Text": "7 2 5.",
        "Entity": "Normal"
    },
    {
        "Text": "4 3 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 7 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 6 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 Lexical features + Stem Pr ec isi on ( % ) Re cal l ( % )F m ea su re ( % ) To tal 7 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 5 9.",
        "Entity": "Normal"
    },
    {
        "Text": "4 6 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 F A C G P E L O C O R G P E R V E H W E A 7 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 7 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 6 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 7 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 8 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 7 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 2 9.",
        "Entity": "Normal"
    },
    {
        "Text": "0 6 7.",
        "Entity": "Normal"
    },
    {
        "Text": "2 3 1.",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 7.",
        "Entity": "Normal"
    },
    {
        "Text": "2 6 4.",
        "Entity": "Normal"
    },
    {
        "Text": "6 3 5.",
        "Entity": "Normal"
    },
    {
        "Text": "9 2 9.",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 7 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 6 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "2                                                                                  \n\t\t\tTo assess the impact of stemming n-gram features on the system under different conditions, we consider two cases: one where the system only has access to lexical features (the tokens and direct derivatives including standard n-gram features), and one where the system has access to a richer set of information, including lexical features, POS tags, text chunks, parse tree, and gazetteer information.",
        "Entity": "Normal"
    },
    {
        "Text": "The former framework has the advantage of being fast (making it more appropriate for deployment in commercial systems).",
        "Entity": "Normal"
    },
    {
        "Text": "The number of parameters to optimize in the MaxEnt framework we use when only lexical features are explored is around 280K parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "This number increases to 443K approximately when all information is used except the stemming feature.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of parameters introduced by the use of stemming is around 130K parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "It is important to notice the stemming n-gram features improved the performance of each category of the main type.",
        "Entity": "Normal"
    },
    {
        "Text": "In the second case, the systems have access to a large amount of feature types, including lexical, syntactic, gazetteer, and those obtained by running other 3 The ACE value is an important factor for us, but its relative complexity, due to different weights associated with the subparts, makes for a hard comparison, while the F-measure is relatively easy to interpret.",
        "Entity": "Normal"
    },
    {
        "Text": "interesting improvement in terms of ACE value to the hole EDR system as showed in section 6.3.",
        "Entity": "Normal"
    },
    {
        "Text": "Pr ec isi on ( % ) Re cal l ( % )F m ea su re ( % ) All Fe atu res All Fe atu res +S te m 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 5.",
        "Entity": "Normal"
    },
    {
        "Text": "3 5 5.",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 Le xic al Le xic al+ St em 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 5 0.",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 2.",
        "Entity": "Normal"
    },
    {
        "Text": "0 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "6                                                                                                                                                                                                                                                                                                                         \n\t\t\tFeatures are also extracted from the shallow parsing information associated with the tokens in window of 3, POS, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "The All-features system incorporates all the features except for the stem n- grams.",
        "Entity": "Normal"
    },
    {
        "Text": "This is true for all types.",
        "Entity": "Normal"
    },
    {
        "Text": "It is interesting to note that the increase in performance in both cases (Tables 1 and 2) is obtained from increased recall, with little change in precision.",
        "Entity": "Normal"
    },
    {
        "Text": "When the prefix and suffix n-gram features are removed from the feature set, we notice in both cases (Tables 1 and 2) a insignificant decrease of the overall performance, which is expected: what should a feature of preceeding (or following) prepositions or finite articles captures?",
        "Entity": "Normal"
    },
    {
        "Text": "As stated in Section 4.1, the mention detection system uses a cascade approach.",
        "Entity": "Normal"
    },
    {
        "Text": "However, we were curious to see if the gain we obtained at the first level was successfully transfered into the overall performance of the mention detection system.",
        "Entity": "Normal"
    },
    {
        "Text": "Despite the fact that the improvement was small in terms of F-measure (59.4 vs. 59.7), the stemming n-gram features gave 4 The difference in performance is not statistically significant 6.3 Coreference Resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we present the coreference results on the devtest defined earlier.",
        "Entity": "Normal"
    },
    {
        "Text": "First, to see the effect of stem matching features, we compare two coreference systems: one with the stem features, the other without.",
        "Entity": "Normal"
    },
    {
        "Text": "We test the two systems on both  true  and system mentions of the devtest set.",
        "Entity": "Normal"
    },
    {
        "Text": "True  mentions mean that input to the coreference system are mentions marked by human, while system mentions are output from the mention detection system.",
        "Entity": "Normal"
    },
    {
        "Text": "We report results with two metrics: ECM-F and ACE- Value.",
        "Entity": "Normal"
    },
    {
        "Text": "ECM-F is an entity-constrained mention F- measure (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "(Luo et al., 2004) for how ECM-F is computed), and ACE-Value is the official ACE evaluation metric.",
        "Entity": "Normal"
    },
    {
        "Text": "On true mention, the stem matching features improve ECM-F from 77.7% to 80.0%, and ACE-value from 86.9% to 88.2%.",
        "Entity": "Normal"
    },
    {
        "Text": "The similar improvement is also observed on system mentions.The overall ECM- F improves from 62.3% to 64.2% and the ACE value improves from 61.9 to 63.1%.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that the increase on the ACE value is smaller than ECM-F.",
        "Entity": "Normal"
    },
    {
        "Text": "This is because ACE-value is a weighted metric which emphasizes on NAME mentions and heavily discounts PRONOUN mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "Overall the stem features give rise to consistent gain to the coreference system.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we present a fully fledged Entity Detection and Tracking system for Arabic.",
        "Entity": "Normal"
    },
    {
        "Text": "At its base, the system fundamentally depends on a finite state segmenter and makes good use of the relationships that occur between word stems, by introducing features which take into account the type of each segment.",
        "Entity": "Normal"
    },
    {
        "Text": "In mention detection, the features are represented as stem n-grams, while in coreference resolution they are captured through stem-tailored match features.",
        "Entity": "Normal"
    },
    {
        "Text": "B a s e B a s e + S t e m ECM F ACEVal ECM F ACEVal Tr ut h Sy ste m 7 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 86.9 6 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 61.9 8 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 88.2 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 63.1                                                                       \n\t\t\tThe row marked with  Truth  represents the results with  true  mentions while the row marked with  System  represents that mentions are detected by the system.",
        "Entity": "Normal"
    },
    {
        "Text": "Numbers under  ECM- F  are Entity-Constrained-Mention F-measure and numbers under  ACE-Val  are ACE-values.",
        "Entity": "Normal"
    },
    {
        "Text": "These types of features result in an improvement in both the mention detection and coreference resolution performance, as shown through experiments on the ACE 2004 Arabic data.",
        "Entity": "Normal"
    },
    {
        "Text": "The experiments are performed on a clearly specified partition of the data, so comparisons against the presented work can be correctly and accurately made in the future.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we also report results on the official test data.",
        "Entity": "Normal"
    },
    {
        "Text": "The presented system has obtained competitive results in the ACE 2004 evaluation, being ranked amongst the top competitors.",
        "Entity": "Normal"
    },
    {
        "Text": "This work was partially supported by the Defense Advanced Research Pro jects Agency and monitored by SPAWAR under contract No.",
        "Entity": "Normal"
    },
    {
        "Text": "N6600199-28916.",
        "Entity": "Normal"
    },
    {
        "Text": "The views and findings contained in this material are those of the authors and do not necessarily reflect the position of policy of the U.S. government and no official endorsement should be inferred.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tIn this article, we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming (DP).",
        "Entity": "Normal"
    },
    {
        "Text": "The search algorithm uses the translation model presented in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Starting from a DP-based solution to the traveling-salesman problem, we present a novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "Word reordering restrictions especially useful for the translation direction German to English are presented.",
        "Entity": "Normal"
    },
    {
        "Text": "The restrictions are generalized, and a set of four parameters to control the word reordering is introduced, which then can easily be adopted to new translation directions.",
        "Entity": "Normal"
    },
    {
        "Text": "The beam search procedure has been successfully tested on the Verbmobil task (German to English, 8,000-word vocabulary) and on the Canadian Hansards task (French to English, 100,000-word vocabulary).",
        "Entity": "Normal"
    },
    {
        "Text": "For the medium-sized Verbmobil task, a sentence can be translated in a few seconds, only a small number of search errors occur, and there is no performance degradation as measured by the word error criterion used in this article.",
        "Entity": "Normal"
    },
    {
        "Text": "This article is about a search procedure for statistical machine translation (MT).",
        "Entity": "Normal"
    },
    {
        "Text": "The task of the search procedure is to find the most likely translation given a source sentence and a set of model parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we will use a trigram language model and the translation model presented in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Since the number of possible translations of a given source sentence is enormous, we must find the best output without actually generating the set of all possible translations; instead we would like to focus on the most likely translation hypotheses during the search process.",
        "Entity": "Normal"
    },
    {
        "Text": "For this purpose, we present a data-driven beam search algorithm similar to the one used in speech recognition search algorithms (Ney et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1992).",
        "Entity": "Normal"
    },
    {
        "Text": "The major difference between the search problem in speech recognition and statistical MT is that MT must take into account the different word order for the source and the target language, which does not enter into speech recognition.",
        "Entity": "Normal"
    },
    {
        "Text": "Tillmann, Vogel, Ney, and Zubiaga (1997) proposes a dynamic programming (DP) based search algorithm for statistical MT that monotonically translates the input sentence from left to right.",
        "Entity": "Normal"
    },
    {
        "Text": "The word order difference is dealt with using a suitable preprocessing step.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the resulting search procedure is very fast, the preprocessing is language specific and requires a lot of manual   IBM T. J. Watson Research Center, Yorktown Heights, NY 10598.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: ctill@us.ibm.com.",
        "Entity": "Normal"
    },
    {
        "Text": "The research reported here was carried out while the author was with Lehrstuhl fu  r Informatik VI, Computer Science Department, RWTH Aachen.",
        "Entity": "Normal"
    },
    {
        "Text": "Lehrstuhl fu  r Informatik VI, Computer Science Department, RWTH Aachen, D-52056 Aachen, Germany.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: ney@informatik.rwthaachen.de.",
        "Entity": "Normal"
    },
    {
        "Text": "Oc 2003 Association for Computational Linguistics work.",
        "Entity": "Normal"
    },
    {
        "Text": "Currently, most search algorithms for statistical MT proposed in the literature are based on the A  concept (Nilsson 1971).",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the word reordering can be easily included in the search procedure, since the input sentence positions can be processed in any order.",
        "Entity": "Normal"
    },
    {
        "Text": "The work presented in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996) that is based on the A  concept, however, introduces word reordering restrictions in order to reduce the overall search space.",
        "Entity": "Normal"
    },
    {
        "Text": "The search procedure presented in this article is based on a DP algorithm to solve the traveling-salesman problem (TSP).",
        "Entity": "Normal"
    },
    {
        "Text": "A data-driven beam search approach is presented on the basis of this DP-based algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The cities in the TSP correspond to source positions of the input sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "By imposing constraints on the possible word reorderings similar to that described in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996), the DP-based approach becomes more effective: when the constraints are applied, the number of word re- orderings is greatly reduced.",
        "Entity": "Normal"
    },
    {
        "Text": "The original reordering constraint in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996) is shown to be a special case of a more general restriction scheme in which the word reordering constraints are expressed in terms of simple combinatorical restrictions on the processed sets of source sentence positions.1 A set of four parameters is given to control the word reordering.",
        "Entity": "Normal"
    },
    {
        "Text": "Additionally, a set of four states is introduced to deal with grammatical reordering restrictions (e.g., for the translation direction German to English, the word order difference between the two languages is mainly due to the German verb group.",
        "Entity": "Normal"
    },
    {
        "Text": "In combination with the reordering restrictions, a data-driven beam search organization for the search procedure is proposed.",
        "Entity": "Normal"
    },
    {
        "Text": "A beam search pruning technique is conceived that jointly processes partial hypotheses according to two criteria: (1) The partial hypotheses cover the same set of source sentence positions,and (2) the partial hypotheses cover sets C of source sentence positions of equal car dinality.",
        "Entity": "Normal"
    },
    {
        "Text": "A partial hypothesis is said to cover a set of source sentence positions when exactly the positions in the set have already been processed in the search process.",
        "Entity": "Normal"
    },
    {
        "Text": "To verify the effectiveness of the proposed techniques, we report and analyze results for two translation tasks: the German to English Verbmobil task and French to English Canadian Hansards task.The article is structured as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 2 gives a short introduction to the trans lation model used and reports on other approaches to the search problem in statistical MT.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 3, a DP-based search approach is presented, along with appropriate pruning techniques that yield an efficient beam search algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4 reports and analyzes translation results for the different translation directions.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 5, we conclude with a discussion of the achieved results.",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 IBM Translation Approach.",
        "Entity": "Normal"
    },
    {
        "Text": "In this article, we use the translation model presented in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993), and the mathematical notation we use here is taken from that paper as well: a source string 1 = f1     fj     fJ is to be translated into a target string eI = e1     ei     eI .",
        "Entity": "Normal"
    },
    {
        "Text": "Here, I is the length of the target string, and J is the length of the source string.",
        "Entity": "Normal"
    },
    {
        "Text": "Among all possible target strings, we will choose the string with the highest probability as given by Bayes  1 The word reordering restriction used in the search procedure described in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996) is not.",
        "Entity": "Normal"
    },
    {
        "Text": "mentioned in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993), although exactly the translation model described there is used.",
        "Entity": "Normal"
    },
    {
        "Text": "Equivalently, we use exactly the translation model described in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) but try different reordering restrictions for the DP-based search procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "98                                                                                             \n\t\t\tdecision rule:  eI = arg max{Pr (eI | f J )} 1 I 1 1 1 = arg max{Pr (eI )   Pr(f J | eI )} (1) I 1 1 1 1 Pr (eI ) is the language model of the target language, whereas Pr (f J | eI ) is the string 1 1 1translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "The language model probability is computed using a trigram lan guage model.",
        "Entity": "Normal"
    },
    {
        "Text": "The string translation probability Pr (f J | eI ) is modeled using a series of 1 1five models of increasing complexity in training.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the model used for the trans lation experiments is the IBM4 model.",
        "Entity": "Normal"
    },
    {
        "Text": "This model uses the same parameter set as the IBM5 model, which in preliminary experiments did not yield better translationresults.",
        "Entity": "Normal"
    },
    {
        "Text": "The actual implementation used during the experiments is described in Al Onaizan et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1999) and in Och and Ney (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "The argmax operation denotes the search problem (i.e., the generation of the output sentence in the target language).",
        "Entity": "Normal"
    },
    {
        "Text": "The transformations may range from simple word categorization to more complex preprocessing steps that require someparsing of the source string.",
        "Entity": "Normal"
    },
    {
        "Text": "In this article, however, we will use only word catego 99 rization as an explicit transformation step.",
        "Entity": "Normal"
    },
    {
        "Text": "In the search procedure both the language and the translation model are applied after the text transformation steps.",
        "Entity": "Normal"
    },
    {
        "Text": "The following  types  of parameters are used for the IBM4 translation model: Lexicon probabilities: We use the lexicon probability p(f | e) for translating the single target word e as the single source word f .",
        "Entity": "Normal"
    },
    {
        "Text": "A source word f may be translated by the  null  word e0 (i.e., it does not produce any target word e).",
        "Entity": "Normal"
    },
    {
        "Text": "A translation probability p(f | e0 ) is trained along with the regular translation probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "Fertilities: A single target word e may be aligned to n = 0, 1 or more source words.",
        "Entity": "Normal"
    },
    {
        "Text": "This is explicitly modeled by the fertility parameter  (n | e): the probability that the target word e is translated by n source words is  (n | e).",
        "Entity": "Normal"
    },
    {
        "Text": "The fertility for the  null  word is treated specially (for details see Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "[1993]).",
        "Entity": "Normal"
    },
    {
        "Text": "Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996) describes the extension of a partial hypothesis by a pair of target words (e1, e), where e1 is not connected to any source word f .",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, the so-called spontaneous target word e1 is accounted for with the fertility.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the translation probability  (0 | e1) and no- translation probability p(f | e1).",
        "Entity": "Normal"
    },
    {
        "Text": "Class-based distortion probabilities: When covering a source sentence position j, we use distortion probabilities that depend on the previously covered source sentence positions (we say that a source sentence position j is covered for a partial hypothesis when it is taken account of in the translation process by generating a target word or the  null  word e0 ).",
        "Entity": "Normal"
    },
    {
        "Text": "In Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993), two types of distortion probabilities are distinguished: (1) the leftmost word of a set of source words f aligned to the same target word e (which is called the  head ) is placed, and (2) the remaining source words are placed.",
        "Entity": "Normal"
    },
    {
        "Text": "Two separate distributions are used for these two cases.",
        "Entity": "Normal"
    },
    {
        "Text": "For placing the  head  the center function center (i) (Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "[1993] uses the notation 8i ) is used: the average position of the source words with which the target word ei 1 is aligned.",
        "Entity": "Normal"
    },
    {
        "Text": "The distortion probabilities are class-based: They depend on the word class F (f ) of a covered source word f as well as on the word class E (e) of the previously generated target word e. The classes are automatically trained (Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1992).",
        "Entity": "Normal"
    },
    {
        "Text": "When the IBM4 model parameters are used during search, an input sentence can be processed one source position at a time in a certain order primarily determined by the distortion probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "We will use the following simplified set of translation model parameters: lexicon probabilities p(f | e) and distortion probabilities p(j | j1, J).",
        "Entity": "Normal"
    },
    {
        "Text": "Here, j is the currently covered input sentence position and j1 is the previously covered input sentence position.",
        "Entity": "Normal"
    },
    {
        "Text": "The input sentence length J is included, since we would like to think of the distortion probability as normalized according to J.",
        "Entity": "Normal"
    },
    {
        "Text": "No fertility probabilities or  null  word probabilities are used; thus each source word f is translated as exactly one target word e and each target word e is translated as exactly one source word f .",
        "Entity": "Normal"
    },
    {
        "Text": "The simplified notation will help us to focus on the most relevant details of the DP-based search procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "The simplified set of parameters leads to an unrealistic assumption about the length of the source and target sentence, namely, I = J.",
        "Entity": "Normal"
    },
    {
        "Text": "During the translation experiments we will, of course, not make this assumption.",
        "Entity": "Normal"
    },
    {
        "Text": "The implementation details for using the full set of IBM4 model parameters are given in Section 3.9.2.",
        "Entity": "Normal"
    },
    {
        "Text": "100 2.2 Search Algorithms for Statistical Machine Translation.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we give a short overview of search procedures used in statistical MT: Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1990) and Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) describe a statistical MT system that is based on the same statistical principles as those used in most speech recognition systems (Jelinek 1976).",
        "Entity": "Normal"
    },
    {
        "Text": "Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1994) describes the French-to-English Candide translation system, which uses the translation model proposed in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993).",
        "Entity": "Normal"
    },
    {
        "Text": "A detailed description of the decoder used in that system is given in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996) but has never been published in a paper: Throughout the search process, partial hypotheses are maintained in a set of priority queues.",
        "Entity": "Normal"
    },
    {
        "Text": "There is a single priority queue for each subset of covered positions in the source string.",
        "Entity": "Normal"
    },
    {
        "Text": "In practice, the priority queues areinitialized only on demand; far fewer than the full number of queues possible are actu ally used.",
        "Entity": "Normal"
    },
    {
        "Text": "The priority queues are limited in size, and only the 1,000 hypotheses with the highest probability are maintained.",
        "Entity": "Normal"
    },
    {
        "Text": "Each priority queue is assigned a threshold to select the hypotheses that are going to be extended, and the process of assigning these thresholds is rather complicated.",
        "Entity": "Normal"
    },
    {
        "Text": "A restriction on the possible word reorderings, which is described in Section 3.6, is applied.",
        "Entity": "Normal"
    },
    {
        "Text": "Wang and Waibel (1997) presents a search algorithm for the IBM2 translation model based on the A  concept and multiple stacks.",
        "Entity": "Normal"
    },
    {
        "Text": "An extension of this algorithm is demonstrated in Wang and Waibel (1998).",
        "Entity": "Normal"
    },
    {
        "Text": "Here, a reshuffling step on top of the original decoder is used to handle more complex translation models (e.g., the IBM3 model is added).",
        "Entity": "Normal"
    },
    {
        "Text": "Translation approaches that use the IBM2 model parameters but are based on DP are presented in Garc  a-Varea, Casacuberta, and Ney (1998) and Niessen et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998).",
        "Entity": "Normal"
    },
    {
        "Text": "An approach based on the hidden Markov model alignments as used in speech recognition is presented in Tillmann, Vogel, Ney, and Zubiaga (1997) and Tillmann, Vogel, Ney, Zubiaga, and Sawaf (1997).",
        "Entity": "Normal"
    },
    {
        "Text": "This approach assumes that source and target language have the same word order, and word order differences are dealt with in a preprocessing stage.",
        "Entity": "Normal"
    },
    {
        "Text": "The work by Wu (1996) also uses the original IBM model parameters and obtains an efficient search algorithm by restricting the possible word reorderings using the so-called stochastic bracketing transduction grammar.",
        "Entity": "Normal"
    },
    {
        "Text": "Three different decoders for the IBM4 translation model are compared in Germann et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2001).",
        "Entity": "Normal"
    },
    {
        "Text": "The first is a reimplementation of the stack-based decoder described in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996).",
        "Entity": "Normal"
    },
    {
        "Text": "The second is a greedy decoder that starts with an approximate solution and then iteratively improves this first rough solution.",
        "Entity": "Normal"
    },
    {
        "Text": "The third converts the decoding problem into an integer program (IP), and a standard software package for solving IP is used.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the last approach is guaranteed to find the optimal solution, it is tested only for input sentences of length eight or shorter.",
        "Entity": "Normal"
    },
    {
        "Text": "This article will present a DP-based beam search decoder for the IBM4 translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "The decoder is designed to carry out an almost full search with a small number of search errors and with little performance degradation as measured by the word error criterion.",
        "Entity": "Normal"
    },
    {
        "Text": "A preliminary version of the work presented here was published in Tillmann and Ney (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Inverted Alignment Concept.",
        "Entity": "Normal"
    },
    {
        "Text": "To explicitly describe the word order difference between source and target language, Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) introduced an alignment concept, in which a source position j is mapped to exactly one target position i: regular alignment: j   i = aj 101 .",
        "Entity": "Normal"
    },
    {
        "Text": "May of fourth the on you visit not can colleague my case this In I d F k m K S a v M n b .",
        "Entity": "Normal"
    },
    {
        "Text": "n i a a e o i m i a i e          e l n s l n e m i l e e i c s n l r h u e t t c g e h e n e n Regular alignment example for the translation direction German to English.",
        "Entity": "Normal"
    },
    {
        "Text": "For each German source word there is exactly one English target word on the alignment path.",
        "Entity": "Normal"
    },
    {
        "Text": "An example for this kind of alignment is given in Figure 2, in which each German source position j is mapped to an English target position i.",
        "Entity": "Normal"
    },
    {
        "Text": "In Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993), this alignment concept is used for model IBM1 through model IBM5.",
        "Entity": "Normal"
    },
    {
        "Text": "For search purposes, we use the inverted alignment concept as introduced in Niessen et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1998) and Ney et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2000).",
        "Entity": "Normal"
    },
    {
        "Text": "An inverted alignment is defined as follows: inverted alignment: i   j = bi Here, a target position i is mapped to a source position j.",
        "Entity": "Normal"
    },
    {
        "Text": "The coverage constraint for an inverted alignment is not expressed by the notation: Each source position j should be  hit  exactly once by the path of the inverted alignment bI = b1     bi     bI .",
        "Entity": "Normal"
    },
    {
        "Text": "The advantage of the inverted alignment concept is that we can construct target sentence hypotheses from bottom to top along the positions of the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Using the inverted alignments in the maximum approximation, we rewrite equation (1) to obtain the following search criterion, in which we are looking for the most likely target 102 Figure 3 Illustration of the transitions in the regular and in the inverted alignment model.",
        "Entity": "Normal"
    },
    {
        "Text": "The regular alignment model (left figure) is used to generate the sentence from left to right; the inverted alignment model (right figure) is used to generate the sentence from bottom to top.",
        "Entity": "Normal"
    },
    {
        "Text": "sentence eI of length I = J for an observed source sentence f J of length J: 1 1 max p(J | I)   max{p(eI )   p(f J | eI )} (2) I I 1 1 1 1 I I  = max I p(J | I)   max e n p(ei | ei 1 , ei 2 )   max n[p(bi | bi 1 , J)   p(fbi | ei )] b 1 i=1 I 1 i=1 = max p(J | I)   max n[p(ei | ei 1 , ei 2 )   p(bi | bi 1 , J)   p(fbi | ei )] I eI I 1 ,b1 i=1 The following notation is used: ei 1 , ei 2 are the immediate predecessor target words, ei is the word to be hypothesized, p(ei | ei 1 , ei 2 ) denotes the trigram language model probability, p(fbi | ei ) denotes the lexicon probability for translating the target word ei as source word fbi , and p(bi | bi 1 , J) is the distortion probability for covering source position bi after source position bi 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "Note that in equation (2) two products over i are merged into a single product over i.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation probability p(f J | eI ) is computed in 1 1 the maximum approximation using the distortion and the lexicon probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, p(J | I) is the sentence length model, which will be dropped in the following (it is not used in the IBM4 translation model).",
        "Entity": "Normal"
    },
    {
        "Text": "For each source sentence f J to be translated, we are searching for the unknown mapping that optimizes equation (2): i   (bi , ei ) In Section 3.3, we will introduce an auxiliary quantity that can be evaluated recursively using DP to find this unknown mapping.",
        "Entity": "Normal"
    },
    {
        "Text": "We will explicitly take care of the coverage constraint by introducing a coverage set C of source sentence positions that have already been processed.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 3 illustrates the concept of the search algorithm using inverted alignments: Partial hypotheses are constructed from bottom to top along the positions of the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Partial hypotheses of length i 1 are extended to obtain partial hypotheses of the length i.",
        "Entity": "Normal"
    },
    {
        "Text": "Extending a partial hypothesis means covering a source sentence position j that has not yet been covered.",
        "Entity": "Normal"
    },
    {
        "Text": "For a given grid point in the 103 Table 1 DP-based algorithm for solving traveling-salesman problems due to Held and Karp.",
        "Entity": "Normal"
    },
    {
        "Text": "The outermost loop is over the cardinality of subsets of already visited cities.",
        "Entity": "Normal"
    },
    {
        "Text": "input: cities j = 1, ...\n\t\t\t, J with distance matrix djj 1 initialization: D({k}, k) := d1k for each path length c = 2, ...\n\t\t\t, J do for each pair (C, j), where C   {2, ...\n\t\t\t, J} and j  C and |C| = c do D(C, j) = min {djj 1 + D(C\\{j}, j )} traceback: j1  C\\{j}   find shortest tour: D  = min [D({2, ...\n\t\t\t, J}, k)+ dk1 ] k {2,...,J}   recover optimal sequence of cities translation lattice, the unknown target word sequence can be obtained by tracing back the translation decisions to the partial hypothesis at stage i = 1.",
        "Entity": "Normal"
    },
    {
        "Text": "The grid points are defined in Section 3.3.",
        "Entity": "Normal"
    },
    {
        "Text": "In the left part of the figure the regular alignment concept is shown for comparison purposes.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Held and Karp Algorithm for Traveling-Salesman Problem.",
        "Entity": "Normal"
    },
    {
        "Text": "Held and Karp (1962) presents a DP approach to solve the TSP, an optimization problem that is defined as follows: Given are a set of cities {1, ...\n\t\t\t, J} and for each pair of cities j, j1 the cost djj 1 > 0 for traveling from city j to city j1.",
        "Entity": "Normal"
    },
    {
        "Text": "We are looking for the shortest tour, starting and ending in city 1, that visits all cities in the set of cities exactly once.",
        "Entity": "Normal"
    },
    {
        "Text": "We are using the notation C for the set of cities, since it corresponds to a coverage set of processed source positions in MT.",
        "Entity": "Normal"
    },
    {
        "Text": "A straightforward way to find the shortest tour is by trying all possible permutations of the J cities.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting algorithm has a complexity of O(J!).",
        "Entity": "Normal"
    },
    {
        "Text": "DP can be used, however, to find the shortest tour in O(J2   2J ), which is a much smaller complexity for larger values of J.",
        "Entity": "Normal"
    },
    {
        "Text": "The approach recursively evaluates the quantity D(C, j): D(C, j) := costs of the partial tour starting in city 1, ending in city j, and visiting all cities in C Subsets of cities C of increasing cardinality c are processed.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm, shown in Table 1, works because not all permutations of cities have to be considered explicitly.",
        "Entity": "Normal"
    },
    {
        "Text": "During the computation, for a pair (C, j), the order in which the cities in C have been visited can be ignored (except j); only the costs for the best path reaching j has to be stored.",
        "Entity": "Normal"
    },
    {
        "Text": "For the initialization the costs for starting from city 1 are set: D({k}, k) = d1k for each k   {2, ...\n\t\t\t, |C|}.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, subsets C of increasing cardinality are processed.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the cost for the optimal tour is obtained in the second-to-last line of the algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The optimal tour itself can be found using a back-pointer array in which the optimal decision for each grid point (C, j) is stored.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 4 illustrates the use of the algorithm by showing the  supergraph  that is searched in the Held and Karp algorithm for a TSP with J = 5 cities.",
        "Entity": "Normal"
    },
    {
        "Text": "When traversing the lattice from left to right following the different possibilities, a partial path to a node j corresponds to the subset C of all cities on that path together with the last visited 104 Figure 4 Illustration of the algorithm by Held and Karp for a traveling salesman problem with J = 5 cities.",
        "Entity": "Normal"
    },
    {
        "Text": "Not all permutations of cities have to be evaluated explicitly.",
        "Entity": "Normal"
    },
    {
        "Text": "For a given subset of cities the order in which the cities have been visited can be ignored.",
        "Entity": "Normal"
    },
    {
        "Text": "city j.",
        "Entity": "Normal"
    },
    {
        "Text": "Of all the different paths merging into the node j, only the partial path with the smallest cost has to be retained for further computation.",
        "Entity": "Normal"
    },
    {
        "Text": "3.3 DP-Based Algorithm for Statistical Machine Translation.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, the Held and Karp algorithm is applied to statistical MT.",
        "Entity": "Normal"
    },
    {
        "Text": "Using the concept of inverted alignments as introduced in Section 3.1, we explicitly take care of the coverage constraint by introducing a coverage set C of source sentence positions that have already been processed.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the correspondence is according to the fact that each source sentence position has to be covered exactly once, fulfilling the coverage constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "The cities of the more complex translation TSP correspond roughly to triples (e1, e, j), the notation for which is given below.",
        "Entity": "Normal"
    },
    {
        "Text": "The final path output by the translation algorithm will contain exactly one triple (e1, e, j) for each source position j.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm processes subsets of partial hypotheses with coverage sets C of increasing cardinality c. For a trigram language model, the partial hypotheses are of the form (e1, e, C, j), where e1, e are the last two target words, C is a coverage set for the already covered source positions, and j is the last covered position.",
        "Entity": "Normal"
    },
    {
        "Text": "The target word sequence that ends in e1, e is stored as a back pointer to the predecessor partial hypothesis (and recursively to its predecessor hypotheses) and is not shown in the notation.",
        "Entity": "Normal"
    },
    {
        "Text": "Each distance in the TSP now corresponds to the negative logarithm of the product of the translation, distortion, and language model probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "The following 105 Table 2 DP-based algorithm for statistical MT that consecutively processes subsets C of source sentence positions of increasing cardinality.",
        "Entity": "Normal"
    },
    {
        "Text": "input: source language string f1     fj     fJ initialization for each cardinality c = 1, 2, ...\n\t\t\t, J do for each pair (C, j), where C   {1, ...\n\t\t\t, J} and j  C and |C| = c do for each pair of target words e , e   E traceback: Qe1 (e, , j) = p(fj e) max e11 j1  C\\{j} {p(j | j , J)   p(e | e , e )   Qe11 (e , C\\{j}, j )}   find best end hypothesis: max{p($ | e, e )   Qe1 (e, {1, ...\n\t\t\t, J}, j)}   recover optimal word sequence auxiliary quantity is defined: Qe1 (e, C, j) := probability of the best partial hypothesis (ei , bi ), where 1 1 C = {bk | k = 1, ...\n\t\t\t, i}, bi = j, ei = e, and ei 1 = e1 The above auxiliary quantity satisfies the following recursive DP equation: Qe1 (e, C, j) = p(fj | e)   max p(j | j1, J)   p(e | e1, e11)   Qe11 (e1, C\\{j}, j ) e11 j1  C\\{j} Here, j1 is the previously covered source sentence position and e1, e11 are the predecessor words.",
        "Entity": "Normal"
    },
    {
        "Text": "The DP equation is evaluated recursively for each hypothesis (e1, e, C, j).",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting algorithm is depicted in Table 2.",
        "Entity": "Normal"
    },
    {
        "Text": "Some details concerning the initialization and the finding of the best target language string are presented in Section 3.4.\n\t\t\tp($ | e, e1) is the trigram language probability for predicting the sentence boundary symbol $.",
        "Entity": "Normal"
    },
    {
        "Text": "The complexity of the algorithm is O(E3   J2   2J ), where E is the size of the target language vocabulary.",
        "Entity": "Normal"
    },
    {
        "Text": "3.4 Verb Group Reordering: German to English.",
        "Entity": "Normal"
    },
    {
        "Text": "The above search space is still too large to translate even a medium-length inputsentence.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, only very restricted reorderings are necessary; for ex ample, for the translation direction German to English, the word order difference is mostly restricted to the German verb group.",
        "Entity": "Normal"
    },
    {
        "Text": "The approach presented here assumes a mostly monotonic traversal of the source sentence positions from left to right.2 A small number of positions may be processed sooner than they would be in that monotonic traversal.",
        "Entity": "Normal"
    },
    {
        "Text": "Each source position then generates a certain number of target words.",
        "Entity": "Normal"
    },
    {
        "Text": "The restrictions are fully formalized in Section 3.5.A typical situation is shown in Figure 5.",
        "Entity": "Normal"
    },
    {
        "Text": "When translating the sentence monotoni cally from left to right, the translation of the German finite verb kann, which is the left verbal brace in this case, is skipped until the German noun phrase mein Kollege, which is the subject of the sentence, is translated.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, the right verbal brace is translated: 2 Also, this assumption is necessary for the beam search pruning techniques to work efficiently..\n\t\t\t106 .",
        "Entity": "Normal"
    },
    {
        "Text": "May of fourth the on you visit not can colleague my case this In I d F k m K S a v M n b .",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 5 n i a e l s l e m a e o n i l n n l e g e i m i a i e e e i c s r h u t t c e h n e n Word reordering for the translation direction German to English: The reordering is restricted to the German verb group.",
        "Entity": "Normal"
    },
    {
        "Text": "The infinitive besuchen and the negation particle nicht.",
        "Entity": "Normal"
    },
    {
        "Text": "The following restrictions are used: One position in the source sentence may be skipped for a distance of up to L = 4 source positions, and up to two source positions may be moved for a distance of at most R = 10 source positions (the notation L and R shows the relation to the handling of the left and right verbal brace).",
        "Entity": "Normal"
    },
    {
        "Text": "To formalize the approach, we introduce four verb group states S:   Initial : A contiguous initial block of source positions is covered.",
        "Entity": "Normal"
    },
    {
        "Text": "Skip: One word may be skipped, leaving a  hole  in the monotonic traversal.",
        "Entity": "Normal"
    },
    {
        "Text": "Move : Up to two words may be  moved  from later in the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Cover : The sentence is traversed monotonically until the state Initial is reached.",
        "Entity": "Normal"
    },
    {
        "Text": "107 4.\n\t\t\tmein 5.",
        "Entity": "Normal"
    },
    {
        "Text": "Kollege.",
        "Entity": "Normal"
    },
    {
        "Text": "Skip Initial Move Cover 1.",
        "Entity": "Normal"
    },
    {
        "Text": "In.",
        "Entity": "Normal"
    },
    {
        "Text": "6.\n\t\t\tkann 7.\n\t\t\tnicht 9.",
        "Entity": "Normal"
    },
    {
        "Text": "Sie.",
        "Entity": "Normal"
    },
    {
        "Text": "2.\n\t\t\tdiesem 12.",
        "Entity": "Normal"
    },
    {
        "Text": "Mai 8.\n\t\t\tbesuchen 10.\n\t\t\tam 3.",
        "Entity": "Normal"
    },
    {
        "Text": "Fall.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 6 13.",
        "Entity": "Normal"
    },
    {
        "Text": "11.\n\t\t\tvierten Order in which the German source positions are covered for the German-to-English reordering example given in Figure 5.",
        "Entity": "Normal"
    },
    {
        "Text": "The states Move and Skip both allow a set of upcoming words to be processed sooner than would be the case in the monotonic traversal.",
        "Entity": "Normal"
    },
    {
        "Text": "The state Initial is entered whenever there are no uncovered positions to the left of the rightmost covered position.",
        "Entity": "Normal"
    },
    {
        "Text": "The sequence of states needed to carry out the word reordering example in Figure 5 is given in Figure 6.",
        "Entity": "Normal"
    },
    {
        "Text": "The 13 source sentence words are processed in the order shown.",
        "Entity": "Normal"
    },
    {
        "Text": "A formal specification of the state transitions is given in Section 3.5.",
        "Entity": "Normal"
    },
    {
        "Text": "Any number of consecutive German verb phrases in a sentence can be processed by the algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The finite-state control presented here is obtained from a simple analysis of the German- to-English word reordering problem and is not estimated from the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "It can be viewed as an extension of the IBM4 model distortion probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "Using the above states, we define partial hypothesis extensions of the following type: (S1, C\\{j}, j1)   (S, C, j) Not only the coverage set C and the positions j, j1, but also the verb group states S, S1, are taken into account.",
        "Entity": "Normal"
    },
    {
        "Text": "For the sake of brevity, we have omitted the target language words e, e1 in the notation of the partial hypothesis extension.",
        "Entity": "Normal"
    },
    {
        "Text": "For each extension an uncovered position is added to the coverage set C of the partial hypothesis, and the verb group state S may change.",
        "Entity": "Normal"
    },
    {
        "Text": "A more detailed description of the partial hypothesis extension for a certain state S is given in the next section in a more generalcontext.",
        "Entity": "Normal"
    },
    {
        "Text": "Covering the first uncovered position in the source sentence, we use the lan 108 guage model probability p(e | $, $).",
        "Entity": "Normal"
    },
    {
        "Text": "Here, $ is the sentence boundary symbol, which is thought to be at position 0 in the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "The search starts in the hypothesis (Initial , { }, 0).",
        "Entity": "Normal"
    },
    {
        "Text": "{ } denotes the empty set, where no source sentence position is covered.",
        "Entity": "Normal"
    },
    {
        "Text": "The following recursive equation is evaluated: Qe1 (e, S, C, j) (3) = p(fj | e) max e11 ,S1 ,j1 (S1 ,C\\{j},j1 ) (S,C,j) j1  C\\{j} {p(j | j1, J)   p(e | e1, e11)   Qe11 (e1, S1, C\\{j}, j1)} The search ends in the hypotheses (Initial , {1, ...\n\t\t\t, J}, j); the last covered position may be in the range j   {J  L, ...\n\t\t\t, J}, because some source positions may have been skipped at the end of the input sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "{1, ...\n\t\t\t, J} denotes a coverage set including all positions from position 1 to position J.",
        "Entity": "Normal"
    },
    {
        "Text": "The final translation probability QF is QF = max e,e1 j {J L,...,J} p($ | e, e1)   Qe1 (e, Initial , {1, ...\n\t\t\t, J}, j) (4) where p($ | e, e1) denotes the trigram language model, which predicts the sentence boundary $ at the end of the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "QF can be obtained using an algorithm very similar to the one given in Table 2.",
        "Entity": "Normal"
    },
    {
        "Text": "The complexity of the verb group reordering for the translation direction German to English is O(E3   J   (R2   L   R)), as shown in Tillmann (2001).",
        "Entity": "Normal"
    },
    {
        "Text": "3.5 Word Reordering: Generalization.",
        "Entity": "Normal"
    },
    {
        "Text": "For the translation direction English to German, the word reordering can be restricted in a similar way as for the translation direction German to English.",
        "Entity": "Normal"
    },
    {
        "Text": "Again, the word order difference between the two languages is mainly due to the German verb group.",
        "Entity": "Normal"
    },
    {
        "Text": "During the translation process, the English verb group is decomposed as shown inFigure 7.",
        "Entity": "Normal"
    },
    {
        "Text": "When the sentence is translated monotonically from left to right, the trans lation of the English finite verb can is moved, and it is translated as the German left verbal brace before the English noun phrase my colleague, which is the subject of the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "The translations of the infinitive visit and of the negation particle not areskipped until later in the translation process.",
        "Entity": "Normal"
    },
    {
        "Text": "For this translation direction, the trans lation of one source sentence position may be moved for a distance of up to L = 4 source positions, and the translation of up to two source positions may be skipped for a distance of up to R = 10 source positions (we take over the L and R notation from the previous section).",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, the role of the skipping and the moving are simply reversed with respect to their roles in German-to-English translation.",
        "Entity": "Normal"
    },
    {
        "Text": "For the example translation in Figure 7, the order in which the source sentence positions are covered is given in Figure 8.We generalize the two approaches for the different translation directions as fol lows: In both approaches, we assume that the source sentence is mainly processedmonotonically.",
        "Entity": "Normal"
    },
    {
        "Text": "A small number of upcoming source sentence positions may be pro cessed earlier than they would be in the monotonic traversal: The states Skip and Move are used as explained in the preceding section.",
        "Entity": "Normal"
    },
    {
        "Text": "The positions to be processed outside the monotonic traversal are restricted as follows:   The number of positions dealt with in the states Move and Skip is restricted.",
        "Entity": "Normal"
    },
    {
        "Text": "There are distance restrictions on the source positions processed in those states.",
        "Entity": "Normal"
    },
    {
        "Text": "109 .",
        "Entity": "Normal"
    },
    {
        "Text": "besuchen nicht Mai vierten am Sie Kollege mein kann Fall diesem In I t c m c c n v y o t f o M .",
        "Entity": "Normal"
    },
    {
        "Text": "n h a y o a o i o n h o f a Figure 7 i s l n t s u s e l i e t a g u e e u y r t h Word reordering for the translation direction English to German: The reordering is restricted to the English verb group.",
        "Entity": "Normal"
    },
    {
        "Text": "These restrictions will be fully formalized later in this section.",
        "Entity": "Normal"
    },
    {
        "Text": "In the state Move , some source sentence positions are  moved  from later in the sentence to earlier.",
        "Entity": "Normal"
    },
    {
        "Text": "After source sentence positions are moved, they are marked, and the translation of the sentence is continued monotonically, keeping track of the positions already covered.",
        "Entity": "Normal"
    },
    {
        "Text": "To formalize the approach, we introduce four reordering states S:   Initial : A contiguous initial block of source positions is covered.",
        "Entity": "Normal"
    },
    {
        "Text": "Skip: A restricted number of source positions may be skipped, leaving  holes  in the monotonic traversal.",
        "Entity": "Normal"
    },
    {
        "Text": "Move : A restricted number of words may be  moved  from later in the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Cover : The sentence is traversed monotonically until the state Initial is reached.",
        "Entity": "Normal"
    },
    {
        "Text": "To formalize the approach, the following notation is introduced: rmax (C) = max c c C 110 7.\n\t\t\tyou 8.\n\t\t\ton 9.\n\t\t\tthe 10.\n\t\t\tfourth 11.\n\t\t\tof 12.",
        "Entity": "Normal"
    },
    {
        "Text": "May.",
        "Entity": "Normal"
    },
    {
        "Text": "13.\n\t\t\tnot 5.\n\t\t\tmy Cover Skip Initial 1.",
        "Entity": "Normal"
    },
    {
        "Text": "In.",
        "Entity": "Normal"
    },
    {
        "Text": "2.\n\t\t\tthis 3.\n\t\t\tcase 6.\n\t\t\tcolleague 14.\n\t\t\tvisit Move Figure 8 15.",
        "Entity": "Normal"
    },
    {
        "Text": "4.\n\t\t\tcan Order in which the English source positions are covered for the English-to-German reordering example given in Figure 7.\n\t\t\tlmin (C) = mi n c c / C u ( C ) m ( C ) w ( C ) = = = car d ({c | c  / C and c < rmax (C) }) car d ({c | c   C an d c > lmi n (C) }) rma x (C)   lmi n (C) rmax (C) is the rightmost covered and lmin (C) is the leftmost uncovered source position.",
        "Entity": "Normal"
    },
    {
        "Text": "u(C) is the number of  skipped  positions, and m(C) is the number of  moved  positions.",
        "Entity": "Normal"
    },
    {
        "Text": "The function card ( ) returns the cardinality of a set of source positions.",
        "Entity": "Normal"
    },
    {
        "Text": "The function w(C) describes the  window  size in which the word reordering takes place.",
        "Entity": "Normal"
    },
    {
        "Text": "A procedural description for the computation of the set of successor hypotheses for a given partial hypothesis (S, C, j) is given in Table 3.",
        "Entity": "Normal"
    },
    {
        "Text": "There are restrictions on the possible successor states: A partial hypothesis in state Skip cannot be expanded into a partial hypothesis in state Move and vice versa.",
        "Entity": "Normal"
    },
    {
        "Text": "If the coverage set for the newly generated hypothesis covers a contiguous initial block of source positions, the state Initial is entered.",
        "Entity": "Normal"
    },
    {
        "Text": "No other state S is considered as a successor state in this case (hence the use of the continue statement in the procedural description).",
        "Entity": "Normal"
    },
    {
        "Text": "The set of successor hypotheses Succ by which to extend the partial hypothesis (S, C, j) is computed using the constraints defined by the values for numskip, widthskip, nummove , and widthmove , as explained in the Appendix.",
        "Entity": "Normal"
    },
    {
        "Text": "In particular, a source position k is discarded for extension if the  window  restrictions are violated.",
        "Entity": "Normal"
    },
    {
        "Text": "Within the restrictions all possible successors are computed.",
        "Entity": "Normal"
    },
    {
        "Text": "It can be observed that the set of successors, as computed in Table 3, is never empty.",
        "Entity": "Normal"
    },
    {
        "Text": "111 Table 3 Procedural description to compute the set Succ of successor hypotheses by which to extend a partial hypothesis (S, C, j).",
        "Entity": "Normal"
    },
    {
        "Text": "input: partial hypothesis (S, C, j) Succ := { } for each k  / C do Set C = C  {k} if u(C ) = 0 Succ := Succ   (Initial, C , k) continue if (S = Initial) or (S = Skip) if w(C )   widthskip and u(C )   numskip Succ := Succ   (Skip, C , k) if (S = Initial) or (S = Move) if k I= lmin (C ) and w(C )   widthmove and m(C )   nummove Succ := Succ   (Move, C , k) if (S = Move) or (S = Cover) if (lmin (C ) = k) Succ := Succ   (Cover, C , k) output: set Succ of successor hypotheses There is an asymmetry between the two reordering states Move and Skip: While in state Move , the algorithm is not allowed to cover the position lmin (C).",
        "Entity": "Normal"
    },
    {
        "Text": "It must first enter the state Cover to do so.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, for the state Skip, the newly generated hypothesis always remains in the state Skip (until the state Initial is entered.)",
        "Entity": "Normal"
    },
    {
        "Text": "This is motivated by the word reordering for the German verb group.",
        "Entity": "Normal"
    },
    {
        "Text": "After the right verbal brace has been processed, no source words may be moved into the verbal brace from later in the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "There is a redundancy in the reorderings: The same reordering might be carried out using either the state Skip or Move , especially if widthskip and widthmove are about the same.",
        "Entity": "Normal"
    },
    {
        "Text": "The additional computational burden is alleviated somewhat by the fact that the pruning, as introduced in Section 3.8, does not distinguish hypotheses according to the states.",
        "Entity": "Normal"
    },
    {
        "Text": "A complexity analysis for different reordering constraints is given in Tillmann (2001).",
        "Entity": "Normal"
    },
    {
        "Text": "3.6 Word Reordering: IBM-Style Restrictions.",
        "Entity": "Normal"
    },
    {
        "Text": "We now compare the new word reordering approach with the approach used in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996).",
        "Entity": "Normal"
    },
    {
        "Text": "In the approach presented in this article, source sentence words are aligned with hypothesized target sentence words.3 When a source sentence word is aligned, we say its position is covered.",
        "Entity": "Normal"
    },
    {
        "Text": "During the search process, a partial hypothesis is extended by choosing an uncovered source sentence position, and this choice is restricted.",
        "Entity": "Normal"
    },
    {
        "Text": "Only one of the first n uncovered positions in a coverage set may be chosen, where n is set to 4.",
        "Entity": "Normal"
    },
    {
        "Text": "This choice is illustrated in Figure 9.",
        "Entity": "Normal"
    },
    {
        "Text": "In the figure, covered positions are marked by a filled circle, and uncovered positions are marked by an unfilled circle.",
        "Entity": "Normal"
    },
    {
        "Text": "Positions that may be covered next are marked by an unfilled square.",
        "Entity": "Normal"
    },
    {
        "Text": "The restrictions for a coverage set C can be expressed in terms of the expression u(C) defined in the previous section: The number of uncovered source sentence positions to the left of the rightmost covered position.",
        "Entity": "Normal"
    },
    {
        "Text": "Demanding u(C)   3, we obtain the S3 restriction 3 In Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996), a morphological analysis is carried out and word morphemes are processed.",
        "Entity": "Normal"
    },
    {
        "Text": "during the search.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we process only full-form words.",
        "Entity": "Normal"
    },
    {
        "Text": "112 uncovered position covered position uncovered position for extension 1 j J Figure 9 Illustration of the IBM-style reordering constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "introduced in the Appendix.",
        "Entity": "Normal"
    },
    {
        "Text": "An upper bound of O(E3   J4 ) for the word reordering complexity is given in Tillmann (2001).",
        "Entity": "Normal"
    },
    {
        "Text": "3.7 Empirical Complexity Calculations.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to demonstrate the complexity of the proposed reordering constraints, wehave modified our translation algorithm to show, for the different reordering con straints, the overall number of successor states generated by the algorithm given inTable 3.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of successors shown in Figure 10 is counted for a pseudotransla tion task in which a pseudo source word x is translated into the identically pseudo  target word x.",
        "Entity": "Normal"
    },
    {
        "Text": "No actual optimization is carried out; the total number of successors is simply counted as the algorithm proceeds through subsets of increasing cardinality.",
        "Entity": "Normal"
    },
    {
        "Text": "The complexity differences for the different reordering constraints result from the different number of coverage subsets C and corresponding reordering states S allowed.",
        "Entity": "Normal"
    },
    {
        "Text": "For the different reordering constraints we obtain the following results (the abbreviations MON, GE, EG, and S3 are taken from the Appendix):   MON: For this reordering restriction, a partial hypothesis is always extended by the position lmin (C), hence the number of processed arcs is J.   GE, EG: These two reordering constraints are very similar in terms of complexity: The number of word reorderings is heavily restricted in each.",
        "Entity": "Normal"
    },
    {
        "Text": "Actually, since the distance restrictions (expressed by the variables widthskip and widthmove ) apply, the complexity is linear in the length of the input sentence J.   S3: The S3 reordering constraint has a complexity close to J4 .",
        "Entity": "Normal"
    },
    {
        "Text": "Since no distance restrictions for the skipped positions apply, the overall search space is significantly larger than for the GE or EG restriction.",
        "Entity": "Normal"
    },
    {
        "Text": "113 1e+07 1e+06 \" J 4 \" \" S 3 \" \" E G \" \" G E \" \" M O N \" 100000 10000 1000 100 10 1 0 5 10 15 20 25 30 35 40 45 50 Figure 10 Number of processed arcs for the pseudotranslation task as a function of the input sentence length J (y-axis is given in log scale).",
        "Entity": "Normal"
    },
    {
        "Text": "The complexity for the four different reordering constraints MON, GE, EG, and S3 is given.",
        "Entity": "Normal"
    },
    {
        "Text": "The complexity of the S3 constraint is close to J4 .",
        "Entity": "Normal"
    },
    {
        "Text": "3.8 Beam Search Pruning Techniques.",
        "Entity": "Normal"
    },
    {
        "Text": "To speed up the search, a beam search strategy is used.",
        "Entity": "Normal"
    },
    {
        "Text": "There is a direct analogy to the data-driven search organization used in continuous-speech recognition (Ney et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1992).",
        "Entity": "Normal"
    },
    {
        "Text": "The full DP search algorithm proceeds cardinality-synchronously over subsets of source sentence positions of increasing cardinality.",
        "Entity": "Normal"
    },
    {
        "Text": "Using the beam search concept, the search can be focused on the most likely hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "The hypotheses Qe1 (e, C, j) are distinguished according to the coverage set C, with two kinds of pruning based on this coverage set: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "The coverage pruning is carried out separately for each coverage set C..\n\t\t\t2.",
        "Entity": "Normal"
    },
    {
        "Text": "The cardinality pruning is carried out jointly for all coverage sets C with.",
        "Entity": "Normal"
    },
    {
        "Text": "the same cardinality c = c(C).",
        "Entity": "Normal"
    },
    {
        "Text": "After the pruning is carried out, we retain for further consideration only hypotheses with a probability close to the maximum probability.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of surviving hypotheses is controlled by four kinds of thresholds:   the coverage pruning threshold tC   the coverage histogram threshold nC   the cardinality pruning threshold tc   the cardinality histogram threshold nc For the coverage and the cardinality pruning, the probability Qe1 (e, C, j) is adjusted to take into account the uncovered source sentence positions   = {1, ...\n\t\t\t, J}\\C.",
        "Entity": "Normal"
    },
    {
        "Text": "To make 114 this adjustment, for a source word f at an uncovered source position, we precompute an upper bound  p(f ) for the product of language model and lexicon probability:  p(f ) = max p(e e1, e11) p(f e) e11 ,e1 ,e The above optimization is carried out only over the word trigrams (e, e1, e11) that have actually been seen in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Additionally, the observation pruning described below is applied to the possible translations e of a source word f .",
        "Entity": "Normal"
    },
    {
        "Text": "The upper bound is used in the beam search concept to increase the comparability between hypotheses covering different coverage sets.",
        "Entity": "Normal"
    },
    {
        "Text": "Even more benefit from the upper bound  p(f ) can be expected if the distortion and the fertility probabilities are taken into account (Tillmann 2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Using the definition of  p(f ), the following modified probability Q  e1 (e, C, j) is used to replace the original probability Qe1 (e, C, j), and all pruning is applied to the new probability: Q  e1 (e, C, j) = Qe1 (e, C, j)   n  p(fj ) j    For the translation experiments, equation (3) is recursively evaluated over subsets of source positions of equal cardinality.",
        "Entity": "Normal"
    },
    {
        "Text": "For reasons of brevity, we omit the state descrip tion S in equation (3), since no separate pruning according to the states S is carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "The set of surviving hypotheses for each cardinality c is referred to as the beam.",
        "Entity": "Normal"
    },
    {
        "Text": "The size of the beam for cardinality c depends on the ambiguity of the translation task for that cardinality.",
        "Entity": "Normal"
    },
    {
        "Text": "To fully exploit the speedup of the DP beam search, the search space is dynamically constructed as described in Tillmann, Vogel, Ney, Zubiaga, and Sawaf (1997), rather than using a static search space.",
        "Entity": "Normal"
    },
    {
        "Text": "To carry out the pruning, the maximum probabilities with respect to each coverage set C and cardinality c are computed:   Coverage pruning: Hypotheses are distinguished according to the subset of covered positions C. The probability Q  (C) is defined: Q  ( ) = max Q  e1 (e, , j) e,e1 ,j   Cardinality pruning: Hypotheses are distinguished according to the cardinality c(C) of subsets C of covered positions.",
        "Entity": "Normal"
    },
    {
        "Text": "The probability Q  (c) is defined for all hypotheses with c(C) = c: Q  (c) = max Q  ( ) C c(C)=c The coverage pruning threshold tC and the cardinality pruning threshold tc are used to prune active hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "We call this pruning translation pruning.",
        "Entity": "Normal"
    },
    {
        "Text": "Hypotheses are pruned according to their translation probability: Q  e1 (e, C, j) < tC   Q  (C) Q  e1 (e, C, j) < tc   Q  (c) For the translation experiments presented in Section 4, the negative logarithms of the actual pruning thresholds tc and tC are reported.",
        "Entity": "Normal"
    },
    {
        "Text": "A hypothesis (e1, e, C, j) is discarded if its probability is below the corresponding threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "For the current experiments, the 115 coverage and the cardinality threshold are constant for different coverage sets C and cardinalities c. Together with the translation pruning, histogram pruning is carried out: The overall number N(C) of active hypotheses for the coverage set C and the overall number N(c) of active hypotheses for all subsets of a given cardinality may not exceed a given number; again, different numbers are used for coverage and cardinality pruning.",
        "Entity": "Normal"
    },
    {
        "Text": "The coverage histogram pruning is denoted by nC , and the cardinality histogram pruning is denoted by nc : N(C) > nC N(c) > nc If the numbers of active hypotheses for each coverage set C and cardinality c, N(C) and N(c), exceed the above thresholds, only the partial hypotheses with the highest translation probabilities are retained (e.g., we may use nC = 1,000 for the coverage histogram pruning).",
        "Entity": "Normal"
    },
    {
        "Text": "The third type of pruning conducted observation pruning: The number of words that may be produced by a source word f is limited.",
        "Entity": "Normal"
    },
    {
        "Text": "For each source language word f the list of its possible translations e is sorted according to p(f | e)   puni (e) where puni (e) is the unigram probability of the target language word e. Only the best no target words e are hypothesized during the search process (e.g., during the experiments to hypothesize, the best no = 50 words was sufficient.",
        "Entity": "Normal"
    },
    {
        "Text": "3.9 Beam Search Implementation.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we describe the implementation of the beam search algorithm presented in the previous sections and show how it is applied to the full set of IBM4 model parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "3.9.1 Baseline DP Implementation.",
        "Entity": "Normal"
    },
    {
        "Text": "The implementation described here is similar to that used in beam search speech recognition systems, as presented in Ney et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1992).",
        "Entity": "Normal"
    },
    {
        "Text": "The similarities are given mainly in the following:   The implementation is data driven.",
        "Entity": "Normal"
    },
    {
        "Text": "Both its time and memory requirements are strictly linear in the number of path hypotheses (disregarding the sorting steps explained in this section).",
        "Entity": "Normal"
    },
    {
        "Text": "The search procedure is developed to work most efficiently when the input sentences are processed mainly monotonically from left to right.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm works cardinality-synchronously, meaning that all the hypotheses that are processed cover subsets of source sentence positions of equal cardinality c.   Since full search is prohibitive, we use a beam search concept, as in speech recognition.",
        "Entity": "Normal"
    },
    {
        "Text": "We use appropriate pruning techniques in connection with our cardinality-synchronous search procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 4 shows a two-list implementation of the search algorithm given in Table 2 in which the beam pruning is included.",
        "Entity": "Normal"
    },
    {
        "Text": "The two lists are referred to as S and Snew : S is the list of hypotheses that are currently expanded, and Snew is the list of newly 116 Table 4 Two-list implementation of a DP-based search algorithm for statistical MT.",
        "Entity": "Normal"
    },
    {
        "Text": "input: source string f1     fj     fJ initial hypothesis lists: S = {($, $, { }, 0)} for each cardinality c = 1, 2, ...\n\t\t\t, J do Snew = { } for each hypothesis (e , e, C, j )   S, where j  C and |C| = c do Expand (e , e, C, j ) using probabilities p(fj | e)   p(j | j , J)   p(e | e , e ) Look up and add or update expanded hypothesis in Snew Sort hypotheses in Snew according to translation score Carry out cardinality pruning Sort hypotheses in Snew according to coverage set C and translation score Carry out coverage pruning Bookkeeping of surviving hypotheses in Snew S := Snew output: get best target word sequence eI from bookkeeping array generated hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "The search procedure processes subsets of covered source sentence positions of increasing cardinality.",
        "Entity": "Normal"
    },
    {
        "Text": "The search starts with S = {($, $, { }, 0)}, where $ denotes the sentence start symbol for the immediate two predecessor words and { } denotes the empty coverage set, in which no source position is covered yet.",
        "Entity": "Normal"
    },
    {
        "Text": "For the initial search state, the position last covered is set to 0.",
        "Entity": "Normal"
    },
    {
        "Text": "A set S of active hypotheses is expanded for each cardinality c using lexicon model, language model, and distortion model probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "The newly generated hypotheses are added to the hypothesis set Snew ; for hypotheses that are not distinguished according to our DP approach, only the best partial hypothesis is retained for further consideration.",
        "Entity": "Normal"
    },
    {
        "Text": "This so-called recombination is implemented as a set of simple lookup and update operations on the set Snew of partial hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "During the partial hypothesis extensions, an anticipated pruning is carried out: Hypotheses are discarded before they are considered for recombination and are never added to Snew .",
        "Entity": "Normal"
    },
    {
        "Text": "(The anticipated pruning is not shown in Table 4.",
        "Entity": "Normal"
    },
    {
        "Text": "It is based on the pruning thresholds described in Section 3.8.)",
        "Entity": "Normal"
    },
    {
        "Text": "After the extension of all partial hypotheses in S, a pruning step is carried out for the hypotheses in the newly generated set Snew .",
        "Entity": "Normal"
    },
    {
        "Text": "The pruning is based on two simple sorting steps on the list of partial hypotheses Snew .",
        "Entity": "Normal"
    },
    {
        "Text": "(Instead of sorting the partial hypothe ses, we might have used hashing.)",
        "Entity": "Normal"
    },
    {
        "Text": "First, the partial hypotheses are sorted according to their translation scores (within the implementation, all probabilities are converted into translation scores by taking the negative logarithm   log()).",
        "Entity": "Normal"
    },
    {
        "Text": "Cardinality prun ing can then be carried out simply by running down the list of hypotheses, starting with the maximum-probability hypothesis, and applying the cardinality thresholds.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, the partial hypotheses are sorted a second time according to their coverage set C and their translation score.",
        "Entity": "Normal"
    },
    {
        "Text": "After this sorting step, all partial hypotheses that cover the same subset of source sentence positions are located in consecutive fragments in the overall list of partial hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "Coverage pruning is carried out in a single run over the list of partial hypotheses: For each fragment corresponding to the same coverage set C, the coverage pruning threshold is applied.",
        "Entity": "Normal"
    },
    {
        "Text": "The partial hypotheses that survive the two pruning stages are then written into the so-called bookkeeping array (Ney et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1992).",
        "Entity": "Normal"
    },
    {
        "Text": "For the next expansion step, the set S is set to the newly generated list of hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the target translation is constructed from the bookkeeping array.",
        "Entity": "Normal"
    },
    {
        "Text": "117 3.9.2 Details for IBM4 Model.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we outline how the DP-based beam search approach can be carried out using the full set of IBM4 parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "(More details can be found in Tillmann [2001] or in the cited papers.)",
        "Entity": "Normal"
    },
    {
        "Text": "First, the full set of IBM4 parameters does not make the simplifying assumption given in Section 3.1, namely, that source and target sentences are of equal length: Either a target word e may be aligned with several source words (its fertility is greater than one) or a single source word may produce zero, one, or two target words, as described in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996), or both.",
        "Entity": "Normal"
    },
    {
        "Text": "Zero target words are generated if f is aligned to the  null  word e0 .",
        "Entity": "Normal"
    },
    {
        "Text": "Generating a single target word e is the regular case.",
        "Entity": "Normal"
    },
    {
        "Text": "Two target words (e1, e11) may be generated.",
        "Entity": "Normal"
    },
    {
        "Text": "The costs for generating the target word e1 are given by its fertility  (0 | e1) and the language model probability; no lexicon probability is used.",
        "Entity": "Normal"
    },
    {
        "Text": "During the experiments, we restrict ourselves to triples of target words (e, e1, e11) actually seen in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach is used for the French-to-English translation experiments presented in this article.",
        "Entity": "Normal"
    },
    {
        "Text": "Another approach for mapping a single source language word to several target language words involves preprocessing by the word-joining algorithm given in Till- mann (2001), which is similar to the approach presented in Och, Tillmann, and Ney (1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Target words are joined during a training phase, and several joined target language words are dealt with as a new lexicon entry.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach is used for the German-to-English translation experiments presented in this article.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to deal with the IBM4 fertility parameters within the DP-based concept, we adopt the distinction between open and closed hypotheses given in Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1996).",
        "Entity": "Normal"
    },
    {
        "Text": "A hypothesis is said to be open if it is to be aligned with more source positions than it currently is (i.e., at least two).",
        "Entity": "Normal"
    },
    {
        "Text": "Otherwise it is called closed.",
        "Entity": "Normal"
    },
    {
        "Text": "The difference between open and closed is used to process the input sentence one position a time (for details see Tillmann 2001).",
        "Entity": "Normal"
    },
    {
        "Text": "The word reordering restrictions and the beam search pruning techniques are directly carried over to the full set of IBM4 parameters, since they are based on restrictions on the coverage vectors C only.",
        "Entity": "Normal"
    },
    {
        "Text": "To ensure its correctness, the implementation was tested by carrying out forced alignments on 500 German-to-English training sentence pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "In a forced alignment,the source sentence f J and the target sentence eI are kept fixed, and a full search with 1 1 out reordering restrictions is carried out only over the unknown alignment aJ .",
        "Entity": "Normal"
    },
    {
        "Text": "The language model probability is divided out, and the resulting probability is compared to the Viterbi probability as obtained by the training procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "For 499 training sentencesthe Viterbi alignment probability as obtained by the forced-alignment search was exactly the same as the one produced by the training procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "In one case the forced alignment search did obtain a better Viterbi probability than the training procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation experiments are carried out for the translation directions German to English and English to German (Verbmobil task) and for the translation directions French to English and English to French (Canadian Hansards task).",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4.1 reports on the performance measures used.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4.2 shows translation results for the Verbmobil task.",
        "Entity": "Normal"
    },
    {
        "Text": "Sections 4.2.1 and 4.2.2 describe that task and the preprocessing steps applied.",
        "Entity": "Normal"
    },
    {
        "Text": "In Sections 4.2.3 through 4.2.5, the efficiency of the beam search pruning techniques is shown for German-to-English translation, as the most detailed experiments are conducted for that direction.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4.2.6 gives translation results for the translation direction English to German.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 4.3, translation results for the Canadian Hansards task are reported.",
        "Entity": "Normal"
    },
    {
        "Text": "118 4.1 Performance Measures for Translation Experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "To measure the performance of the translation methods, we use three types of au tomatic and easy-to-use measures of the translation errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Additionally, a subjective evaluation involving human judges is carried out (Niessen et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2000).",
        "Entity": "Normal"
    },
    {
        "Text": "The following evaluation criteria are employed:   WER (word error rate): The WER is computed as the minimum number of substitution, insertion, and deletion operations that have to be performed to convert the generated string into the reference target string.",
        "Entity": "Normal"
    },
    {
        "Text": "This performance criterion is widely used in speech recognition.",
        "Entity": "Normal"
    },
    {
        "Text": "The minimum is computed using a DP algorithm and is typically referred to as edit or Levenshtein distance.",
        "Entity": "Normal"
    },
    {
        "Text": "mWER (multireference WER): We use the Levenshtein distance between the automatic translation and several reference translations as a measure of the translation errors.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, on the Verbmobil TEST-331 test set, an average of six reference translations per automatic translation are available.",
        "Entity": "Normal"
    },
    {
        "Text": "The Levenshtein distance between the automatic translation and each of the reference translations is computed, and the minimum Levenshtein distance is taken.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting measure, the mWER, is more robust than the WER, which takes into account only a single reference translation.",
        "Entity": "Normal"
    },
    {
        "Text": "PER (position-independent word error rate): In the case in which only a single reference translation per sentence is available, we introduce as an additional measure the position-independent word error rate (PER).",
        "Entity": "Normal"
    },
    {
        "Text": "This measure compares the words in the two sentences without taking the word order into account.",
        "Entity": "Normal"
    },
    {
        "Text": "Words in the reference translation that have no counterpart in the translated sentence are counted as substitution errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Depending on whether the translated sentence is longer or shorter than the reference translation, the remaining words result in either insertion (if the translated sentence is longer) or deletion (if the translated sentence is shorter) errors.",
        "Entity": "Normal"
    },
    {
        "Text": "The PER is guaranteed to be less than or equal to the WER.",
        "Entity": "Normal"
    },
    {
        "Text": "The PER is more robust than the WER since it ignores translation errors due to different word order in the translated and reference sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "SSER (subjective sentence error rate): For a more fine-grained evaluation of the translation results and to check the validity of the automatic evaluation measures subjective judgments by test persons are carried out (Niessen et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2000).",
        "Entity": "Normal"
    },
    {
        "Text": "The following scale for the error count per sentence is used in these subjective evaluations: 0.0 : semantically correct and syntactically correct     :     0.5 : semantically correct and syntactically wrong     :     1.0 : semantically wrong (independent of syntax) Each translated sentence is judged by a human examiner according to the above error scale; several human judges may be involved in judging the same translated sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Subjective evaluation is carried out only for the Verbmobil TEST-147 test set.",
        "Entity": "Normal"
    },
    {
        "Text": "119 Table 5 Training and test conditions for the German-to-English Verbmobil corpus (*number of words without punctuation).",
        "Entity": "Normal"
    },
    {
        "Text": "German English Trai nin g: Se nte nc es W or ds 58,0 5 1 9 , 5 2 3 73 54 9, 92 1 W or ds* 4 1 8 , 9 7 9 45 3, 63 2 Voc abu lary : Siz e 7 , 9 1 1 4 , 6 4 8 Sin gle to ns 3 , 4 5 3 1 , 6 9 9 TEST 331: Se nte nc es W or ds 33 5 , 5 9 1 1 6 , 2 7 9 Bigram/Trigram Perplexity 84.0/68.2 49.3/38.3 TEST-147: Sentences 147 Words 1,968 2,173 Bigram/Trigram Perplexity   34.6/28.1 4.2 Verbmobil Translation Experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.1 The Task and the Corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation system is tested on the Verbmobil task(Wahlster 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "In that task, the goal is the translation of spontaneous speech in face to-face situations for an appointment scheduling domain.",
        "Entity": "Normal"
    },
    {
        "Text": "We carry out experiments for both translation directions: German to English and English to German.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the Verbmobil task is still a limited-domain task, it is rather difficult in terms of vocabulary size, namely, about 5,000 words or more for each of the two languages; second, the syntactic structures of the sentences are rather unrestricted.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the ultimate goal of the Verbmobil project is the translation of spoken language, the input used for the translation experiments reported on in this article is mainly the (more or less) correct orthographic transcription of the spoken sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, the effects of spontaneous speech are present in the corpus; the effect of speech recognition errors, however, is not covered.",
        "Entity": "Normal"
    },
    {
        "Text": "The corpus consists of 58,073 training pairs; its characteristics are given in Table 5.",
        "Entity": "Normal"
    },
    {
        "Text": "For the translation experiments, a trigram language model with a perplexity of 28.1 is used.",
        "Entity": "Normal"
    },
    {
        "Text": "The following two test corpora are used for the translation experiments: TEST-331: This test set consists of 331 test sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Only automatic evaluation is carried out on this test corpus: The WER and the mWER are computed.",
        "Entity": "Normal"
    },
    {
        "Text": "For each test sentence in the source language there is a range of acceptable reference translations (six on average) provided by a human translator, who is asked to produce word-to-word translations wherever it is possible.",
        "Entity": "Normal"
    },
    {
        "Text": "Part of the reference sentences are obtained by correcting automatic translations of the test sentences that are produced using the approach presented in this article with different reordering constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "The other part is produced from the source sentences without looking at any of their translations.",
        "Entity": "Normal"
    },
    {
        "Text": "The TEST-331 test set is used as held-out data for parameter optimization (for the language mode scaling factor and for the distortion model scaling factor).",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, the beam search experiments in which the effect of the different pruning thresholds is demonstrated are carried out on the TEST-331 test set.",
        "Entity": "Normal"
    },
    {
        "Text": "TEST-147: The second, separate test set consists of 147 test sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation results are given in terms of mWER and SSER.",
        "Entity": "Normal"
    },
    {
        "Text": "No parameter optimization 120 is carried out on the TEST-147 test set; the parameter values as obtained from the experiments on the TEST-331 test set are used.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.2 Preprocessing Steps.",
        "Entity": "Normal"
    },
    {
        "Text": "To improve the translation performance the following preprocessing steps are carried out: Categorization: We use some categorization, which consists of replacing a single word by a category.",
        "Entity": "Normal"
    },
    {
        "Text": "The only words that are replaced by a category label are proper nouns denoting German cities.",
        "Entity": "Normal"
    },
    {
        "Text": "Using the new labeled corpus, all probability models are trained anew.",
        "Entity": "Normal"
    },
    {
        "Text": "To produce translations in the  normal  language, the categories are translated by rule and are inserted into the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Word joining: Target language words are joined using a method similar to the one described in Och, Tillmann, and Ney (1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Words are joined to handle cases like the German compound noun  Zahnarzttermin  for the English  dentist s appointment,  because a single word has to be mapped to two or more target words.",
        "Entity": "Normal"
    },
    {
        "Text": "The word joining is applied only to the target language words; the source language sentences remain unchanged.",
        "Entity": "Normal"
    },
    {
        "Text": "During the search process several joined target language words may be generated by a single source language word.",
        "Entity": "Normal"
    },
    {
        "Text": "Manual lexicon: To account for unseen words in the test sentences and to obtain a greater number of focused translation probabilities p(f | e), we use a bilin gual GermanEnglish dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "For each word e in the target vocabulary, we create a list of source translations f according to this dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation probability pdic (f | e) for the dictionary entry (f , e) is defined as   1 pdic (f | e) =   Ne if (f , e) is in dictionary  0 otherwise where Ne is the number of source words listed as translations of the target word e. The dictionary probability pdic (f | e) is linearly combined with the automatically trained translation probabilities paut (f | e) to obtain smoothed probabilities p(f | e): p(f | e) = (1    )   pdic (f | e)+     paut (f | e) For the translation experiments, the value of the interpolation parameter is fixed at   = 0.5.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.3 Effect of the Scaling Factors.",
        "Entity": "Normal"
    },
    {
        "Text": "In speech recognition, in which Bayes  decision rule is applied, a language model scaling factor  LM is used; a typical value is  LM   15.",
        "Entity": "Normal"
    },
    {
        "Text": "This scaling factor is employed because the language model probabilities are more reliably estimated than the acoustic probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "Following this use of a language model scaling factor in speech recognition, such a factor is introduced into statistical MT, too.",
        "Entity": "Normal"
    },
    {
        "Text": "The optimization criterion in equation (1) is modified as follows:  eI = arg max{p(eI ) LM   p(f J | eI )} 1 I 1 1 1 1 where p(eI ) is the language model probability of the target language sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "In the experiments presented here, a trigram language model is used to compute p(eI ).",
        "Entity": "Normal"
    },
    {
        "Text": "The 121 Table 6 Computing time, mWER, and SSER for three different reordering constraints on the TEST-147 test set.",
        "Entity": "Normal"
    },
    {
        "Text": "During the translation experiments, reordered words are not allowed to cross punctuation marks.",
        "Entity": "Normal"
    },
    {
        "Text": "Re or de rin g co nst rai nt C P U ti m e [ s e c ] m W E R [ % ] S S E R [ % ] MO N 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 4 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 28 .6 GE 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 3 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 21 .0 S3 1 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 3 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 19 .9 effect of the language model scaling factor  LM is studied on the TEST-331 test set.",
        "Entity": "Normal"
    },
    {
        "Text": "A minimum mWER is obtained for  LM = 0.8, as reported in Tillmann (2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike in speech recognition, the translation model probabilities seem to be estimated as reliably as the language model probabilities in statistical MT.",
        "Entity": "Normal"
    },
    {
        "Text": "A second scaling factor  D is introduced for the distortion model probabilities p(j | j1, J).",
        "Entity": "Normal"
    },
    {
        "Text": "A minimum mWER is obtained for  D = 0.4, as reported in Tillmann (2001).",
        "Entity": "Normal"
    },
    {
        "Text": "The WER and mWER on the TEST-331 test set increase significantly, if no distortion probability is used, for the case  D = 0.0.",
        "Entity": "Normal"
    },
    {
        "Text": "The benefit of a distortion probability scaling factor of  D = 0.4 comes from the fact that otherwise, a low distortion probability might suppress long-distant word reordering that is important for German-to-English verb group reordering.",
        "Entity": "Normal"
    },
    {
        "Text": "The setting  LM = 0.8 and  D = 0.4 is used for all subsequent translation results (including the translation direction English to German).",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.4 Effect of the Word Reordering Constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 6 shows the computing time, mWER, and SSER on the TEST-147 test set as a function of three reordering constraints: MON, GE, and S3 (as discussed in the Appendix).",
        "Entity": "Normal"
    },
    {
        "Text": "The computing time is given in terms of central processing unit (CPU) time per sentence (on a 450 MHz Pentium III personal computer).",
        "Entity": "Normal"
    },
    {
        "Text": "For the SSER, it turns out that restricting the word reordering such that it may not cross punctuation marks improves translation performance significantly.",
        "Entity": "Normal"
    },
    {
        "Text": "The average length of the sentence fragments that are separated by punctuation marks is rather small: 4.5 words per fragment.",
        "Entity": "Normal"
    },
    {
        "Text": "A coverage pruning threshold 4 of tC = 5.0 and an observation pruning of no = 50 are applied during the experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "No other type of pruning is used.5 The MON constraint performs worst in terms of both mWER and SSER.",
        "Entity": "Normal"
    },
    {
        "Text": "The computing time is small, since no reordering is carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "Constraints GE and S3 perform nearly identically in terms of both mWER and SSER.",
        "Entity": "Normal"
    },
    {
        "Text": "The GE constraint, however, works about three times as fast as the S3 constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 7 shows example translations obtained under the three different reordering constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Again, the MON reordering constraint performs worst.",
        "Entity": "Normal"
    },
    {
        "Text": "In the second and third translation examples, the S3 word reordering constraint performs worse than the GE reordering constraint, since it cannot take the word reordering due to the German verb group properly into account.",
        "Entity": "Normal"
    },
    {
        "Text": "The German finite verbs bin (second example) and ko nnten (third example) are too far away from the personal pronouns ich and Sie (six 4 For the translation experiments, the negative logarithm of the actual pruning thresholds tc and tC is.",
        "Entity": "Normal"
    },
    {
        "Text": "reported; for simplicity reasons we do not change the notation.",
        "Entity": "Normal"
    },
    {
        "Text": "5 In a speech-to-speech demo system, we would use the GE reordering restriction and a slightly sharper.",
        "Entity": "Normal"
    },
    {
        "Text": "pruning in order to achieve translation times of about one second per sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "122 Table 7 Example translations for the translation direction German to English using three different reordering constraints: MON, GE, and S3.",
        "Entity": "Normal"
    },
    {
        "Text": "Input: Ja, wunderbar.",
        "Entity": "Normal"
    },
    {
        "Text": "Ko  nnen wir machen.",
        "Entity": "Normal"
    },
    {
        "Text": "MON: Yes, wonderful.",
        "Entity": "Normal"
    },
    {
        "Text": "Can we do.",
        "Entity": "Normal"
    },
    {
        "Text": "GE: Yes, wonderful.",
        "Entity": "Normal"
    },
    {
        "Text": "We can do that.",
        "Entity": "Normal"
    },
    {
        "Text": "S3: Yes, wonderful.",
        "Entity": "Normal"
    },
    {
        "Text": "We can do that.",
        "Entity": "Normal"
    },
    {
        "Text": "Input: Das ist zu knapp , weil ich ab dem dritten in Kaiserslautern bin.",
        "Entity": "Normal"
    },
    {
        "Text": "Genaugenommen nur am dritten.",
        "Entity": "Normal"
    },
    {
        "Text": "Wie wa  re es denn am a  hm Samstag, dem zehnten Februar?",
        "Entity": "Normal"
    },
    {
        "Text": "MON: That is too tight , because I from the third in Kaiserslautern.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact only on the third.",
        "Entity": "Normal"
    },
    {
        "Text": "How about a  hm Saturday , the tenth of February?",
        "Entity": "Normal"
    },
    {
        "Text": "GE: That is too tight, because I am from the third in Kaiserslautern.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact only on the third.",
        "Entity": "Normal"
    },
    {
        "Text": "A  hm how about Saturday, February the tenth?",
        "Entity": "Normal"
    },
    {
        "Text": "S3: That is too tight, from the third because I will be in Kaiserslautern.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact only on the third.",
        "Entity": "Normal"
    },
    {
        "Text": "A  hm how about Saturday, February the tenth?",
        "Entity": "Normal"
    },
    {
        "Text": "Input: Wenn Sie dann noch den siebzehnten ko  nnten, wa  re das toll, ja.",
        "Entity": "Normal"
    },
    {
        "Text": "MON: If you then also the seventeenth could, would be the great, yes.",
        "Entity": "Normal"
    },
    {
        "Text": "GE: If you could then also the seventeenth, that would be great, yes.",
        "Entity": "Normal"
    },
    {
        "Text": "S3: Then if you could even take seventeenth, that would be great, yes.",
        "Entity": "Normal"
    },
    {
        "Text": "Input: Ja, das kommt mir sehr gelegen.",
        "Entity": "Normal"
    },
    {
        "Text": "Machen wir es dann am besten so.",
        "Entity": "Normal"
    },
    {
        "Text": "MON: Yes, that suits me perfectly.",
        "Entity": "Normal"
    },
    {
        "Text": "Do we should best like that.",
        "Entity": "Normal"
    },
    {
        "Text": "GE: Yes, that suits me fine.",
        "Entity": "Normal"
    },
    {
        "Text": "We do it like that then best.",
        "Entity": "Normal"
    },
    {
        "Text": "S3: Yes, that suits me fine.",
        "Entity": "Normal"
    },
    {
        "Text": "We should best do it like that.",
        "Entity": "Normal"
    },
    {
        "Text": "and five source sentence positions, respectively) to be reordered properly.",
        "Entity": "Normal"
    },
    {
        "Text": "In the last example, the less restrictive S3 reordering constraint leads to a better translation; the GE translation is still acceptable, though.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.5 Effect of the Beam Search Pruning Thresholds.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, the effect of the beam search pruning is demonstrated.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation results on the TEST-331 test set are presented to evaluate the effectiveness of the pruning techniques.6 The quality of the search algorithm with respect to the GE and S3 reordering constraints is evaluated using two criteria: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of search errors for a certain combination of pruning.",
        "Entity": "Normal"
    },
    {
        "Text": "thresholds is counted.",
        "Entity": "Normal"
    },
    {
        "Text": "A search error occurs for a test sentence if the final translation probability QF for a candidate translation eI as given in equation (4) is smaller than a reference probability for that test sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "We will compute reference probabilities two ways, as explained below.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "The mWER performance measure is computed as a function of the.",
        "Entity": "Normal"
    },
    {
        "Text": "pruning thresholds used.",
        "Entity": "Normal"
    },
    {
        "Text": "Generally, decreasing the pruning threshold 6 The CPU times on the TEST-331 set are higher, since the average fragment length is greater than for the.",
        "Entity": "Normal"
    },
    {
        "Text": "TEST-147 set.",
        "Entity": "Normal"
    },
    {
        "Text": "123 Effect of the coverage pruning threshold tC on the number of search errors and mWER on the TEST-331 test set (no cardinality pruning carried out: tc =  ).",
        "Entity": "Normal"
    },
    {
        "Text": "A cardinality histogram pruning of 200,000 is applied to restrict the maximum overall size of the search space.",
        "Entity": "Normal"
    },
    {
        "Text": "The negative logarithm of tC is reported.",
        "Entity": "Normal"
    },
    {
        "Text": "Re or de rin g co nst rai nt t C C P U ti m e [ s e c ] S e a r c h e r r o r s Qref > QF QF  > QF m W E R [ % ] GE 0.",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 1 3 1 8 3 2 3 7 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 0.",
        "Entity": "Normal"
    },
    {
        "Text": "1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 3 2 3 1 3 0 1 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 1.",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 3 1 0 2 2 6 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 2.",
        "Entity": "Normal"
    },
    {
        "Text": "5 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 5 1 4 2 2 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "6   3 5 2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 7.",
        "Entity": "Normal"
    },
    {
        "Text": "5 1 5 6   2 2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 10.",
        "Entity": "Normal"
    },
    {
        "Text": "0 6 3 0     2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 12.",
        "Entity": "Normal"
    },
    {
        "Text": "5 1 3 0 0     2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 S3 0.",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 8 3 1 4 3 2 4 7 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 0.",
        "Entity": "Normal"
    },
    {
        "Text": "1 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 1 2 2 5 3 0 3 5 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 1.",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 4 2 2 3 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 2.",
        "Entity": "Normal"
    },
    {
        "Text": "5 1 9 0   1 2 9 2 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 8 3 0     2 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 leads to a higher word error rate, since the optimal path through the translation lattice is missed, resulting in translation errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Two automatically generated reference probabilities are used.",
        "Entity": "Normal"
    },
    {
        "Text": "These probabilities are computed separately for the reordering constraints GE and S3 (the difference is not shown in the notation, but will be clear from the context): Qref : A forced alignment is carried out between each of the test sentences and its corresponding reference translation; only a single reference translation for each test sentence is used.",
        "Entity": "Normal"
    },
    {
        "Text": "The probability obtained for the reference translation is denoted by Qref .",
        "Entity": "Normal"
    },
    {
        "Text": "QF  : A translation is carried out with conservatively large pruning thresholds, yielding a translation close to the one with the maximum translation probability.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation probability for that translation is denoted by QF  .",
        "Entity": "Normal"
    },
    {
        "Text": "First, in a series of experiments we study the effect of the coverage and cardinality pruning for the reordering constraints GE and S3.",
        "Entity": "Normal"
    },
    {
        "Text": "(When we report on the different pruning thresholds, we will show the negative logarithm of those pruning thresholds.)",
        "Entity": "Normal"
    },
    {
        "Text": "The experiments are carried out on two different pruning  dimensions : 1.",
        "Entity": "Normal"
    },
    {
        "Text": "In Table 8, only coverage pruning using threshold tC is carried out; no.",
        "Entity": "Normal"
    },
    {
        "Text": "cardinality pruning is applied: tc =  .",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "In Table 9, only cardinality pruning using threshold tc is carried out; no.",
        "Entity": "Normal"
    },
    {
        "Text": "coverage pruning is applied: tC =  .",
        "Entity": "Normal"
    },
    {
        "Text": "Both tables use an observation pruning of no = 50.",
        "Entity": "Normal"
    },
    {
        "Text": "The effect of the coverage pruning threshold tC is demonstrated in Table 8.",
        "Entity": "Normal"
    },
    {
        "Text": "For the translation experiments reportedin this table, the cardinality pruning threshold is set to tc =  ; thus, no compari son between partial hypotheses that do not cover the same set C of source sentence 124 Effect of the cardinality pruning threshold tc on the number of search errors and mWER on the TEST-331 test set (no coverage pruning is carried out: tC =  ).",
        "Entity": "Normal"
    },
    {
        "Text": "A coverage histogram pruning of 1,000 is applied to restrict the overall size of the search space.",
        "Entity": "Normal"
    },
    {
        "Text": "The negative logarithm of tc is shown.",
        "Entity": "Normal"
    },
    {
        "Text": "Re or de rin g co nst rai nt t c C P U ti m e [ s e c ] S e a r c Qre f > QF h error s QF   > QF m W E R [ % ] GE 1.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 3 4 5 2 8 7 4 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 2.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 6 2 0 2 7 7 4 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 3 1 6 2 6 6 3 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 4.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 0 6 2 3 9 3 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 5 2 2 1 2 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 7.",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "2   1 0 6 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 10.",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "2   3 2 2 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 12.",
        "Entity": "Normal"
    },
    {
        "Text": "5 4 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "2   5 2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 15.",
        "Entity": "Normal"
    },
    {
        "Text": "0 9 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "9     2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 17.",
        "Entity": "Normal"
    },
    {
        "Text": "5 1 7 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "7     2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 S3 1.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 2 1 0 3 3 1 5 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 2.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 5 1 2 8 3 4 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 3.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 0 1 2 7 4 4 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 4.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 2   2 5 1 4 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 0   2 2 7 3 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 7.",
        "Entity": "Normal"
    },
    {
        "Text": "5 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "3   1 7 1 3 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 10.",
        "Entity": "Normal"
    },
    {
        "Text": "0 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8   9 9 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 12.",
        "Entity": "Normal"
    },
    {
        "Text": "5 1 2 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "3   4 9 2 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 15.",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 3 0     2 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 positions is carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "To restrict the overall size of the search space in terms of CPU time and memory requirements, a cardinality pruning of nc = 200,000 is applied.",
        "Entity": "Normal"
    },
    {
        "Text": "As can be seen from Table 8, mWER and the number of search errors decrease significantly as the coverage pruning threshold tC increases.",
        "Entity": "Normal"
    },
    {
        "Text": "For the GE reordering constraint, mWER decreases from 73.5% to 24.9%.",
        "Entity": "Normal"
    },
    {
        "Text": "For a coverage pruning threshold tC   5.0, mWER remains nearly constant at 25.0%, although search errors still occur.",
        "Entity": "Normal"
    },
    {
        "Text": "For the S3 reordering constraint, mWER decreases from 70.0% to 28.3%.",
        "Entity": "Normal"
    },
    {
        "Text": "The largest coverage threshold tested for the S3 constraint is tC = 5.0, since for larger threshold values tC , the search procedure cannot be carried out because of memory and time restrictions.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of search errors is reduced as the coverage pruning threshold is increased.",
        "Entity": "Normal"
    },
    {
        "Text": "It turns out to be difficult to verify search errors by looking at the reference translation probabilities Qref alone.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation with the maximum translation probability seems to be quite narrowly defined.",
        "Entity": "Normal"
    },
    {
        "Text": "The coverage pruning is more effective for the GE constraint than for the S3 constraint, since the overall search space for the GE reordering is smaller.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 9 shows the effect of the cardinality pruning threshold tc on mWER when no coverage pruning is carried out (a histogram coverage pruning of 1,000 is applied to restrict the overall size of the search space).",
        "Entity": "Normal"
    },
    {
        "Text": "The cardinality threshold tc has a strong effect on mWER, which decreases significantly as the cardinality threshold tc increases.",
        "Entity": "Normal"
    },
    {
        "Text": "For the GE reordering constraint, mWER decreases from 48.5% to 24.9%; for the S3 reordering constraint, mWER decreases from 51.4% to 28.2%.",
        "Entity": "Normal"
    },
    {
        "Text": "For the coverage threshold t = 15.0, the GE constraint works about four times as fast as the S3 constraint, since the overall search space for the S3 constraint is much larger.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the overall search space is much larger for the S3 constraint, for smaller values of the coverage 125 Effect of observation pruning on the number of search errors and mWER on the TEST-331 test set (parameter setting: tc =  , tC = 10.0 ).",
        "Entity": "Normal"
    },
    {
        "Text": "No histogram pruning is applied.",
        "Entity": "Normal"
    },
    {
        "Text": "The results are reported for the GE constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "Ob ser vat ion pr un in g no C P U ti m e [ s e c ] S e a r c h e r r o r s Qref > QF QF  > QF m W E R [ % ] 1 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 3 2 8 4 2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 2 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 6 2 3 9 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 2 1 9 6 2 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 2 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 2 1 4 0 2 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 10 6 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "9   9 9 2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 25 2 3 8   4 4 2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 50 6 3 0     2 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 threshold tC   5.0, the S3 constraint works as fast as the GE constraint or even faster, because only a very small portion of the overall search space is searched for small values of the cardinality pruning threshold tc .",
        "Entity": "Normal"
    },
    {
        "Text": "There is some computational overhead in expanding a partial hypothesis for the GE constraint because the finite-state control has to be handled.",
        "Entity": "Normal"
    },
    {
        "Text": "No results are obtained for the S3 constraint and the coverage threshold tc = 17.5 because of memory restrictions.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of search errors is reduced as the cardinality pruning threshold is increased.",
        "Entity": "Normal"
    },
    {
        "Text": "Again, it is difficult to verify search errors by looking at the reference translation probabilities alone.",
        "Entity": "Normal"
    },
    {
        "Text": "Both coverage and cardinality pruning are more efficient for the GE reordering constraint than for the S3 reordering constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "For the S3 constraint, no translation results are obtained for a coverage threshold tc > 5.0 without cardinality pruning applied because of memory and computing time restrictions.",
        "Entity": "Normal"
    },
    {
        "Text": "For the GE constraint virtually a full search can be carried out where only observation pruning is applied: Identical target translations and translation probabilities are produced for the hypoth esis files for the two cases (1) tC = 10.0, tc =  , and (2) tC =  , tc = 15.0.",
        "Entity": "Normal"
    },
    {
        "Text": "(Actually, for one test sentence in the TEST-331 test set, the translations are different, although the translation probabilities are exactly the same.)",
        "Entity": "Normal"
    },
    {
        "Text": "Since the pruning is carried out independently on two different pruning dimensions, no search errors will occur if the thresholds are further increased.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 10 shows the effect of the observation pruning parameter no on mWER for the reordering constraint GE.",
        "Entity": "Normal"
    },
    {
        "Text": "mWER is significantly reduced by hypothesizing up to the best 50 target words e for a source language word f .",
        "Entity": "Normal"
    },
    {
        "Text": "mWER increases from 24.9% to 29.3% when the number of hypothesized words is decreased to only a single word.Table 11 demonstrates the effect of the combination of the coverage pruning thresh old tC = 5.0 and the cardinality pruning threshold tc = 12.5, where the actual values are found in informal experiments: In a typical setting of the two parameters tc should be at least twice as big as tC .",
        "Entity": "Normal"
    },
    {
        "Text": "For the GE reordering constraint, the average computing time is about seven seconds per sentence without any loss in translation performance as measured in terms of mWER.",
        "Entity": "Normal"
    },
    {
        "Text": "For the S3 reordering constraint, the average computing time per sentence is 27 seconds.",
        "Entity": "Normal"
    },
    {
        "Text": "Again, the combination of coverage and cardinality pruning works more efficiently for the GE constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "The memory requirement for the algorithm is about 100 MB.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.6 English-to-German Translation Experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "A series of translation experiments for the translation direction English to German are also carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "The results, given 126 Demonstration of the combination of the two pruning thresholds tC = 5.0 and tc = 12.5 to speed up the search process for the two reordering constraints GE and S3 (no = 50).",
        "Entity": "Normal"
    },
    {
        "Text": "The translation performance is shown in terms of mWER on the TEST-331 test set.",
        "Entity": "Normal"
    },
    {
        "Text": "Reordering tC tc CPU time Search errors mWER con stra int [s e c] Q ref > Q F QF  > QF [ % ] GE 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 12.",
        "Entity": "Normal"
    },
    {
        "Text": "5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 0 3 8 24 .7 S3 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 12.",
        "Entity": "Normal"
    },
    {
        "Text": "5 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 0 6 5 29 .2 Table 12 Translation results for the translation direction English to German on the TEST-331 test set.",
        "Entity": "Normal"
    },
    {
        "Text": "The results are given in terms of computing time, WER, and PER for three different reordering constraints: MON, EG, and S3.",
        "Entity": "Normal"
    },
    {
        "Text": "Re or de rin g co nst rai nt C P U ti m e [ s e c ] W E R [ % ] P E R [ % ] MO N 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 70 .6 57.",
        "Entity": "Normal"
    },
    {
        "Text": "0 EG 1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 70 .1 55.",
        "Entity": "Normal"
    },
    {
        "Text": "9 S3 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 70 .1 55.",
        "Entity": "Normal"
    },
    {
        "Text": "8 in terms of WER and PER, are shown in Table 12.",
        "Entity": "Normal"
    },
    {
        "Text": "For the English-to-German translation direction, a single reference translation for each test sentence is used to carry out the automatic evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation task for the translation direction English to German is more difficult than for the translation direction German to English; the trigram language model perplexity increases from 38.3 to 68.2 on the TEST-331 test set, as can be seen in Table 5.",
        "Entity": "Normal"
    },
    {
        "Text": "No parameter optimization is carried out for this translation direction; the parameter settings are carried over from the results obtained in Table 11.",
        "Entity": "Normal"
    },
    {
        "Text": "The word error rates for the translation direction English to German are significantly higher than those for the translation direction German to English.",
        "Entity": "Normal"
    },
    {
        "Text": "There are several reasons for this: German vocabulary and perplexity are significantly larger than those for English, and only a single reference translation per test sentence is available for English-to-German translation.",
        "Entity": "Normal"
    },
    {
        "Text": "There is only a very small difference in terms of word error rates for the reordering constraints EG and S3; in particular, WER is 70.1% for both.",
        "Entity": "Normal"
    },
    {
        "Text": "The reordering constraint MON performs slightly worse: WER increases to 70.6%, and PER increases to 57.0%.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 13 shows translation examples for the translation direction English to German.",
        "Entity": "Normal"
    },
    {
        "Text": "The MON constraint performs worst; there is no significant difference in quality of translations produced under the EG and the S3 constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Canadian Hansards Translation Experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3.1 The Task and the Corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The second corpus on which we perform translationexperiments is the Hansard corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "By law, the proceedings of the Canadian parliament are recorded in both French and English.",
        "Entity": "Normal"
    },
    {
        "Text": "(For historical reasons, these proceed ings are called  Hansards. )",
        "Entity": "Normal"
    },
    {
        "Text": "The remarks of the parliament members are written down in whichever of the two languages they use.",
        "Entity": "Normal"
    },
    {
        "Text": "They are then translated into the other language to produce complete sets of the proceedings, one in French and the other in English.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting bilingual data have been sentence-aligned using statistical methods (Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1990).",
        "Entity": "Normal"
    },
    {
        "Text": "Originally, about three million sentences were selected.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we use a subset of the original training data; the details regarding this subset 127 Example translations for the translation direction English to German using three different reordering constraints: MON, EG, and S3.",
        "Entity": "Normal"
    },
    {
        "Text": "Input: Yeah , that wouldn t be bad.",
        "Entity": "Normal"
    },
    {
        "Text": "Do you have any ideas where I could stay?",
        "Entity": "Normal"
    },
    {
        "Text": "MON: Ja, das wa  re schade.",
        "Entity": "Normal"
    },
    {
        "Text": "Haben Sie irgendwelche Ideen wo ich ko  nnten u  bernachten?",
        "Entity": "Normal"
    },
    {
        "Text": "EG: Ja, das wa  re nicht schlecht.",
        "Entity": "Normal"
    },
    {
        "Text": "Haben Sie irgendwelche Ideen wo wir wohnen ko  nnten?",
        "Entity": "Normal"
    },
    {
        "Text": "S3: Ja, das wa  re nicht schlecht.",
        "Entity": "Normal"
    },
    {
        "Text": "Haben Sie irgendwelche Ideen wo wir wohnen ko  nnten?",
        "Entity": "Normal"
    },
    {
        "Text": "Input: Oh, that sounds great .",
        "Entity": "Normal"
    },
    {
        "Text": "Could you arrange a suite for me?",
        "Entity": "Normal"
    },
    {
        "Text": "MON: Oh, das klingt gut.",
        "Entity": "Normal"
    },
    {
        "Text": "Ko  nnten Sie unbedingt ein Suite bei mir?",
        "Entity": "Normal"
    },
    {
        "Text": "EG: Oh, das klingt gut.",
        "Entity": "Normal"
    },
    {
        "Text": "Ko  nnten Sie einen Suite ausmachen fu  r mich?",
        "Entity": "Normal"
    },
    {
        "Text": "S3: Oh, das klingt gut.",
        "Entity": "Normal"
    },
    {
        "Text": "Ko  nnten Sie mir einen Suite ausmachen?",
        "Entity": "Normal"
    },
    {
        "Text": "Input: Well, I still need your signature here and then I will check with your company.",
        "Entity": "Normal"
    },
    {
        "Text": "MON: Also, ich konnte Arbeitskraft Unterschrift hier und ich werde nachsehen mit Ihrer Firma.",
        "Entity": "Normal"
    },
    {
        "Text": "EG: Also, ich bra  uchte noch Ihre Unterschrift und dann gucke ich hier mit Ihrer Firma.",
        "Entity": "Normal"
    },
    {
        "Text": "S3: Also, ich brauche hier noch Ihre Unterschrift und dann werde ich veranlassen mit Ihrer Firma.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 14 Training and test conditions for the Hansards task (*number of words without punctuation).",
        "Entity": "Normal"
    },
    {
        "Text": "French English Train: Sentences 1,470,473 W or ds 2 4 , 3 3 8 , 1 9 5 22 ,1 63 ,0 92 W or ds* 2 2 , 1 7 5 , 0 6 9 20 ,0 63 ,3 78 Voc abu lary : Siz e 1 0 0 , 2 6 9 7 8 , 3 3 2 Sin gle to ns 4 0 , 1 9 9 3 1 , 3 1 9 Test: Sentences 5,432 Words 97,646 80,559 Bigr./Tri.",
        "Entity": "Normal"
    },
    {
        "Text": "Perplexity 196.9/121.8 269.9/179.8 are given in Table 14.",
        "Entity": "Normal"
    },
    {
        "Text": "The Hansards corpus presents by far a more difficult task than the Verbmobil corpus in terms of vocabulary size and number of training sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "The training and test sentences are less restrictive than for the Verbmobil task.",
        "Entity": "Normal"
    },
    {
        "Text": "For the translation experiments on the Hansards corpus, no word joining is carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "Two target words can be produced by a single source word, as described in Section 3.9.2.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3.2 Translation Results.",
        "Entity": "Normal"
    },
    {
        "Text": "As can be seen in Table 15 for the translation direction French to English and in Table 16 for the translation direction English to French, the word error rates are rather high compared to those for the Verbmobil task.",
        "Entity": "Normal"
    },
    {
        "Text": "The reason for the higher error rates is that, as noted in the previous section, the Hansards task is by far less restrictive than the Verbmobil task, and the vocabulary size is much 128 Computing time, WER, and PER for the translation direction French to English using the two reordering constraints MON and S3.",
        "Entity": "Normal"
    },
    {
        "Text": "An almost  full  search is carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "Reordering CPU time WER PER con stra int [ s e c ] [ % ] [ % ] MO N 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 6 5.",
        "Entity": "Normal"
    },
    {
        "Text": "5 53.",
        "Entity": "Normal"
    },
    {
        "Text": "0 S3 5 8 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 6 4.",
        "Entity": "Normal"
    },
    {
        "Text": "9 51.",
        "Entity": "Normal"
    },
    {
        "Text": "4 Table 16 Computing time, WER, and PER for the translation direction English to French using the two reordering constraints MON and S3.",
        "Entity": "Normal"
    },
    {
        "Text": "An almost  full  search is carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "Reordering CPU time WER PER con stra int [ s e c ] [ % ] [ % ] MO N 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 6 6.",
        "Entity": "Normal"
    },
    {
        "Text": "6 56.",
        "Entity": "Normal"
    },
    {
        "Text": "3 S3 1 8 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 6 6.",
        "Entity": "Normal"
    },
    {
        "Text": "0 54.",
        "Entity": "Normal"
    },
    {
        "Text": "4 larger.",
        "Entity": "Normal"
    },
    {
        "Text": "There is only a slight difference in performance between the MON and the S3 reordering constraints on the Hansards task.",
        "Entity": "Normal"
    },
    {
        "Text": "The computation time is also rather high compared to the Verbmobil task: For the S3 constraint, the average translation time is about 3 minutes per sentence for the translation direction English to French and about 10 minutes per sentence for the translation direction French to English.",
        "Entity": "Normal"
    },
    {
        "Text": "The following parameter setting is used for the experiment conducted here: tC = 5.0, tc = 10.0, nC = 250, and to = 12.",
        "Entity": "Normal"
    },
    {
        "Text": "(The actual parameters are chosen in informal experiments to obtain reasonable CPU times while permitting only a small number of search errors.)",
        "Entity": "Normal"
    },
    {
        "Text": "No cardinality histogram pruning is carried out.",
        "Entity": "Normal"
    },
    {
        "Text": "As for the German- to-English translation experiments, word reordering is restricted so that it may not cross punctuation boundaries.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting fragment lengths are much larger for the translation direction English to French, and still larger for the translation direction French to English, when compared to the fragment lengths for the translation direction German to English, hence the high CPU times.",
        "Entity": "Normal"
    },
    {
        "Text": "In an additional experiment for the translation direction French to English and the reordering constraint S3, we find we can speed up the translation time to about 18 seconds per sentence by using the following parameter setting: tC = 3.0, tc = 7.5, nC = 20, nc = 400, and no = 5.",
        "Entity": "Normal"
    },
    {
        "Text": "For the resulting hypotheses file, PER increases only slightly, from 51.4% to 51.6%.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation examples for the translation direction French to English under the S3 reordering constraint are given in Table 17.",
        "Entity": "Normal"
    },
    {
        "Text": "The French input sentences show some preprocessing that is carried out beforehand to simplify the translation task (e.g., des is transformed into de les and l est is transformed into le est).",
        "Entity": "Normal"
    },
    {
        "Text": "The translations produced are rather approximative in some cases, although the general meaning is often preserved.",
        "Entity": "Normal"
    },
    {
        "Text": "We have presented a DP-based beam search algorithm for the IBM4 translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "The approach is based on a DP solution to the TSP, and it gains efficiency by imposing constraints on the allowed word reorderings between source and target language.",
        "Entity": "Normal"
    },
    {
        "Text": "A data-driven search organization in conjunction with appropriate pruning techniques 129 Example translations for the translation direction French to English using the S3 reordering constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "Input Je crois que cela donne une bonne ide  e de les principes a` retenir et de ce que devraient e  tre nos responsabilite  s. S3 I think it is a good idea of the principles and to what should be our responsibility.",
        "Entity": "Normal"
    },
    {
        "Text": "Input Je pense que, inde  pendamment de notre parti, nous trouvons tous cela inacceptable.",
        "Entity": "Normal"
    },
    {
        "Text": "S3 I think, regardless of our party, we find that unacceptable.",
        "Entity": "Normal"
    },
    {
        "Text": "Input Je ai le intention de parler surtout aujourd  hui de les nombreuses ame  liorations apporte  es a` les programmes de pensions de tous les Canadiens.",
        "Entity": "Normal"
    },
    {
        "Text": "S3 I have the intention of speaking today about the many improvements in pensions for all Canadians especially those programs.",
        "Entity": "Normal"
    },
    {
        "Text": "Input Chacun en lui - me  me est tre` s complexe et le lien entre les deux le est encore davantage de sorte que pour beaucoup la situation pre  sente est confuse.",
        "Entity": "Normal"
    },
    {
        "Text": "S3 Each in itself is very complex and the relationship between the two is more so much for the present situation is confused.",
        "Entity": "Normal"
    },
    {
        "Text": "is proposed.",
        "Entity": "Normal"
    },
    {
        "Text": "For the medium-sized Verbmobil task, a sentence can be translated in a few seconds on average, with a small number of search errors and no performance degradation as measured by the word error criterion used.",
        "Entity": "Normal"
    },
    {
        "Text": "Word reordering is parameterized using a set of four parameters, in such a way that it can easily be adopted to new translation directions.",
        "Entity": "Normal"
    },
    {
        "Text": "A finite-state control is added, and its usefulness is demonstrated for the translation direction German to English, in which the word order difference between the two languages is mainly due to the German verb group.",
        "Entity": "Normal"
    },
    {
        "Text": "Future work might aim at a tighter integration of the IBM4 model distortion probabilities and the finite-state control; the finite-state control itself may be learned from training data.",
        "Entity": "Normal"
    },
    {
        "Text": "The applicability of the algorithm applied in the experiments in this article is not restricted to the IBM translation models or to the simplified translation model used in the description of the algorithm in Section 3.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the efficiency of the beam search approach is based on restrictions on the allowed coverage vectors C alone, the approach may be used for different types of translation models as well (e.g., for the multiword-based translation model proposed in Och, Tillmann, and Ney [1999]).",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, since the decoding problem for the IBM4 translation model is provably NP-complete, as shown in Knight (1999) and Germann et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2001), wordreordering restrictions as introduced in this article are essential for obtaining an effi cient search algorithm that guarantees that a solution close to the optimal one will be found.",
        "Entity": "Normal"
    },
    {
        "Text": "Appendix: Quantification of Reordering Restrictions To quantify the reordering restrictions in Section 3.5, the four non-negative numbers numskip, widthskip, nummove , and widthmove are used (width skip corresponds to L, widthmove corresponds to R in Section 3.4; here, we use a more intuitive notation).",
        "Entity": "Normal"
    },
    {
        "Text": "Within the implementation of the DP search, the restrictions are provided to the 130 algorithm as an input parameter of the following type: S numskip widthskip M nummove widthmove The meaning of the reordering string is as follows: The two numbers following S that are separated by an underscore describe the way words may be skipped; the two numbers following M that are separated by an underscore describe the way words may be moved during word reordering.",
        "Entity": "Normal"
    },
    {
        "Text": "The first number after S and M denotes the number of positions that may be skipped or moved, respectively (e.g., for the translation direction German to English [GE in the chart below], one position may be skipped and two positions may be moved).",
        "Entity": "Normal"
    },
    {
        "Text": "The second number after S and M restricts the distance a word may be skipped or moved, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "These  width  parameters restrict the word reordering to take place within a  window  of a certain size, established by the distance between the positions lmin (C) and rmax (C) as defined in Section 3.5.",
        "Entity": "Normal"
    },
    {
        "Text": "In the notation, either the substring headed by S or that headed by M (or both) may be omitted altogether to indicate that the corresponding reordering is not allowed.",
        "Entity": "Normal"
    },
    {
        "Text": "Any numerical value in the string may be set to INF, denoting that an arbitrary number of positions may be skipped/moved or that the moving or skipping distance may be arbitrarily large.",
        "Entity": "Normal"
    },
    {
        "Text": "The following reordering strings are used in this article: Word reordering Description string E The empty string denotes the reordering restriction in which (short: MON) no reordering is allowed.",
        "Entity": "Normal"
    },
    {
        "Text": "S 01 04 M 02 10 This string describes the German-to-English word reordering.",
        "Entity": "Normal"
    },
    {
        "Text": "(short: GE) Up to one word may be skipped for at most 4 positions, and up to two words may be moved up to 10 positions.",
        "Entity": "Normal"
    },
    {
        "Text": "S 02 10 M 01 04 This string describes the English-to-German word reordering.",
        "Entity": "Normal"
    },
    {
        "Text": "(short: EG) Up to two words may be skipped for at most 10 positions and up to one word may be moved for up to 4 positions.",
        "Entity": "Normal"
    },
    {
        "Text": "S 03 INF This string describes the IBM-style word reordering (short: S3) given in Section 3.6.",
        "Entity": "Normal"
    },
    {
        "Text": "Up to three words may be skipped for an unrestricted number of positions.",
        "Entity": "Normal"
    },
    {
        "Text": "No words may be moved.",
        "Entity": "Normal"
    },
    {
        "Text": "S INF INF or These strings denote the word reordering without M INF INF restrictions.",
        "Entity": "Normal"
    },
    {
        "Text": "(short: NO) The word reordering strings can be directly used as input parameters to the DP-based search procedure to test different reordering restrictions within a single implementation.",
        "Entity": "Normal"
    },
    {
        "Text": "This work has been supported as part of the Verbmobil project (contract number 01 IV 601 A) by the German Federal.",
        "Entity": "Normal"
    },
    {
        "Text": "Ministry of Education, Science, Research and Technology and as part of the Eutrans 131 project (ESPRIT project number 30268) by the European Community.",
        "Entity": "Normal"
    },
    {
        "Text": "Some of the experiments on the Canadian Hansards task have been carried out by Nicola Ueffing using the existing implementation of the search algorithm (Och, Ueffing, and Ney [2001]).",
        "Entity": "Normal"
    },
    {
        "Text": "We would like to thank the anonymous reviewers for their detailed comments on an earlier version of this article.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, we would like to thank Niyu Ge, Scott McCarley, Salim Roukos, Nicola Ueffing, and Todd Ward for their valuable remarks.",
        "Entity": "Normal"
    },
    {
        "Text": "\nText Segmentation Using Reiteration and Collocation\n\t\n\t\tA method is presented for segmenting text into subtopic areas.",
        "Entity": "Normal"
    },
    {
        "Text": "The proportion of related pairwise words is calculated between adjacent windows of text to determine their lexical similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "The lexical cohesion relations of reiteration and collocation are used to identify related words.",
        "Entity": "Normal"
    },
    {
        "Text": "These relations are automatically located using a combination of three linguistic features: word repetition, collocation and relation weights.",
        "Entity": "Normal"
    },
    {
        "Text": "This method is shown to successfully detect known subject changes in text and corresponds well to the segmentations placed by test subjects.",
        "Entity": "Normal"
    },
    {
        "Text": "Many examples of heterogeneous data can be found in daily life.",
        "Entity": "Normal"
    },
    {
        "Text": "The Wall Street Journal archives, for example, consist of a series of articles about different subject areas.",
        "Entity": "Normal"
    },
    {
        "Text": "Segmenting such data into distinct topics is useful for information retrieval, where only those segments relevant to a user's query can be retrieved.",
        "Entity": "Normal"
    },
    {
        "Text": "Text segmentation could also be used as a pre-processing step in automatic summarisation.",
        "Entity": "Normal"
    },
    {
        "Text": "Each segment could be summarised individually and then combined to provide an abstract for a document.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous work on text segmentation has used term matching to identify clusters of related text.",
        "Entity": "Normal"
    },
    {
        "Text": "Salton and Buckley (1992) and later, Hearst (1994) extracted related text pmtions by matching high frequency terms.",
        "Entity": "Normal"
    },
    {
        "Text": "Yaari ( 1997) segmented text into a hierarchical structure, identifying sub-segments of larger segments.",
        "Entity": "Normal"
    },
    {
        "Text": "Ponte and Croft ( 1997) used word co-occurrences to expand the number of terms for matching.",
        "Entity": "Normal"
    },
    {
        "Text": "Reynar ( 1994) compared all Lindsay J. Evett Department of Computing Nottingham Trent University Nottingham NGI 4BU, UK lje@doc.ntu.ac.uk words across a text rather than the more usual nearest neighbours.",
        "Entity": "Normal"
    },
    {
        "Text": "A problem with using word repetition is that inappropriate matches can be made because of the lack of contextual information (Salton et al., 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Another approach to text segmentation is the detection of semantically related words.",
        "Entity": "Normal"
    },
    {
        "Text": "Hearst (1993) incorporated semantic information derived from WordNet but in later work reported that this information actually degraded word repetition results (Hearst, 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Related words have been located using spreading activation on a semantic network (Kozima, 1993), although only one text was segmented.",
        "Entity": "Normal"
    },
    {
        "Text": "Another approach extracted semantic information from Roget's Thesaurus (RT).",
        "Entity": "Normal"
    },
    {
        "Text": "Lexical cohesion relations (Halliday and Hasan, 1976) between words were identified in RT and used to construct lexical chains of related words in five texts (Morris and Hirst, 1991 ).",
        "Entity": "Normal"
    },
    {
        "Text": "It was reported that the lexical chains closely correlated to the intentional structure (Grosz and Sidner, 1986) of the texts, where the start and end of chains coincided with the intention ranges.",
        "Entity": "Normal"
    },
    {
        "Text": "However, RT does not capture all types of lexical cohesion relations.",
        "Entity": "Normal"
    },
    {
        "Text": "In previous work, it was found that collocation (a lexical cohesion relation) was under-represented in the thesaurus.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, this process was not automated and relied on subjective decision making.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Morris and Hirst's work, a segmentation algorithm was developed based on identifying lexical cohesion relations across a text.",
        "Entity": "Normal"
    },
    {
        "Text": "The proposed algorithm is fully automated, and a quantitative measure of the association between words is calculated.",
        "Entity": "Normal"
    },
    {
        "Text": "This algorithm utilises linguistic features additional to those captured in the thesaurus to identify the other types of lexical cohesion relations that can exist in text.",
        "Entity": "Normal"
    },
    {
        "Text": "1 Background Theory: Lexical Cohesion.",
        "Entity": "Normal"
    },
    {
        "Text": "Cohesion concerns how words in a text are related.",
        "Entity": "Normal"
    },
    {
        "Text": "The major work on cohesion in English was conducted by Halliday and Hasan (1976).",
        "Entity": "Normal"
    },
    {
        "Text": "An instance of cohesion between a pair of elements is referred to as a tie.",
        "Entity": "Normal"
    },
    {
        "Text": "Ties can be anaphoric or cataphoric, and located at both the sentential and suprasentential level.",
        "Entity": "Normal"
    },
    {
        "Text": "Halliday and Hasan classified cohesion under two types: grammatical and lexical.",
        "Entity": "Normal"
    },
    {
        "Text": "Grammatical cohesion is expressed through the grammatical relations in text such as ellipsis and conjunction.",
        "Entity": "Normal"
    },
    {
        "Text": "Lexical cohesion is expressed through the vocabulary used in text and the semantic relations between those words.",
        "Entity": "Normal"
    },
    {
        "Text": "Identifying semantic relations in a text can be a useful indicator of its conceptual structure.",
        "Entity": "Normal"
    },
    {
        "Text": "Lexical cohesion is divided into three classes: general noun, reiteration and collocation.",
        "Entity": "Normal"
    },
    {
        "Text": "General noun's cohesive function is both grammatical and lexical, although Halliday and Hasan's analysis showed that this class plays a minor cohesive role.",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, it was not further considered.",
        "Entity": "Normal"
    },
    {
        "Text": "Reiteration is subdivided into four cohesive effects: word repetition (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "ascent and ascent), synonym (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "ascent and climb) which includes near-synonym and hyponym, superordinate (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "ascent and task) and general word (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "ascent and thing).",
        "Entity": "Normal"
    },
    {
        "Text": "The effect of general word is difficult to automatically identify because no common referent exists between the general word and the word to which it refers.",
        "Entity": "Normal"
    },
    {
        "Text": "A collocation is a predisposed combination of words, typically pairwise words, that tend to regularly co-occur (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "orange and peel).",
        "Entity": "Normal"
    },
    {
        "Text": "All semantic relations not classified under the class of reiteration are attributed to the class of collocation.",
        "Entity": "Normal"
    },
    {
        "Text": "To automatically detect lexical cohesion tics between pairwise words, three linguistic features were considered: word repetition, collocation and relation weights.",
        "Entity": "Normal"
    },
    {
        "Text": "The first two methods represent lexical cohesion relations.",
        "Entity": "Normal"
    },
    {
        "Text": "Word repetition is a component of the lexical cohesion class of reiteration, and collocation is a lexical cohesion class in its entirety.",
        "Entity": "Normal"
    },
    {
        "Text": "The remaining types of lexical cohesion considered, include synonym and superordinate (the cohesive effect of general word was not included).",
        "Entity": "Normal"
    },
    {
        "Text": "These types can be identified using relation weights (Jobbins and Evett, 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "Word repetition: Word repetition ties in lexical cohesion are identified by same word matches and matches on inflections derived from the same stem.",
        "Entity": "Normal"
    },
    {
        "Text": "An inflected word was reduced to its stem by look\u00ad up in a lexicon (Keenan and Evett, 1989) comprising inflection and stem word pair records (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "\"orange oranges\").",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "o                                                      \n\t\t\t                                    .",
        "Entity": "Normal"
    },
    {
        "Text": "Relation Weights: Relation weights quantify the amount of semantic relation between words based on the lexical organisation of RT (Jobbins and Evett, 1995).",
        "Entity": "Normal"
    },
    {
        "Text": "A thesaurus is a collection of synonym groups, indicating that synonym relations are captured, and the hierarchical structure of RT implies that superordinate relations are also captured.",
        "Entity": "Normal"
    },
    {
        "Text": "An alphabetically-ordered index of RT was generated, referred to as the Thesaurus Lexicon (TLex).",
        "Entity": "Normal"
    },
    {
        "Text": "Relation weights for pairwise words are calculated based on the satisfaction of one or more of four possible connections in TLex.",
        "Entity": "Normal"
    },
    {
        "Text": "The proposed segmentation algorithm compares adjacent windows of sentences and determines their lexical similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "A window size of three sentences was found to produce the best results.",
        "Entity": "Normal"
    },
    {
        "Text": "Multiple sentences were compared because calculating lexical similarity between words is too fine (Rotondo, 1984) and between individual sentences is unreliable (Salton and Buckley, 1991).",
        "Entity": "Normal"
    },
    {
        "Text": "Lexical similarity is calculated for each window comparison based on the proportion of related words, and is given as a normalised score.",
        "Entity": "Normal"
    },
    {
        "Text": "Word repetitions are identified between identical words and words derived from the same stem.",
        "Entity": "Normal"
    },
    {
        "Text": "troughs placed subject change linguistic feature points located average std.",
        "Entity": "Normal"
    },
    {
        "Text": "dev.",
        "Entity": "Normal"
    },
    {
        "Text": "(out of 42 poss.)",
        "Entity": "Normal"
    },
    {
        "Text": "word repetition 7.1 3.16 41 collocation (97.6%) word repetition 7.3 5.22 41 relation weights (97.6%) 41 Collocations are located by looking up word pairs in the collocation lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "Relation weights are word repetition 8.5 3.62 (97.6%) calculated between pairwise words according to their location in RT.",
        "Entity": "Normal"
    },
    {
        "Text": "The lexical similarity score indicates the amount of lexical cohesion demonstrated by two windows.",
        "Entity": "Normal"
    },
    {
        "Text": "Scores plotted on a graph show a series of peaks (high scores) and troughs (low scores).",
        "Entity": "Normal"
    },
    {
        "Text": "Low scores indicate a weak collocation 5.8 3.70 40 relation weights (95.2%) word repetition 40 collocation 6.4 4.72 (95.2%) relation weights 39 level of cohesion.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, a trough signals a potential subject change and texts can be relation weights 7 4.23 (92.9%) segmented at these points.",
        "Entity": "Normal"
    },
    {
        "Text": "An investigation was conducted to determine whether the segmentation algorithm could reliably locate subject change in text.",
        "Entity": "Normal"
    },
    {
        "Text": "Method: Seven topical articles of between 250 to 450 words in length were extracted from the World Wide Web.",
        "Entity": "Normal"
    },
    {
        "Text": "A total of 42 texts for test data were generated by concatenating pairs of these articles.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, each generated text consisted of two articles.",
        "Entity": "Normal"
    },
    {
        "Text": "The transition from the first article to the second represented a known subject change point.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous work has identified the breaks between concatenated texts to evaluate the performance of text segmentation algorithms (Reynar, 1994; Stairmand, 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "For each text, the troughs placed by the segmentation algorithm were compared to the location of the known subject change point in that text.",
        "Entity": "Normal"
    },
    {
        "Text": "An error margin of one sentence either side of this point, determined by empirical analysis, was allowed.",
        "Entity": "Normal"
    },
    {
        "Text": "collocation 6.3 3.83 35 (83.3%)          /S>\n\t\t\t                                                                         \n\t\t\tDiscussion: The segmentation algorithm using the linguistic features word repetition and collocation in combination achieved the best result.",
        "Entity": "Normal"
    },
    {
        "Text": "A total of 41 out of a possible 42 known subject change points were identified from the least number of troughs placed per text (7.I).",
        "Entity": "Normal"
    },
    {
        "Text": "For the text where the known subject change point went undetected, a total of three troughs were placed at sentences 6, 11 and 18.",
        "Entity": "Normal"
    },
    {
        "Text": "The subject change point occurred at sentence 13, just two sentences after a predicted subject change at sentence 11.",
        "Entity": "Normal"
    },
    {
        "Text": "In this investigation, word repetition alone achieved better results than using either collocation or relation weights individually.",
        "Entity": "Normal"
    },
    {
        "Text": "The combination of word repetition with another linguistic feature improved on its individual result, where less troughs were placed per text.",
        "Entity": "Normal"
    },
    {
        "Text": "ECTION>\n\t\n\t\t\tThe objective of the current investigation was to determine whether all troughs coincide with a subject change.",
        "Entity": "Normal"
    },
    {
        "Text": "The troughs placed by the algorithm were compared to the segmentations identified by test subjects for the same texts.",
        "Entity": "Normal"
    },
    {
        "Text": "Method: Twenty texts were randomly selected for test data each consisting of approximately 500 words.",
        "Entity": "Normal"
    },
    {
        "Text": "These texts were presented to seven test subjects who were instructed to identify the sentences at which a new subject area commenced.",
        "Entity": "Normal"
    },
    {
        "Text": "No restriction was placed on the number of subject changes that could be identified.",
        "Entity": "Normal"
    },
    {
        "Text": "Segmentation points, indicating a change of subject, were determined by the agreement of three or more test subjects (Litman ami Passonneau, 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "Adjacent segmentation points were treated as one point because it is likely that they refer to the same subject change.",
        "Entity": "Normal"
    },
    {
        "Text": "The troughs placed by the segmentation algorithm were compared to the segmentation points identified by the test subjects.",
        "Entity": "Normal"
    },
    {
        "Text": "In Experiment 1, the top five approaches investigated identified at least 40 out of 42 known subject change points.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to that success, these five approaches were applied in this experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "To evaluate the results, the information retrieval metrics precision and recall were used.",
        "Entity": "Normal"
    },
    {
        "Text": "These metrics have tended to be adopted for the assessment of text segmentation algorithms, but they do not provide a scale of correctness (Beeferman et al., 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "The degree to which a segmentation point was missed by a trough, for instance, is not considered.",
        "Entity": "Normal"
    },
    {
        "Text": "Allowing an error margin provides some degree of flexibility.",
        "Entity": "Normal"
    },
    {
        "Text": "An error margin of two sentences either side of a segmentation point was used by Hearst (1993) and Reynar ( 1994) allowed three sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "In this investigation, an error margin of two sentences was considered.",
        "Entity": "Normal"
    },
    {
        "Text": "Results:                                                                                                                                                                              .",
        "Entity": "Normal"
    },
    {
        "Text": "Discussion: The segmentation algorithm usmg word repetition and relation weights in combination achieved mean precision and recall rates of 0.80 and 0.69, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "For 9 out of the 20 texts segmented, all troughs were relevant.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, many of the troughs placed by the segmentation algorithm represented valid subject Table 2.",
        "Entity": "Normal"
    },
    {
        "Text": "Comparison of troughs to segmentation points placed by the test subjects.",
        "Entity": "Normal"
    },
    {
        "Text": "changes.",
        "Entity": "Normal"
    },
    {
        "Text": "Both word repetition in combination with collocation and all three features in combination also achieved a precision rate of 0.80 but attained a lower recall rate of 0.62.",
        "Entity": "Normal"
    },
    {
        "Text": "These results demonstrate that supplementing word repetition with other linguistic features can improve text segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, a text segmentation algorithm developed by Hearst ( 1994) based on word repetition alone attained inferior precision and recall rates of 0.66 and 0.61.",
        "Entity": "Normal"
    },
    {
        "Text": "In this investigation, recall rates tended to be lower than precision rates because the algorithm identified fewer segments (4.1 per text) than the test subjects (4.5).",
        "Entity": "Normal"
    },
    {
        "Text": "Each text was only 500 words in length and was related to a specific subject area.",
        "Entity": "Normal"
    },
    {
        "Text": "These factors limited the degree of subject change that occurred.",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, the test subjects tended to identify subject changes that were more subtle than the algorithm could detect.",
        "Entity": "Normal"
    },
    {
        "Text": "Conclusion The text segmentation algorithm developed used three linguistic features to automatically detect lexical cohesion relations across windows.",
        "Entity": "Normal"
    },
    {
        "Text": "The combination of features word repetition and relation weights produced the best precision and recall rates of 0.80 and 0.69.",
        "Entity": "Normal"
    },
    {
        "Text": "When used in isolation, the performance of each feature was inferior to a combined approach.",
        "Entity": "Normal"
    },
    {
        "Text": "This fact provides evidence that different lexical relations are detected by each linguistic feature considered.",
        "Entity": "Normal"
    },
    {
        "Text": "Areas for improving the segmentation algorithm include incorporation of a threshold for troughs.",
        "Entity": "Normal"
    },
    {
        "Text": "Currently, all troughs indicate a subject change, however, minor fluctuations in scores may be discounted.",
        "Entity": "Normal"
    },
    {
        "Text": "Future work with this algorithm should include application to longer documents.",
        "Entity": "Normal"
    },
    {
        "Text": "With trough thresholding the segments identified in longer documents could detect significant subject changes.",
        "Entity": "Normal"
    },
    {
        "Text": "Having located the related segments in text, a method of determining the subject of each segment could be developed, for example, for information retrieval purposes.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tA phrase-based statistical machine translation approach   the alignment template approach   is described.",
        "Entity": "Normal"
    },
    {
        "Text": "This translation approach allows for general many-to-many relations between words.",
        "Entity": "Normal"
    },
    {
        "Text": "Thereby, the context of words is taken into account in the translation model, and local changes in word order from source to target language can be learned explicitly.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Thereby, the model is easier to extend than classical statistical machine translation systems.",
        "Entity": "Normal"
    },
    {
        "Text": "We describe in detail the process for learning phrasal translations, the feature functions used, and the search algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The evaluation of this approach is performed on three different tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "For the German English speech Verbmobil task, we analyze the effect of various system components.",
        "Entity": "Normal"
    },
    {
        "Text": "On the French English Canadian Hansards task, the alignment template system obtains significantly better results than a single-word-based translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "In the Chinese English 2002 National Institute of Standards and Technology (NIST) machine translation evaluation it yields statistically significantly better NIST scores than all competing research and commercial translation systems.",
        "Entity": "Normal"
    },
    {
        "Text": "Machine translation (MT) is a hard problem, because natural languages are highly complex, many words have various meanings and different possible translations, sentences might have various readings, and the relationships between linguistic entities are often vague.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, it is sometimes necessary to take world knowledge into account.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of relevant dependencies is much too large and those dependencies are too complex to take them all into account in a machine translation system.",
        "Entity": "Normal"
    },
    {
        "Text": "Given these boundary conditions, a machine translation system has to make decisions (produce translations) given incomplete knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "In such a case, a principled approach to solving that problem is to use the concepts of statistical decision theory to try to make optimal decisions given incomplete knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "This is the goal of statistical machine translation.",
        "Entity": "Normal"
    },
    {
        "Text": "The use of statistical techniques in machine translation has led to dramatic improvements in the quality of research systems in recent years.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the statistical approaches of the Verbmobil evaluations (Wahlster 2000) or the U.S. National   1600 Amphitheatre Parkway, Mountain View, CA 94043.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: och@google.com.",
        "Entity": "Normal"
    },
    {
        "Text": "Lehrstuhl fu  r Informatik VI, Computer Science Department, RWTH Aachen University of Technology, Ahornstr.",
        "Entity": "Normal"
    },
    {
        "Text": "55, 52056 Aachen, Germany.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: ney@cs.rwthaachen.de.",
        "Entity": "Normal"
    },
    {
        "Text": "Submission received: 19 November 2002; Revised submission received: 7 October 2003; Accepted for publication: 1 June 2004  c 2004 Association for Computational Linguistics Institute of Standards and Technology (NIST)/TIDES MT evaluations 2001 through 20031 obtain the best results.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, the field of statistical machine translation israpidly progressing, and the quality of systems is getting better and better.",
        "Entity": "Normal"
    },
    {
        "Text": "An im portant factor in these improvements is definitely the availability of large amounts of data for training statistical models.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet the modeling, training, and search methods have also improved since the field of statistical machine translation was pioneered by IBM in the late 1980s and early 1990s (Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1990; Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1993; Berger etal.",
        "Entity": "Normal"
    },
    {
        "Text": "1994).",
        "Entity": "Normal"
    },
    {
        "Text": "This article focuses on an important improvement, namely, the use of (gen eralized) phrases instead of just single words as the core elements of the statistical translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "We describe in Section 2 the basics of our statistical translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "W                                                                                                                                                                                           .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 3, we describe the statistical alignment models used to obtain a word alignment and techniques for learning phrase translations from word alignments.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the term phrase just refers to a consecutive sequence of words occurring in text and has to be distinguished from the use of the term in a linguistic sense.",
        "Entity": "Normal"
    },
    {
        "Text": "The learned bilingual phrases are not constrained by linguistic phrase boundaries.",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to the word-based statistical translation models in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993), this model is based on a (statistical) phrase lexicon instead of a single-word-based lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "Looking at the results of the recent machine translation evaluations, this approach seems currently to give the best results, and an increasing number of researchers are working on different methods for learning phrase translation lexica for machine translation purposes (Marcu and Wong 2002; Venugopal, Vogel, and Waibel 2003; Tillmann 2003; Koehn, Och, and Marcu 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "Our approach to learning a phrase translation lexicon works in two stages: In the first stage, we compute an alignment between words, and in the second stage, we extract the aligned phrase pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "In our machine translation system, we then use generalized versions of these phrases, called alignment templates, that also include the word alignment and use word classes instead of the words themselves.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 4, we describe the various components of the statistical translationmodel.",
        "Entity": "Normal"
    },
    {
        "Text": "The backbone of the translation model is the alignment template feature function, which requires that a translation of a new sentence be composed of a set of align ment templates that covers the source sentence and the produced translation.",
        "Entity": "Normal"
    },
    {
        "Text": "Other feature functions score the well-formedness of the produced target language sentence(i.e., language model feature functions), the number of produced words, or the or der of the alignment templates.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that all components of our statistical machine translation model are purely data-driven and that there is no need for linguisticallyannotated corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "This is an important advantage compared to syntax-based trans lation models (Yamada and Knight 2001; Gildea 2003; Charniak, Knight, and Yamada 2003) that require a parser for source or target language.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 5, we describe in detail our search algorithm and discuss an efficient implementation.",
        "Entity": "Normal"
    },
    {
        "Text": "We use a dynamic-programming-based beam search algorithm that allows a trade-off between efficiency and quality.",
        "Entity": "Normal"
    },
    {
        "Text": "We also discuss the use of heuristic functions to reduce the number of search errors for a fixed beam size.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 6, we describe various results obtained on different tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "For theGerman English Verbmobil task, we analyze the effect of various system compo 1 http://www.nist.gov/speech/tests/mt/.",
        "Entity": "Normal"
    },
    {
        "Text": "418                                                                                          .",
        "Entity": "Normal"
    },
    {
        "Text": "nents.",
        "Entity": "Normal"
    },
    {
        "Text": "On the French English Canadian Hansards task, the alignment template system obtains significantly better results than a single-word-based translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "In the Chinese English 2002 NIST machine translation evaluation it yields results that are significantly better statistically than all competing research and commercial translation systems.",
        "Entity": "Normal"
    },
    {
        "Text": "We are given a source (French) sentence f = f J = f1 , ...\n\t\t\t, fj , ...\n\t\t\t, fJ , which is to be trans lated into a target (English) sentence e = eI = e1 , ...\n\t\t\t, ei , ...\n\t\t\t, eI .",
        "Entity": "Normal"
    },
    {
        "Text": ":2                                  1 1 1 I 1                                                                                                                       .",
        "Entity": "Normal"
    },
    {
        "Text": "As an alternative to the often used source channel approach (Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1993),                                                          (Och and Ney 2002).",
        "Entity": "Normal"
    },
    {
        "Text": "An es pecially well-founded framework for doing this is the maximum-entropy framework(Berger, Della Pietra, and Della Pietra 1996).",
        "Entity": "Normal"
    },
    {
        "Text": "In this framework, we have a set of M fea ture functions hm (eI , f J ), m = 1, ...\n\t\t\t, M. For each feature function, there exists a model 1 1 2 The notational convention employed in this article is as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the symbol Pr( ) to denote.",
        "Entity": "Normal"
    },
    {
        "Text": "general probability distributions with (nearly) no specific assumptions.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, for model-based probability distributions, we use the generic symbol p( ).",
        "Entity": "Normal"
    },
    {
        "Text": "419 parameter  m , m = 1, ...\n\t\t\t, M.                                                                                                                                           e                                                                                                                                                      \n\t\t\t                                                                                                                     Hence,                                                                           .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "..\n\t\t\t, S} for log-linear models is the maximum class posterior probability criterion, which can be derived from the maximum-entropy principle:                                                                                                                                                           .",
        "Entity": "Normal"
    },
    {
        "Text": "This direct optimization of the posterior probability in Bayes  decision rule is referred to as discriminative training (Ney 1995) because we directly take into account the overlap in the probability distributions.",
        "Entity": "Normal"
    },
    {
        "Text": "The optimization problem under this criterion has very nice properties: There is one unique global optimum, and there are algorithms (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "gradient descent) that are guaranteed to converge to the global optimum.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet the ultimate goal is to obtain good translation quality on unseen test data.",
        "Entity": "Normal"
    },
    {
        "Text": "An alternative training criterion therefore directly optimizes translation quality as measured by an automatic evaluation criterion (Och 2003).",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "To include these dependencies in our log-linear model, we extend the feature functions to include the dependence on the additional hidden variable.",
        "Entity": "Normal"
    },
    {
        "Text": "Using for example the alignment aJ as hidden variable, we obtain M feature functions of the form hm (eI , f J , aJ ), m = 1, ...\n\t\t\t, M and the following model: 1 1 1 exp M  m hm (eI , f J , aJ ) Pr(eI , aJ | f J ) = m=1 1 1 1 1 1 1 M I J J e  I   J exp  m hm (e 1 , f , a  ) 1 ,a 1 m=1 1 1 Obviously, we can perform the same step for translation models with an even richer set of hidden variables than only the alignment aJ .",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we describe methods for learning the single-word and phrase-based translation lexica that are the basis of the machine translation system described in 420 Section 4.",
        "Entity": "Normal"
    },
    {
        "Text": "First, we introduce the basic concepts of statistical alignment models, which are used to learn word alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, we describe how these alignments can be used to learn bilingual phrasal translations.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Statistical Alignment Models.",
        "Entity": "Normal"
    },
    {
        "Text": "In (statistical)                                      a  hidden  alignment a = aJis intro 1 1 1 1 duced that describes a mapping from a source position j to a target position aj .",
        "Entity": "Normal"
    },
    {
        "Text": "The relationship between the translation model and the alignment model is given by                                                      The alignment aJ may contain alignments aj = 0 with the  empty  word e0 to account for source words that are not aligned with any target word.",
        "Entity": "Normal"
    },
    {
        "Text": "In general, the statistical model depends on a set of unknown parameters   that is learned from training data.",
        "Entity": "Normal"
    },
    {
        "Text": "To express the dependence of the model on the parameter set, we use the following notation:                                                          A detailed description of different specific statistical alignment models can be found in Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) and Och and Ney (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we use the hidden Markov model (HMM) alignment model (Vogel, Ney, and Tillmann 1996) and Model 4 of Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) to compute the word alignment for the parallel training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "To train the unknown parameters  , we are given a parallel training corpus consisting of S sentence pairs {(fs , es ): s = 1, ...\n\t\t\t, S}.",
        "Entity": "Normal"
    },
    {
        "Text": "For each sentence pair (fs , es ), the alignment variable is denoted by a = aJ .",
        "Entity": "Normal"
    },
    {
        "Text": "T                                                                                                                      \n\t\t\tFor a given sentence pair there are a large number of alignments.",
        "Entity": "Normal"
    },
    {
        "Text": ":                                                    A detailed comparison of the quality of these Viterbi alignments for various statistical alignment models compared to human-made word alignments can be found in Och and Ney (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Symmetrization.",
        "Entity": "Normal"
    },
    {
        "Text": "The baseline alignment model does not allow a source word to be aligned with two or more target words.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, lexical correspondences like the German compound word Zahnarzttermin for dentist s appointment cause problems because a single source word must be mapped onto two or more target words.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, the resulting Viterbi alignment of the standard alignment models has a systematic loss in recall.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we 421 F                                                                   \n\t\t\tdescribe various methods for performing a symmetrization of our directed statistical alignment models by applying a heuristic postprocessing step that combines the alignments in both translation directions (source to target, target to source).",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "To solve this problem, we train in both translation directions.",
        "Entity": "Normal"
    },
    {
        "Text": "For each sentence pair, we compute two Viterbi alignments aJ and bI .",
        "Entity": "Normal"
    },
    {
        "Text": "Let A1 = {(aj , j) | aj > 0} and A2 = {(i, bi ) | bi > 0} denote the sets of alignments in the two Viterbi alignments.",
        "Entity": "Normal"
    },
    {
        "Text": "To increase the quality of the alignments, we can combine (symmetrize) A1 and A2 into one alignment matrix A using one of the following combination methods:   Intersection: A = A1   A2 .",
        "Entity": "Normal"
    },
    {
        "Text": "Union: A = A1   A2 .",
        "Entity": "Normal"
    },
    {
        "Text": "Refined method: In a first step, the intersection A = A1   A2 is determined.",
        "Entity": "Normal"
    },
    {
        "Text": "The elements of this intersection result from both Viterbi alignments and are therefore very reliable.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, we extend the alignment A iteratively by adding alignments (i, j) occurring only in the 422 alignment A1 or in the alignment A2 if neither fj nor ei have an alignment in A, or if the following conditions both hold:   The alignment (i, j) has a horizontal neighbor (i   1, j), (i + 1, j) or a vertical neighbor (i, j   1), (i, j + 1) that is already in A.",
        "Entity": "Normal"
    },
    {
        "Text": "The set A   {(i, j)} does not contain alignments with both horizontal and vertical neighbors.",
        "Entity": "Normal"
    },
    {
        "Text": "Obviously, the intersection yields an alignment consisting of only one-to-one alignments with a higher precision and a lower recall.",
        "Entity": "Normal"
    },
    {
        "Text": "The union yields a higher recall and a lower precision of the combined alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "The refined alignment method is often able to improve precision and recall compared to the nonsymmetrized alignments.",
        "Entity": "Normal"
    },
    {
        "Text": "Whether a higher precision or a higher recall is preferred depends on the final application of the word alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "For the purpose of statistical MT, it seems that a higher recall is more important.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we use the union or the refined combination method to obtain a symmetrized alignment matrix.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting symmetrized alignments are then used to train single-word-based translation lexica p(e | f ) by computing relative frequencies using the count N(e, f ) of how many times e and f are aligned divided by the count N(f ) of how many times the word f occurs: p(e | f ) = N(e, f ) N(f ) 3.3 Bilingual Contiguous Phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we present a method for learning relationships between whole phrases of m source language words and n target language words.",
        "Entity": "Normal"
    },
    {
        "Text": "This algorithm, whichwill be called phrase-extract, takes as input a general word alignment matrix (Sec tion 3.2).",
        "Entity": "Normal"
    },
    {
        "Text": "The output is a set of bilingual phrases.",
        "Entity": "Normal"
    },
    {
        "Text": ":                                                                                                                                                Hence, the set of all bilingual phrases that are consistent with the alignment is constituted by all bilingual phrase pairs in which all words within the source language phrase are aligned only with the words of the target language phrase and the words of the target language phrase are aligned only with the words of the source language phrase.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that we require that at least one word in the source language phrase be aligned with at least one word of the target language phrase.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result there are no empty source or target language phrases that would correspond to the  empty word  of the word-based statistical alignment models.",
        "Entity": "Normal"
    },
    {
        "Text": "These phrases can be computed straightforwardly by enumerating all possible phrases in one language and checking whether the aligned words in the other language are consecutive, with the possible exception of words that are not aligned at all.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "423                                                                                                                                        .",
        "Entity": "Normal"
    },
    {
        "Text": "ja , yes , ja , ich yes , I ja , ich denke mal yes , I think ja , ich denke mal , yes , I think , ja , ich denke mal , also yes , I think , well , ich , I , ich denke mal , I think , ich denke mal , , I think , , ich denke mal , also , I think , well , ich denke mal , also wir , I think , well we ich denke mal I think ich denke mal , I think , ich denke mal , also I think , well ich denke mal , also wir I think , well we ich denke mal , also wir wollten I think , well we plan to denke mal , think , denke mal , also think , well denke mal , also wir think , well we denke mal , also wir wollten think , well we plan to , also , well , also wir , well we , also wir wollten , well we plan to also wir well we also wir wollten well we plan to wir wollten we plan to in unserer in our in unserer Abteilung in our department in unserer Abteilung ein neues Netzwerk a new network in our department in unserer Abteilung ein neues Netzwerk set up a new network in our department aufbauen unserer Abteilung our department ein neues a new ein neues Netzwerk a new network ein neues Netzwerk aufbauen set up a new network neues Netzwerk new network                                                                                                 \n\t\t\tIf a consecutive phrase in one language is translated into two or three nonconsecutive phrases in the other language, there is no corresponding bilingual phrase pair learned by this approach.",
        "Entity": "Normal"
    },
    {
        "Text": "In principle, this approach to learning phrases from a word-aligned corpus could be extended straightforwardly to handle nonconsecutive phrases in source and target language as well.",
        "Entity": "Normal"
    },
    {
        "Text": "Informal experiments have shown that allowing for nonconsecutive phrases significantly increases the number of extracted phrases and especially increases the percentage of wrong phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we consider only consecutive phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "3.4 Alignment Templates.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following, we add generalization capability to the bilingual phrase lexicon by replacing words with word classes and also by storing the alignment information for each phrase pair.",
        "Entity": "Normal"
    },
    {
        "Text": "These generalized and alignment-annotated phrase pairs are called alignment templates.",
        "Entity": "Normal"
    },
    {
        "Text": "Formally, an alignment template z is a triple (FJ  , EI  , A  ) 1 1 424 INPUT: eI , f J , A 1 1 i1 := 1 WHILE i1   I i2 := i1 WHILE i2   I TP := {j| i : i1   i   i2   A(i, j)}IF quasi consecutive(TP) TH EN j1 := min(TP) j2 := max(TP) SP := {i| j : j1   j   j2   A(i, j)} IF SP   {i1 , i1 + 1, ...\n\t\t\t, i2 } TH EN BP := BP   {(ei2 , f j2 )} i 1 j 1 WHILE j1 > 0    i : A(i, j1 ) = 0 j   := j2 WHILE j     J    i : A(i, j  ) = 0 BP := BP   {(ei 2 , f j )     i 1 j 1 } j   := j   + 1 j1 := j1   1 OUTPUT: BP Figure 3 Algorithm phrase-extract for extracting phrases from a word-aligned sentence pair.",
        "Entity": "Normal"
    },
    {
        "Text": "Here quasi-consecutive(TP) is a predicate that tests whether the set of words TP is consecutive, with the possible exception of words that are not aligned.",
        "Entity": "Normal"
    },
    {
        "Text": "that describes the alignment A  between a source class sequence FJ  and a target class sequence EI  .",
        "Entity": "Normal"
    },
    {
        "Text": "If each word corresponds to one class, an alignment template corresponds to a bilingual phrase together with an alignment within this phrase.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The alignment A  is represented as a matrix with J    (I  + 1) binary elements.",
        "Entity": "Normal"
    },
    {
        "Text": "A matrix element with value 1 means that the words at the corresponding positions are aligned, and the value 0 means that the words are not aligned.",
        "Entity": "Normal"
    },
    {
        "Text": "If a source word is not aligned with a target word, then it is aligned with the empty word e0 , which is at the imaginary position i = 0.",
        "Entity": "Normal"
    },
    {
        "Text": "The classes used in FJ  and EI  are automatically trained bilingual classes using the method described in Och (1999) and constitute a partition of the vocabulary of source and target language.",
        "Entity": "Normal"
    },
    {
        "Text": "In general, we are not limited to disjoint classes as long as each specific instance of a word is disambiguated, that is, uniquely belongs to a specific class.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following, we use the class function C to map words to their classes.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, it would be possible to employ parts-of-speech or semantic categories instead of the automatically trained word classes used here.",
        "Entity": "Normal"
    },
    {
        "Text": "The use of classes instead of the words themselves has the advantage of better generalization.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, if there exist classes in source and target language that contain town names, it is possible that an alignment template learned using a specific town name can be generalized to other town names.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following,  e and  f denote target and source phrases, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "To train 1 1 |   the probability of applying an alignment template p(z = (FJ  , EI  , A  ) f ), we use an extended version of the algorithm phrase-extract from Section 3.3.",
        "Entity": "Normal"
    },
    {
        "Text": "All bilingualphrases that are consistent with the alignment are extracted together with the align 425                                                              .",
        "Entity": "Normal"
    },
    {
        "Text": "ment within this bilingual phrase.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, we obtain a count N(z) of how often an alignment template occurred in the aligned training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": ":                                                       )                                                                                                                                                                    \n\t\t\t426 Depending on the size of the corpus, the maximal length in the experiments is between four and seven words.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we remove alignment templates that have a probability lower than a certain threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "In the experiments, we use a threshold of 0.01.",
        "Entity": "Normal"
    },
    {
        "Text": "It should be emphasized that this algorithm for computing aligned phrase pairs and their associated probabilities is very easy to implement.",
        "Entity": "Normal"
    },
    {
        "Text": "The joint translation model suggested by Marcu and Wong (2002) tries to learn phrases as part of a full EM algorithm, which leads to very large memory requirements and a rather complicated training algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "A comparison of the two approaches can be found in Koehn, Och, and Marcu (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "To describe our translation model based on the alignment templates described in the previous section in a formal way, we first decompose both the source sentence f J and the target sentence eI into a sequence of phrases (k = 1, ...\n\t\t\t,                         .",
        "Entity": "Normal"
    },
    {
        "Text": "..\n\t\t\t,        ) Note that there are a large number of possible segmentations of a sentence pair into K phrase pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following, we will describe the model for a specific segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "Eventually, however, a model can be described in which the specific segmentation is not known when new text is translated.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, as part of the overall search process (Section 5), we also search for the optimal segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "To allow possible reordering of phrases, we introduce an alignment on the phrase level  K between the source phrases  f K and the target phrases  eK .",
        "Entity": "Normal"
    },
    {
        "Text": "Hence,  K is a 1 1 1 1 permutation of the phrase positions 1, ...\n\t\t\t, K and indicates that the phrases  ek and  f  are transl ations of one anoth er.",
        "Entity": "Normal"
    },
    {
        "Text": "We assum e that for the transl ation betwe en these phrases a specific alignment template zk is used:  e zk f Hence, our model has the following hidden variables:  K K 1 , z1                                                                                                                                                                  .",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, all knowl edge sources are described as feature functions that include the given source language string f J , the target language string eI , and the above-stated hidden variables.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, 1 1 we have the following functional form of all feature functions: h(eI , f J ,  K , zK ) 1 1 1 1                                                                                  \n\t\t\t                                                                                                                                                                                                             \n\t\t\t                                                                                                 \n\t\t\tFinally, the sequence of phrases  eK constitutes the sequence of words eI .",
        "Entity": "Normal"
    },
    {
        "Text": "427                                                                                                         .",
        "Entity": "Normal"
    },
    {
        "Text": "l.\n\t\t\t428 4.1 Feature Functions.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1.1 Alignment Template Selection.",
        "Entity": "Normal"
    },
    {
        "Text": "To score the use of an alignment template, we use the probability p(z |  f ) defined in Section 3.\n\t\t\t                                                                                                                                     :                                                                              Here, j k  1 + 1 is the position of the first word of alignment template zk in the source language sentence and j k is the position of the last word of that alignment template.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that this feature function requires that a translation of a new sentence be composed of a set of alignment templates that covers both the source sentence and the produced translation.",
        "Entity": "Normal"
    },
    {
        "Text": "There is no notion of  empty phrase  that corresponds to the  empty word  in word-based statistical alignment models.",
        "Entity": "Normal"
    },
    {
        "Text": "The alignment on the phrase level is actually a permutation, and no insertions or deletions are allowed.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1.2 Word Selection.",
        "Entity": "Normal"
    },
    {
        "Text": "For scoring the use of target language words, we use a lexicon probability p(e | f ), which is estimated using relative frequencies as described in Sec tion 3.2.",
        "Entity": "Normal"
    },
    {
        "Text": "The target word e depends on the aligned source words.",
        "Entity": "Normal"
    },
    {
        "Text": "If we denote the resulting word alignment matrix by A := A K K and the predicted word class for word 1 ,z1 ei by Ei , then the feature function hWRD is defined as follows: I                                                                                   For p(ei | {fj | (i, j)   A}) we use a uniform mixture of a single-word model p(e | f ), which is constrained to predict only words that are in the predicted word class Ei : j|(i,j) A} p(ei | fj ) p(ei | {fj | (i, j)   A}, Ei ) = { |{j | (i, j)   A}|    (C(ei ), Ei ) A disadvantage of this model is that the word order is ignored in the translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "The translations the day after tomorrow or after the day tomorrow for the German word u  bermorgen receive an identical probability.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet the first one should obtain a significantly higher probability.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, we also include a dependence on the word positions in the lexicon model p                                                                                   Here, [(i , j)   A] is 1 if (i , j)   A and 0 otherwise.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result, the word ei depends not only on the aligned French word fj , but also on the number of preceding French words aligned with ei and on the number of the preceding English words aligned with fj .",
        "Entity": "Normal"
    },
    {
        "Text": "This model distinguishes the positions within a phrasal translation.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of parameters of p(e | f , i, j) is significantly higher than that of p(e | f ) alone.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, there is a data estimation problem especially for words that rarely occur.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we linearly interpolate the models p(e | f ) and p(e | f , i, j).",
        "Entity": "Normal"
    },
    {
        "Text": "4.1.3 Phrase Alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "The phrase alignment feature simply takes into account that very often a monotone alignment is a correct alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, the feature function hAL measures the  amount of nonmonotonicity  by summing over the distance (in the 429 source language) of alignment templates that are consecutive in the target language: K+1                                                                  Here, j 0 is defined to equal 0 and j K+1  1 is defined to equal J.",
        "Entity": "Normal"
    },
    {
        "Text": "The above-stated sum includes k = K + 1 to include the distance from the end position of the last phrase to the end of sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "The sequence of K = 6 alignment templates in Figure 5 corresponds to the following sum of seven jump distances: 0 + 0 + 1 + 3 + 2 + 0 + 0 = 6.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1.4 Language Model Features.",
        "Entity": "Normal"
    },
    {
        "Text": "As a default language model feature, we use a standard backing-off word-based trigram language model (Ney, Generet, and Wessel 1995):                                                                               In addition, we use a 5-gram class-based language model:                                                              .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "4.1.5 Word Penalty.",
        "Entity": "Normal"
    },
    {
        "Text": "To improve the scoring for different target sentence lengths, we also use as a feature the number of produced target language words (i.e., the length of the produced target language sentence): hWP(eI , f J ,  K , zK ) = I (19) 1 1 1 1 Without this feature, we typically observe that the produced sentences tend to be too short.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1.6 Conventional Lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "We also use a feature that counts how many entries of a conventional lexicon co-occur in the given sentence pair.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, the weight for the provided conventional dictionary can be learned:                                                                               The intuition is that the conventional dictionary LEX is more reliable than the automatically trained lexicon and therefore should get a larger weight.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1.7 Additional Features.",
        "Entity": "Normal"
    },
    {
        "Text": "A major advantage of the log-linear modeling approach used is that we can add numerous features that deal with specific problems of the baseline statistical MT system.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we will restrict ourselves to the described set of features.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet we could use grammatical features that relate certain grammatical dependencies of source and target language.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, using a function k( ) that counts how many arguments the main verb of a sentence has in the source or target sentence, we can define the following feature, which has a nonzero value if the verb in each of the two sentences has the same number of arguments: h(f J , eI ,  K , zK ) =  (k(f J ), k(eI )) (21) 1 1 1 1 1 1 In the same way, we can introduce semantic features or pragmatic features such as the dialogue act classification.",
        "Entity": "Normal"
    },
    {
        "Text": "430 4.2 Training.",
        "Entity": "Normal"
    },
    {
        "Text": "For the three different tasks on which we report results, we use two different training approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "For the French  English Hansards task and the Chinese English NIST task, we simply tune the modelparameters by coordinate descent on held-out data with respect to the automatic eval uation metric employed, using as a starting point the model parameters obtained on the Verbmobil task.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that this tuning depends on the starting point of the model parameters and is not guaranteed to converge to the global optimum on the trainingdata.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result, this approach is limited to a very small number of model parame ters.",
        "Entity": "Normal"
    },
    {
        "Text": "An efficient algorithm for performing this tuning for a larger number of model parameters can be found in Och (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "A standard approach to training the log-linear model parameters of the maximum class posterior probability criterion is the GIS (Generalized Iterative Scaling) algorithm(Darroch and Ratcliff 1972).",
        "Entity": "Normal"
    },
    {
        "Text": "To apply this algorithm, we have to solve various practi cal problems.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, we ap proximate this sum by extracting a large set of highly probable sentences as a sample from the space of all possible sentences (n-best approximation).",
        "Entity": "Normal"
    },
    {
        "Text": "The set of considered sentences is computed by means of an appropriately extended version of the search algorithm described in Section 5.",
        "Entity": "Normal"
    },
    {
        "Text": "Using an n-best approximation, we might face the problem that the parameters trained with the GIS algorithm yield worse translation results even on the training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "This can happen because with the modified model scaling factors, the n-best list can change significantly and can include sentences that have not been taken into account in training.",
        "Entity": "Normal"
    },
    {
        "Text": "Using these sentences, the new model parameters might perform worse than the old model parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "To avoid this problem, we proceed as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "In a first step, we perform a search, compute an n-best list, and use this n-best list to train the model parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, we use the new model parameters in a new search and compute a new n-best list, which is combined with the existing n-best list.",
        "Entity": "Normal"
    },
    {
        "Text": "Third, using this extended n-best list, new model parameters are computed.",
        "Entity": "Normal"
    },
    {
        "Text": "This process is iterated until the resulting n-best list does not change.",
        "Entity": "Normal"
    },
    {
        "Text": "In this algorithm, convergence is guaranteed, as in the limit the n-best list will contain all possible translations.",
        "Entity": "Normal"
    },
    {
        "Text": "In practice, the algorithm converges after five to seven iterations.",
        "Entity": "Normal"
    },
    {
        "Text": "In our experiments this final n-best list contains about 500 1000 alternative translations.",
        "Entity": "Normal"
    },
    {
        "Text": "We might have the problem that none of the given reference translations is part of the n-best list because the n-best list is too small or because the search algorithmperforms pruning which in principle limits the possible translations that can be pro duced given a certain input sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "To solve this problem, we define as reference translation for maximum-entropy training each sentence that has the minimal number of word errors with respect to any of the reference translations in the n-best list.",
        "Entity": "Normal"
    },
    {
        "Text": "More details of the training procedure can be found in Och and Ney (2002).",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we describe an efficient search architecture for the alignment template model.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 General Concept.",
        "Entity": "Normal"
    },
    {
        "Text": "In general, the search problem for statistical MT even using only Model 1 of Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) is NP-complete (Knight 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we cannot expect to develop 431 efficient search algorithms that are guaranteed to solve the problem without search errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet for practical applications it is acceptable to commit some search errors (Section 6.1.2).",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, the art of developing a search algorithm lies in finding suitable approximations and heuristics that allow an efficient search without committing too many search errors.",
        "Entity": "Normal"
    },
    {
        "Text": "In the development of the search algorithm described in this section, our main aim is that the search algorithm should be efficient.",
        "Entity": "Normal"
    },
    {
        "Text": "It should be possible to translate a sentence of reasonable length within a few seconds of computing time.",
        "Entity": "Normal"
    },
    {
        "Text": "We accept that the search algorithm sometimes results in search errors, as long as the impact on translation quality is minor.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet it should be possible to reduce the number of search errors by increasing computing time.",
        "Entity": "Normal"
    },
    {
        "Text": "In the limit, it should be possible to search without search errors.",
        "Entity": "Normal"
    },
    {
        "Text": "The search algorithm should not impose any principal limitations.",
        "Entity": "Normal"
    },
    {
        "Text": "We also expect that the search algorithm be able to scale up to very long sentences with an acceptable computing time.",
        "Entity": "Normal"
    },
    {
        "Text": "To meet these aims, it is necessary to have a mechanism that restricts the search effort.",
        "Entity": "Normal"
    },
    {
        "Text": "We accomplish such a restriction by searching in a breadth-first manner with pruning: beam search.",
        "Entity": "Normal"
    },
    {
        "Text": "In pruning, we constrain the set of considered translation candidates (the  beam ) only to the promising ones.",
        "Entity": "Normal"
    },
    {
        "Text": "We compare in beam search those hypotheses that cover different parts of the input sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "This makes the comparison of the probabilities problematic.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we integrate an admissible estimation of the remaining probabilities to arrive at a complete translation (Section 5.6) Many of the other search approaches suggested in the literature do not meet the described aims:   Neither optimal A* search (Och, Ueffing, and Ney 2001) nor optimal integer programming (Germann et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2001) for statistical MT allows efficient search for long sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Greedy search algorithms (Wang 1998; Germann et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2001) typically commit severe search errors (Germann et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Other approaches to solving the search problem obtain polynomial time algorithms by assuming monotone alignments (Tillmann et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1997) or imposing a simplified recombination structure (Nie en et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1998).",
        "Entity": "Normal"
    },
    {
        "Text": "Others make simplifying assumptions about the search space (Garc  a-Varea, Casacuberta, and Ney 1998; Garc  a-Varea et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2001), as does the original IBM stack search decoder (Berger et al.",
        "Entity": "Normal"
    },
    {
        "Text": "1994).",
        "Entity": "Normal"
    },
    {
        "Text": "All these simplifications ultimately make the search problem simpler but introduce fundamental search errors.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following, we describe our search algorithm based on the concept of beam search, which allows a trade-off between efficiency and quality by adjusting the size of the beam.",
        "Entity": "Normal"
    },
    {
        "Text": "The search algorithm can be easily adapted to other phrase-based translation models.",
        "Entity": "Normal"
    },
    {
        "Text": "For single-word-based search in MT, a similar algorithm has been described in Tillmann and Ney (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "5.2 Search Problem.",
        "Entity": "Normal"
    },
    {
        "Text": "Putting everything together and performing search in maximum approximation, we obtain the following decision rule:  eI = argmax M )  m   hm (eI , f J ,  K , zK ) (22) 1 eI K K 1 1 1 1 1 , 1 ,z1 m=1 432 Using the four feature functions AT, AL, WRD, and LM, we obtain the following decision rule:3  eI = argmax (23) eI K K 1 , 1 ,z1 I i=1 ( LM log p(ei | ei 2 , ei 1 )+  WRD log p(ei | {fj | (i, j)   A}, Ei )) (24) K j k + k=1  AT log p(zk | fj  k 1 +1 )+  AL   |j k   j k 1 +1 | (25) + AL   (J   j K )+  LM log p(EOS | eI 1 , eI ) (26) Here, we have grouped the contributions of the various feature functions into those for each word (from LM and WRD, expression (24)), those for every alignment template (from AT and AL, expression (25)), and those for the end of sentence (expression (26)), which includes a term log p(EOS | eI 1 , eI ) for the end-of-sentence language model probability.To extend this decision rule for the word penalty (WP) feature function, we sim ply obtain an additional term  WP for each word.",
        "Entity": "Normal"
    },
    {
        "Text": "The class-based 5-gram language model (CLM) can be included like the trigram language model.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that all these feature functions decompose nicely into contributions for each produced target language word or for each covered source language word.",
        "Entity": "Normal"
    },
    {
        "Text": "This makes it possible to develop an efficient dynamic programming search algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "Not all feature functions have this nice property: For the conventional lexicon feature function (LEX), we obtain an additional term in our decision rule which depends on the full sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, this feature function will not be integrated in the dynamic programming search but instead will be used to rerank the set of candidate translations produced by the search.",
        "Entity": "Normal"
    },
    {
        "Text": "5.3 Structure of Search Space.",
        "Entity": "Normal"
    },
    {
        "Text": "We have to structure the search space in a suitable way to search efficiently.",
        "Entity": "Normal"
    },
    {
        "Text": "In our search algorithm, we generate search hypotheses that correspond to prefixes of target language sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "Each hypothesis is the translation of a part of the source languagesentence.",
        "Entity": "Normal"
    },
    {
        "Text": "A hypothesis is extended by appending one target word.",
        "Entity": "Normal"
    },
    {
        "Text": "The set of all hy potheses can be structured as a graph with a source node representing the sentencestart, goal nodes representing complete translations, and intermediate nodes repre senting partial translations.",
        "Entity": "Normal"
    },
    {
        "Text": "There is a directed edge between hypotheses n1 and n2 if the hypothesis n2 is obtained by appending one word to hypothesis n1 .",
        "Entity": "Normal"
    },
    {
        "Text": "Each edge has associated costs resulting from the contributions of all feature functions.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, our search problem can be reformulated as finding the optimal path through this graph.In the first step, we determine the set of all source phrases in  f for which an appli cable alignment template exists.",
        "Entity": "Normal"
    },
    {
        "Text": "Every possible application of an alignment template z = (FJ  , EI  , A  ) to a subsequence f j+J   1 of the source sentence is called an alignment 1 1 j template instantiation Z = (z, j).",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, the set of all alignment template instantiations for the source sentence f J is Z = (z, j) | z = (FJ , EI  , A  ) j : p(z f j+J   1 ) > 0 (27) 1 1    | j 3 Note that here some of the simplifying notation of Section 4 has been used..\n\t\t\t433 If the source sentence contains words that have not been seen in the training data, we introduce a new alignment template that performs a one-to-one translation of each of these words by itself.",
        "Entity": "Normal"
    },
    {
        "Text": "In the second step, we determine a set of probable target language words for each target word position in the alignment template instantiation.",
        "Entity": "Normal"
    },
    {
        "Text": "Only these words are then hypothesized in the search.",
        "Entity": "Normal"
    },
    {
        "Text": "We call this selection of highly probable words observation pruning (Tillmann and Ney 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "As a criterion for a word e at position i in the alignment template instantiation, we use  (Ei , C(e))   J  j=0 A  (i, j) A  (i , j)   p(e | fj ) (28) In our experiments, we hypothesize only the five best-scoring words.",
        "Entity": "Normal"
    },
    {
        "Text": "A decision is a triple d = (Z, e, l) consisting of an alignment template instantiation Z, the generated word e, and the index l of the generated word in Z.",
        "Entity": "Normal"
    },
    {
        "Text": "A hypothesis n corresponds to a valid sequence of decisions di .",
        "Entity": "Normal"
    },
    {
        "Text": "The possible decisions are as follows: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Start a new alignment template: di = (Zi , ei , 1).",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, the index l =.",
        "Entity": "Normal"
    },
    {
        "Text": "1.",
        "Entity": "Normal"
    },
    {
        "Text": "This decision can be made only if the previous decision di 1 finished.",
        "Entity": "Normal"
    },
    {
        "Text": "an alignment template and if the newly chosen alignment template instantiation does not overlap with any previously chosen alignment template instantiation.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting decision score corresponds to the contribution of the LM and the WRD features (expression (24)) for the produced word and the contribution of AL and AT features (expression (25)) for the started alignment template.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "Extend an alignment template: di = (Zi , ei , l).",
        "Entity": "Normal"
    },
    {
        "Text": "This decision can be made.",
        "Entity": "Normal"
    },
    {
        "Text": "only if the previous decision uses the same alignment template instantiation and has as index l   1: di 1 = (Zi , ei 1 , l   1).",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting decision score corresponds to the contribution of the LM and the WRD features (expression (24)).",
        "Entity": "Normal"
    },
    {
        "Text": "3.",
        "Entity": "Normal"
    },
    {
        "Text": "Finish the translation of a sentence: di = (EOS, EOS, 0).",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, the.",
        "Entity": "Normal"
    },
    {
        "Text": "hypothesis is marked as a goal hypothesis.",
        "Entity": "Normal"
    },
    {
        "Text": "This decision is possible only if the previous decision di 1 finished an alignment template and if the alignment template instantiations completely cover the input sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting decision score corresponds to the contribution of expression (26).",
        "Entity": "Normal"
    },
    {
        "Text": "Any valid and complete sequence of decisions dI+1 uniquely corresponds to a certain translation eI , a segmentation into K phrases, a phrase alignment  K , and a sequence 1 1 of alignment template instantiations zK .",
        "Entity": "Normal"
    },
    {
        "Text": "The sum of the decision scores is equal to the corresponding score described in expressions (24) (26).",
        "Entity": "Normal"
    },
    {
        "Text": "A straightforward representation of all hypotheses would be the prefix tree of all possible sequences of decisions.",
        "Entity": "Normal"
    },
    {
        "Text": "Obviously, there would be a large redundancy in thissearch space representation, because there are many search nodes that are indistin guishable in the sense that the subtrees following these search nodes are identical.",
        "Entity": "Normal"
    },
    {
        "Text": "We can recombine these identical search nodes; that is, we have to maintain only the most probable hypothesis (Bellman 1957).",
        "Entity": "Normal"
    },
    {
        "Text": "In general, the criterion for recombining a set of nodes is that the hypotheses can be distinguished by neither language nor translation model.",
        "Entity": "Normal"
    },
    {
        "Text": "In performing recombination, 434 INPUT: implicitly defined search space (functions Recombine, Extend)H = {initial hypothesis} WHILE H  =   Hext :=   FOR n   H IF hypothesis n is final THEN Hfin := Hfin   {n} EL SE Hext := Hext   Extend( n) H := Recombine(Hext ) Q  = maxn H Q(n) H := {n   H : Q(n) > log(tp )+ Q  } H := HistogramPrun ing(H, Np ) n   = a r g m a x Q ( n ) n   H f i n OUTPUT: n                                                          .",
        "Entity": "Normal"
    },
    {
        "Text": "we obtain a search graph instead of a search tree.",
        "Entity": "Normal"
    },
    {
        "Text": "The exact criterion for performing recombination for the alignment templates is described in Section 5.5.",
        "Entity": "Normal"
    },
    {
        "Text": "5.4 Search Algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "Theoretically, we could use any graph search algorithm to search the optimal path in the search space.",
        "Entity": "Normal"
    },
    {
        "Text": "We use a breadth-first search algorithm with pruning.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach offers very good possibilities for adjusting the trade-off between quality and efficiency.",
        "Entity": "Normal"
    },
    {
        "Text": "In pruning, we always compare hypotheses that have produced the same number of target words.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we represent the searchspace implicitly, using the functions Extend and Recombine.",
        "Entity": "Normal"
    },
    {
        "Text": "The function Extend produces new hypotheses extending the current hypothesis by one word.",
        "Entity": "Normal"
    },
    {
        "Text": "Some hypothe ses might be identical or indistinguishable by the language and translation models.",
        "Entity": "Normal"
    },
    {
        "Text": "These are recombined by the function Recombine.",
        "Entity": "Normal"
    },
    {
        "Text": "We expand the search space such that only hypotheses with the same number of target language words are recombined.In the pruning step, we use two different types of pruning.",
        "Entity": "Normal"
    },
    {
        "Text": "First, we perform prun ing relative to the score Q  of the current best hypothesis.",
        "Entity": "Normal"
    },
    {
        "Text": "We ignore all hypotheses that have a probability lower than log(tp )+ Q  , where tp is an adjustable pruning parameter.",
        "Entity": "Normal"
    },
    {
        "Text": "This type of pruning can be performed when the hypothesis extensions are computed.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, in histogram pruning (Steinbiss, Tran, and Ney 1994), we maintain only the best Np hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "The two pruning parameters tp and Np have to be optimized with respect to the trade-off between efficiency and quality.",
        "Entity": "Normal"
    },
    {
        "Text": "5.5 Implementation.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we describe various issues involved in performing an efficient imple mentation of a search algorithm for the alignment template approach.",
        "Entity": "Normal"
    },
    {
        "Text": "A very important design decision in the implementation is the representation of a hypothesis.",
        "Entity": "Normal"
    },
    {
        "Text": "Theoretically, it would be possible to represent search hypotheses only by the associated decision and a back-pointer to the previous hypothesis.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet this would be a very inefficient representation for the implementation of the operations 435 that have to be performed in the search.",
        "Entity": "Normal"
    },
    {
        "Text": "The hypothesis representation should contain all information required to perform efficiently the computations needed in the search but should contain no more information than that, to keep the memory consumption small.",
        "Entity": "Normal"
    },
    {
        "Text": "In search, we produce hypotheses n, each of which contains the following information: 1.\n\t\t\te: the final target word produced 2.\n\t\t\th: the state of the language model (to predict the following word) 3.\n\t\t\tc = cJ : the coverage vector representing the already covered positions of the source sentence (cj = 1 means the position j is covered, cj = 0 means the position j is not covered) 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Z: a reference to the alignment template instantiation that produced the final target word 5.\n\t\t\tl: the position of the final target word in the alignment template instantiation\n\t\n\t\n\t\t\t7.\n\t\t\tn : a reference to the previous hypothesis Using this representation, we can perform the following operations very efficiently:   Determining whether a specific alignment template instantiation can be used to extend a hypothesis.",
        "Entity": "Normal"
    },
    {
        "Text": "To do this, we check whether the positions of the alignment template instantiation are still free in the hypothesis coverage vector.",
        "Entity": "Normal"
    },
    {
        "Text": "Checking whether a hypothesis is final.",
        "Entity": "Normal"
    },
    {
        "Text": "To do this, we determine whether the coverage vector contains no uncovered position.",
        "Entity": "Normal"
    },
    {
        "Text": "Using a bit vector as representation, the operation to check whether a hypothesis is final can be implemented very efficiently.",
        "Entity": "Normal"
    },
    {
        "Text": "Checking whether two hypotheses can be recombined.",
        "Entity": "Normal"
    },
    {
        "Text": "The criterion for recombining two hypotheses n1 = (e1 , h1 , c1 , Z1 , l1 ) and n2 = (e2 , h2 , c2 , Z2 , l2 ) is h1 = h2   identical language model state c1 = c2   identical coverage vector ( (Z1 = Z2   l1 = l2 )  alignment template instantiation is identical (J(Z1 ) = l1   J(Z2 ) = l2 ) ) alignment template instantiation finished We compare in beam search those hypotheses that cover different parts of the input sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "This makes the comparison of the probabilities problematic.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we integrate an admissible estimation of the remaining probabilities to arrive at a complete translation.",
        "Entity": "Normal"
    },
    {
        "Text": "Details of the heuristic function for the alignment templates are provided in the next section.",
        "Entity": "Normal"
    },
    {
        "Text": "5.6 Heuristic Function.",
        "Entity": "Normal"
    },
    {
        "Text": "To improve the comparability of search hypotheses, we introduce heuristic functions.",
        "Entity": "Normal"
    },
    {
        "Text": "A heuristic function estimates the probabilities of reaching the goal node from a certain 436 search node.",
        "Entity": "Normal"
    },
    {
        "Text": "An admissible heuristic function is always an optimistic estimate; that is, for each search node, the product of edge probabilities of reaching a goal node is always equal to or smaller than the estimated probability.",
        "Entity": "Normal"
    },
    {
        "Text": "For an A*-based search algorithm, a good heuristic function is crucial to being able to translate long sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "For a beam search algorithm, the heuristic function has a different motivation.",
        "Entity": "Normal"
    },
    {
        "Text": "It is used to improve the scoring of search hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "The goal is to make the probabilities of all hypotheses more comparable, in order to minimize the chance that the hypothesis leading to the optimal translation is pruned away.",
        "Entity": "Normal"
    },
    {
        "Text": "Heuristic functions for search in statistical MT have been used in Wang and Waibel (1997) and Och, Ueffing, and Ney (2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Wang and Waibel (1997) have described a simple heuristic function for Model 2 of Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) that was not admissible.",
        "Entity": "Normal"
    },
    {
        "Text": "Och, Ueffing, and Ney (2001) have described an admissible heuristic function for Model 4 of Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) and an almost-admissible heuristic function that is empirically obtained.",
        "Entity": "Normal"
    },
    {
        "Text": "We have to keep in mind that a heuristic function is helpful only if the overhead introduced in computing the heuristic function is more than compensated for by the gain obtained through a better pruning of search hypotheses.",
        "Entity": "Normal"
    },
    {
        "Text": "The heuristic functions described in the following are designed such that their computation can be performed efficiently.",
        "Entity": "Normal"
    },
    {
        "Text": "The basic idea for developing a heuristic function for an alignment model is that all source sentence positions that have not been covered so far still have to be translated to complete the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "If we have an estimation rX(j) of the optimal score for translating position j, then the value of the heuristic function RX(n) for a node n can be inferred by summing over the contribution for every position j that is not in the coverage vector c(n) (here X denotes different possibilities to choose the heuristic function): RX(n) = j  c(n) rX(j) (29) The situation in the case of the alignment template approach is more complicated, as not every word is translated alone, but typically the words are translated in context.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, the basic quantity for the heuristic function in the case of the alignment template approach is a function r(Z) that assigns to every alignment template in- stantiation Z a maximal probability.",
        "Entity": "Normal"
    },
    {
        "Text": "Using r(Z), we can induce a position-dependent heuristic function r(j): r(j) := max Z:j(Z) j j(Z)+J(Z) 1 r(Z)/J(Z) (30) Here, J(Z) denotes the number of source language words produced by the alignment template instantiation Z and j(Z) denotes the position of the first source language word.",
        "Entity": "Normal"
    },
    {
        "Text": "It can be easily shown that if r(Z) is admissible, then r(j) is also admissible.",
        "Entity": "Normal"
    },
    {
        "Text": "We have to show that for all nonoverlapping sequences ZK the following holds: K k=1 r(Zk )   j c(ZK ) r(j) (31) Here, c(ZK ) denotes the set of all positions covered by the sequence of alignment templates ZK .",
        "Entity": "Normal"
    },
    {
        "Text": "This can be shown easily: K r(Zk ) = K J(Zk ) r(Zk )/J(Zk ) (32) k=1 k=1 j=1 437 INPUT: covera ge vector cJ , previou sly covere d positio n j 1 ff = min({j  | cj  = 0}) mj = |j   ff| WHILE ff  = (J + 1) fo := mi n({ j  | j  > ff   cj  = 1}) ff := mi n({ j  | j  > fo   cj  = 0   j  = J + 1}) mj := mj + |ff   fo| OUTP UT: mj                                                                                                                 .",
        "Entity": "Normal"
    },
    {
        "Text": "= j c(ZK ) r(Zk(j) )/J(Zk(j) ) ( 33)   j c(ZK ) max Z:j(Z) j j(Z)+J(Z) 1 r(Z)/J(Z) (34) Here, k(j) denotes the phrase index k that includes the target language word position j.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following, we develop various heuristic functions r(Z) of increasing complexity.",
        "Entity": "Normal"
    },
    {
        "Text": "The simplest realization of a heuristic function r(Z) takes into account only the prior probability of an alignment template instantiation: RAT(Z = (z, j)) =  AT   log p(z | fj,j+J(z) The lexicon model can be integrated as follows:  1 ) (35) RWRD(Z) =  WRD   j(Z)+J(Z) 1 j  =j(Z) max log p(e fj  ) (36) e The language model can be incorporated by considering that for each target word there exists an optimal language model probability: pL(e) = max p(e e , e  ) (37) e  ,e   Here, we assume a trigram language model.",
        "Entity": "Normal"
    },
    {
        "Text": "In general, it is necessary to maximize over all possible different language model histories.",
        "Entity": "Normal"
    },
    {
        "Text": "We can also combine the language model and the lexicon model into one heuristic function: RWRD+LM(Z) = j(Z)+J(Z) 1 j  =j(Z) max  WRD log(p(e | fj  )) +  LM log(pL(e)) (38) To include the phrase alignment probability in the heuristic function, we compute the minimum sum of all jump widths that is needed to complete the translation.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Then, an admissible heuristic function for the jump width is obtained by RAL(c, j) =  AL   D(c, j) (39) 438 Table 2 Statistics for Verbmobil task: training corpus (Train), conventional dictionary (Lex), development corpus (Dev), test corpus (Test) (Words*: words without punctuation marks).",
        "Entity": "Normal"
    },
    {
        "Text": "No Preprocessing With Preprocessing G e r m a n E n g l i s h Ger man E n g l i s h Trai n S e n t e n c e s W o r d s 5 1 9 , 5 2 3 5 4 9 , 9 2 1 58,0 73 522, 933 5 4 8 , 8 7 4 W o r d s * 4 1 8 , 9 7 4 4 5 3 , 6 1 2 420, 919 4 5 0 , 2 9 7 S i n g l e t o n s 3 , 4 5 3 1 , 6 9 8 3, 5 7 0 1 , 7 6 3 V o c a b u l a r y 7 , 9 4 0 4 , 6 7 3 8, 1 0 2 4 , 7 8 0 Lex E n t r i e s E x t e n d e d v o c a b u l a r y 1 1 , 5 0 1 6 , 8 6 7 12,7 79 11, 90 4 7 , 0 8 9 Dev S e n t e n c e s W o r d s 3 , 1 5 9 3 , 4 3 8 27 6 3, 1 7 2 3 , 4 4 5 T r i g r a m p e r p l e x i t y   2 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "1   2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 Test S e n t e n c e s W o r d s 2 , 6 2 8 2 , 8 7 1 25 1 2, 6 4 0 2 , 8 6 2 T r i g r a m p e r p l e x i t y   3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "5   2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 Combining all the heuristic functions for the various models, we obtain as final heuristic function for a search hypothesis n 6.",
        "Entity": "Normal"
    },
    {
        "Text": "Results.",
        "Entity": "Normal"
    },
    {
        "Text": "R(n) = RAL(c(n), j(n)) + j  c(n) RAT(j)+ RWRD+LM(j) (40) 6.1 Results on the Verbmobil Task.",
        "Entity": "Normal"
    },
    {
        "Text": "We present results on the Verbmobil task, which is a speech translation task in the domain of appointment scheduling, travel planning, and hotel reservation (Wahlster 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "T                                                 \n\t\t\tWe use a training corpus, which is used to train the alignment template model and the language models, a development corpus, which is used to estimate the model scaling factors, and a test corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "On average, 3.32 reference translations for the development corpus and 5.14 reference translations for the test corpus are used.",
        "Entity": "Normal"
    },
    {
        "Text": "A standard vocabulary had been defined for the various speech recognizers usedin Verbmobil.",
        "Entity": "Normal"
    },
    {
        "Text": "However, not all words of this vocabulary were observed in the train ing corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, the translation vocabulary was extended semiautomatically byadding about 13,000 German English entries from an online bilingual lexicon avail able on the Web.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting lexicon contained not only word-word entries, but also multi-word translations, especially for the large number of German compound words.",
        "Entity": "Normal"
    },
    {
        "Text": "To counteract the sparseness of the training data, a couple of straightforward rule-based preprocessing steps were applied before any other type of processing:   normalization of   numbers   time and date phrases   spelling (e.g., don t   do not)   splitting of German compound words.",
        "Entity": "Normal"
    },
    {
        "Text": "439 So far, in machine translation research there is no generally accepted criterion for the evaluation of experimental results.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we use various criteria.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following experiments, we use:   WER (word error rate)/mWER (multireference word error rate): The WER is computed as the minimum number of substitution, insertion, and deletion operations that have to be performed to convert the generated sentence into the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "In the case of the multireference word error rate for each test sentence, not just a single reference translation is used, as for the WER, but a whole set of reference translations.",
        "Entity": "Normal"
    },
    {
        "Text": "For each translation hypothesis, the edit distance to the most similar sentence is calculated (Nie en et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2000).",
        "Entity": "Normal"
    },
    {
        "Text": "PER (position-independent WER): A shortcoming of the WER is the fact that it requires a perfect word order.",
        "Entity": "Normal"
    },
    {
        "Text": "An acceptable sentence can have a word order that is different from that of the target sentence, so the WER measure alone could be misleading.",
        "Entity": "Normal"
    },
    {
        "Text": "To overcome this problem, we introduce as an additional measure the position-independent word error rate.",
        "Entity": "Normal"
    },
    {
        "Text": "This measure compares the words in the two sentences, ignoring the word order.",
        "Entity": "Normal"
    },
    {
        "Text": "BLEU (bilingual evalutation understudy) score: This score measures the precision of unigrams, bigrams, trigrams, and 4-grams with respect to a whole set of reference translations, with a penalty for too-short sentences (Papineni et al.",
        "Entity": "Normal"
    },
    {
        "Text": "2001).",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike all other evaluation criteria used here, BLEU measures accuracy, that is, the opposite of error rate.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, the larger BLEU scores, the better.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following, we analyze the effect of various system components: alignment template length, search pruning, and language model n-gram size.",
        "Entity": "Normal"
    },
    {
        "Text": "A systematic evaluation of the alignment template system comparing it with other translation approaches (e.g., rule-based) has been performed in the Verbmobil project and is described in Tessiore and von Hahn (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "There, the alignment-template-based system achieved a significantly larger number of  approximately correct  translations than the competing translation systems (Ney, Och, and Vogel 2001).",
        "Entity": "Normal"
    },
    {
        "Text": "6.1.1 Effect of Alignment Template Length.",
        "Entity": "Normal"
    },
    {
        "Text": "Typically, it is necessary to restrict the alignment template length to keep memory requirements low.",
        "Entity": "Normal"
    },
    {
        "Text": "We see that using alignment templates with only one or two words in the source languages results in very bad translation quality.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet using alignment templates with lengths as small as three words yields optimal results.",
        "Entity": "Normal"
    },
    {
        "Text": "6.1.2 Effect of Pruning and Heuristic Function.",
        "Entity": "Normal"
    },
    {
        "Text": "In the following, we analyze the effect of beam search pruning and of the heuristic function.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the following criteria:   Number of search errors: A search error occurs when the search algorithm misses the most probable translation and produces a translation which is less probable.",
        "Entity": "Normal"
    },
    {
        "Text": "As we typically cannot efficiently compute the probability of the optimal translation, we cannot efficiently compute the number of search errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet we can compute a lower bound on the number of search errors by comparing the translation 440 Table 3 Effect of alignment template length on translation quality.",
        "Entity": "Normal"
    },
    {
        "Text": "AT len gth P E R [ % ] m W E R [ % ] B L E U [ % ] 1 2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 2 2 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 3 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 3 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 4 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 6 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 7 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 Table 4 Effect of pruning parameter tp and heuristic function on search efficiency for direct-translation model (Np = 50,000).",
        "Entity": "Normal"
    },
    {
        "Text": "no heuristic function AT+WRD +LM +AL tp 10 2 10 4 10 6 10 8 10 10 10 12 found under specific pruning thresholds with the best translation that we have found using very conservative pruning thresholds.",
        "Entity": "Normal"
    },
    {
        "Text": "Average translation time per sentence: Pruning is used to adjust the trade-off between efficiency and quality.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, we present the average time needed to translate one sentence of the test corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation quality (mWER, BLEU): Typically, a sentence can have many different correct translations.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, a search error does not necessarily result in poorer translation quality.",
        "Entity": "Normal"
    },
    {
        "Text": "It is even possible that a search error can improve translation quality.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, we analyze the effect of search on translation quality, using the automatic evaluation criteria mWER and BLEU.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The first is an estimate of the alignment template and the lexicon probability (AT+WRD), the second adds an estimate of the language model (+LM) probability, and the third also adds the alignment probability (+AL).",
        "Entity": "Normal"
    },
    {
        "Text": "These heuristic functions are described in Section 5.6.",
        "Entity": "Normal"
    },
    {
        "Text": "Without a heuristic function, even more than a hundred seconds per sentence cannot guarantee search-error-free translation.",
        "Entity": "Normal"
    },
    {
        "Text": "We draw the conclusion that a good heuristic function is very important to obtaining an efficient search algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "441                                                                                                                        \n\t\t\ttp 10 2 10 4 10 6 10 8 10 10 10 12 e r r o r r a t e s [ % ] no heuristic function AT+WRD +LM +AL                                                                                                                              .",
        "Entity": "Normal"
    },
    {
        "Text": "no heuristic function AT+WRD +LM +AL N p t i m e [ s ] s e a r c h e r r o r s t i m e [ s ] s e a r c h e r r o r s t i m e [ s ] s e a r c h e r r o r s t i m e [ s ] se a rc h e rr o rs 1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 2 3 7 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 2 3 8 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 2 3 8 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 2 3 2 10 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 6 9 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 5 4 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 1 4 8 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 98 10 0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 1 0 1 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 6 9 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 6 0 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 21 1,0 00 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 65 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 3 3 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 2 7 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 5 10,0 00 1 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 40 1 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 1 0 2 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 5 1 4.",
        "Entity": "Normal"
    },
    {
        "Text": "3 1 50,0 00 11 4.",
        "Entity": "Normal"
    },
    {
        "Text": "6 34 11 9.",
        "Entity": "Normal"
    },
    {
        "Text": "2 5 14 6.",
        "Entity": "Normal"
    },
    {
        "Text": "2 2 7 5.",
        "Entity": "Normal"
    },
    {
        "Text": "2 0                                                                                                                        \n\t\t\terror rates [%] no heuristic function AT+WRD +LM +AL N p m W E R B L E U m W E R B L E U m W E R B L E U m W E R B L E U 1 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 6 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 3 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 10 4 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 4 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 4 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 3 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 5 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 10 0 4 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 3 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 1,0 00 3 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 5 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 10,0 00 3 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 50,0 00 3 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 5 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 442                                                                                                                          \n\t\t\tLan gua ge mo del typ e P P P E R [ % ] m W E R [ % ] B L E U [ % ] Zer ogr am 4 7 8 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 3 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 4 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 Uni gra m 2 0 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 4 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 Bigr am 3 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 Trig ram 2 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 5 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 Trig ram + CL M   2 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "1 In addition, the search errors have a more severe effect on the error rates if we do not use a heuristic function.",
        "Entity": "Normal"
    },
    {
        "Text": "The reason is that without a heuristic function, often the  easy  part of the input sentence is translated first.",
        "Entity": "Normal"
    },
    {
        "Text": "This yields severe reordering errors.",
        "Entity": "Normal"
    },
    {
        "Text": "6.1.3 Effect of the Length of the Language Model History.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work, we use only n-gram-based language models.",
        "Entity": "Normal"
    },
    {
        "Text": "Ideally, we would like to take into account long-range dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet long n-grams are seen rarely and are therefore rarely used on unseen data.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we expect that extending the history length will at some point not improve further translation quality.",
        "Entity": "Normal"
    },
    {
        "Text": "T                                                                                                               .",
        "Entity": "Normal"
    },
    {
        "Text": "If we perform log-linear interpolation of a trigram model with a class-based 5-gram model, we observe an additional small improvement in translation quality to an mWER of 30.9%.",
        "Entity": "Normal"
    },
    {
        "Text": "6.2 Results on the Hansards task.",
        "Entity": "Normal"
    },
    {
        "Text": "The Hansards task involves the proceedings of the Canadian parliament, which are kept by law in both French and English.",
        "Entity": "Normal"
    },
    {
        "Text": "About three million parallel sentences of this bilingual data have been made available by the Linguistic Data Consortium (LDC).",
        "Entity": "Normal"
    },
    {
        "Text": "Here, we use a subset of the data containing only sentences of up to 30 words.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Because of memory limitations, the maximum alignment template length has been restricted to four words.",
        "Entity": "Normal"
    },
    {
        "Text": "We compare here against the single-word-based search for Model 4 described in Tillmann (2001).",
        "Entity": "Normal"
    },
    {
        "Text": "We see that the alignment template approach obtains significantly better results than the single-word-based search.",
        "Entity": "Normal"
    },
    {
        "Text": "6.3 Results on Chinese English.",
        "Entity": "Normal"
    },
    {
        "Text": "Various statistical, example-based, and rule-based MT systems for a Chinese English news domain were evaluated in the NIST 2002 MT evaluation.4 Using the alignment 4 Evaluation home page: http://www.nist.gov/speech/tests/mt/mt2001/index.htm..\n\t\t\t443                                                                                     ).",
        "Entity": "Normal"
    },
    {
        "Text": "F r e n c h E n g l i s h Trai nin g S e n t e n c e s W o r d s 2 4 , 3 3 8 , 1 9 5 1,4 70, 47 3 22 ,1 63 ,0 92 W o r d s * 2 2 , 1 7 5 , 0 6 9 20 ,0 63 ,3 78 V o c a b u l a r y 1 0 0 , 2 6 9 7 8 , 3 3 2 S i n g l e t o n s 4 0 , 1 9 9 3 1 , 3 1 9 Test S e n t e n c e s W o r d s 9 7 , 6 4 6 5 , 4 3 2 8 8 , 7 7 3 T r i g r a m p e r p l e x i t y   1 7 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "8                                                  .",
        "Entity": "Normal"
    },
    {
        "Text": "French English English French Translation approach WER [%] PER [%] WER [%] PER [%] Ali gn me nt tem plat es 6 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 4 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 6 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 7 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 Single word bas ed: mo not one sear ch 6 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 5 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 6 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 5 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 Single word bas ed: reor deri ng sear ch 6 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "9 5 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 6 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "0 5 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 Table 11 Corpus statistics for Chinese English corpora large data track (Words*: words without punctuation marks).",
        "Entity": "Normal"
    },
    {
        "Text": "N o p r e p r o c e s s i n g C hi n es e English With preproc essing Chinese English Trai n Sen tenc es 1,645,631 Uni que sent enc es 1,289,890 W o r d s 3 1, 1 7 5, 0 2 3 3 3, 0 4 4, 3 7 4 30,849 ,149 3 2, 5 1 1, 4 1 8 W o r d s * 2 7, 0 9 1, 2 8 3 2 9, 2 1 2, 3 8 4 26,828 ,721 2 8, 8 0 6, 7 3 5 S i n g l e t o n s 1 5 , 3 2 4 2 4 , 9 3 3 5 , 3 3 6 2 6 , 3 4 4 V o c a b u l a r y 6 7 , 1 0 3 9 2 , 4 8 8 4 5, 11 1 8 5 , 1 1 6 Lex Ent ries 80,9 77 Ext end ed voc abu lary 7 6 , 1 8 2 1 0 0 , 7 0 4 54 ,1 90 9 3 , 3 5 0 Dev Sen tenc es 99 3 Wor ds 2 6 , 3 6 1 3 2 , 2 6 7 25 ,8 52 3 1 , 6 0 7 Trig ram per plex ity   2 3 7 , 1 5 4   1 7 1 , 9 2 2 Test Sen tenc es 87 8 Wor ds 2 4 , 5 4 0   24 ,1 44   template approach described in this article, we participated in these evaluations.",
        "Entity": "Normal"
    },
    {
        "Text": "The problem domain is the translation of Chinese news text into English.",
        "Entity": "Normal"
    },
    {
        "Text": "The English vocabulary consists of full- form words that have been converted to lowercase letters.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of sentences has been artificially increased by adding certain parts of the original training material more than once to the training corpus, in order to give larger weight to those parts of the training corpus that consist of high-quality aligned Chinese news text and are therefore expected to be especially helpful for the translation of the test data.",
        "Entity": "Normal"
    },
    {
        "Text": "444 Table 12 Results of Chinese English NIST MT evaluation, June 2002, large data track (NIST09 score: larger values are better).",
        "Entity": "Normal"
    },
    {
        "Text": "System NIST09 score Alignment template approach 7.65 Competing research systems 5.03 7.34 Best of six commercial off-the-shelf systems 6.08 The Chinese language poses special problems because the boundaries of Chinese words are not marked.",
        "Entity": "Normal"
    },
    {
        "Text": "Chinese text is provided as a sequence of characters, and it is unclear which characters have to be grouped together to obtain entities that can be interpreted as words.",
        "Entity": "Normal"
    },
    {
        "Text": "For statistical MT, it would be possible to ignore this fact and treat the Chinese characters as elementary units and translate them into English.",
        "Entity": "Normal"
    },
    {
        "Text": "Yet preliminary experiments showed that the existing alignment models produce better results if the Chinese characters are segmented in a preprocessing step into single words.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the LDC segmentation tool.5 For the English corpus, the following preprocessing steps are applied.",
        "Entity": "Normal"
    },
    {
        "Text": "First, the corpus is tokenized; it is then segmented into sentences, and all uppercase characters are converted to lowercase.",
        "Entity": "Normal"
    },
    {
        "Text": "As the final evaluation criterion does not distinguish case, it is not necessary to deal with the case information.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, the preprocessed Chinese and English corpora are sentence aligned in which the lengths of the source and target sentences are significantly different.",
        "Entity": "Normal"
    },
    {
        "Text": "From the resulting corpus, we automatically replace translations.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, only sentences with less than 60 words in English and Chinese are used.",
        "Entity": "Normal"
    },
    {
        "Text": "To improve the translation of Chinese numbers, we use a categorization of Chinese number and date expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "For the statistical learning, all number and date expressions are replaced with one of two generic symbols, $number or $date.",
        "Entity": "Normal"
    },
    {
        "Text": "The number and date expressions are subjected to a rule-based translation by simple lexicon lookup.",
        "Entity": "Normal"
    },
    {
        "Text": "The translation of the number and date expressions is inserted into the output using the alignment information.",
        "Entity": "Normal"
    },
    {
        "Text": "For Chinese and English, this categorization is implemented independently of the other language.",
        "Entity": "Normal"
    },
    {
        "Text": "To evaluate MT quality on this task, NIST made available the NIST09 evaluation tool.",
        "Entity": "Normal"
    },
    {
        "Text": "This tool provides a modified BLEU score by computing a weighted precision of n-grams modified by a length penalty for very short translations.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 12 shows the results of the official evaluation performed by NIST in June 2002.",
        "Entity": "Normal"
    },
    {
        "Text": "With a score of 7.65, the results obtained were statistically significantly better than any other competing approach.",
        "Entity": "Normal"
    },
    {
        "Text": "Differences in the NIST score larger than 0.12 are statistically significant at the 95% level.",
        "Entity": "Normal"
    },
    {
        "Text": "We conclude that the developed alignment template approach is also applicable to unrelated language pairs such as Chinese English and that the developed statistical models indeed seem to be largely language-independent.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 13 shows various example translations.",
        "Entity": "Normal"
    },
    {
        "Text": "We have presented a framework for statistical MT for natural languages which is more general than the widely used source channel approach.",
        "Entity": "Normal"
    },
    {
        "Text": "It allows a baseline MT 5 The LDC segmentation tool is available at.",
        "Entity": "Normal"
    },
    {
        "Text": "http://morph.ldc.upenn.edu/Projects/Chinese/LDC ch.htm#cseg.",
        "Entity": "Normal"
    },
    {
        "Text": "445 Table 13 Example translations for Chinese English MT.",
        "Entity": "Normal"
    },
    {
        "Text": "Reference Significant Accomplishment Achieved in the Economic Construction of the Fourteen Open Border Cities in China Translation The opening up of the economy of China s fourteen City made significant achievements in construction Reference Xinhua News Agency, Beijing, Feb. 12 Exciting accomplishment has been achieved in 1995 in the economic construction of China s fourteen border cities open to foreigners.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation Xinhua News Agency, Beijing, February 12 China s opening up to the outside world of the 1995 in the fourteen border pleased to obtain the construction of the economy.",
        "Entity": "Normal"
    },
    {
        "Text": "Reference Foreign Investment in Jiangsu s Agriculture on the Increase Translation To increase the operation of foreign investment in Jiangsu agriculture Reference According to the data provided today by the Ministry of Foreign Trade and Economic Cooperation, as of November this year, China has actually utilized 46.959 billion US dollars of foreign capital, including 40.007 billion US dollars of direct investment from foreign businessmen.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation The external economic and trade cooperation Department today provided that this year, the foreign capital actually utilized by China on November to US $46.959 billion, including of foreign company direct investment was US $40.007 billion.",
        "Entity": "Normal"
    },
    {
        "Text": "Reference According to officials from the Provincial Department of Agriculture and Forestry of Jiangsu, the  Three-Capital  ventures approved by agencies within the agricultural system of Jiangsu Province since 1994 have numbered more than 500 and have utilized over 700 million US dollars worth of foreign capital, respectively three times and seven times more than in 1993.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation Jiangsu Province for the Secretaries said that, from the 1994 years, Jiangsu Province system the approval of the  three-funded  enterprises, there are more than 500, foreign investment utilization rate of more than US $700 million, 1993 years before three and seven.",
        "Entity": "Normal"
    },
    {
        "Text": "Reference The actual amount of foreign capital has also increased more than 30% as compared with the same period last year.",
        "Entity": "Normal"
    },
    {
        "Text": "Translation The actual amount of foreign investment has increased by more than 30% compared with the same period last year.",
        "Entity": "Normal"
    },
    {
        "Text": "Reference Import and Export in Pudong New District Exceeding 9 billion US dollars This Year Translation Foreign trade imports and exports of this year to the Pudong new Region exceeds US $9 billion system to be extended easily by adding new feature functions.",
        "Entity": "Normal"
    },
    {
        "Text": "We have described the alignment template approach for statistical machine translation, which uses two different alignment levels: a phrase-level alignment between phrases and a word- level alignment between single words.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result the context of words has a greater influence, and the changes in word order from source to target language can be learned explicitly.",
        "Entity": "Normal"
    },
    {
        "Text": "An advantage of this method is that machine translation is learned fully automatically through the use of a bilingual training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "We have shown that the presented approach is capable of achieving better translation results on various tasks compared to other statistical, example-based, or rule-based translation systems.",
        "Entity": "Normal"
    },
    {
        "Text": "This is especially interesting, as our system is structured simpler than many competing systems.",
        "Entity": "Normal"
    },
    {
        "Text": "446 We expect that better translation can be achieved by using models that go beyond the flat phrase segmentation that we perform in our model.",
        "Entity": "Normal"
    },
    {
        "Text": "A promising avenue is to gradually extend the model to take into account to some extent the recursive structure of natural languages using ideas from Wu and Wong (1998) or Alshawi, Bangalore, and Douglas (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "We expect other improvements as well from learning nonconsecutive phrases in source or target language and from better generalization methods for the learned-phrase pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "The work reported here was carried out while the first author was with the Lehrstuhl fu  r Informatik VI, Computer Science Department, RWTH Aachen  University of Technology.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tThis paper describes a Chinese word segmentation system that is based on majority voting among three models: a forward maximum matching model, a conditional random field (CRF) model using maximum subword-based tagging, and a CRF model using minimum subword- based tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, it contains a post-processing component to deal with inconsistencies.",
        "Entity": "Normal"
    },
    {
        "Text": "Testing on the closed track of CityU, MSRA and UPUC corpora problem.",
        "Entity": "Normal"
    },
    {
        "Text": "In the next step, the solutions from these three methods are combined via the hanzi- level majority voting algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, a post- processing procedure is applied in order to to get the final output.",
        "Entity": "Normal"
    },
    {
        "Text": "This procedure merges adjoining words to match the dictionary entries and then splits words which are inconsistent with entries in the training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Input Sentence in the third SIGHAN Chinese Word Segmentation Bakeoff, the system achieves a F-score of 0.961, 0.953 and 0.919, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Tokenizing input text into words is the first step of any text analysis task.",
        "Entity": "Normal"
    },
    {
        "Text": "In Chinese, a sentence is written as a string of characters, to which we shall refer by their traditional name of hanzi, without separations between words.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result, before any text analysis on Chinese, word segmentation task Forward Maximum Matching CRF with Maximum Subword based Tagging Majority Voting Post processing Result CRF with Minimum Subword based Tagging has to be completed so that each word is  isolated  by the word-boundary information.",
        "Entity": "Normal"
    },
    {
        "Text": "Participating in the third SIGHAN Chinese Word Segmentation Bakeoff in 2006, our system is tested on the closed track of CityU, MSRA and UPUC corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "The sections below provide a detailed description of the system and our experimental results.",
        "Entity": "Normal"
    },
    {
        "Text": "The maximum matching algorithm is a greedy segmentation approach.",
        "Entity": "Normal"
    },
    {
        "Text": "It proceeds through the sentence, mapping the longest word at each point with an entry in the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "In our system, the well-known forward maximum matching algorithm (Chen and Liu, 1992) is implemented.",
        "Entity": "Normal"
    },
    {
        "Text": "The maximum matching approach is simple and efficient, and it results in high in-vocabulary accuracy; However, the small size of the dictionary, which is obtained only from the training data, is a major bottleneck for this approach to be applied by itself.",
        "Entity": "Normal"
    },
    {
        "Text": "126 Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 126 129, Sydney, July 2006.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2006 Association for Computational Linguistics 2.2 CRF Model with Maximum.",
        "Entity": "Normal"
    },
    {
        "Text": "Subword-based Tagging Conditional random fields (CRF), a statistical sequence modeling approach (Lafferty et al., 2001), has been widely applied in various sequence learning tasks including Chinese word segmentation.",
        "Entity": "Normal"
    },
    {
        "Text": "In this approach, most existing methods use the character-based IOB tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "For example,  ;g(all) 3'::KJ!!",
        "Entity": "Normal"
    },
    {
        "Text": "(extremely important)  is labeled as  ;g(all)/O 3'(until)/B ::K(close)/I J!!",
        "Entity": "Normal"
    },
    {
        "Text": "(heavy)/I  (demand)/I .",
        "Entity": "Normal"
    },
    {
        "Text": "Recently (Zhang et al., 2006) proposed a maximum subword-based IOB tagger for Chinese word segmentation, and our system applies their approach which obtains a very high accuracy on the shared task data from previous SIGHAN competitions.",
        "Entity": "Normal"
    },
    {
        "Text": "In this method, all single-hanzi words and the top frequently occurring multihanzi words are extracted from the training corpus to form the lexicon subset.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, each word in the training corpus is segmented for IOB tagging, with the forward maximum matching algorithm, using the formed lexicon subset as the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "In the above example, the tagging labels become  ;g(all)/O3'(until)/B ::K(close)/I J!!",
        "Entity": "Normal"
    },
    {
        "Text": "(important)/I , assuming that  J!!",
        "Entity": "Normal"
    },
    {
        "Text": "(important)  is the longest sub word in this word, and it is one of the top frequently occurring words in the training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "After tagging the training corpus, we use the package CRF++1 to train the CRF model.",
        "Entity": "Normal"
    },
    {
        "Text": "Suppose w0 represents the current word, w 1 is the first word to the left, w 2 is the second word to the left, w1 is the first word to the right, and w2 is the second word to the right, then in our experiments, the types of unigram features used include w0, w 1, w1, w 2, w2, w0w 1, w0w1, w 1w1, w 2w 1, and w2w0.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, only combinations of previous observation and current observation are exploited as bigram features.",
        "Entity": "Normal"
    },
    {
        "Text": "2.3 CRF Model with Minimum.",
        "Entity": "Normal"
    },
    {
        "Text": "Subword-based Tagging In our third model, we applies a similar approach as in the previous section.",
        "Entity": "Normal"
    },
    {
        "Text": "However, instead of finding the maximum subwords, we explore the minimum subwords.",
        "Entity": "Normal"
    },
    {
        "Text": "At the beginning, we build the dictionary using the whole training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, for each word in the training data, a forward shortest matching is used to get the sequence of minimum-length subwords, and this sequence is 1 available from http://www/chasen.org/ taku/software tagged in the same IOB format as before.",
        "Entity": "Normal"
    },
    {
        "Text": "Suppose  a ,  ac ,  de  and  acde  are the only entries in the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, for the word  acde , the sequence of subwords is  a ,  c  and  de , and the tags assigned to  acde  are  a/B c/I de/I .",
        "Entity": "Normal"
    },
    {
        "Text": "After tagging the training data set, CRF++ package is executed again to train this type of model, using the identical unigram and bigram feature sets that are used in the previous model.",
        "Entity": "Normal"
    },
    {
        "Text": "Meanwhile, the unsegmented test data is segmented by the forward shortest matching algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "After this initial segmentation process, the result is fed into the trained CRF model for re- segmentation by assigning IOB tags.",
        "Entity": "Normal"
    },
    {
        "Text": "2.4 Majority Voting.",
        "Entity": "Normal"
    },
    {
        "Text": "Having the segmentation results from the above three models in hand, in this next step, we adopt the hanzi-level majority voting algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "First, for each hanzi in a segmented sentence, we tag it either as  B  if it is the first hanzi of a word or a single-hanzi word, or as  I  otherwise.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, for a given hanzi in the results from those three models, if at least two of the models provide the identical tag, it will be assigned that tag.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, suppose  a c de  is the segmentation result via forward maximum matching, and it is also the result from CRF model with maximum subword- based tagging, and  ac d e  is the result from the third model.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, for  a , since all of them assign  B  to it,  a  is given the  B  tag; for  c , because two of segmentations tag it as  B ,  c  is given the  B  tag as well.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, the tag for each remaining hanzi is determined by this majority voting process, and we get  a c de  as the result for this example.",
        "Entity": "Normal"
    },
    {
        "Text": "To test the performance of each of the three models and that of the majority voting, we divide the MSRA corpus into training set and held- out set.",
        "Entity": "Normal"
    },
    {
        "Text": "Throughout all the experiments we conducted, we discover that those two CRF models perform much better than the pure hanzi-based CRF method, and that the voting process improves the performance further.",
        "Entity": "Normal"
    },
    {
        "Text": "2.5 Post-processing.",
        "Entity": "Normal"
    },
    {
        "Text": "While analyzing errors with the segmentation result from the held-out set, we find two inconsistency problems: First, the inconsistency between the dictionary and the result: that is, certain words that appear in the dictionary are separated into consecutive words in the test result; Second, the inconsistency among words in the dictionary; For instance, both  t'\"ltlil'Jl (scientific research) and  t'\"lt(science) lil'Jl(research)  appear in the training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "To deal with the first phenomena, for the segmented result, we try to merge adjoining words to match the dictionary entries.",
        "Entity": "Normal"
    },
    {
        "Text": "Suppose  a b c de  are the original voting result, and  ab ,  abc  and  cd  form the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, we merge  a ,  b  and  c  together to get the longest match with the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, the output is  abc de .",
        "Entity": "Normal"
    },
    {
        "Text": "For the second problem, we introduce the split procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "In our system, we only consider two consecutive words.",
        "Entity": "Normal"
    },
    {
        "Text": "First, all bigrams are extracted from the training corpus, and their frequencies are counted.",
        "Entity": "Normal"
    },
    {
        "Text": "After that, for example, if  a b  appears more often than  ab , then whenever in the test result we encounter  ab , we split it into  a b .",
        "Entity": "Normal"
    },
    {
        "Text": "The post-processing steps detailed above attempt to maximize the value of known words in the training data as well as attempting to deal with the word segmentation inconsistencies in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "The third International Chinese Language Processing Bakeoff includes four different corpora, Academia Sinica (CKIP), City University of Hong Kong (CityU), Microsoft Research (MSRA), and University of Pennsylvania and University of Colorado, Boulder (UPUC), for the word segmentation task.",
        "Entity": "Normal"
    },
    {
        "Text": "In this bakeoff, we test our system in CityU, MSRA and UPUC corpora, and follow the closed track.",
        "Entity": "Normal"
    },
    {
        "Text": "That is, we only use training material from the training data for the particular corpus we are testing on.",
        "Entity": "Normal"
    },
    {
        "Text": "No other material or any type of external knowledge is used, including part-of-speech information, externally generated word-frequency counts, Arabic and Chinese numbers, feature characters for place names and common Chinese surnames.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Results on SIGHAN Bakeoff 2006.",
        "Entity": "Normal"
    },
    {
        "Text": "To observe the result of majority voting and the contribution of the post-processing step, the experiment is ran for each corpus by first producing the outcome of majority voting and then producing the output from the post-processing.",
        "Entity": "Normal"
    },
    {
        "Text": "In each experiment, the precision (P ), recall (R), F-measure (F ), Out-of-Vocabulary rate (OOV ), OOV recall rate (ROOV ), and In-Vocabulary rate (RI V ) are recorded.",
        "Entity": "Normal"
    },
    {
        "Text": ", ,  show the scores for the CityU corpus, for the MSRA corpus, and for the UPUC corpus, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, the post- processing step indeed helps to improve the performance.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Error analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "The errors that occur in our system are mainly due to the following three factors: First, there is inconsistency between the gold segmentation and the training corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the inconsistency problem within the training corpus is intended to be tackled in the post-processing step, we cannot conclude that the segmentation for certain words in the gold test set always follows the convention in the training data set.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in the MSRA training corpus,    00 ll&JM (Chinese government) is usually considered as a single word; while in the gold test set, it is separated as two words   00 (Chinese) and  ll& JM (government).",
        "Entity": "Normal"
    },
    {
        "Text": "This inconsistency issue lowers the system performance.",
        "Entity": "Normal"
    },
    {
        "Text": "This problem, of course, affects all competing systems.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, we don t have specific steps to deal with words with postfixes such as    (person).",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to our system, (Zhang, 2005) proposed a segmentation system that contains morphologically derived word recognition post-processing component to solve this problem.",
        "Entity": "Normal"
    },
    {
        "Text": "Lacking of such a step prevents us from identifying certain types of words such as   }J  (worker) to be a single word.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, the unknown words are still troublesome because of the limited size of the training corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "In the class of unknown words, we encounter person names, numbers, dates, organization names and words translated from languages other than Chinese.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in the produced CityU test result, the translated person name  *  ft1l  (Mihajlovic) is incorrectly separatedas  *   ft 1  and  l   .",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, in cer tain cases, person names can also create ambiguity.",
        "Entity": "Normal"
    },
    {
        "Text": "Take the name  Of d /J (Qiu, Beifang) in UPUC test set for example, without understanding the meaning of the whole sentence, it is difficult even for human to determine whether it is a person name or it represents  Of (autumn),  d /J (north), with the meaning of  the autumn in the north .",
        "Entity": "Normal"
    },
    {
        "Text": "In designing the voting procedure, we also attempt to develop and use a segmentation lattice, which proceeds using a similar underlying principle as the one applied in (Xu et al., 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "In our approach, for an input sentence, the segmentation result using each of our three models is transformed into an individual lattice.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, each edge in the lattice is assigned a particular weight, according to certain features such as whether or not the output word from that edge is in the dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "After building the three lattices, one for each model, we merge them together.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, the shortest path, referring to the path that has the minimum weight, is extracted from the merged lattice, and therefore, the segmentation result is determined by this shortest path.",
        "Entity": "Normal"
    },
    {
        "Text": "However, in the time we had to run our experiments on the test data, we were unable to optimize the edge weights to obtain high accuracy on some held-out set from the training corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "So instead, we tried a simple method for finding edge weights by uniformly distributing the weight for each feature; Nevertheless, by testing on the shared task data from the 2005 SIGHAN bakeoff, the performance is not competitive, compared to our simple majority voting method described above.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result, we decide to abandon this approach for this year s SIGHAN bakeoff.",
        "Entity": "Normal"
    },
    {
        "Text": "Our Chinese word segmentation system is based on majority voting among the initial outputs from forward maximum matching, from a CRF model with maximum subword-based tagging, and from a CRF model with minimum subword-based tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we experimented with various steps in post-processing which effectively boosted the overall performance.",
        "Entity": "Normal"
    },
    {
        "Text": "In future research, we shall explore more sophisticated ways of voting, including the continuing investigation on the segmentation lattice approach.",
        "Entity": "Normal"
    },
    {
        "Text": "Also, more powerful methods on how to accurately deal with unknown words, including person and place names, without external knowledge, will be studied as well.",
        "Entity": "Normal"
    },
    {
        "Text": "\nDiscovering Corpus-Specific Word Senses\n\t\n\t\tThis paper presents an unsupervised algorithm which automatically discovers word senses from text.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm is based on a graph model representing words and relationships between them.",
        "Entity": "Normal"
    },
    {
        "Text": "Sense clusters are iteratively computed by clustering the local graph of similar words around an ambiguous word.",
        "Entity": "Normal"
    },
    {
        "Text": "Discrimination against previously extracted sense clusters enables us to discover new senses.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the same data for both recognising and resolving ambiguity.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper describes an algorithm which automatically discovers word senses from free text and maps them to the appropriate entries of existing dictionaries or taxonomies.",
        "Entity": "Normal"
    },
    {
        "Text": "Automatic word sense discovery has applications of many kinds.",
        "Entity": "Normal"
    },
    {
        "Text": "It can greatly facilitate a lexicographer's work and can be used to automatically construct corpus-based taxonomies or to tune existing ones.",
        "Entity": "Normal"
    },
    {
        "Text": "The same corpus evidence which supports a clustering of an ambiguous word into distinct senses can be used to decide which sense is referred to in a given context (Schiitze, 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "This paper is organised as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "In section 2, we present the graph model from which we discover word senses.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 3 describes the way we divide graphs surrounding ambiguous words into different areas corresponding to different senses, using Markov clustering (van Dongen, 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "The quality of the Markov clustering depends strongly on several parameters such as a granularity factor and the size of the local graph.",
        "Entity": "Normal"
    },
    {
        "Text": "In section 4, we outline a word sense discovery algorithm which bypasses the problem of parameter tuning.",
        "Entity": "Normal"
    },
    {
        "Text": "We conducted a pilot experiment to examine the performance of our algorithm on a set of words with varying degree of ambiguity.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 5 describes the experiment and presents a sample of the results.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, section 6 sketches applications of the algorithm and discusses future work.",
        "Entity": "Normal"
    },
    {
        "Text": "The model from which we discover distinct word senses is built automatically from the British National corpus, which is tagged for parts of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "Based on the intuition that nouns which co-occur in a list are often semantically related, we extract contexts of the form Noun, Noun,... and/or Noun, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "\"genomic DNA from rat, mouse and dog\".",
        "Entity": "Normal"
    },
    {
        "Text": "Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Lin's work (1998), we are currently investigating a graph with verb-object, verb-subject and modifier-noun-collocations from which it is possible to infer more about the senses of systematically polysemous words.",
        "Entity": "Normal"
    },
    {
        "Text": "The word sense clustering algorithm as outlined below can be applied to any kind of similarity measure based on any set of features.",
        "Entity": "Normal"
    },
    {
        "Text": "1 Si mple cutoff functions proved unsatisfactory because of the bias they give to more frequent words.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead we link each word to its top n neighbors where n can be determined by the user (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "section 4)..\n\t\t\t41=0 441=P .4161.\n\t\t\tsz44, CD miltrA, litrepate inovio.\ufffd h,)                                            \n\t\n\t\n\t\t\tAmbiguous words link otherwise unrelated areas of meaning                                                                                                                     .",
        "Entity": "Normal"
    },
    {
        "Text": "There are, of course, many more types of polysemy (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "(Kilgarriff, 1992)).",
        "Entity": "Normal"
    },
    {
        "Text": ";.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore,                                                                                        .",
        "Entity": "Normal"
    },
    {
        "Text": "The same happens with wing \"part of a building\" and wing \"political group\" which are linked via policy.",
        "Entity": "Normal"
    },
    {
        "Text": "However, whereas there are many edges within an area of meaning, there is only a small number of (weak) links between different areas of meaning.",
        "Entity": "Normal"
    },
    {
        "Text": "To detect the different areas of meaning in our local graphs, we use a cluster algorithm for graphs (Markov clustering, MCL) developed by van Dongen (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "The idea underlying the MCL-algorithm is that random walks within the graph will tend to stay in the same cluster rather than jump between clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "The following notation and description of the MCL algorithm borrows heavily from van Dongen (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "Let G\ufffd, denote the local graph around the ambiguous word w. The adjacency matrix MG\ufffd 4111) 11\ufffd 41 4Wit ler,1110.1/.17, cgtoserek\ufffdIlt                                                   G\ufffd, is defined by setting (111G\ufffd) pq equal to the weight of the edge between nodes v and v q .",
        "Entity": "Normal"
    },
    {
        "Text": "Normalizing the columns of A/G\ufffd results in the Markov Matrix Taw whose entries (Thi,)pq can be interpreted as transition probability from v q to vv .",
        "Entity": "Normal"
    },
    {
        "Text": "It can easily be shown that the k-th power of TG\ufffd lists the probabilities (TL )pq of a path of length k starting at node vq and ending at node V. The MCL-algorithm simulates flow in Gw by iteratively recomputing the set of transition probabilities via two steps, expansion and inflation.",
        "Entity": "Normal"
    },
    {
        "Text": "The expansion step corresponds with taking the k-th power of TG\ufffd as outlined above and allows nodes to see new neighbours.",
        "Entity": "Normal"
    },
    {
        "Text": "The inflation step takes each matrix entry to the r-th power and then rescales each column so that the entries sum to 1.Vi a inflation, popular neighbours are further supported at the expense of less popular ones.",
        "Entity": "Normal"
    },
    {
        "Text": "Flow within dense regions in the graph is concentrated by both expansion and inflation.",
        "Entity": "Normal"
    },
    {
        "Text": "Eventually, flow between dense regions will disappear, the matrix of transition probabilities TG\ufffd will converge and the limiting matrix can be interpreted as a clustering of the graph.",
        "Entity": "Normal"
    },
    {
        "Text": "The output of the MCL-algorithm strongly depends on the inflation and expansion parameters r and k as well as the size of the local graph which serves as input to MCL.",
        "Entity": "Normal"
    },
    {
        "Text": "An appropriate choice of the inflation param 80 eter r can depend on the ambiguous word w to be clustered.",
        "Entity": "Normal"
    },
    {
        "Text": "In case of homonymy, a small inflation parameter r would be appropriate.",
        "Entity": "Normal"
    },
    {
        "Text": "However, there are ambiguous words with more closely related senses which are metaphorical or metonymic variations of one another.",
        "Entity": "Normal"
    },
    {
        "Text": "In that case, the different regions of meaning are more strongly interlinked and a small power coefficient r would lump different meanings together.",
        "Entity": "Normal"
    },
    {
        "Text": "Usually, one sense of an ambiguous word w is much more frequent than its other senses present in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "If the local graph handed over to the MCL process is small, we might miss some of w's meanings in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, if the local graph is too big, we will get a lot of noise.",
        "Entity": "Normal"
    },
    {
        "Text": "Below, we outline an algorithm which circumvents the problem of choosing the right parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast to pure Markov clustering, we don't try to find a complete clustering of G into senses at once.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead, in each step of the iterative process, we try to find the most disctinctive cluster c of G w (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "the most distinctive meaning of w) only.",
        "Entity": "Normal"
    },
    {
        "Text": "We then recompute the local graph Gw by discriminating against c's features.",
        "Entity": "Normal"
    },
    {
        "Text": "This is achieved, in a manner similar to Pantel and Lin's (2002) sense clustering approach, by removing c's features from the set of features used for finding similar words.",
        "Entity": "Normal"
    },
    {
        "Text": "The process is stopped if the similarity between w and its best neighbour under the reduced set of features is below a fixed threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "Let F be the set of w's features, and let L be the output of the algorithm, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "a list of sense clusters initially empty.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm consists of the following steps: 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Compute a small local graph Gw around w using the set of features F. If the similarity between w and its closest neighbour is below a fixed threshold go to 6.",
        "Entity": "Normal"
    },
    {
        "Text": "2.",
        "Entity": "Normal"
    },
    {
        "Text": "Recursively remove all nodes of degree one.",
        "Entity": "Normal"
    },
    {
        "Text": "Then remove the node corresponding with w from G. 3.",
        "Entity": "Normal"
    },
    {
        "Text": "Apply MCL to Gw with a fairly big inflation parameter r which is fixed.",
        "Entity": "Normal"
    },
    {
        "Text": "4.",
        "Entity": "Normal"
    },
    {
        "Text": "Take the \"best\" cluster (the one that is most strongly connected to w in Gw before removal of w), add it to the final list of clusters L and remove/devalue its features from F. 5.",
        "Entity": "Normal"
    },
    {
        "Text": "Go back to 1 with the reduced/devalued set of features F. 6.",
        "Entity": "Normal"
    },
    {
        "Text": "Go through the final list of clusters L and assign a name to each cluster using a broad-coverage taxonomy (see below).",
        "Entity": "Normal"
    },
    {
        "Text": "Merge semantically close clusters using a taxonomy-based semantic distance measure (Budanitsky and Hirst, 2001) and assign a class-label to the newly formed cluster.",
        "Entity": "Normal"
    },
    {
        "Text": "7.",
        "Entity": "Normal"
    },
    {
        "Text": "Output the list of class-labels which best represent the different senses of w in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The local graph in step 1 consists of w, the ni neighbours of w and the n9 neighbours of the neighbours of w. Since in each iteration we only attempt to find the \"best\" cluster, it suffices to build a relatively small graph in 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Step 2 removes noisy strings of nodes pointing away from G. The removal of w from G w might already separate the different areas of meaning, but will at least significantly loosen the ties between them.",
        "Entity": "Normal"
    },
    {
        "Text": "In our simple model based on noun co-occurrences in lists, step 5 corresponds to rebuilding the graph under the restriction that the nodes in the new graph not co-occur (or at least not very often) with any of the cluster members already extracted.",
        "Entity": "Normal"
    },
    {
        "Text": "The class-labelling (step 6) is accomplished using the taxonomic structure of WordNet, using a robust algorithm developed specially for this purpose.",
        "Entity": "Normal"
    },
    {
        "Text": "The hypemym which subsumes as many cluster members as possible and does so as closely as possible in the taxonomic tree is chosen as class-label.",
        "Entity": "Normal"
    },
    {
        "Text": "The family of such algorithms is described in (Widdows, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we describe an initial evaluation experiment and present the results.",
        "Entity": "Normal"
    },
    {
        "Text": "We will soon carry out and report on a more thorough analysis of our algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "We used the simple graph model based on co-occurrences of nouns in lists (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "section 2) for our experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "We gathered a list of nouns with varying degree of ambiguity, from homonymy (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "arms) to systematic polysemy (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "cherry).",
        "Entity": "Normal"
    },
    {
        "Text": "Our algorithm was applied to each word in the list (with parameters Iii = 20, n2 = 10, r = 2.0, k = 2.0) in order to extract the top two sense clusters only.",
        "Entity": "Normal"
    },
    {
        "Text": "We then determined the WordNet synsets which most adequately characterized the sense clusters.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The benefits of automatic, data-driven word sense discovery for natural language processing and lexicography would be very great.",
        "Entity": "Normal"
    },
    {
        "Text": "Here we only mention a few direct results of our work.",
        "Entity": "Normal"
    },
    {
        "Text": "Our algorithm does not only recognise ambiguity, but can also be used to resolve it, because the features shared by the members of each sense cluster provide strong indication of which reading of an ambiguous word is appropriate given a certain context.",
        "Entity": "Normal"
    },
    {
        "Text": "This gives rise to an automatic, unsupervised word sense disambiguation algorithm which is trained on the data to be disambiguated.",
        "Entity": "Normal"
    },
    {
        "Text": "The ability to map senses into a taxonomy using the class-labelling algorithm can be used to ensure that the sense-distinctions discovered correspond to recognised differences in meaning.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach to disambiguation combines the benefits of both Yarowsky's (1995) and Schtitze's (1998) approaches.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Off-the-shelf lexical resources are rarely adequate for NLP tasks without being adapted.",
        "Entity": "Normal"
    },
    {
        "Text": "They often contain many rare senses, but not the same ones that are relevant for specific domains or corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "The problem can be addressed by using word sense clustering to attune an existing resource to accurately describe the meanings used in a particular corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "We prepare an evaluation of our algorithm as applied to the collocation relationships (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "section 2), and we plan to evaluate the uses of our clustering algorithm for unsupervised disambiguation more thoroughly.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tMany types of polysemy are not word specific, but are instances of general sense alternations such as ANIMAL-FOOD.",
        "Entity": "Normal"
    },
    {
        "Text": "Despite their pervasiveness, regular alternations have been mostly ignored in empirical computational semantics.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper presents (a) a general framework which grounds sense alternations in corpus data, generalizes them above individual words, and allows the prediction of alternations for new words; and (b) a concrete unsupervised implementation of the framework, the Centroid Attribute Model.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluate this model against a set of 2,400 ambiguous words and demonstrate that it outperforms two baselines.",
        "Entity": "Normal"
    },
    {
        "Text": "One of the biggest challenges in computational semantics is the fact that many words are polysemous.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, lamb can refer to an animal (as in The lamb squeezed through the gap) or to a food item (as in Sue had lamb for lunch).",
        "Entity": "Normal"
    },
    {
        "Text": "Polysemy is pervasive in human language and is a problem in almost all applications of NLP, ranging from Machine Translation (as word senses can translate differently) to Textual Entailment (as most lexical entailments are sense-specific).",
        "Entity": "Normal"
    },
    {
        "Text": "The field has thus devoted a large amount of effort to the representation and modeling of word senses.",
        "Entity": "Normal"
    },
    {
        "Text": "The arguably most prominent effort is Word Sense Disambiguation, WSD (Navigli, 2009), an in-vitro task whose goal is to identify which, of a set of predefined senses, is the one used in a given context.",
        "Entity": "Normal"
    },
    {
        "Text": "In work on WSD and other tasks related to pol- ysemy, such as word sense induction, sense alternations are treated as word-specific.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts.",
        "Entity": "Normal"
    },
    {
        "Text": "A large number of studies in linguistics and cognitive science show evidence that there are regulari- ties in the way words vary in their meaning (Apresjan, 1974; Lakoff and Johnson, 1980; Copestake and Briscoe, 1995; Pustejovsky, 1995; Gentner et al., 2001; Murphy, 2002), due to general analogical processes such as regular polysemy, metonymy and metaphor.",
        "Entity": "Normal"
    },
    {
        "Text": "Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD.",
        "Entity": "Normal"
    },
    {
        "Text": "Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise).",
        "Entity": "Normal"
    },
    {
        "Text": "Disregarding this evidence is empirically inadequate and leads to the well-known lexical bottleneck of current word sense models, which have serious problems in achieving high coverage (Navigli, 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "We believe that empirical computational semantics could profit from a model of polysemy1 which (a) is applicable across individual words, and thus capable of capturing general patterns and generalizing to new 1 Our work is mostly inspired in research on regular polysemy.",
        "Entity": "Normal"
    },
    {
        "Text": "However, given the fuzzy nature of  regularity  in meaning variation, we extend the focus of our attention to include other types of analogical sense construction processes.",
        "Entity": "Normal"
    },
    {
        "Text": "151 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 151 160, Montre al, Canada, June 78, 2012.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2012 Association for Computational Linguistics words, and (b) is induced in an unsupervised fashion from corpus data.",
        "Entity": "Normal"
    },
    {
        "Text": "This is a long-term goal with many unsolved subproblems.",
        "Entity": "Normal"
    },
    {
        "Text": "The current paper presents two contributions towards this goal.",
        "Entity": "Normal"
    },
    {
        "Text": "First, since we are working on a relatively unexplored area, we introduce a formal framework that can encompass different approaches (Section 2).",
        "Entity": "Normal"
    },
    {
        "Text": "Second, we implement a concrete instantiation of this framework, the unsupervised Centroid Attribute Model (Section 3), and evaluate it on a new task, namely, to detect which of a set of words in- stantiate a given type of polysemy (Sections 4 and 5).",
        "Entity": "Normal"
    },
    {
        "Text": "We finish with some conclusions and future work (Section 7).",
        "Entity": "Normal"
    },
    {
        "Text": "In addition to introducing formal definitions for terms commonly found in the literature, our framework provides novel terminology to deal with regular polysemy in a general fashion (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, let lambanm denote the ANIMAL sense of lamb, lambfod the FOOD sense, and lambhum the PERSON sense.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, an appropriate model of meta alternations should predict that score(animal, food, lambanm, lambfod) is greater than score(animal, food, lambanm, lambhum).",
        "Entity": "Normal"
    },
    {
        "Text": "Meta alternations are defined as unordered pairs of meta senses, or crossword senses like ANIMAL.",
        "Entity": "Normal"
    },
    {
        "Text": "The meta senses M can be defined a priori or induced from data.",
        "Entity": "Normal"
    },
    {
        "Text": "They are equivalence classes of senses to which they are linked through the function meta.",
        "Entity": "Normal"
    },
    {
        "Text": "A sense s instantiates a meta sense m iff meta(s) = m. Functions inst and sns allow us to define meta senses and lemma-specific senses in terms of actual instances, or occurrences of words in context.",
        "Entity": "Normal"
    },
    {
        "Text": "2 We reuse inst as a function that returns the set of instances.",
        "Entity": "Normal"
    },
    {
        "Text": "We decompose the score function into two parts: a representation function repA that maps a meta alternation into some suitable representation for meta alternations, A, and a compatibility function comp that compares the relation between the senses of a word to the meta alternation s representation.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, comp   repA = score.",
        "Entity": "Normal"
    },
    {
        "Text": "The Centroid Attribute Model (CAM) is a simple instantiation of the framework defined in Section 2, designed with two primary goals in mind.",
        "Entity": "Normal"
    },
    {
        "Text": "First, it is a data-driven model.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, it does not require any manual sense disambiguation, a notorious bottleneck.",
        "Entity": "Normal"
    },
    {
        "Text": "To achieve the first goal, CAM uses a distributional approach.",
        "Entity": "Normal"
    },
    {
        "Text": "It represents the relevant entities as co-occurrence vectors that can be acquired from a large corpus (Turney and Pantel, 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "To achieve the second goal, CAM represents meta senses using monosemous words only, that is, words whose senses all correspond to one meta sense.",
        "Entity": "Normal"
    },
    {
        "Text": "4 Examples are cattle and robin for the meta sense ANIMAL.",
        "Entity": "Normal"
    },
    {
        "Text": "We define the vector for a meta sense as the centroid (average vector) of the monosemous words instantiating it.",
        "Entity": "Normal"
    },
    {
        "Text": "In turn, meta alternations are represented by the centroids of their meta senses  vectors.",
        "Entity": "Normal"
    },
    {
        "Text": "This strategy is not applicable to test lemmas, which instantiate some meta alternation and are by definition ambiguous.",
        "Entity": "Normal"
    },
    {
        "Text": "To deal with these without for a sense: SL    (IL ) and assume that senses partition lemmas  instances:  l : inst(l) = Us sns(l) inst(s).",
        "Entity": "Normal"
    },
    {
        "Text": "3 Consistent with the theoretical literature, this paper focuses on two-way polysemy.",
        "Entity": "Normal"
    },
    {
        "Text": "See Section 7 for further discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "and 2.3% are disemous, while, on a token level, 23.3% are monosemous and 20.2% disemous.",
        "Entity": "Normal"
    },
    {
        "Text": "CoreLex: A Semantic Inventory.",
        "Entity": "Normal"
    },
    {
        "Text": "CAM uses CoreLex (Buitelaar, 1998) as its meta sense inventory.",
        "Entity": "Normal"
    },
    {
        "Text": "CoreLex is a lexical resource that was designed specifically for the study of polysemy.",
        "Entity": "Normal"
    },
    {
        "Text": "It builds on WordNet (Fellbaum, 1998), whose sense distinctions are too fine-grained to describe general sense alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "These classes are linked to one or more Wordnet anchor nodes, the definitions for vecL and repA.",
        "Entity": "Normal"
    },
    {
        "Text": "First, vecL defines a lemma s vector as the centroid of its instances: vecL(l) = C{vecI (i) | i   inst(l)} (1) Before defining repA, we specify a function repM that computes vector representations for meta senses m. In CAM, this vector is defined as the centroid of the vectors for all monosemous lemmas whose WordNet sense maps onto m: repM(m) = C{vecL(l) | meta(sns(l)) = {m}} (2) Now, repA can be defined simply as the centroid of the meta senses instantiating a: repA(m1, m2) = C{repM(m1), repM(m2)} (3) Predicting Meta Alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "The final component of CAM is an instantiation of comp (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "Since CAM does not represent these senses separately, we define comp as comp(a, s1, s2) = sim(a, vecL(l)) which define a mapping from WordNet synsets onto basic types: A synset s maps onto a basic type b if b so that {s1, s2} = sns(l) (4) has an anchor node that dominates s and there is no other anchor node on the path from b and s.5 We adopt the WordNet synsets as S, the set of senses, and the CoreLex basic types as our set of meta senses M .",
        "Entity": "Normal"
    },
    {
        "Text": "The meta function (mapping word senses onto meta senses) is given directly by the anchor mapping defined in the previous paragraph.",
        "Entity": "Normal"
    },
    {
        "Text": "This means that the set of meta alternations is given by the set of pairs of basic types.",
        "Entity": "Normal"
    },
    {
        "Text": "Although basic types do not perfectly model meta senses, they constitute an approximation that allows us to model many prominent alternations such as ANIMAL-FOOD.",
        "Entity": "Normal"
    },
    {
        "Text": "Vectors for Meta Senses and Alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "All representations used by CAM are co-occurrence vec tors in Rk (i.e., A := Rk ).",
        "Entity": "Normal"
    },
    {
        "Text": "vecI returns a vector for a lemma instance, vecL a (type) vector for a lemma, and C the centroid of a set of vectors.",
        "Entity": "Normal"
    },
    {
        "Text": "We leave vecI and C unspecified: we will experiment with these functions in Section 4.",
        "Entity": "Normal"
    },
    {
        "Text": "CAM does fix 5 This is necessary because some classes have non-disjoint anchor nodes: e.g., ANIMALs are a subset of LIVING BEINGs.",
        "Entity": "Normal"
    },
    {
        "Text": "The complete model, score, can now be stated as: score(m, m!, s, s!)",
        "Entity": "Normal"
    },
    {
        "Text": "= sim(repA(m, m!",
        "Entity": "Normal"
    },
    {
        "Text": "), vecL(l)) so that {s, s!}",
        "Entity": "Normal"
    },
    {
        "Text": "= sns(l) (5) CAM thus assesses how well a meta alternation a = (m, m!)",
        "Entity": "Normal"
    },
    {
        "Text": "explains a lemma l by comparing the centroid of the meta senses m, m!",
        "Entity": "Normal"
    },
    {
        "Text": "to l s centroid.",
        "Entity": "Normal"
    },
    {
        "Text": "Discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "The central feature of CAM is that it avoids word sense disambiguation, although it still relies on a predefined sense inventory (Word- Net, through CoreLex).",
        "Entity": "Normal"
    },
    {
        "Text": "Our use of monosemous words to represent meta senses and meta alternations goes beyond previous work which uses monosemous words to disambiguate polysemous words in context (Izquierdo et al., 2009; Navigli and Velardi, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "Because of its focus on avoiding disambiguation, CAM simplifies the representation of meta alternations and polysemous words to single centroid vectors.",
        "Entity": "Normal"
    },
    {
        "Text": "In the future, we plan to induce word senses (Schu  tze, 1998; Pantel and Lin, 2002; Reisinger and Mooney, 2010), which will allow for more flexible and realistic models.",
        "Entity": "Normal"
    },
    {
        "Text": "ab s AB STR AC TIO N e nt EN TIT Y l o c LO CAT ION p rt PAR T ac t AC T ev t EV ENT l o g GE O.",
        "Entity": "Normal"
    },
    {
        "Text": "LO CAT ION p s y PS YC HO L. FE ATU RE ag t AG ENT fo d FO OD m e a ME AS UR E q u d DE FINI TE QU AN TIT Y an m AN IM AL fr m FO RM m ic MI CR OO RG ANI SM q ui IND EFI NIT E QU AN TIT Y ar t AR TIF ACT gr b BIO LO G. GR OU P n a t NA TU RAL BO DY r e l RE LAT ION at r AT TRI BU TE gr p GR OU PIN G p h m PH EN OM EN ON s p c SPA CE c el CE LL gr s SO CIA L GR OU P p h o PH YSI CAL OB JEC T st a STA TE ch m CH EMI CA L hu m HU MA N p lt PL AN T s u b SU BST AN CE co m CO MM UNI CAT ION lf r LIV ING BEI NG p o s PO SSE SSI ON t m e TI ME co n CO NS EQ UE NC E lm e LIN EA R ME AS UR E p r o PR OC ESS p r o PR OC ESS                                                                         \n\t\t\tCAM adopts these as meta senses.",
        "Entity": "Normal"
    },
    {
        "Text": "We test CAM on the task of identifying which lemmas of a given set instantiate a specific meta alternation.",
        "Entity": "Normal"
    },
    {
        "Text": "We let the model rank the lemmas through the score function (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "(5)) and evaluate the ranked list using Average Precision.",
        "Entity": "Normal"
    },
    {
        "Text": "While an alternative would be to rank meta alternations for a given polysemous lemma, the method chosen here has the benefit of providing data on the performance of individual meta senses and meta alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Data.",
        "Entity": "Normal"
    },
    {
        "Text": "All modeling and data extraction was carried out on the written part of the British National Corpus (BNC; Burnage and Dunlop (1992)) parsed with the C&C sen so that they match targets in frequency.",
        "Entity": "Normal"
    },
    {
        "Text": "For each meta alternation, we randomly select 40 lemmas as experimental items (10 targets and 10 distractors of each type) so that a total of 2,400 lemmas is used in the evaluation.7 Table 4 shows four targets and their distractors for the meta alternation ANIMAL-FOOD.8 4.2 Evaluation Measure and Baselines.",
        "Entity": "Normal"
    },
    {
        "Text": "To measure success on this task, we use Average Precision (AP), an evaluation measure from IR that reaches its maximum value of 1 when all correct items are ranked at the top (Manning et al., 2008).It interpolates the precision values of the top-n prediction lists for all positions n in the list that con tools (Clark and Curran, 2007).",
        "Entity": "Normal"
    },
    {
        "Text": "6 For the evaluation, we focus on disemous words, tain a target.",
        "Entity": "Normal"
    },
    {
        "Text": "Let T = q1, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", qm be the list of words which instantiate exactly two meta senses according to WordNet.",
        "Entity": "Normal"
    },
    {
        "Text": "For each meta alternationtargets, and let P = p1, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", pn be the list of pre dictions as ranked by the model.",
        "Entity": "Normal"
    },
    {
        "Text": "Let I(xi) = 1 if pi   T , and zero otherwise.",
        "Entity": "Normal"
    },
    {
        "Text": "Then AP (P, T ) =(m, m!",
        "Entity": "Normal"
    },
    {
        "Text": "), we evaluate CAM on a set of disemous tar 1 ' m i j=1 I (xi ) gets (lemmas that instantiate (m, m!))",
        "Entity": "Normal"
    },
    {
        "Text": "and disemous m i=1 I(xi) i .",
        "Entity": "Normal"
    },
    {
        "Text": "AP measures the quality distractors (lemmas that do not).",
        "Entity": "Normal"
    },
    {
        "Text": "We define three types of distractors: (1) distractors sharing m with the targets (but not m!",
        "Entity": "Normal"
    },
    {
        "Text": "), (2) distractors sharing m!",
        "Entity": "Normal"
    },
    {
        "Text": "with the targets (but not m), and (3) distractors shar ing neither.",
        "Entity": "Normal"
    },
    {
        "Text": "In this way, we ensure that CAM cannot obtain good results by merely modeling the similarity of targets to either m or m!, which would rather be a coarse-grained word sense modeling task.",
        "Entity": "Normal"
    },
    {
        "Text": "To ensure that we have enough data, we evaluate CAM on all meta alternations with at least ten targets that occur at least 50 times in the corpus, discarding nouns that have fewer than 3 characters or contain non-alphabetical characters.",
        "Entity": "Normal"
    },
    {
        "Text": "The distractors are cho 6 The C&C tools were able to reliably parse about 40M words..\n\t\t\tof the ranked list for a single meta alternation.",
        "Entity": "Normal"
    },
    {
        "Text": "The overall quality of a model is given by Mean Average Precision (MAP), the mean of the AP values for all meta alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "We consider two baselines: (1) A random baseline that ranks all lemmas in random order.",
        "Entity": "Normal"
    },
    {
        "Text": "This baseline is the same for all meta alternations, since the distribution is identical.",
        "Entity": "Normal"
    },
    {
        "Text": "We estimate it by sampling.",
        "Entity": "Normal"
    },
    {
        "Text": "(2) A meta alternation-specific frequency baseline which orders the lemmas by their corpus frequencies.",
        "Entity": "Normal"
    },
    {
        "Text": "This 7 Dataset available at http://www.nlpado.de/.",
        "Entity": "Normal"
    },
    {
        "Text": "sebastian/data.shtml.",
        "Entity": "Normal"
    },
    {
        "Text": "8 Note that this experimental design avoids any overlap be-.",
        "Entity": "Normal"
    },
    {
        "Text": "tween the words used to construct sense vectors (one meta sense) and the words used in the evaluation (two meta senses).",
        "Entity": "Normal"
    },
    {
        "Text": "Ta rg et s Di str act ors wit h me ta se ns e an m Di str act ors wit h me ta se ns e fo d Ra nd om dis tra ct or s c a r p d u c kl in g e el ha re a m p h i b i a n ( a n m a r t ) a p e ( a n m h u m ) l e o p a r d ( a n m s u b ) l i z a r d ( a n m h u m ) m o u s s e ( a r t f o d ) p a r s l e y ( f o d p l t ) p i c k l e ( f o d s t a ) p o r k ( f o d m e a ) a p pr o pr ia ti o n ( a ct m e a ) sc is s or s ( a c t a r t) s h o w m a n ( a gt h u m ) u p h ol st er y ( a c t a r t)                                                                       \n\t\t\t                                      \n\t\t\tbaseline uses the intuition that frequent words will tend to exhibit more typical alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Model Parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "There are four more parameters to set.",
        "Entity": "Normal"
    },
    {
        "Text": "Definition of vector space.",
        "Entity": "Normal"
    },
    {
        "Text": "We instantiate the vecI function in three ways.",
        "Entity": "Normal"
    },
    {
        "Text": "All three are based on dependency-parsed spaces, following our intuition that topical similarity as provided by window-based spaces is insufficient for this task.",
        "Entity": "Normal"
    },
    {
        "Text": "The functions differ in the definition of the space s dimensions, incorporating different assumptions about distributional differences among meta alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "The first option, gram, uses grammatical paths of lengths 1 to 3 as dimensions and thus characterizes lemmas and meta senses in terms of their grammatical context (Schulte im Walde, 2006), with a total of 2,528 paths.",
        "Entity": "Normal"
    },
    {
        "Text": "The second option, lex, uses words as dimensions, treating the dependency parse as a co-occurrence filter (Pado  and Lapata, 2007), and captures topical distinctions.",
        "Entity": "Normal"
    },
    {
        "Text": "The third option, gramlex, uses lexicalized dependency paths like obj see to mirror more fine-grained semantic properties (Grefenstette, 1994).",
        "Entity": "Normal"
    },
    {
        "Text": "Both lex and gramlex use the 10,000 most frequent items in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Vector elements.",
        "Entity": "Normal"
    },
    {
        "Text": "We use  raw  corpus co- occurrence frequencies as well as log-likelihood- transformed counts (Lowe, 2001) as elements of the co-occurrence vectors.",
        "Entity": "Normal"
    },
    {
        "Text": "Definition of centroid computation.",
        "Entity": "Normal"
    },
    {
        "Text": "There are three centroid computations in CAM: to combine instances into lemma (type) vectors (function vecL in Eq.",
        "Entity": "Normal"
    },
    {
        "Text": "(1)); to combine lemma vectors into meta sense vectors (function repM in Eq.",
        "Entity": "Normal"
    },
    {
        "Text": "(2)); and to combine meta sense vectors into meta alternation vectors (function repA in Eq.",
        "Entity": "Normal"
    },
    {
        "Text": "(3)).",
        "Entity": "Normal"
    },
    {
        "Text": "For vecL, the obvious definition of the centroid function is as a micro-average, that is, a simple average over all instances.",
        "Entity": "Normal"
    },
    {
        "Text": "For repM and repA, there is a design choice: The centroid can be computed by micro-averaging as well, which assigns a larger weight to more frequent lemmas (repM) or meta senses (repA).",
        "Entity": "Normal"
    },
    {
        "Text": "Alternatively, it can be computed by macro-averaging, that is, by normalizing the individual vectors before averaging.",
        "Entity": "Normal"
    },
    {
        "Text": "This gives equal weight to the each lemma or meta sense, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Macro-averaging in repA thus assumes that senses are equally distributed, which is an oversimplification, as word senses are known to present skewed distributions (McCarthy et al., 2004) and vectors for words with a predominant sense will be similar to the dominant meta sense vector.",
        "Entity": "Normal"
    },
    {
        "Text": "Micro-averaging partially models sense skewedness under the assumption that word frequency correlates with sense frequency.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarity measure.",
        "Entity": "Normal"
    },
    {
        "Text": "As the vector similarity measure in Eq.",
        "Entity": "Normal"
    },
    {
        "Text": "(5), we use the standard cosine similar ity (Lee, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "It ranges between  1 and 1, with 1 denoting maximum similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "In the current model where the vectors do not contain negative counts, the range is [0; 1].",
        "Entity": "Normal"
    },
    {
        "Text": "Effect of Parameters The four parameters of Section 4.3 (three space types, macro-/micro-averaging for repM and repA, and log-likelihood transformation) correspond to 24 instantiations of CAM.",
        "Entity": "Normal"
    },
    {
        "Text": "The only significant difference is tied to the use of lexicalized vector spaces (gramlex / lex are better than gram).",
        "Entity": "Normal"
    },
    {
        "Text": "The statistical significance of this difference was verified by a t-test (p < 0.01).",
        "Entity": "Normal"
    },
    {
        "Text": "This indicates that meta alternations can be characterized better through fine-grained semantic distinctions than by syntactic ones.",
        "Entity": "Normal"
    },
    {
        "Text": "The choice of micro- vs. macro-average does not have a clear effect, and the large variation observed in                                                                                                                                                                         False True LL transformation firmed that the difference to the frequency baseline is significant at p < 0.01 for all 24 models.",
        "Entity": "Normal"
    },
    {
        "Text": "The difference to the random baseline is significant at p < 0.01 for 23 models and at p < 0.05 for the remaining model.",
        "Entity": "Normal"
    },
    {
        "Text": "This shows that the models cap ture the meta alternations to some extent.",
        "Entity": "Normal"
    },
    {
        "Text": "The best model uses macro averaging for repM and repA in a log likelihood transformed gramlex space and achieves a MAP of 0.399.",
        "Entity": "Normal"
    },
    {
        "Text": "It shows an encouraging picture: CAM outperforms the frequency baseline for 49 of the 60 meta alternations and both baselines for 44 (73.3%) of all alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "The performance shows a high degree of variance, however, ranging from 0.22 to 0.71.",
        "Entity": "Normal"
    },
    {
        "Text": "A data point is the mean AP (MAP) across all meta alternations for a specific setting.",
        "Entity": "Normal"
    },
    {
        "Text": "modeled.",
        "Entity": "Normal"
    },
    {
        "Text": "Focusing on meta alternations, whether the two intervening meta senses should be balanced or not can be expected to depend on the frequencies of the concepts denoted by each meta sense, which vary for each case.",
        "Entity": "Normal"
    },
    {
        "Text": "Indeed, for AGENT-HUMAN, the alternation which most benefits from the micro-averaging setting, the targets are much more similar to the HUMAN meta sense (which is approximately 8 times as frequent as AGENT) than to the AGENT meta sense.",
        "Entity": "Normal"
    },
    {
        "Text": "The latter contains anything that can have an effect on something, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "emulsifier, force, valium.",
        "Entity": "Normal"
    },
    {
        "Text": "The targets for AGENT-HUMAN, in contrast, contain words such as engineer, manipulator, operative, which alternate between an agentive role played by a person and the person herself.",
        "Entity": "Normal"
    },
    {
        "Text": "While lacking in clear improvement, log- likelihood transformation tends to reduce variance, consistent with the effect previously found in selectional preference modeling (Erk et al., 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "Overall Performance Although the performance of the CAM models is still far from perfect, all 24 models obtain MAP scores of 0.35 or above, while the random baseline is at 0.313, and the overall frequency baseline at 0.291.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, all models consistently outperform both baselines.",
        "Entity": "Normal"
    },
    {
        "Text": "A bootstrap resampling test (Efron and Tibshirani, 1994) con Analysis by Meta Alternation Coherence Meta alternations vary greatly in their difficulty.",
        "Entity": "Normal"
    },
    {
        "Text": "Since CAM is an attribute similarity-based approach, we expect it to perform better on the alternations whose meta senses are ontologically more similar.",
        "Entity": "Normal"
    },
    {
        "Text": "We next test this hypothesis.",
        "Entity": "Normal"
    },
    {
        "Text": "Let Dmi = {dij } be the set of distractors for the targets T = {tj } that share the meta sense mi, and DR = {d3j } the set of random distractors.",
        "Entity": "Normal"
    },
    {
        "Text": "We define the coherence   of an alternation a of meta senses m1, m2 as the mean ( ) difference between the similarity of each target vector to a and the similarity of the corresponding distractors to a, or formally  (a) =   sim(repA(m1, m2), vecL(tj ))   sim(repA(m1, m2), vecL(dij )), for 1   i   3 and 1   j   10.",
        "Entity": "Normal"
    },
    {
        "Text": "That is,   measures how much more similar, on average, the meta alternation vector is to the target vectors than to the distractor vectors.",
        "Entity": "Normal"
    },
    {
        "Text": "For a meta alternation with a higher  , the targets should be easier to distinguish from the distractors.",
        "Entity": "Normal"
    },
    {
        "Text": "As we expect from the definition of  , AP is strongly correlated with  .",
        "Entity": "Normal"
    },
    {
        "Text": "However, there is a marked Y shape, i.e., a divergence in behavior between high-   and mid-AP alternations (upper right corner) and mid-  and high-AP alternations (upper left corner).",
        "Entity": "Normal"
    },
    {
        "Text": "In the first case, meta alternations perform worse than expected, and we find that this typically points to missing senses, that is, problems in the underlying lexical resource (WordNet, via CoreLex).",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, the FOOD-PLANT distractor almond is given grs ps y 0.7 09 com ev t 0.5 01 art co m 0.4 00 a tr c o m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "36 1 a r t f r m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "28 6 pro st a 0.6 78 art gr s 0.4 98 act po s 0.3 96 a t r s t a 0.",
        "Entity": "Normal"
    },
    {
        "Text": "36 1 a ct h u m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "28 1 fod pl t 0.6 45 hum ps y 0.4 86 phm st a 0.3 88 a ct p h m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "33 9 a r t f o d 0.",
        "Entity": "Normal"
    },
    {
        "Text": "28 0 psy st a 0.6 30 hum na t 0.4 56 atr p sy 0.3 84 a n m a rt 0.",
        "Entity": "Normal"
    },
    {
        "Text": "33 5 g r s h u m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "27 2 hum pr t 0.6 02 anm hu m 0.4 48 fod hu m 0.3 83 a r t a t r 0.",
        "Entity": "Normal"
    },
    {
        "Text": "33 3 a c t a r t 0.",
        "Entity": "Normal"
    },
    {
        "Text": "26 7 grp ps y 0.5 74 com ps y 0.4 43 plt s u b 0.3 83 a ct p s y 0.",
        "Entity": "Normal"
    },
    {
        "Text": "33 3 a r t g r p 0.",
        "Entity": "Normal"
    },
    {
        "Text": "25 8 grs lo g 0.5 73 act gr s 0.4 41 act co m 0.3 82 a gt h u m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "31 9 a r t n a t 0.",
        "Entity": "Normal"
    },
    {
        "Text": "24 8 act ev t 0.5 39 atr re l 0.4 40 grp gr s 0.3 79 a r t e v t 0.",
        "Entity": "Normal"
    },
    {
        "Text": "31 4 a c t a t r 0.",
        "Entity": "Normal"
    },
    {
        "Text": "24 6 evt ps y 0.5 26 art q ui 0.4 33 art p sy 0.3 73 a t r e v t 0.",
        "Entity": "Normal"
    },
    {
        "Text": "31 2 a rt h u m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "24 0 act tm e 0.5 23 act st a 0.4 13 art pr t 0.3 64 a r t s t a 0.",
        "Entity": "Normal"
    },
    {
        "Text": "30 2 a r t l o c 0.",
        "Entity": "Normal"
    },
    {
        "Text": "23 8 art p h o 0.5 20 art su b 0.4 12 evt st a 0.3 64 a ct g r p 0.",
        "Entity": "Normal"
    },
    {
        "Text": "29 6 a rt p o s 0.",
        "Entity": "Normal"
    },
    {
        "Text": "22 8 act pr o 0.5 13 art lo g 0.4 07 anm fo d 0.3 61 c o m h u m 0.",
        "Entity": "Normal"
    },
    {
        "Text": "29 2 c o m s t a 0.",
        "Entity": "Normal"
    },
    {
        "Text": "21 9                                                                            \n\t\t\tThe random baseline performs at 0.313 while the frequency baseline ranges from 0.255 to 0.369 with a mean of 0.291.",
        "Entity": "Normal"
    },
    {
        "Text": "Alternations for which the model outperforms the frequency baseline are in boldface (mean AP: 0.399, standard deviation: 0.119).",
        "Entity": "Normal"
    },
    {
        "Text": "grspsy democracy, faculty, humanism, regime, pro-sta bondage, dehydration, erosion,urbanization psysta anaemia,delight, pathology, sensibility hum-prt bum, contractor, peter, subordinate grppsy category, collectivism, socialism, underworld grs psy pro sta psy sta hum prt grp psy eavctt  pesvyt grs log fod plt                                                                                     \n\t\t\ta PLANT sense by WordNet, but no FOOD sense.",
        "Entity": "Normal"
    },
    {
        "Text": "In the case of SOCIAL GROUP-GEOGRAPHICAL LOCATION, distractors laboratory and province are missing SOCIAL GROUP senses, which they clearly possess (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "The whole laboratory celebrated Christmas).",
        "Entity": "Normal"
    },
    {
        "Text": "This suggests that our approach can help in Word Sense Induction and thesaurus construction.",
        "Entity": "Normal"
    },
    {
        "Text": "In the second case, meta alternations perform better than expected: They have a low  , but a high AP.",
        "Entity": "Normal"
    },
    {
        "Text": "These include grspsy, pro-sta, psysta, hum-prt and grppsy.",
        "Entity": "Normal"
    },
    {
        "Text": "These meta alternations involve fairly abstract meta senses such as PSYCHOLOGICAL FEATURE and STATE.9                                                                           \n\t\t\tThe targets are clearly similar to each other on the level of their meta senses.",
        "Entity": "Normal"
    },
    {
        "Text": "However, they can occur in very different semantic contexts.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, here it is the underlying model (the gramlex space) that can explain the lower than average coherence.",
        "Entity": "Normal"
    },
    {
        "Text": "It is striking that CAM can account for abstract words and meta alternations between these, given that it uses first-order co-occurrence information only.",
        "Entity": "Normal"
    },
    {
        "Text": "9 An exception is hum-prt.",
        "Entity": "Normal"
    },
    {
        "Text": "It has a low coherence because many WordNet lemmas with a PART sense are body parts.",
        "Entity": "Normal"
    },
    {
        "Text": "aacctt  ptrmoeart pho arcto mg resvt  psy hum nat  gartstr qrueil araarctat r ltso tgsaub fgor dpc  ohgmuprmlst sub atrr t sa cstnpotmrma tfod aacrattn  mpa shtaymrt aagattrr t h euevmvtt aacrrottm   fgshrrtumpam art agrrp tatt r  ltanho taucprtmos 0.00 0.05 0.10 0.15 0.20 0.25 coherence                                                                         \n\t\t\tCorrelation: r = 0.743 (p < 0.001)\n\t\n\t\n\t\t\tAs noted in Section 1, there is little work in empirical computational semantics on explicitly modeling sense alternations, although the notions that we have formalized here affect several tasks across NLP sub- fields.",
        "Entity": "Normal"
    },
    {
        "Text": "Most work on regular sense alternations has focused on regular polysemy.",
        "Entity": "Normal"
    },
    {
        "Text": "A pioneering study is Buitelaar (1998), who accounts for regular polysemy through the CoreLex resource (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 3).",
        "Entity": "Normal"
    },
    {
        "Text": "A similar effort is carried out by Tomuro (2001), but he represents regular polysemy at the level of senses.",
        "Entity": "Normal"
    },
    {
        "Text": "Recently, Utt and Pado  (2011) explore the differences between between idiosyncratic and regular polysemy patterns building on CoreLex.",
        "Entity": "Normal"
    },
    {
        "Text": "Lapata (2000) focuses on the default meaning arising from word combinations, as opposed to the polysemy of single words as in this study.",
        "Entity": "Normal"
    },
    {
        "Text": "Meta alternations other than regular polysemy, such as metonymy, play a crucial role in Information Extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, the meta alternation SOCIAL GROUP-GEOGRAPHICAL LOCATION corresponds to an ambiguity between the LOCATION- ORGANIZATION Named Entity classes which is known to be a hard problem in Named Entity Recognition and Classification (Markert and Nissim, 2009).",
        "Entity": "Normal"
    },
    {
        "Text": "Metaphorical meta alternations have also received attention recently (Turney et al., 2011) On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera).",
        "Entity": "Normal"
    },
    {
        "Text": "The framework defined in Section 2 conceptualizes our task in a way parallel to that of analogical reasoning, modeling not  first-order  semantic similarity, but  second-order  semantic relations.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the two tasks cannot be approached with the same methods, as Turney s model relies on contexts linking two nouns in corpus sentences (what does A do to B?).",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, we are interested in relations within words, namely between word senses.",
        "Entity": "Normal"
    },
    {
        "Text": "We cannot expect two different senses of the same noun to co-occur in the same sentence, as this is discouraged for pragmatic reasons (Gale et al., 1992).",
        "Entity": "Normal"
    },
    {
        "Text": "A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.",
        "Entity": "Normal"
    },
    {
        "Text": "However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not.",
        "Entity": "Normal"
    },
    {
        "Text": "The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "However, in most of this research polysemy is ignored.",
        "Entity": "Normal"
    },
    {
        "Text": "A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(to appear) explicitly model regular polysemy for adjectives.",
        "Entity": "Normal"
    },
    {
        "Text": "We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics.",
        "Entity": "Normal"
    },
    {
        "Text": "We have presented a formal framework to represent and operate with regular sense alternations, as well as a first simple instantiation of the framework.",
        "Entity": "Normal"
    },
    {
        "Text": "We have conducted an evaluation of different implementations of this model in the new task of determining whether words match a given sense alternation.",
        "Entity": "Normal"
    },
    {
        "Text": "All models significantly outperform the baselines when considered as a whole, and the best implementation outperforms the baselines for 73.3% of the tested alternations.",
        "Entity": "Normal"
    },
    {
        "Text": "We have two next steps in mind.",
        "Entity": "Normal"
    },
    {
        "Text": "The first is to become independent of WordNet by unsupervised induction of (meta) senses and alternations from the data.",
        "Entity": "Normal"
    },
    {
        "Text": "This will allow for models that, unlike CAM, can go beyond  disemous  words.",
        "Entity": "Normal"
    },
    {
        "Text": "Other improvements on the model and evaluation will be to develop more informed baselines that capture semantic shifts, as well as to test alternate weighting schemes for the co-occurrence vectors (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "PMI) and to use larger corpora than the BNC.",
        "Entity": "Normal"
    },
    {
        "Text": "The second step is to go beyond the limited in-vitro evaluation we have presented here by integrating alternation prediction into larger NLP tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "Knowledge about alternations can play an important role in counteracting sparseness in many tasks that involve semantic compatibility, e.g., testing the applicability of lexical inference rules (Szpektor et al., 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "This research is partially funded by the Spanish Ministry of Science and Innovation (FFI201015006, TIN200914715-C0404), the AGAUR (2010 BPA00070), the German Research Foundation (SFB 732), and the EU (PASCAL2; FP7ICT-216886).",
        "Entity": "Normal"
    },
    {
        "Text": "It is largely inspired on a course by Ann Copestake at U. Pompeu Fabra (2008).",
        "Entity": "Normal"
    },
    {
        "Text": "We thank Marco Baroni, Katrin Erk, and the reviewers of this and four other conferences for valuable feedback.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tBinding constraints form one of the most robust modules of grammatical knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "Despite their crosslinguistic generality and practical relevance for anaphor resolution, they have resisted full integration into grammar processing.",
        "Entity": "Normal"
    },
    {
        "Text": "The ultimate reason for this is to be found in the original exhaustive coindexation rationale for their specification and verification.",
        "Entity": "Normal"
    },
    {
        "Text": "As an alternative, we propose an approach which, while permitting a unification-based specification of binding constraints, allows for a verification methodology that helps to overcome previous drawbacks.",
        "Entity": "Normal"
    },
    {
        "Text": "This alternative approach is based on the rationale that anaphoric nominals can be viewed as binding machines.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the so-called integrative approach to anaphor resolution was developed in the late 1980s (Carbonell and Brown 1988; Rich and LuperFoy 1988; Asher and Wada 1989), and its practical viability extensively tested (e.g., Lappin and Leass 1994; Mitkov 1997, 1998), it has been common wisdom that factors determining the antecedentsof anaphors divide into filters and preferences.",
        "Entity": "Normal"
    },
    {
        "Text": "The former exclude impossible an tecedents and help to circumscribe the set of antecedent candidates; the latter help to pick the most likely candidate, which will be proposed as the antecedent.Binding constraints are a significant subset of such filters.",
        "Entity": "Normal"
    },
    {
        "Text": "As they delimit the rel ative positioning of anaphors and their possible antecedents in grammatical geometry,these constraints are crucial to restricting the search space for antecedents and enhanc ing the performance of anaphor resolvers.1 From an empirical perspective, they stemfrom quite robust generalizations and exhibit a universal character, given their param eterized validity across natural languages.",
        "Entity": "Normal"
    },
    {
        "Text": "From a conceptual point of view, in turn, the relations among binding constraints involve nontrivial symmetry, which lends them a modular nature.",
        "Entity": "Normal"
    },
    {
        "Text": "Accordingly, they have been considered one of the most robust and intriguing grammar submodules, usually referred to as binding theory.",
        "Entity": "Normal"
    },
    {
        "Text": "However, in contrast to this, the formal and computational handling of binding constraints has presented considerable resistance.",
        "Entity": "Normal"
    },
    {
        "Text": "Anaphor resolution typically builds on many sources of information among them,information about the grammatical structure of the sentence so that the different fil ters and preferences may be used.",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, it must in general be regarded as a postgrammatical process, in the sense that it is completed after sentences are parsed.",
        "Entity": "Normal"
    },
    {
        "Text": "Binding constraints, as a subset of the filters for anaphor resolution, are a special case   Department of Informatics, Faculdade de Ci encias de Lisboa, Campo Grande, 1700 Lisboa, Portugal.",
        "Entity": "Normal"
    },
    {
        "Text": "Email: Antonio.Branco@di.fc.ul.pt.",
        "Entity": "Normal"
    },
    {
        "Text": "1 See the Appendix for a specification of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "We adhere to the following terminological.",
        "Entity": "Normal"
    },
    {
        "Text": "convention: anaphors divide into reflexives and nonreflexives; reflexives form a class that includes short-distance (ruled by Constraint A; e.g., himself ) and long-distance reflexives (Constraint Z; e.g., Chinese ziji); nonreflexives include pronouns (Constraint B; e.g., he) and nonpronouns (Constraint C; e.g., the student).",
        "Entity": "Normal"
    },
    {
        "Text": "Oc 2002 Association for Computational Linguistics in this respect.",
        "Entity": "Normal"
    },
    {
        "Text": "Given that they form a submodule of grammar, they are specified on a par with other grammatical submodules and constraints, and they are thus expected to be integrated already into the processing of grammar.",
        "Entity": "Normal"
    },
    {
        "Text": "Nevertheless, this integration cannot be considered to have been adequately achieved.",
        "Entity": "Normal"
    },
    {
        "Text": "As we will discuss at length, the original methodology for verifying the compliance of grammatical representations with binding constraints requires extragrammatical processing steps delivering a forest of indexed trees to anaphor resolvers (Chomsky 1981).",
        "Entity": "Normal"
    },
    {
        "Text": "More recently, constraint-based grammatical frameworks either require special- purpose extensions of the description formalism, though ensuring only a partial handling of these constraints, as in Lexical-Functional Grammar (LFG; Dalrymple 1993), or do not offer a solution yet to integrate them into grammar, as in Head-Driven Phrase Structure Grammar (HPSG; Pollard and Sag 1994).2 Our primary goal here is thus to bridge the gap between the grammatical nature of binding constraints and their full integration into grammar processing.",
        "Entity": "Normal"
    },
    {
        "Text": "In particular, we aim at achieving this in such a way that a lean interface between grammar and reference processing emerges.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 2, we first underline the distinction, seldom taken into account, between specification and verification of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "We then review advances proposed in the literature concerning the completion of the verification task.",
        "Entity": "Normal"
    },
    {
        "Text": "We observe that three major lines of progress can be identified: packing of anaphoric ambiguity, packing of nonlocal context, and lexicalization of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Building on these contributions, in Section 3 we argue that the remaining step forward is to harmonize these different advances.",
        "Entity": "Normal"
    },
    {
        "Text": "We suggest that a more accurate, semantics-driven comprehension of the nature of binding constraints is a relevant move toward this harmonization.",
        "Entity": "Normal"
    },
    {
        "Text": "On the basis of this revision, we introduce a methodology for verifying these constraints, which rests on the new concept of binding machine, to be defined.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 4, in the light of this new methodology, we show how binding constraints can be given a unification-based specification and can be fully integrated into grammar.",
        "Entity": "Normal"
    },
    {
        "Text": "In Section 5, we present an illustrative example and discuss in detail how binding constraints and reference-processing systems are coordinated, and how the previously identified drawbacks are overcome.",
        "Entity": "Normal"
    },
    {
        "Text": "In recent decades, great strides have been made toward an empirically adequate specification of binding constraints, this being an important research issue in theoretical linguistics.",
        "Entity": "Normal"
    },
    {
        "Text": "Many aspects of this issue a parameterizable definition of local domain, the existence of a fourth constraint for long-distance reflexives, the possible subject- orientedness of some anaphors, and the degree of universality of binding constraints, to name just a few have come under intense scrutiny.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, the verification task has been studied much less extensively.",
        "Entity": "Normal"
    },
    {
        "Text": "Even though important problems also remain to be solved in this more applied dimension 2 The fragment of grammar developed and extensively discussed in Pollard and Sag (1994) is formally.",
        "Entity": "Normal"
    },
    {
        "Text": "specified in its Appendix with the HPSG unification-based description language.",
        "Entity": "Normal"
    },
    {
        "Text": "Binding constraints escape such encoding.",
        "Entity": "Normal"
    },
    {
        "Text": "While noting that these constraints have yet to be accommodated in HPSG grammars, Bredenkamp s (1996) and Backofen et al.",
        "Entity": "Normal"
    },
    {
        "Text": "s (1996) subsequent elaboration of this issue implies that some kind of essential limitation of the unification-based formalism might have been reached, a suggestion we seek to contradict here.",
        "Entity": "Normal"
    },
    {
        "Text": "2 of the so-called binding theory, the issue of determining whether a given grammatical representation complies with binding constraints has not attracted similar attention.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we briefly review major advances reported in resolving this issue.",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 Exhaustive Coindexing for Filtering.",
        "Entity": "Normal"
    },
    {
        "Text": "The first formulation of a verification procedure, based on exhaustive coindexation,dates back to Chomsky (1980, Appendix; 1981, Section 3.2.3).",
        "Entity": "Normal"
    },
    {
        "Text": "The basics of this ap proach can be outlined as follows: After the grammatical parsing of a sentence with n NPs has been completed, for every parse tree t: a.",
        "Entity": "Normal"
    },
    {
        "Text": "Indexation: Generate a new, annotated tree by assigning indices to the NPs in t. b. Filtering: Store this annotated tree if the indexation of NPs respects binding constraints; otherwise, delete it.",
        "Entity": "Normal"
    },
    {
        "Text": "c. Iteration: Repeat (a) (b) until all type-different assignments of n possibly different indices have been exhausted.",
        "Entity": "Normal"
    },
    {
        "Text": "As discussed in Correa (1988), this procedure is grossly inefficient: its complexity was shown in Fong (1990) to be of exponential order.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, this approach is conceptually awkward, given that a submodule of the grammar, the set of binding constraints, is not operative during grammatical processing, but functions as an extragrammatical add-on.3 This proposal also disregards the need to interface grammar with systems for reference processing.",
        "Entity": "Normal"
    },
    {
        "Text": "The input for such systems will not be a grammatical representation to be refined visa` -vis the preferences for anaphor resolution, but a forest of differently labeled trees that have to be internally searched and compared with each other by anaphor resolvers.",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 Packing Anaphoric Ambiguity.",
        "Entity": "Normal"
    },
    {
        "Text": "A first proposal for improving the exhaustive coindexation-driven methodology is due to Correa (1988), whose goal was to enhance the integration of binding constraints into grammar and obtain a tractable verification procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "Simplifying some details, the proposed algorithm can be outlined as follows: Let t be a constituency tree where every NP has a type-distinct index.",
        "Entity": "Normal"
    },
    {
        "Text": "Start from the top node of t with two empty stacks, A and B, where indices will be collected, respectively local c-commanding4 indices and nonlocal c-commanding indices, while descending the tree.",
        "Entity": "Normal"
    },
    {
        "Text": "When an NPj is found: a.",
        "Entity": "Normal"
    },
    {
        "Text": "Copy: Leave a copy of A (if NPj is a short-distance reflexive) or B (if it is a pronoun) at the NPj .",
        "Entity": "Normal"
    },
    {
        "Text": "3 Correa (1988, page 123) observes that although the integration of binding constraints  into rules which.",
        "Entity": "Normal"
    },
    {
        "Text": "may be used to derive structure that already satisfies the [constraints] is not a straightforward task,  that should be the path to follow, a point also strongly stressed in subsequent elaboration on this issue by Merlo (1993).",
        "Entity": "Normal"
    },
    {
        "Text": "4 C-command is a configurational version of the command relation where x c-commands y iff the first branching node that dominates x dominates y (Barker and Pullum 1990).",
        "Entity": "Normal"
    },
    {
        "Text": "3 b.",
        "Entity": "Normal"
    },
    {
        "Text": "Assign: Take the first index i of the stack copied into the NPj node, and annotate NPj with j = i. c. Collect: Add index j to A in each sister node of NPj .",
        "Entity": "Normal"
    },
    {
        "Text": "When a local domain border is crossed: d. Reset: Reset B to A   B.",
        "Entity": "Normal"
    },
    {
        "Text": "This algorithm has been given two different implementations, one by Correa (1988), the other by Ingria and Stallard (1989).",
        "Entity": "Normal"
    },
    {
        "Text": "Further elaboration by Giorgi, Pianesi, and Satta (1990) and Pianesi (1991) offers a variant in terms of formal language techniques, where the stack copied into pronouns contains the antecedent candidates excluded by Principle B.",
        "Entity": "Normal"
    },
    {
        "Text": "The  do-it-while-parsing  approach of Correa s implementation has the advantage of discarding a special-purpose postgrammatical module for binding.",
        "Entity": "Normal"
    },
    {
        "Text": "Nevertheless, this solution turns out to be dependent on a top-down parsing strategy.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, while Ingria and Stallard s implementation is independent of the parsing strategy adopted, its independence comes at the cost of still requiring a special-purpose postgrammatical parsing module for binding.",
        "Entity": "Normal"
    },
    {
        "Text": "Besides incorporating binding theory into grammar, Correa s development inside the coindexation-driven methodology presents other significant improvements.",
        "Entity": "Normal"
    },
    {
        "Text": "If one disregards step (b) a disguised recency preference mixed with binding constraints  and considers the result of verifying these constraints to be the assignment to an NP of the set of indices of its grammatically admissible antecedents, then it is possible to discard the proliferation of indexed trees as a way to express anaphoric ambiguity.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, this packing of anaphoric ambiguity provides for a neat interface with anaphor resolvers, whose preferences will then pick the most likely antecedent candidate from the relevant stack of indices.",
        "Entity": "Normal"
    },
    {
        "Text": "These advances permit a verification procedure of tractable complexity (Correa 1988, page 127; Giorgi, Pianesi, and Satta 1990, page 5).",
        "Entity": "Normal"
    },
    {
        "Text": "This results crucially from the move toward the lexicalization of the constraining effect of binding principles, a solution also adopted in subsequent proposals by other authors, as we will discuss below.",
        "Entity": "Normal"
    },
    {
        "Text": "The binding constraint of each anaphor is now enforced independently of how the surrounding anaphors happen to be resolved.",
        "Entity": "Normal"
    },
    {
        "Text": "This implies that there is no need to anticipate all the different resolutions for every relevant anaphor with a process of exhaustive coindexation.",
        "Entity": "Normal"
    },
    {
        "Text": "It also implies that cases of undesired transitive anaphoricity are handled by other filters during the anaphor resolution process.5 However, these positive results regarding the verification task seem to be obtainedat the cost of some negative consequences regarding the specification task and em pirical adequacy.",
        "Entity": "Normal"
    },
    {
        "Text": "The above algorithm is acknowledged not to be able to cope with 5 Consider the sentence John said that he shaved him.",
        "Entity": "Normal"
    },
    {
        "Text": "Ignoring how other anaphors are resolved, in the light.",
        "Entity": "Normal"
    },
    {
        "Text": "of Binding Constraint B, he can take John as its antecedent, as empirically replicated in other minimally different examples such as Johni said that he shaved Peter; likewise, him can take John as its antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "A point worth noting is that, if he actually ends up resolved against John, the latter cannot be the antecedent of him, and vice versa.",
        "Entity": "Normal"
    },
    {
        "Text": "This specific resolution of he and him, out of the many possible resolutions, blocks two anaphoric links that would otherwise have been admissible.",
        "Entity": "Normal"
    },
    {
        "Text": "It induces a contingent violation of binding constraint B due to an accidental, transitive anaphoric relationship between he and him.",
        "Entity": "Normal"
    },
    {
        "Text": "This issue is not discussed in Correa (1988), since this paper is strictly focused on syntax and binding.",
        "Entity": "Normal"
    },
    {
        "Text": "See footnote 13 below for a suggestion on how this issue may be handled in a grammatical framework integrating syntactic and semantic representations.",
        "Entity": "Normal"
    },
    {
        "Text": "4 constraints involving nonlocal dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "It does not account for Principle C, and it only partially accommodates the anaphoric potential of anaphors complying with Principle B.",
        "Entity": "Normal"
    },
    {
        "Text": "As Stack B only contains indices of the nonlocal c-commanders rather than all indices except those of the local c-commanders the algorithm does not correctly account for the constraining effect of Principle B.",
        "Entity": "Normal"
    },
    {
        "Text": "Also this approach does not account for backward anaphora or crossover cases (Correa 1988, page 127; Ingria and Stallard 1989, page 268).6 2.3 Packing Nonlocality.",
        "Entity": "Normal"
    },
    {
        "Text": "Other improvements in the task of verifying binding constraints are due to Dalrymple (1993) and Johnson (1995).",
        "Entity": "Normal"
    },
    {
        "Text": "Instead of being concerned with packing ambiguity, they are concerned with packing nonlocality.",
        "Entity": "Normal"
    },
    {
        "Text": "2.3.1 Trees in Nodes of Trees.",
        "Entity": "Normal"
    },
    {
        "Text": "Johnson s (1995) algorithm is embodied in Prolog code.",
        "Entity": "Normal"
    },
    {
        "Text": "Abstracting away from details associated with that format, it can be outlined as follows: Let t be a constituency tree where every NP has a type-distinct index.",
        "Entity": "Normal"
    },
    {
        "Text": "For every NPi in t, traverse the tree from NPi upward until the top node is reached.",
        "Entity": "Normal"
    },
    {
        "Text": "When a locally c-commanding NPj is found: a. Annotate NPi with i = j if NPi is a short-distance reflexive.",
        "Entity": "Normal"
    },
    {
        "Text": "b. Annotate NPi with i /= j if NPi is a nonreflexive.",
        "Entity": "Normal"
    },
    {
        "Text": "When a nonlocally c-commanding NPj is found: c. Annotate NPi with i /= j if NPi is a nonpronoun.",
        "Entity": "Normal"
    },
    {
        "Text": "Although this outline renders the algorithm in a bottom-up fashion, Johnson ingeniously develops an implementation of it that is independent of the parsing strategy by resorting to delaying mechanisms.",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, despite its postgrammatical flavor, this implementation does not require postgrammatical processing, thus incorporating the task of binding constraint verification into grammar processing.",
        "Entity": "Normal"
    },
    {
        "Text": "These results are obtained with some auxiliary devices.",
        "Entity": "Normal"
    },
    {
        "Text": "Each node in the tree is  conceptualized as a pair consisting of a tree and a vertex in that tree  (Johnson 1995, page 62).",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, the whole tree where a given NP appears is locally accessible to be  walked up  since its replica is present at the pair (Category, Tree), which is the NP node itself.",
        "Entity": "Normal"
    },
    {
        "Text": "This algorithm makes the verification of binding constraints more efficient because it does not resort to exhaustive indexation.",
        "Entity": "Normal"
    },
    {
        "Text": "However, it does so at the cost of highly complicating the grammatical representation, since the tree is replicated at each one of its nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "While avoiding exhaustive indexation, this approach does not fully eliminate the proliferation of trees.",
        "Entity": "Normal"
    },
    {
        "Text": "For a given ambiguous reflexive, with more than one admissible 6 See the Appendix for the notion of locality and local domain and other auxiliary notions in the.",
        "Entity": "Normal"
    },
    {
        "Text": "definition of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Backward anaphora occurs in cases where the anaphor is resolved against an antecedent that occurs linearly after the anaphor, as in If hei is around, Peteri will do it.",
        "Entity": "Normal"
    },
    {
        "Text": "An example of so-called crossover cases is the ungrammatical construction *Whoi did Peter think shei saw?",
        "Entity": "Normal"
    },
    {
        "Text": "or *Peteri , hei said you like, where the fronted phrase is meant to be the antecedent of some pronoun c-commanding the position from which this phrase is displaced.",
        "Entity": "Normal"
    },
    {
        "Text": "5 antecedent, each antecedent candidate corresponds to a different coindexation and, consequently, to a different tree.",
        "Entity": "Normal"
    },
    {
        "Text": "That is what generally happens with long-distance reflexives, whose antecedents can be found in any of the binding domains induced by the local or by the upward predicators, but it may also happen with short-distance ones, as in (2) below.",
        "Entity": "Normal"
    },
    {
        "Text": "As to the interface with reference processing, problems arise with reflexives and nonreflexives, though of different nature.",
        "Entity": "Normal"
    },
    {
        "Text": "Reflexives, if ambiguous, give rise to proliferation of trees, thus requiring comparison between trees during subsequent anaphor resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "As to nonreflexives pronouns and nonpronouns their analysis does not give rise to proliferation of trees, but the representation of their ambiguity is not fully made explicit in the grammatical representation of the sentence being parsed.",
        "Entity": "Normal"
    },
    {
        "Text": "This is so because they end up associated with negative information, that is, information about what NPs cannot be their antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "The index of a pronoun is made unequal with the indices of its local c-commanders; it is not made equal with the indices of its grammatically admissible antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "The same holds for nonpronouns with respect to their c-commanders.",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, in this case, the task of determining the antecedent candidates that satisfy the relevant binding constraint of nonreflexives remains to be completed after grammatical processing is finished.",
        "Entity": "Normal"
    },
    {
        "Text": "This will involve some postgrammatical rescanning of the parse tree generated for extracting the indices that do not enter in the inequalities obtained during the parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, like Correa s approach, Johnson s does not account for backward anaphora, as only surface c-commanders are visible to the tree-climbing procedure.",
        "Entity": "Normal"
    },
    {
        "Text": "2.3.2 Equations with Regular Expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "The basic LFG account of binding, set forth by Dalrymple (1993), adopts a different approach to generalize over the possible nonlocality of intrasentential anaphoric dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "This approach makes crucial use of a special-purpose extension of the LFG description formalism, the so-called binding equations, which are lexically associated with anaphors.",
        "Entity": "Normal"
    },
    {
        "Text": "Building on Kaplan and Maxwell s (1988) proposal concerning functional uncertainty, binding equations are designed to encode the uncertainty concerning the long-distance path between the positions of the anaphor and its permissible antecedent in the grammatical structure.7 Given that uncertainty concerning long-distance dependencies involves a (possibly infinite) disjunction of possibilities, the basic idea is to encode such a disjunction in finite terms by the use of regular expressions over feature structures.",
        "Entity": "Normal"
    },
    {
        "Text": "An example of a binding equation encoding functional uncertainty is given in (1), preceded by an example with the corresponding long-distance subject-oriented reflexive, Chinese ziji.",
        "Entity": "Normal"
    },
    {
        "Text": "(1) Zhangsani yiwei [Lisij yiwei [... zijii/j/...\n\t\t\tZhangsani thought [Lisij thought [... himi/j/...\n\t\t\t]] ziji: ((COMP* OBJ  ) SUBJ)  =     The right-hand side of the equation stands for the semantic representation (   ) of the anaphor (   ), while the left-hand side stands for the semantic representation of the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "The description of the antecedent indicates that the long-distance reflexive is an object and that this object is constrained to be part of a feature structure where 7 Koenig (1999) introduces a device in HPSG description language for stating inside-out constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "This.",
        "Entity": "Normal"
    },
    {
        "Text": "would help in developing an HPSG emulation of the LFG approach for the verification of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "6 its antecedent may be one of the possibly many upward subjects.",
        "Entity": "Normal"
    },
    {
        "Text": "The Kleene operator  *  allows abbreviation of the set of paths consisting of zero or more occurrences of COMP corresponding to possible successive clausal embeddings followed by one occurrence of OBJ.",
        "Entity": "Normal"
    },
    {
        "Text": "While regular expressions may be used in binding equations, such expressions are not necessary if the grammatical relation between the anaphor and its admissible antecedents does not involve a long-distance dependency.",
        "Entity": "Normal"
    },
    {
        "Text": "That is the case in (2), which displays the binding equation for the short-distance reflexive himself.",
        "Entity": "Normal"
    },
    {
        "Text": "Given that both the subject and the object are admissible antecedents for the reflexive, in the binding equation the use of the attribute GF, which stands for any grammatical function, underspecifies the grammatical functions of the admissible antecedents (Dalrymple 1993, Section 4.4.2).",
        "Entity": "Normal"
    },
    {
        "Text": "(2) Johni described Billj to himselfi/j .",
        "Entity": "Normal"
    },
    {
        "Text": "himself: ((OBLGoal  ) GF)  =    Binding equations may also express negative constraints, as in (3), where the semantic representation of the pronoun is constrained to be different from that of its local coarguments.",
        "Entity": "Normal"
    },
    {
        "Text": "(3)  Johni described Billj to himi/j .",
        "Entity": "Normal"
    },
    {
        "Text": "him: ((OBLGoal  ) GF)  /=    As noted in Dalrymple (1993, Section 3.3), a few aspects of this approach for binding need to be fully worked out.",
        "Entity": "Normal"
    },
    {
        "Text": "For instance, the positive equations for reflexives do not require identity of indices of anaphorically related expressions, but instead impose identity of semantic representations.",
        "Entity": "Normal"
    },
    {
        "Text": "Without further elaboration, this will incorrectly enforce any type of anaphoric link (coreference, bound, bridging, e-type, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "to the sole mode of coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Another important issue is the account of nonlexical anaphoric NPs: it is not clear how this type of NP (e.g., anaphoric definite descriptions, ruled by Principle C) may be assigned the corresponding binding equation.",
        "Entity": "Normal"
    },
    {
        "Text": "However these difficulties turn out to be resolved, the LFG approach for binding, though building on a different strategy for handling nonlocality, presents the same sort of problems as Johnson s proposal.",
        "Entity": "Normal"
    },
    {
        "Text": "The interfacing of grammar with reference-processing systems is problematic since the proliferation of representations is not avoided.",
        "Entity": "Normal"
    },
    {
        "Text": "Constructions with reflexives, if these are ambiguous, end up associated with several grammatical representations.",
        "Entity": "Normal"
    },
    {
        "Text": "In the case of long-distance reflexives, as exemplified in (1), these representations result from the possibly many solutions for the functional uncertainty encoded by the regular expression in the binding equation.",
        "Entity": "Normal"
    },
    {
        "Text": "In the case of short-distance reflexives, as exemplified in (2), they result from the different solutions for the unification of the different grammatical functions of the admissible antecedents with the attribute GF in the binding equation.",
        "Entity": "Normal"
    },
    {
        "Text": "Likewise, the anaphoric capacity of pronouns and nonpronouns, typically ambiguous, is not explicitly captured in the final grammatical representation.",
        "Entity": "Normal"
    },
    {
        "Text": "These anaphors are lexically associated with negative equations, and for this type of equation there is only one possible solution, namely, the grammatical structure where the semantic representation of the anaphor is not identical to the semantic representations of any of the phrases complying with the description of the antecedent in the left-hand side 7 of the equation (Dalrymple 1993, Section 4.1.5).",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, for these anaphors the final grammatical representation provides no information about what their admissible antecedents are according to the relevant binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "The contributions assessed above share a common point of departure with regard to the verification algorithm first proposed by Chomsky (1981), each addressing and solving some of its more significant drawbacks.",
        "Entity": "Normal"
    },
    {
        "Text": "The common move toward the lexical- ization of binding constraints represents an important shift in the verification strategy: verifying binding constraints is not a matter of inspecting final grammatical representations, but instead a matter of some local operation triggered by information lexically associated with anaphors about their anaphoric class.",
        "Entity": "Normal"
    },
    {
        "Text": "This move has allowed binding constraint verification to be incorporated into grammar processing and permitted tractable verification procedures.",
        "Entity": "Normal"
    },
    {
        "Text": "From the discussion in the previous section, it follows also that these contributions have been partially successful in overcoming other problems of the verification methodology based on exhaustive coindexation.",
        "Entity": "Normal"
    },
    {
        "Text": "Though partially successful, they have brought to the fore important dimensions of binding that have to be concomitantly accounted for.",
        "Entity": "Normal"
    },
    {
        "Text": "Accordingly, an alternative method for the verification of binding constraints has to find a way to harmonize all those different dimensions lexicalization, anaphoric ambiguity packing, and nonlocal context packing while providing adequate empirical coverage and neatly interfacing grammar with reference processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Against this background, a breakthrough depends, in our view, on reconsidering some primitives underlying the conception of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "In the previous section, we made a clear distinction between specification and verification of binding constraints, so that the latter task could be isolated and better assessed.",
        "Entity": "Normal"
    },
    {
        "Text": "We will argue now that further progress on the verification task depends on bridging this distinction and possibly changing the way the specification of binding constraints is understood.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Patterns in the Semantics of Anaphors.",
        "Entity": "Normal"
    },
    {
        "Text": "Binding constraints have generally been viewed as well-formedness conditions on syntactic representations, thus belonging to the realm of syntax.",
        "Entity": "Normal"
    },
    {
        "Text": "In line with Gawron and Peters (1990), however, we think these constraints should rather be understood as conditions on semantic representations, since they primarily delimit (nonlocal) aspects of semantic composition, rather than aspects of syntactic composition.8Like other types of constraints on semantic composition, binding constraints im pose conditions on the interpretation of certain expressions anaphors, in the present case based on syntactic geometry.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this cannot be viewed as implying that they express grammaticality requirements.",
        "Entity": "Normal"
    },
    {
        "Text": "By replacing a pronoun with a reflexive in a given sentence, for instance, we do not turn a grammatical construction into anungrammatical one, even if we assign to the reflexive the antecedent appropriately se 8 As implied by the title of this section, and as will become clear in the following discussion, this does.",
        "Entity": "Normal"
    },
    {
        "Text": "not mean that we are claiming that binding theory can be built without any reference to syntactic constructs.",
        "Entity": "Normal"
    },
    {
        "Text": "In the argument in the following paragraphs, we are assuming a notion of semantic composition not in its strict sense, as used for example in Montague Grammar, but in the broader sense that the intermediate semantic representations of the expressions are composed from other representations, as used in Discourse Representation Theory (DRT).",
        "Entity": "Normal"
    },
    {
        "Text": "Note that reformulations of frameworks like DRT can be worked out that result in a semantic system adhering to strict compositionality; see Janssen (1997, Section 4.4) for references and a thorough discussion of this issue.",
        "Entity": "Normal"
    },
    {
        "Text": "8 lected for the pronoun.",
        "Entity": "Normal"
    },
    {
        "Text": "In that case, we are simply asking the hearer to try to assign to that sentence a meaning it cannot express just as if we were to ask whether someone could interpret The red book is on the white table as describing a situation where a white book is on a red table.",
        "Entity": "Normal"
    },
    {
        "Text": "In this example, given how they happen to be syntactically related, the semantic values of red and table cannot be composed in such a way that the sentence could be used to describe a situation concerning a red table, rather than a white table.",
        "Entity": "Normal"
    },
    {
        "Text": "Likewise, in the sentence John thinks Peter shaved him, given how they happen to be syntactically related, the semantic values of Peter and him cannot be composed in such a way that this sentence could be used to describe a situation where John thinks that Peter shaved himself (i.e., Peter), rather than a situation where John thinks that Peter shaved other people (e.g., Paul, Bill, or John himself).",
        "Entity": "Normal"
    },
    {
        "Text": "The difference between these two cases is that in the former, the composition of the semantic contributions of white and table (for the interpretation of the NP white table) is constrained by local syntactic geometry, while in the latter, the composition of the semantic contributions of John and him (for the interpretation of the NP him) is constrained by nonlocal syntactic geometry.",
        "Entity": "Normal"
    },
    {
        "Text": "This discussion leads us to consider that, semantically, an anaphor should be specified in the lexicon as a function whose argument is a suitable representation of the context providing a semantic representation of the NPs available in the discourse vicinity and its value is the set of the grammatically admissible antecedents for that anaphor.",
        "Entity": "Normal"
    },
    {
        "Text": "This rationale is in line with other approaches to the meaning of anaphors that, building in other sorts of arguments or research concerns, understand it also as a projection from some relevant representation of contexts to entities.9 But given the specific focus of the present study, what should be noted is that, all in all, there will be four such functions available to be lexically associated with anaphors, each corresponding to one of the four different classes of anaphors, in accordance with the four binding constraints A, B, C, and Z.10 3.2 Binding Machines.",
        "Entity": "Normal"
    },
    {
        "Text": "Given these considerations, we can show that this conceptual shift to a semantics driven approach for the verification of binding constraints provides an adequate basis for harmonizing the advances put forward in the literature and discussed above.",
        "Entity": "Normal"
    },
    {
        "Text": "To make this alternative rationale for binding perspicuous, we suggest envisioning an anaphoric NP as a binding machine, which operates by receiving an input, changing its internal state, and returning an output.",
        "Entity": "Normal"
    },
    {
        "Text": "More specifically, an anaphoric NP can be 9 See, among others, Gawron and Peters (1990), Lappin and Francez (1994), and the discussion in.",
        "Entity": "Normal"
    },
    {
        "Text": "Jacobson (1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Adopting Lo  bner  s (1987) duality criterion for quantification in natural language, and the formal tools he developed for the analysis of phase quantification, we showed in Branco (2000) that the four binding constraints can be seen as the effect of four binding quantifiers.",
        "Entity": "Normal"
    },
    {
        "Text": "These phase quantifiers can be viewed as being expressed by the nominals of the four binding classes, and they quantify over the reference markers organized in the obliqueness order.",
        "Entity": "Normal"
    },
    {
        "Text": "A full-fledged account of the empirical support and justification for these results, and of their implications, is beyond the scope of this article.",
        "Entity": "Normal"
    },
    {
        "Text": "For an abridged presentation of the core argument, see Branco (1998).",
        "Entity": "Normal"
    },
    {
        "Text": "10 As there are different grammatical frameworks, binding constraints have been specified under different.",
        "Entity": "Normal"
    },
    {
        "Text": "versions.",
        "Entity": "Normal"
    },
    {
        "Text": "Some differences between versions are due just to this fact that binding constraints are supposed to be accommodated into different grammatical frameworks; some other differences, however, are real differences of specification in the sense that different variants may not have the same empirical coverage or be aimed at predicting the same (un)grammatical constructions.",
        "Entity": "Normal"
    },
    {
        "Text": "In the Appendix, we present a common and fairly well empirically tested version of binding theory given the current state of the art in this area, a version presently adopted in the HPSG framework.",
        "Entity": "Normal"
    },
    {
        "Text": "For an alternative, see for example Reinhart and Reuland (1993).",
        "Entity": "Normal"
    },
    {
        "Text": "9 viewed as a binding machine that (1) takes a representation of its context; (2) updates its own semantic value in response both to its context and to its intrinsic anaphoric potential (i.e., in accordance with its binding constraint); and (3) contributes to the makeup of the context, which the other binding machines read as input (i.e., against which the other anaphoric NPs are interpreted).11 The output of an anaphoric nominal n viewed as a binding machine is simply the incrementing of the context with a copy of its reference marker.12 The internal state of the machine after its operation is a representation of the con- textualized anaphoric capacity of n under the form of the set of reference markers of the grammatically admissible antecedents of n. This internal state results when the binding constraint associated with n is applied to the input, and it is the interface point between grammar and reference processing.",
        "Entity": "Normal"
    },
    {
        "Text": "This set of reference markers collects the antecedent candidates, and its elements are submitted to other filters and preferences by the anaphor resolvers so that one of them ends up being chosen as the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "The input, in turn, is a representation of the aspects of the context relevant to help circumscribe the anaphoric potential of nominal anaphors.",
        "Entity": "Normal"
    },
    {
        "Text": "It is coded under the form of three lists of reference markers, A, Z, and U.",
        "Entity": "Normal"
    },
    {
        "Text": "In list A, the reference markers of the local o-commanders of n are ordered according to their relative grammatical obliqueness; Z includes the o-commanders of n, possibly observing a multiclausal obliqueness hierarchy; and U is the list of all reference markers in the discourse context, including those not linguistically introduced.",
        "Entity": "Normal"
    },
    {
        "Text": "Given this setup, the contribution of binding constraints in circumscribing the an- aphoric potential of nominals is explicitly acknowledged.",
        "Entity": "Normal"
    },
    {
        "Text": "The particular contextualized instantiation of that potential and the verification of binding constraints coincide and consist of a few simple steps.",
        "Entity": "Normal"
    },
    {
        "Text": "If n is a short-distance reflexive, its internal state is set up as At, where At contains the reference markers of the o-commanders of n in A.",
        "Entity": "Normal"
    },
    {
        "Text": "If n is a long-distance reflexive, its semantic representation includes Zt, such that Zt contains the o-commanders of n in Z.",
        "Entity": "Normal"
    },
    {
        "Text": "If n is a pronoun, B = U \\ (At   [r-markn ]) is encoded into its representation, where r-markn is the reference marker of n. Finally, if n is a nonpronoun, its updated semantics keeps a copy of C = U \\ (Zt   [r-markn ]).",
        "Entity": "Normal"
    },
    {
        "Text": "Besides adhering to an empirically grounded conception of binding constraints,this approach embodies, and harmonizes, the crucial contributions of previous pro posals concerning the verification of these constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "It assumes the lexicalization of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Concomitantly, it builds on specific strategies for the packing of anaphoric ambiguity (viz., list of reference markers) and nonlocal context (viz., setof lists of reference markers).",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, it achieves this while avoiding the above mentioned problems related to the proliferation of grammatical representations and to the interfacing of grammar with reference processing, as well as the problems of ensuring complete empirical coverage.What remains to be discussed is whether, given this new format for the verifica tion of binding constraints, they can still be specified and integrated into grammar processing with currently affordable formal and computational tools.",
        "Entity": "Normal"
    },
    {
        "Text": "This new approach to binding constraints can be integrated into grammar easily and in a principled manner.",
        "Entity": "Normal"
    },
    {
        "Text": "In what follows, we outline how these constraints can be specified and handled in a unification-based grammatical framework such as HPSG.",
        "Entity": "Normal"
    },
    {
        "Text": "11 This rationale is in line with the insights of Johnson and Klein (1990) concerning the processing of the.",
        "Entity": "Normal"
    },
    {
        "Text": "semantics of nominals.",
        "Entity": "Normal"
    },
    {
        "Text": "12 See Kamp and Reyle (1993) for the notion of reference marker..\n\t\t\t10 As a proposal for that integration, we designed an extension to the Underspecified Discourse Representation Theory (UDRT) semantics component for HPSG developed by Frank and Reyle (1995).",
        "Entity": "Normal"
    },
    {
        "Text": "This component is encoded as the value of the feature CONT(ENT), which is now extended with the feature ANAPH(ORA); see (4).",
        "Entity": "Normal"
    },
    {
        "Text": "This new feature keeps information about the anaphoric potential of the corresponding nominal n: its subfeature ANTEC(EDENTS) keeps a record of how that potential is updated when the anaphor enters a grammatical construction; and its subfeature R(EFERENCE)-MARK(ER) indicates the reference marker of n, to be contributed to the context.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, and still assuming Pollard and Sag s (1994) feature geometry as a starting point, the NONLOC value is also extended with a new feature, BIND(ING), with subfeatures LIST-A, LIST-Z, and LIST-U.",
        "Entity": "Normal"
    },
    {
        "Text": "These lists provide a specification of the relevant context and correspond to the lists A, Z, and U above.",
        "Entity": "Normal"
    },
    {
        "Text": "Subfeature LIST-LU is a fourth, auxiliary list for encoding the contribution of local context to the global, nonlocal context.",
        "Entity": "Normal"
    },
    {
        "Text": "The SYNSEM value of a pronoun, for instance, can now be designed as shown in (4).",
        "Entity": "Normal"
    },
    {
        "Text": "(4)              ls         l m a x 1 1     l m i n 1                subord {}                    label 1 1     loc | cont              conds                        a r g r 2            r m a r k 2           anaph        antec 5 principleB ( 4 , 3 , 2 '\\           list-a 3          list-z list     nonloc bind         l i s t u 4       list-lu 2 Given this feature structure, the binding constraint associated with pronouns is specified as the relational constraint principleB.",
        "Entity": "Normal"
    },
    {
        "Text": "This relational constraint returns list B as the value of ANTEC.",
        "Entity": "Normal"
    },
    {
        "Text": "It is defined to take (in the first argument) all markers in the discourse context, given in LIST-U value, and remove from them both the local o-commanders of the pronoun (included in the second argument) and the marker corresponding to the pronoun (in the third argument).",
        "Entity": "Normal"
    },
    {
        "Text": "The SYNSEMs of other anaphors, ruled by Principles A, C, and Z, are similar to the one above.13 The only difference lies in the relational constraint in the ANTEC value, which encodes the appropriate binding constraint and returns the updated anaphoric potential under the form of list At, C, or Zt, respectively, as discussed in the previous section.",
        "Entity": "Normal"
    },
    {
        "Text": "Turning to the specification of the context (i.e., the values of LIST-A, LIST-Z, LIST-U, and LIST-LU), this is handled by means of a new HPSG principle, which can be termed the Binding Domains Principle.",
        "Entity": "Normal"
    },
    {
        "Text": "This principle consists of three clauses constraining 13 Binding constraints for nonlexical anaphoric nominals are lexically stated in the corresponding.",
        "Entity": "Normal"
    },
    {
        "Text": "determiners.",
        "Entity": "Normal"
    },
    {
        "Text": "A constraint for pronominal anaphoric transitivity may also be introduced at the lexical representation of pronouns, by including in the CONDS value in (4) Discourse Representation Structure conditions expressing that  ra , rb (( 2 = anaph ra   rb = anaph ra )   ([rb ]   5 = 5 )).",
        "Entity": "Normal"
    },
    {
        "Text": "11 signs and their values with respect to these lists of reference markers.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to space limitations, we illustrate this principle simply by stating Clause I, which constrains LIST-U and LIST-LU.14 (5) Binding Domains Principle, Clause I a.",
        "Entity": "Normal"
    },
    {
        "Text": "In every sign, the LIST-LU value is identical to the concatenation of the LIST-LU values of its daughters.",
        "Entity": "Normal"
    },
    {
        "Text": "b.",
        "Entity": "Normal"
    },
    {
        "Text": "In a sign of sort discourse, the LIST-LU and LIST-U values are token identical.",
        "Entity": "Normal"
    },
    {
        "Text": "c. In a non-NP sign, the LIST-U value is token identical to each LIST-U value of its daughters.",
        "Entity": "Normal"
    },
    {
        "Text": "d. In an NP sign k, i.",
        "Entity": "Normal"
    },
    {
        "Text": "In Spec-daughter, the LIST-U value is the result of removing the elements of the LIST-A value of Head-daughter from the LIST-U value of k; ii.",
        "Entity": "Normal"
    },
    {
        "Text": "In Head-daughter, the LIST-U value is the result of removing the value of R-MARK of Spec-daughter from the LIST-U value of k. LIST-LU collects, up to the outermost sign of sort discourse, all the markers contributed by the different NPs for the context.",
        "Entity": "Normal"
    },
    {
        "Text": "At this sign, they are passed to LIST-U, by means of which they are propagated to every NP.",
        "Entity": "Normal"
    },
    {
        "Text": "The HPSG ontology was extended with the sort discourse, which corresponds to sequences of sentential signs and at whose signs reference markers from the nonlinguistic context may be introduced in the semantic representation.15 Subclause (d) is meant to avoid what is known in the literature as the i-within-i effect.",
        "Entity": "Normal"
    },
    {
        "Text": "The above unification-based specification of binding constraints, while ensuring their integration into grammar, allows the binding module to be suitably hooked up with systems of reference processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Feature ANTEC is the interface point between them.",
        "Entity": "Normal"
    },
    {
        "Text": "14 Clauses II and III constrain LIST-A and LIST-Z, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Roughly, Clause II ensures that the LIST-A.",
        "Entity": "Normal"
    },
    {
        "Text": "value is passed from the lexical head to its successive projections, and also from the head-daughters to their arguments.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that exemption occurs when principleA( 1 , 2 ) is the empty list, in which case the reflexive should find its antecedent outside any binding constraint (Pollard and Sag 1994, Chapter 6).",
        "Entity": "Normal"
    },
    {
        "Text": "Clause III ensures that, at the top node of the grammatical representation, LIST-Z is set up as the LIST-A value of that node, and that LIST-Z is successively incremented at the suitable downstairs nodes by appending its value with the LIST-A value of those nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "At the lexical entry of a predicator, LIST-A is defined as the concatenation of the R-MARK values of its subcategorized arguments specified in the ARG-S value.",
        "Entity": "Normal"
    },
    {
        "Text": "For a detailed specification of the Binding Domains Principle, see Branco (2000).",
        "Entity": "Normal"
    },
    {
        "Text": "15 Reference markers can be introduced linguistically, by the utterance of the corresponding expressions,.",
        "Entity": "Normal"
    },
    {
        "Text": "or nonlinguistically, by means of their cognitive availability in the context of the discourse.",
        "Entity": "Normal"
    },
    {
        "Text": "Theories of natural language semantics can be used to represent these two types of reference markers.",
        "Entity": "Normal"
    },
    {
        "Text": "Nevertheless, only a global theory encompassing natural language and cognition seems to be able to pursue the ambitious goal of providing an integrated account of how both types of markers, and not only those linguistically evoked, are introduced into semantic representation.",
        "Entity": "Normal"
    },
    {
        "Text": "12 We are following a distinction between the notions of anaphor resolution and reference processing commonly assumed in the literature.",
        "Entity": "Normal"
    },
    {
        "Text": "Anaphor resolution is seen as being concerned with the task of identifying the antecedents of anaphors.",
        "Entity": "Normal"
    },
    {
        "Text": "It is therefore part of a reference-processing system, whose overall goal, in turn, is to determine the interpretation of the anaphors.",
        "Entity": "Normal"
    },
    {
        "Text": "This involves determining the appropriate semantic type of the anaphoric link between an anaphor and its antecedent (coreference, bridging, e-type, bound anaphora, etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "and providing a suitable semantic representation for this link.",
        "Entity": "Normal"
    },
    {
        "Text": "Being the interface point between grammatical representation and reference processing, the list value of the feature ANTEC has just to be reduced by anaphor resolvers, given the relevant preferences and filters other than binding constraints, until the most likely antecedent is isolated.",
        "Entity": "Normal"
    },
    {
        "Text": "It is thus a process concerning selection in a list, rather than search in a set of indexed trees.",
        "Entity": "Normal"
    },
    {
        "Text": "As to reference processing in general, the specification suggested in the previous section provides a suitable framework for the correct representation of the semantically different types of anaphoric links, the range of options not being restricted to coreference only.",
        "Entity": "Normal"
    },
    {
        "Text": "After the anaphor has been resolved, the reference marker of the anaphor and the reference marker selected as the antecedent can be related in accordance with the mode of anaphora determined by the reference-processing system.",
        "Entity": "Normal"
    },
    {
        "Text": "This semantic relation between anaphorically related reference markers can be represented simply as another DRS condition in the CONDS value.",
        "Entity": "Normal"
    },
    {
        "Text": "This makes possible a mainstream DRT representation for the resolved anaphoric link, thus building on the substantial number of already worked out solutions available in the literature for DRT-based semantic representation of anaphora.16 This specification of binding theory for HPSG was tested with a computational implementation using ProFIT (Erbach 1995).",
        "Entity": "Normal"
    },
    {
        "Text": "In this implementation, the relational constraints corresponding to binding principles were straightforwardly encoded by means of Prolog predicates associated to the lexical clauses of anaphoric expressions, and defined in terms of simple auxiliary predicates ensuring the component operations of list appending, list difference, and so on.",
        "Entity": "Normal"
    },
    {
        "Text": "It is worth noting that some of these predicates have arguments for example, the LIST-U value, whose value is computed when the whole relevant grammatical representation is built up.",
        "Entity": "Normal"
    },
    {
        "Text": "This is a consequence of packing nonlocal information in such lists.",
        "Entity": "Normal"
    },
    {
        "Text": "As in Johnson s approach, it requires that some delaying device be used, which in this computational grammar was done by resorting to the Prolog built-in predicate freeze/2.",
        "Entity": "Normal"
    },
    {
        "Text": "For the sake of the example, consider the following multiclausal sentence from Portuguese displaying backward anaphora between a topicalized reflexive and a pronoun: (6) De si pro  prio, cada estudante disse que ele gosta.",
        "Entity": "Normal"
    },
    {
        "Text": "of him self every student said that he likes  Himself, every student said that he likes.",
        "Entity": "Normal"
    },
    {
        "Text": "overview concerning the semantic representation of different modes of anaphora.",
        "Entity": "Normal"
    },
    {
        "Text": "13    .",
        "Entity": "Normal"
    },
    {
        "Text": "..CONT|CONDS     ... ARGR  LIST_A 415  .",
        "Entity": "Normal"
    },
    {
        "Text": "LIST_A  LIST_Z    LIST_U     LIST_LU , , , , , , , ,                    LIST_A     LIST_Z  LIST_U     LIST_LU 5 4   5 4     4 1 5 , 2 4 , 2 4 7 , 5 4 , 3 9 2   , , ,            .",
        "Entity": "Normal"
    },
    {
        "Text": "..|BINDING           LIST_Z    LIST_U     LIST_LU 415 , , , ,                  ctx    LIST_A  LIST_Z    LIST_U     LIST_LU 5 4   5 4     , , , ,   , ,     .",
        "Entity": "Normal"
    },
    {
        "Text": "..|ANAPHORA  REFMARK   392       himse lf     ANTEC 24             .",
        "Entity": "Normal"
    },
    {
        "Text": "..|BINDING           LIST_A  LIST_Z    LIST_U     LIST_LU 24 , 392 54 , 24 , 392 415 , 24 , 247 , 54 , 392 392                           LIST_A  LIST_Z    LIST_U     LIST_LU 24 , 392   , ,     , , , ,   392     .",
        "Entity": "Normal"
    },
    {
        "Text": "..|ANAPHORA  REFMARK   247       every stu d e nt          .",
        "Entity": "Normal"
    },
    {
        "Text": "..|BINDING      VAR  LIST_A  LIST_Z    LIST_U   54            54       , , , ,       said that  LIST_A    LIST_Z    LIST_U  LIST_LU 24 , 392     54 , 24 , 392   415 , 24 , 247 , 54 , 392           LIST_LU 247 , 54           REFMARK            he     ...|ANAPHORA            .",
        "Entity": "Normal"
    },
    {
        "Text": "..|BINDING         ANTEC  LIST_A  LIST_Z    LIST_U     LIST_LU , , , 24 , 392 , , , , , , 24                            likes trace in the leaves of the tree, while the ones above the tree correspond to partial representations of some nonterminal nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "First, consider LIST-Z.",
        "Entity": "Normal"
    },
    {
        "Text": "In the outer nodes of the matrix clause, due to the effect of the Binding Domains Principle, Clause III, the LIST-Z value is obtained from the value of LIST-A, with which it is token identical, comprising the list with a single element ( 54 ).",
        "Entity": "Normal"
    },
    {
        "Text": "In the nodes of the embedded clause, the LIST-Z value is the concatenation of that upper LIST-Z value and the LIST-A value ( 24 , 392 ) in the embedded clause, from which the list ( 54 , 24 , 392 ) is the result.",
        "Entity": "Normal"
    },
    {
        "Text": "LIST-A values are obtained from the representation of the subcategorization frames of the verbal predicators.",
        "Entity": "Normal"
    },
    {
        "Text": "Next, consider LIST-LU.",
        "Entity": "Normal"
    },
    {
        "Text": "Reading upward, note that at each higher level in the constituency representation, the list gets longer; by the effect of the Binding Domains Principle, Clause I, the LIST-LU value at a given node gathers the reference markers of the nodes dominated by it.",
        "Entity": "Normal"
    },
    {
        "Text": "At the discourse top node, LIST-LU includes all the reference markers of the NPs in the example, the list ( 415 , 24 , 247 , 54 , 392 ).",
        "Entity": "Normal"
    },
    {
        "Text": "The Binding Domains Principle, Clause I, also ensures that this list of all reference markers is passed to the LIST-U value of the top node and that it is then percolated down to all relevant nodes of the grammatical representation.",
        "Entity": "Normal"
    },
    {
        "Text": "Taking a closer look at the NPs, it is easy to check that every phrase contributes to the global anaphoric potential of its linguistic context by passing the tag of its reference marker into its own LIST-LU.",
        "Entity": "Normal"
    },
    {
        "Text": "In the case of the quantificational NP every student, two tags are passed, corresponding to the REFMARK value, providing for e-type anaphora, and the VAR value, providing for bound anaphora interpretations.",
        "Entity": "Normal"
    },
    {
        "Text": "And in the case of the ctx node, to illustrate how the nonlinguistic context may be taken into account in the linguistic representation, the reference marker ( 415 ) is obtained from the set of semantic conditions that conventionally may capture the nonlinguistic context.On the other hand, the context also contributes to establishing the anaphoric po tential of each NP.",
        "Entity": "Normal"
    },
    {
        "Text": "This is ensured by the different clauses of the Binding Domains Principle, which enforce the presence of suitable values of LIST-A, LIST-Z, and LIST-U at the different nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, token identity is ensured between the ANTEC value and the outcome of the different relational constraints that are lexically associated with each NP and express binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "The value of ANTEC is a list that, at this stage of anaphor resolution, records the grammatically admissible antecedents of the corresponding anaphor only in the light of binding constraints.",
        "Entity": "Normal"
    },
    {
        "Text": "Departing from the coindexation-driven approach for encoding anaphoric dependencies in grammatical representations, we have proposed an alternative methodology where binding constraints are viewed as contributing to circumscribing their contextually determined semantic value.",
        "Entity": "Normal"
    },
    {
        "Text": "This semantics-driven approach allows a principled integration of binding constraints into grammar that supports both a specification format and a verification methodology free from previous difficulties.",
        "Entity": "Normal"
    },
    {
        "Text": "Importantly, it also permits a neat interface between the grammatical module of binding and systems of reference processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Appendix In this article, we consider the version of binding constraints formulated within Head- Driven Phrase Structure Grammar (Pollard and Sag 1994, Chapter 6).",
        "Entity": "Normal"
    },
    {
        "Text": "Recent developments indicate that there are four binding constraints (Xue, Pollard, and Sag 1994; 15 Branco and Marrafa 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the definition of each binding constraint is followed by an illustrative example.",
        "Entity": "Normal"
    },
    {
        "Text": "(7) Principle A A locally o-commanded short-distance reflexive must be locally o-bound.",
        "Entity": "Normal"
    },
    {
        "Text": "Leei thinks [Maxj saw himself i/j ].",
        "Entity": "Normal"
    },
    {
        "Text": "(8) Principle Z An o-commanded long-distance reflexive must be o-bound.",
        "Entity": "Normal"
    },
    {
        "Text": "[O amigo do Ruii ]j acha que o Pedrok gosta dele pro  prio i/j/k .",
        "Entity": "Normal"
    },
    {
        "Text": "[the friend of the Rui] thinks that the Pedro likes of he PRO  PRIO  [Rui s friend]j thinks that Pedrok likes himj /himselfk .",
        "Entity": "Normal"
    },
    {
        "Text": "(Portuguese) (9) Principle B A pronoun must be locally o-free.",
        "Entity": "Normal"
    },
    {
        "Text": "Leei thinks [Maxj saw himi/ j ].",
        "Entity": "Normal"
    },
    {
        "Text": "(10) Principle C A nonpronoun must be o-free.",
        "Entity": "Normal"
    },
    {
        "Text": "[Kimi  s friend]j thinks [Lee saw Kimi/ j ].",
        "Entity": "Normal"
    },
    {
        "Text": "These constraints are defined on the basis of some auxiliary notions.The notion of local domain involves the partition of sentences and associated gram matical geometry into two zones of greater or lesser proximity with respect to the anaphor.",
        "Entity": "Normal"
    },
    {
        "Text": "The exact definition of the boundary separating the local from the nonlocal domain may vary from language to language.",
        "Entity": "Normal"
    },
    {
        "Text": "Typically, the local domain tends to correspond to the structure in the grammatical representation that is affected by the selectional capacity and requirements of a predicator.",
        "Entity": "Normal"
    },
    {
        "Text": "O-command is a partial order under which, in a clause, the subject o-commands the direct object, the direct object o-commands the indirect object, and so on, following the usual obliqueness hierarchy of grammatical functions, while in a multiclausal sentence, the upward arguments o-command the successively embedded arguments.",
        "Entity": "Normal"
    },
    {
        "Text": "The notion of o-binding is such that x o-binds y iff x o-commands y and x and y are coindexed, where coindexation is meant to represent anaphoric links.",
        "Entity": "Normal"
    },
    {
        "Text": "I am grateful to Hans Uszkoreit for advice and helpful discussion, and to Mark Johnson for clarifying criticisms.",
        "Entity": "Normal"
    },
    {
        "Text": "I am solely responsible for remaining errors.",
        "Entity": "Normal"
    },
    {
        "Text": "The results presented here were obtained while I was on leave at the Language Technology Group of the DFKIGerman Research Center on Artificial Intelligence, Saarbru  cken, Germany, whose hospitality and enthusiastic atmosphere I was very fortunate to enjoy and I hereby gratefully acknowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tWe present an unsupervised model for coreference resolution that casts the problem as a clustering task in a directed labeled weighted multigraph.",
        "Entity": "Normal"
    },
    {
        "Text": "The model outperforms most systems participating in the English track of the CoNLL 12 shared task.",
        "Entity": "Normal"
    },
    {
        "Text": "Coreference resolution is the task of determining which mentions in a text refer to the same entity.",
        "Entity": "Normal"
    },
    {
        "Text": "With the advent of machine learning and the availability of annotated corpora in the mid 1990s the research focus shifted from rule-based approaches to supervised machine learning techniques.",
        "Entity": "Normal"
    },
    {
        "Text": "Quite recently, however, rule-based approaches regained popularity due to Stanford s multi-pass sieve approach which exhibits state- of-the-art performance on many standard coreference data sets (Raghunathan et al., 2010) and also won the CoNLL2011 shared task on coreference resolution (Lee et al., 2011; Pradhan et al., 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "These results show that carefully crafted rule-based systems which employ suitable inference schemes can achieve competitive performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Such a system can be considered unsupervised in the sense that it does not employ training data for optimizing parameters.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we present a graph-based approach for coreference resolution that models a document to be processed as a graph.",
        "Entity": "Normal"
    },
    {
        "Text": "The nodes are mentions and the edges correspond to relations between mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "Coreference resolution is performed via graph clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "Our approach belongs to a class of recently proposed graph models for coreference resolution (Cai and Strube, 2010; Sapena et al., 2010; Martschat et al., 2012) and is designed to be a simplified version of existing approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast to previous models belonging to this class we do not learn any edge weights but perform inference on the graph structure only which renders our model unsupervised.",
        "Entity": "Normal"
    },
    {
        "Text": "On the English data of the CoNLL 12 shared task the model outperforms most systems which participated in the shared task.",
        "Entity": "Normal"
    },
    {
        "Text": "Graph-based coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "While not developed within a graph-based framework, factor-based approaches for pronoun resolution (Mitkov, 1998) can be regarded as greedy clustering in a multigraph, where edges representing factors for pronoun resolution have negative or positive weight.",
        "Entity": "Normal"
    },
    {
        "Text": "This yields a model similar to the one presented in this paper though Mitkov s work has only been applied to pronoun resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Nicolae and Nicolae (2006) phrase coreference resolution as a graph clustering problem: they first perform pairwise classification and then construct a graph using the derived confidence values as edge weights.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, work by Culotta et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007), Cai and Strube (2010) and Sapena et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) omits the classification step entirely.",
        "Entity": "Normal"
    },
    {
        "Text": "Sapena et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) and Cai and Strube (2010) perform coreference resolution in one step using graph partitioning approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "These approaches participated in the recent CoNLL 11 shared task (Pradhan et al., 2011; Sapena et al., 2011; Cai et al., 2011b) with excellent results.",
        "Entity": "Normal"
    },
    {
        "Text": "The approach by Cai et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011b) has been modified by Martschat et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2012) and ranked second in the English track at the CoNLL 12 shared task (Pradhan et al., 2012).",
        "Entity": "Normal"
    },
    {
        "Text": "The top performing system at the CoNLL 12 shared task (Fernandes et al., 2012) 81 Proceedings of the ACL Student Research Workshop, pages 81 88, Sofia, Bulgaria, August 49 2013.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2013 Association for Computational Linguistics also represents the problem as a graph by performing inference on trees constructed using the multi-pass sieve approach by Raghunathan et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) and Lee et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011), which in turn won the CoNLL 11 shared task.",
        "Entity": "Normal"
    },
    {
        "Text": "Unsupervised coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Cardie and Wagstaff (1999) present an early approach to unsupervised coreference resolution based on a cent sentences (both in the subject slot), which is also a weak coreference indicator.",
        "Entity": "Normal"
    },
    {
        "Text": "We denote these relations as N Number, P AnaPron and P Subject respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "straightforward clustering approach.",
        "Entity": "Normal"
    },
    {
        "Text": "Angheluta et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2004) build on their approach and devise more sophisticated clustering algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "Haghighi and Klein (2007), Ng (2008) and Charniak and Elsner (2009) employ unsupervised generative models.",
        "Entity": "Normal"
    },
    {
        "Text": "Poon and Domingos (2008) present a Markov Logic Network approach to unsupervised coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "These approaches reach competitive performance on gold mentions but not on system mentions (Ng, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "The multi-pass sieve Leaders recent developments P AnaPron P Subject P AnaPron Paris They approach by Raghunathan et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) can also be viewed as unsupervised.",
        "Entity": "Normal"
    },
    {
        "Text": "We aim for a model which directly represents the relations between mentions in a graph structure.",
        "Entity": "Normal"
    },
    {
        "Text": "Clusters in the graph then correspond to entities.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Motivation.",
        "Entity": "Normal"
    },
    {
        "Text": "To motivate the choice of our model, let us consider a simple made-up example.",
        "Entity": "Normal"
    },
    {
        "Text": "Leaders met in Paris to discuss recent developments.",
        "Entity": "Normal"
    },
    {
        "Text": "They left the city today.",
        "Entity": "Normal"
    },
    {
        "Text": "We want to model that Paris is not a likely candidate antecedent for They due to number disagreement, but that Leaders and recent developments are potential antecedents for They.",
        "Entity": "Normal"
    },
    {
        "Text": "We want to express that Leaders is the preferred antecedent, since Leaders and They are in a parallel construction both occupying the subject position in their respective sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "In other words, our model should express the following relations for this example:   number disagreement for (They, Paris), which indicates that the mentions are not coreferent,  the anaphor being a pronoun for (They, Lead ers), (They, recent developments) and (They, Paris), which is a weak indicator for coreference if the mentions are close to each other,   syntactic parallelism for (They, Leaders):                                                                                                                    \n\t\t\tA directed edge from a mention m to n indicates that n precedes m and that there is some relation between m and n that indicates coreference or non-coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Labeled edges describe the relations between the mentions, multiple relations can hold between a pair.",
        "Entity": "Normal"
    },
    {
        "Text": "Edges may be weighted.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Multigraphs for Coreference Resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Formally, the model is a directed labeled weighted multigraph.",
        "Entity": "Normal"
    },
    {
        "Text": "That is a tuple D = (R, V, A, w) where   R is the set of labels (in our case relations such as P Subject that hold between mentions),   V is the set of nodes (the mentions extracted from a document),   A   V   V   R is the set of edges (relations between two mentions),   w is a mapping w : A   R   {  } (weights for edges).",
        "Entity": "Normal"
    },
    {
        "Text": "Many graph models for coreference resolution operate on A = V  V .",
        "Entity": "Normal"
    },
    {
        "Text": "Our multigraph model allows us to have multiple edges with different labels between mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "To have a notion of order we employ a directed graph: We only allow an edge from m to n if m appears later in the text than n. To perform coreference resolution for a document d, we first construct a directed labeled multi- graph (Section 3.3).",
        "Entity": "Normal"
    },
    {
        "Text": "We then assign a weight to each edge (Section 3.4).",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting graph is clustered to obtain the mentions that refer to the same entity (Section 3.5).",
        "Entity": "Normal"
    },
    {
        "Text": "3.3 Graph Construction.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a set M of mentions extracted from a document d, we set V = M , i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "the nodes of the graph are the mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "To construct the edges A, we consider each pair (m, n) of mentions with n   m. We then check for every relation r   R if r holds for the pair (m, n).",
        "Entity": "Normal"
    },
    {
        "Text": "If this is the case we add the edge (m, n, r) to A.",
        "Entity": "Normal"
    },
    {
        "Text": "For simplicity, we restrict ourselves to binary relations that hold between pairs of mentions (see Section 4).",
        "Entity": "Normal"
    },
    {
        "Text": "3.4 Assigning Weights.",
        "Entity": "Normal"
    },
    {
        "Text": "Depending on whether a relation r   R is indicative for non-coreference (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "number disagree ment) or for coreference (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "string matching) it should be weighted differently.",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore divide R into a set of negative relations R  and a set of positive relations R+.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous work on multigraphs for coreference resolution disallows any edge between mentions for which a negative relations holds (Cai et al., 2011b; Martschat et al., 2012).",
        "Entity": "Normal"
    },
    {
        "Text": "We take a similar approach and set w(m, n, r) =    for (m, n, r)   A when r   R 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Work on graph-based models similar to ours report robustness with regard to the amount of training data used (Cai et al., 2011b; Cai et al., 2011a; Martschat et al., 2012).",
        "Entity": "Normal"
    },
    {
        "Text": "Motivated by their observations we treat every positive relation equally and set w(m, n, r) = 1 for (m, n, r)   A if r   R+.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast to previous work on similar graph models we do not learn any edge weights from training data.",
        "Entity": "Normal"
    },
    {
        "Text": "We compare this unsupervised scheme with supervised variants empirically in Section 5.",
        "Entity": "Normal"
    },
    {
        "Text": "3.5 Clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "To describe the clustering algorithm used in this work we need some additional terminology.",
        "Entity": "Normal"
    },
    {
        "Text": "If there exists an edge (m, n, r)   A we say that n is a child of m. 1 We experimented with different weighting schemes for negative relations on development data (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "setting w(m, n, r) =  1) but did not observe a gain in performance.",
        "Entity": "Normal"
    },
    {
        "Text": "In the graph constructed according to the procedure described in Section 3.3, all children of a mention m are candidate antecedents for m. The relations we employ are indicators for coreference (which get a positive weight) and indicators for non-coreference (which get a negative weight).",
        "Entity": "Normal"
    },
    {
        "Text": "We aim to employ a simple and efficient clustering scheme on this graph and therefore choose 1-nearest-neighbor clustering: for every m, we choose as antecedent m s child n such that the sum of edge weights is maximal and positive.",
        "Entity": "Normal"
    },
    {
        "Text": "We break ties by choosing the closest mention.",
        "Entity": "Normal"
    },
    {
        "Text": "In the unsupervised setting described in Section 3.4 this algorithm reduces to choosing the child that is connected via the highest number of positive relations and via no negative relation.",
        "Entity": "Normal"
    },
    {
        "Text": "The graph model described in Section 3 is based on expressing relations between pairs of mentions via edges built from such relations.",
        "Entity": "Normal"
    },
    {
        "Text": "We now describe the relations currently used by our system.",
        "Entity": "Normal"
    },
    {
        "Text": "They are well-known indicators and constraints for coreference and are taken from previous work (Cardie and Wagstaff, 1999; Soon et al., 2001; Rahman and Ng, 2009; Lee et al., 2011; Cai et al., 2011b).",
        "Entity": "Normal"
    },
    {
        "Text": "All relations operate on pairs of mentions (m, n), where m is the anaphor and n is a candidate antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "If a relation r holds for (m, n), the edge (m, n, r) is added to the graph.",
        "Entity": "Normal"
    },
    {
        "Text": "We finalized the set of relations and their distance thresholds on development data.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Negative Relations.",
        "Entity": "Normal"
    },
    {
        "Text": "Negative relations receive negative weights.",
        "Entity": "Normal"
    },
    {
        "Text": "They allow us to introduce well-known constraints such as agreement into our model.",
        "Entity": "Normal"
    },
    {
        "Text": "(1) N Gender, (2) N Number: Two mentions do not agree in gender or number.",
        "Entity": "Normal"
    },
    {
        "Text": "We compute number and gender for common nouns using the number and gender data provided by Bergsma and Lin (2006).",
        "Entity": "Normal"
    },
    {
        "Text": "(3) N SemanticClass: Two mentions do not agree in semantic class (we only use the top categories Object, Date and Person from WordNet (Fellbaum, 1998)).",
        "Entity": "Normal"
    },
    {
        "Text": "(4) N ItDist: The anaphor is it or they and the sentence distance to the antecedent is larger than one.",
        "Entity": "Normal"
    },
    {
        "Text": "(5) N Speaker12Pron: Two first person pronouns or two second person pronouns with different speakers, or one first person pronoun and one second person pronoun with the same speaker2.",
        "Entity": "Normal"
    },
    {
        "Text": "(6) N ContraSubObj: Two mentions are in the subject/object positions of the same verb, the anaphor is a non-possessive/reflexive pronoun.",
        "Entity": "Normal"
    },
    {
        "Text": "(7) N Mod: Two mentions have the same syntactic heads, and the anaphor has a nominal modifier which does not occur in the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "(8) N Embedding: Two mentions where one embeds the other, which is not a reflexive or possessive pronoun.",
        "Entity": "Normal"
    },
    {
        "Text": "(9) N 2PronNonSpeech: Two second person pronouns without speaker information and not in direct speech.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Positive Relations.",
        "Entity": "Normal"
    },
    {
        "Text": "Positive relations are coreference indicators which are added as edges with positive weights.",
        "Entity": "Normal"
    },
    {
        "Text": "(10) P NonPron StrMatch: Applies only if the anaphor is definite or a proper name3.",
        "Entity": "Normal"
    },
    {
        "Text": "This relation holds if after discarding stop words the strings of mentions completely match.",
        "Entity": "Normal"
    },
    {
        "Text": "(11) P HeadMatch: If the syntactic heads of mentions match.",
        "Entity": "Normal"
    },
    {
        "Text": "(12) P Alias: If mentions are aliases of each other (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "proper names with partial match, full names and acronyms, etc.).",
        "Entity": "Normal"
    },
    {
        "Text": "(13) P Speaker12Pron: If the speaker of the second person pronoun is talking to the speaker of the first person pronoun (applies only to first/second person pronouns).",
        "Entity": "Normal"
    },
    {
        "Text": "(14) P DSPron: One mention is a speak verb s subject, the other mention is a first person pronoun within the corresponding direct speech.",
        "Entity": "Normal"
    },
    {
        "Text": "(15) P ReflPronSub: If the anaphor is a reflexive pronoun, and the antecedent is the subject of the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "(16) P PossPronSub: If the anaphor is a possessive pronoun, and the antecedent is the subject of the anaphor s sentence or subclause.",
        "Entity": "Normal"
    },
    {
        "Text": "(17) P PossPronEmb: The anaphor is a posses 2 Like all relations using speaker information, this relation depends on the gold speaker annotation layer in the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "3 This condition is necessary to cope with the high-recall output of the mention tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "sive pronoun embedded in the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "(18) P AnaPron: If the anaphor is a pronoun and none of the mentions is a first or second person pronoun.",
        "Entity": "Normal"
    },
    {
        "Text": "This relation is restricted to a sentence distance of 3.",
        "Entity": "Normal"
    },
    {
        "Text": "(19) P VerbAgree: If the anaphor is a third person pronoun and has the same predicate as the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "This relation is restricted to a sentence distance of 1.",
        "Entity": "Normal"
    },
    {
        "Text": "(20) P Subject, (21) P Object: The anaphor is a third person pronoun and both mentions are subjects/objects.",
        "Entity": "Normal"
    },
    {
        "Text": "These relations are restricted to a sentence distance of 1.",
        "Entity": "Normal"
    },
    {
        "Text": "(22) P Pron StrMatch: If both mentions are pronouns and their strings match.",
        "Entity": "Normal"
    },
    {
        "Text": "(23) P Pron Agreement: If both mentions are different pronoun tokens but agree in number, gender and person.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Data and Evaluation Metrics.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the data provided for the English track of the CoNLL 12 shared task on multilingual coreference resolution (Pradhan et al., 2012) which is a subset of the upcoming OntoNotes 5.0 release and comes with various annotation layers provided by state-of-the-art NLP tools.",
        "Entity": "Normal"
    },
    {
        "Text": "We used the official dev/test split for development and evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluate the model in a setting that corresponds to the shared task s closed track, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "we use only WordNet (Fellbaum, 1998), the number and gender data of Bergsma and Lin (2006) and the provided annotation layers.",
        "Entity": "Normal"
    },
    {
        "Text": "To extract system mentions we employ the mention extractor described in Martschat et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2012).",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluate our system with the coreference resolution evaluation metrics that were used for the CoNLL shared tasks on coreference, which are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998) and CEAFe (Luo, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "We also report the unweighted average of the three scores, which was the official evaluation metric in the shared tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "To compute the scores we employed the official scorer supplied by the shared task organizers.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2 Results.",
        "Entity": "Normal"
    },
    {
        "Text": "88 74.",
        "Entity": "Normal"
    },
    {
        "Text": "74 69.",
        "Entity": "Normal"
    },
    {
        "Text": "46 66.",
        "Entity": "Normal"
    },
    {
        "Text": "53 78.",
        "Entity": "Normal"
    },
    {
        "Text": "28 71.",
        "Entity": "Normal"
    },
    {
        "Text": "93 54.",
        "Entity": "Normal"
    },
    {
        "Text": "93 43.",
        "Entity": "Normal"
    },
    {
        "Text": "68 48.",
        "Entity": "Normal"
    },
    {
        "Text": "66 63.",
        "Entity": "Normal"
    },
    {
        "Text": "35 me dia n 62.",
        "Entity": "Normal"
    },
    {
        "Text": "3 62.",
        "Entity": "Normal"
    },
    {
        "Text": "8 62.",
        "Entity": "Normal"
    },
    {
        "Text": "0 66.",
        "Entity": "Normal"
    },
    {
        "Text": "7 71.",
        "Entity": "Normal"
    },
    {
        "Text": "8 69.",
        "Entity": "Normal"
    },
    {
        "Text": "1 46.",
        "Entity": "Normal"
    },
    {
        "Text": "4 44.",
        "Entity": "Normal"
    },
    {
        "Text": "9 45.",
        "Entity": "Normal"
    },
    {
        "Text": "6 58.",
        "Entity": "Normal"
    },
    {
        "Text": "9 thi s wo rk (w eig hts fra cti on ) 64.",
        "Entity": "Normal"
    },
    {
        "Text": "00 68.",
        "Entity": "Normal"
    },
    {
        "Text": "56 66.",
        "Entity": "Normal"
    },
    {
        "Text": "20 66.",
        "Entity": "Normal"
    },
    {
        "Text": "59 75.",
        "Entity": "Normal"
    },
    {
        "Text": "67 70.",
        "Entity": "Normal"
    },
    {
        "Text": "84 50.",
        "Entity": "Normal"
    },
    {
        "Text": "48 45.",
        "Entity": "Normal"
    },
    {
        "Text": "52 47.",
        "Entity": "Normal"
    },
    {
        "Text": "87 61.",
        "Entity": "Normal"
    },
    {
        "Text": "63 thi s wo rk (w eig hts Ma xE nt) 63.",
        "Entity": "Normal"
    },
    {
        "Text": "72 65.",
        "Entity": "Normal"
    },
    {
        "Text": "78 64.",
        "Entity": "Normal"
    },
    {
        "Text": "73 66.",
        "Entity": "Normal"
    },
    {
        "Text": "60 73.",
        "Entity": "Normal"
    },
    {
        "Text": "76 70.",
        "Entity": "Normal"
    },
    {
        "Text": "00 47.",
        "Entity": "Normal"
    },
    {
        "Text": "46 45.",
        "Entity": "Normal"
    },
    {
        "Text": "30 46.",
        "Entity": "Normal"
    },
    {
        "Text": "36 60.",
        "Entity": "Normal"
    },
    {
        "Text": "36 this wo rk (u ns up erv ise d) 64.",
        "Entity": "Normal"
    },
    {
        "Text": "01 68.",
        "Entity": "Normal"
    },
    {
        "Text": "58 66.",
        "Entity": "Normal"
    },
    {
        "Text": "22 67.",
        "Entity": "Normal"
    },
    {
        "Text": "00 76.",
        "Entity": "Normal"
    },
    {
        "Text": "45 71.",
        "Entity": "Normal"
    },
    {
        "Text": "41 51.",
        "Entity": "Normal"
    },
    {
        "Text": "10 46.",
        "Entity": "Normal"
    },
    {
        "Text": "16 48.",
        "Entity": "Normal"
    },
    {
        "Text": "51 62.",
        "Entity": "Normal"
    },
    {
        "Text": "05 CoNLL 12 English test data be st 65.",
        "Entity": "Normal"
    },
    {
        "Text": "83 75.",
        "Entity": "Normal"
    },
    {
        "Text": "91 70.",
        "Entity": "Normal"
    },
    {
        "Text": "51 65.",
        "Entity": "Normal"
    },
    {
        "Text": "79 77.",
        "Entity": "Normal"
    },
    {
        "Text": "69 71.",
        "Entity": "Normal"
    },
    {
        "Text": "24 55.",
        "Entity": "Normal"
    },
    {
        "Text": "00 43.",
        "Entity": "Normal"
    },
    {
        "Text": "17 48.",
        "Entity": "Normal"
    },
    {
        "Text": "37 63.",
        "Entity": "Normal"
    },
    {
        "Text": "37 me dia n 62.",
        "Entity": "Normal"
    },
    {
        "Text": "08 63.",
        "Entity": "Normal"
    },
    {
        "Text": "02 62.",
        "Entity": "Normal"
    },
    {
        "Text": "55 66.",
        "Entity": "Normal"
    },
    {
        "Text": "23 70.",
        "Entity": "Normal"
    },
    {
        "Text": "45 68.",
        "Entity": "Normal"
    },
    {
        "Text": "27 45.",
        "Entity": "Normal"
    },
    {
        "Text": "74 44.",
        "Entity": "Normal"
    },
    {
        "Text": "74 45.",
        "Entity": "Normal"
    },
    {
        "Text": "23 58.",
        "Entity": "Normal"
    },
    {
        "Text": "68 thi s wo rk (w eig hts fra cti on ) 64.",
        "Entity": "Normal"
    },
    {
        "Text": "25 68.",
        "Entity": "Normal"
    },
    {
        "Text": "31 66.",
        "Entity": "Normal"
    },
    {
        "Text": "22 65.",
        "Entity": "Normal"
    },
    {
        "Text": "44 74.",
        "Entity": "Normal"
    },
    {
        "Text": "20 69.",
        "Entity": "Normal"
    },
    {
        "Text": "54 49.",
        "Entity": "Normal"
    },
    {
        "Text": "18 44.",
        "Entity": "Normal"
    },
    {
        "Text": "71 46.",
        "Entity": "Normal"
    },
    {
        "Text": "84 60.",
        "Entity": "Normal"
    },
    {
        "Text": "87 thi s wo rk (w eig hts Ma xE nt) 63.",
        "Entity": "Normal"
    },
    {
        "Text": "58 64.",
        "Entity": "Normal"
    },
    {
        "Text": "70 64.",
        "Entity": "Normal"
    },
    {
        "Text": "14 65.",
        "Entity": "Normal"
    },
    {
        "Text": "63 72.",
        "Entity": "Normal"
    },
    {
        "Text": "09 68.",
        "Entity": "Normal"
    },
    {
        "Text": "71 45.",
        "Entity": "Normal"
    },
    {
        "Text": "58 44.",
        "Entity": "Normal"
    },
    {
        "Text": "41 44.",
        "Entity": "Normal"
    },
    {
        "Text": "99 59.",
        "Entity": "Normal"
    },
    {
        "Text": "28 this wo rk (u ns up erv ise d) 63.",
        "Entity": "Normal"
    },
    {
        "Text": "95 67.",
        "Entity": "Normal"
    },
    {
        "Text": "99 65.",
        "Entity": "Normal"
    },
    {
        "Text": "91 65.",
        "Entity": "Normal"
    },
    {
        "Text": "47 74.",
        "Entity": "Normal"
    },
    {
        "Text": "93 69.",
        "Entity": "Normal"
    },
    {
        "Text": "88 49.",
        "Entity": "Normal"
    },
    {
        "Text": "83 45.",
        "Entity": "Normal"
    },
    {
        "Text": "40 47.",
        "Entity": "Normal"
    },
    {
        "Text": "51 61.",
        "Entity": "Normal"
    },
    {
        "Text": "10                                                                         \n\t\t\tCoNLL 12 shared task, which are denoted as best and median respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "best employs a structured prediction model with learned combinations of 70 basic features.",
        "Entity": "Normal"
    },
    {
        "Text": "We also compare with two supervised variants of our model which use the same relations and the same clustering algorithm as the unsupervised model: weights fraction sets the weight of a relation to the fraction of positive instances in training data (as in Martschat et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2012)).",
        "Entity": "Normal"
    },
    {
        "Text": "weights MaxEnt trains a mention-pair model (Soon et al., 2001) via the maximum entropy classifier implemented in the BART toolkit (Versley et al., 2008) and builds a graph where the weight of an edge connecting two mentions is the classifier s prediction4.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the official CoNLL 12 English training set for training.",
        "Entity": "Normal"
    },
    {
        "Text": "Our unsupervised model performs considerably better than the median system from the CoNLL 12 shared task on both data sets according to all metrics.",
        "Entity": "Normal"
    },
    {
        "Text": "It also seems to be able to accommodate well for the relations described in Section 4 since it outperforms both supervised variants5.",
        "Entity": "Normal"
    },
    {
        "Text": "The model performs worse than best, the gap according to B3 and CEAFe being considerably smaller than according to MUC.",
        "Entity": "Normal"
    },
    {
        "Text": "While we observe a decrease of 1 point average score when evaluating on test data the model still would have ranked fourth in the English track of the CoNLL 12 shared task with only 0.2 points difference in average score to the second ranked system.",
        "Entity": "Normal"
    },
    {
        "Text": "4 The classifier s output is a number p   [0, 1].",
        "Entity": "Normal"
    },
    {
        "Text": "In order to have negative weights we use the transformation pi = 2p   1.",
        "Entity": "Normal"
    },
    {
        "Text": "5 Compared with the supervised variants all improvements in F1 score are statistically significant according to a paired t-test (p < 0.05) except for the difference in MUC F1 to weights fraction.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to understand weaknesses of our model we perform an error analysis on the development data.",
        "Entity": "Normal"
    },
    {
        "Text": "We distinguish between precision and recall errors.",
        "Entity": "Normal"
    },
    {
        "Text": "For an initial analysis we split the errors according to the mention type of anaphor and antecedent (name, nominal and pronoun).",
        "Entity": "Normal"
    },
    {
        "Text": "6.1 Precision Errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Our system operates in a pairwise fashion.",
        "Entity": "Normal"
    },
    {
        "Text": "We therefore count one precision error whenever the clustering algorithm assigns two non-coreferent mentions to the same cluster.",
        "Entity": "Normal"
    },
    {
        "Text": "number of clustering decisions made according to the mention type and in brackets the fraction of decisions that erroneously assign two non-coreferent mentions to the same cluster.",
        "Entity": "Normal"
    },
    {
        "Text": "We see that two main sources of error are nominal-nominal pairs and the resolution of pronouns.",
        "Entity": "Normal"
    },
    {
        "Text": "We now focus on gaining further insight into the system s performance for pronoun resolution by investigating the performance per pronoun type.",
        "Entity": "Normal"
    },
    {
        "Text": "We obtain good performance for I and my which in the majority of cases can be resolved unambiguously by the speaker relations employed by our system.",
        "Entity": "Normal"
    },
    {
        "Text": "The relations we use also seem Anaphor all anaphoric I 1260 (13%) 1239 (11%) my 192 (14%) 181 (9%) he 824 (14%) 812 (13%) .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "they 764 (29%) 725 (26%) .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "you 802 (41%) 555 (15%) it 1114 (64%) 720 (44%)                                            \n\t\t\tRows are pronoun surfaces, columns number of clustering decisions and percentage of wrong decisions for all and only anaphoric pronouns respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "to work well for he.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, the local, shallow approach we currently employ is not able to resolve highly ambiguous pronouns such as they, you or it in many cases.",
        "Entity": "Normal"
    },
    {
        "Text": "The reduction in error rate when only considering anaphoric pronouns shows that our system could benefit from an improved detection of expletive it and you.",
        "Entity": "Normal"
    },
    {
        "Text": "6.2 Recall Errors.",
        "Entity": "Normal"
    },
    {
        "Text": "Estimating recall errors by counting all missing pairwise links would consider each entity many times.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we instead count one recall error for a pair (m, n) of anaphor m and antecedent n if (i) m and n are coreferent, (ii) m and n are not assigned to the same cluster, (iii) m is the first mention in its cluster that is coreferent with n, and (iv) n is the closest mention coreferent with m that is not in m s cluster.",
        "Entity": "Normal"
    },
    {
        "Text": "This can be illustrated by an example.",
        "Entity": "Normal"
    },
    {
        "Text": "Considering mentions m1, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", m5, assume that m1, m3, m4 and m5 are coreferent but the system clusters are {m2, m3} and {m4, m5}.",
        "Entity": "Normal"
    },
    {
        "Text": "We then count two recall errors: one for the missing link from m3 to m1 and one for the missing link from m4 to m3.",
        "Entity": "Normal"
    },
    {
        "Text": "According to this definition we count 3528 recall errors on the development set.",
        "Entity": "Normal"
    },
    {
        "Text": "We see that NA M N O M PR O NA M 32 1 22 0 24 7 N O M 30 6 79 7 33 0 PR O 30 6 47 6 52 5                                                                                               \n\t\t\tthe main source of recall errors are missing links of nominal-nominal pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "We randomly extracted 50 of these errors and manually assigned them to different categories.",
        "Entity": "Normal"
    },
    {
        "Text": "29 errors: missing semantic knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "In these cases lexical or world knowledge is needed to build coreference links between mentions with different heads.",
        "Entity": "Normal"
    },
    {
        "Text": "For example our system misses the link between the sauna and the hotbox sweatbox.",
        "Entity": "Normal"
    },
    {
        "Text": "14 errors: too restrictive N Mod.",
        "Entity": "Normal"
    },
    {
        "Text": "In these cases the heads of the mentions matched but no link was built due to N Mod.",
        "Entity": "Normal"
    },
    {
        "Text": "An example is the missing link between our island s last remaining forest of these giant trees and the forest of Chilan.",
        "Entity": "Normal"
    },
    {
        "Text": "4 errors: too cautious string match.",
        "Entity": "Normal"
    },
    {
        "Text": "We only apply string matching for common nouns when the noun is definite.",
        "Entity": "Normal"
    },
    {
        "Text": "Three errors could not be attributed to any of the above categories.",
        "Entity": "Normal"
    },
    {
        "Text": "We presented an unsupervised graph-based model for coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Experiments show that our model exhibits competitive performance on the English CoNLL 12 shared task data sets.",
        "Entity": "Normal"
    },
    {
        "Text": "An error analysis revealed that two main sources of errors of our model are the inaccurate resolution of highly ambiguous pronouns such as it and missing links between nominals with different heads.",
        "Entity": "Normal"
    },
    {
        "Text": "Future work should investigate how semantic knowledge and more complex relations capturing deeper discourse properties such as coherence or information status can be added to the model.",
        "Entity": "Normal"
    },
    {
        "Text": "Processing these features efficently may require a more sophisticated clustering algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "We are surprised by the good performance of this unsupervised model in comparison to the state-of-the-art which uses sophisticated machine learning techniques (Fernandes et al., 2012) or well-engineered rules (Lee et al., 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "We are not sure how to interpret these results and want to leave different interpretations for discussion:   our unsupervised model is really that good (hopefully),   the evaluation metrics employed are to be questioned (certainly),   efficiently making use of annotated trainingdata still remains a challenge for the state-of the-art (likely).",
        "Entity": "Normal"
    },
    {
        "Text": "This work has been funded by the Klaus Tschira Foundation, Germany.",
        "Entity": "Normal"
    },
    {
        "Text": "The author has been supported by a HITS PhD scholarship.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tThis paper proposes a new approach to dynamically determine the tree span for tree kernel-based semantic relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "It exploits constituent dependencies to keep the nodes and their head children along the path connecting the two entities, while removing the noisy information from the syntactic parse tree, eventually leading to a dynamic syntactic parse tree.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper also explores entity features and their combined features in a unified parse and semantic tree, which integrates both structured syntactic parse information and entity-related semantic information.",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation on the ACE RDC 2004 corpus shows that our dynamic syntactic parse tree outperforms all previous tree spans, and the composite kernel combining this tree kernel with a linear state-of-the-art feature-based kernel, achieves the so far best performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Information extraction is one of the key tasks in natural language processing.",
        "Entity": "Normal"
    },
    {
        "Text": "It attempts to identify relevant information from a large amount of natural language text documents.",
        "Entity": "Normal"
    },
    {
        "Text": "Of three sub- tasks defined by the ACE program1, this paper focuses exclusively on Relation Detection and Characterization (RDC) task, which detects and classifies semantic relationships between predefined types of entities in the ACE corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "For   2008.",
        "Entity": "Normal"
    },
    {
        "Text": "Licensed under the Creative Commons Attribution- Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).",
        "Entity": "Normal"
    },
    {
        "Text": "Some rights reserved.",
        "Entity": "Normal"
    },
    {
        "Text": "1 http://www.ldc.upenn.edu/Projects/ACE/ example, the sentence  Microsoft Corp. is based in Redmond, WA  conveys the relation  GPEAFF.Based  between  Microsoft Corp.  [ORG] and  Redmond  [GPE].",
        "Entity": "Normal"
    },
    {
        "Text": "Due to limited accuracy in state-of-the-art syntactic and semantic parsing, reliably extracting semantic relationships between named entities in natural language documents is still a difficult, unresolved problem.",
        "Entity": "Normal"
    },
    {
        "Text": "In the literature, feature-based methods have dominated the research in semantic relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "Featured-based methods achieve promising performance and competitive efficiency by transforming a relation example into a set of syntactic and semantic features, such as lexical knowledge, entity-related information, syntactic parse trees and deep semantic information.",
        "Entity": "Normal"
    },
    {
        "Text": "However, detailed research (Zhou et al., 2005) shows that it s difficult to extract new effective features to further improve the extraction accuracy.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, researchers turn to kernel-based methods, which avoids the burden of feature engineering through computing the similarity of two discrete objects (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "parse trees) directly.",
        "Entity": "Normal"
    },
    {
        "Text": "From prior work (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005) to current research (Zhang et al., 2006; Zhou et al., 2007), kernel methods have been showing more and more potential in relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "The key problem for kernel methods on relation extraction is how to represent and capture the structured syntactic information inherent in relation instances.",
        "Entity": "Normal"
    },
    {
        "Text": "While kernel methods using the dependency tree (Culotta and Sorensen, 2004) and the shortest dependency path (Bunescu andMooney, 2005) suffer from low recall perform ance, convolution tree kernels (Zhang et al., 2006; Zhou et al., 2007) over syntactic parse trees achieve comparable or even better performance than feature-based methods.",
        "Entity": "Normal"
    },
    {
        "Text": "However, there still exist two problems regarding currently widely used tree spans.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) discover that the Shortest Path 697 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 697 704 Manchester, August 2008 enclosed Tree (SPT) achieves the best performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhou et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) further extend it to Context-Sensitive Shortest Path-enclosed Tree (CS- SPT), which dynamically includes necessary predicate-linked path information.",
        "Entity": "Normal"
    },
    {
        "Text": "One problem with both SPT and CS-SPT is that they may still contain unnecessary information.",
        "Entity": "Normal"
    },
    {
        "Text": "The other problem is that a considerable number of useful context-sensitive information is also missing from SPT/CS-SPT, although CS-SPT includes some contextual information relating to predicate- linked path.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper proposes a new approach to dynamically determine the tree span for relation extraction by exploiting constituent dependencies to remove the noisy information, as well as keep the necessary information in the parse tree.",
        "Entity": "Normal"
    },
    {
        "Text": "Our motivation is to integrate dependency information, which has been proven very useful to relation extraction, with the structured syntactic information to construct a concise and effective tree span specifically targeted for relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, we also explore interesting combined entity features for relation extraction via a unified parse and semantic tree.",
        "Entity": "Normal"
    },
    {
        "Text": "The other sections in this paper are organized as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous work is first reviewed in Section 2.",
        "Entity": "Normal"
    },
    {
        "Text": "Then, Section 3 proposes a dynamic syntactic parse tree while the entity-related semantic tree is described in Section 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation on the ACE RDC corpus is given in Section 5.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we conclude our work in Section 6.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to space limitation, here we only review kernel-based methods used in relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "For those interested in feature-based methods, please refer to Zhou et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2005) for more details.",
        "Entity": "Normal"
    },
    {
        "Text": "Zelenko et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2003) described a kernel between shallow parse trees to extract semantic relations, where a relation instance is transformed into the least common sub-tree connecting the two entity nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "The kernel matches the nodes of two corresponding sub-trees from roots to leaf nodes recursively layer by layer in a top- down manner.",
        "Entity": "Normal"
    },
    {
        "Text": "Their method shows successful results on two simple extraction tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "Culotta and Sorensen (2004) proposed a slightly generalized version of this kernel between dependency trees, in which a successful match of two relation instances requires the nodes to be at the same layer and in the identical path starting from the roots to the current nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "These strong constraints make their kernel yield high precision but very low recall on the ACE RDC 2003 corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Bunescu and Mooney (2005) develop a shortest path dependency tree kernel, which simply counts the number of common word classes at each node in the shortest paths between two entities in dependency trees.",
        "Entity": "Normal"
    },
    {
        "Text": "Similar to Culotta and Sorensen (2004), this method also suffers from high precision but low recall.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) describe a convolution tree kernel (CTK, Collins and Duffy, 2001) to investigate various structured information for relation extraction and find that the Shortest Path- enclosed Tree (SPT) achieves the F-measure of 67.7 on the 7 relation types of the ACE RDC 2004 corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "One problem with SPT is that it loses the contextual information outside SPT, which is usually critical for relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhou et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) point out that both SPT and the convolution tree kernel are context-free.",
        "Entity": "Normal"
    },
    {
        "Text": "Theyexpand SPT to CS-SPT by dynamically includ ing necessary predicate-linked path information and extending the standard CTK to context- sensitive CTK, obtaining the F-measure of 73.2 on the 7 relation types of the ACE RDC 2004 corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the CS-SPT only recovers part of contextual information and may contain noisy information as much as SPT.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to fully utilize the advantages of feature-based methods and kernel-based methods, researchers turn to composite kernel methods.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhao and Grishman (2005) define several feature-based composite kernels to capture diverse linguistic knowledge and achieve the F-measure of 70.4 on the 7 relation types in the ACE RDC 2004 corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) design a composite kernel consisting of an entity linear kernel and a standard CTK, obtaining the F-measure of 72.1 on the 7 relation types in the ACE RDC 2004 corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhou et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) describe a composite kernel to integrate a context-sensitive CTK and a state-of-the-art linear kernel.",
        "Entity": "Normal"
    },
    {
        "Text": "It achieves the so far best F-measure of 75.8 on the 7 relation types in the ACE RDC 2004 corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we will further study how to dynamically determine a concise and effective tree span for a relation instance by exploiting constituent dependencies inherent in the parse tree derivation.",
        "Entity": "Normal"
    },
    {
        "Text": "We also attempt to fully capture both the structured syntactic parse information and entity-related semantic information, especially combined entity features, via a unified parse and semantic tree.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we validate the effectiveness of a composite kernel for relation extraction, which combines a tree kernel and a linear kernel.",
        "Entity": "Normal"
    },
    {
        "Text": "This section discusses how to generate dynamic syntactic parse tree by employing constituent dependencies to overcome the problems existing in currently used tree spans.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Constituent Dependencies in Parse Tree.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) explore five kinds of tree spans and find that the Shortest Path-enclosed Tree (SPT) achieves the best performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhou et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) further propose Context-Sensitive SPT (CS-SPT), which can dynamically determine the tree span by extending the necessary predicate-linked path information outside SPT.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the key problem of how to represent the structured syntactic parse tree is still partially resolved.",
        "Entity": "Normal"
    },
    {
        "Text": "As we indicate as follows, current tree spans suffer from two problems: (1) Both SPT and CS-SPT still contain unnecessary information.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, in the sentence   bought one of town s two meat-packing plants , the condensed information  one of plants  is sufficient to determine  DISC  relationship between the entities  one  [FAC] and  plants  [FAC], while SPT/CS-SPT include the redundant underlined part.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore more unnecessary information can be safely removed from SPT/CS-SPT.",
        "Entity": "Normal"
    },
    {
        "Text": "(2) CS-SPT only captures part of context- sensitive information relating to predicate-linked structure (Zhou et al., 2007) and still loses much context-sensitive information.",
        "Entity": "Normal"
    },
    {
        "Text": "Let s take the same example sentence   bought one of town s two meat-packing plants , where indeed there is no relationship between the entities  one  [FAC] and  town  [GPE].",
        "Entity": "Normal"
    },
    {
        "Text": "Nevertheless, the information contained in SPT/CS-SPT ( one of town ) may easily lead to their relationship being misclassified as  DISC , which is beyond our expectation.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore the underlined part outside SPT/CS- SPT should be recovered so as to differentiate it from positive instances.",
        "Entity": "Normal"
    },
    {
        "Text": "Since dependency plays a key role in many NLP problems such as syntactic parsing, semantic role labeling as well as semantic relation extraction, our motivation is to exploit dependency knowledge to distinguish the necessary evidence from the unnecessary information in the structured syntactic parse tree.",
        "Entity": "Normal"
    },
    {
        "Text": "On one hand, lexical or word-word dependency indicates the relationship among words occurring in the same sentence, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "predicate- argument dependency means that arguments are dependent on their target predicates, modifier head dependency means that modifiers are dependent on their head words.",
        "Entity": "Normal"
    },
    {
        "Text": "This dependency relationship offers a very condensed representation of the information needed to assess the relationship in the forms of the dependency tree (Culotta and Sorensen, 2004) or the shortest dependency path (Bunescu and Mooney, 2005) that includes both entities.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, when the parse tree corresponding to the sentence is derived using derivation rules from the bottom to the top, the word- word dependencies extend upward, making a unique head child containing the head word for every non-terminal constituent.",
        "Entity": "Normal"
    },
    {
        "Text": "As indicated as follows, each CFG rule has the form: P   Ln L1 H R1 Rm Here, P is the parent node, H is the head child of the rule, Ln L1 and R1 Rm are left and right modifiers of H respectively, and both n and m may be zero.",
        "Entity": "Normal"
    },
    {
        "Text": "In other words, the parent node P depends on the head child H, this is what we call constituent dependency.",
        "Entity": "Normal"
    },
    {
        "Text": "Vice versa, we can also determine the head child of a constituent in terms of constituent dependency.",
        "Entity": "Normal"
    },
    {
        "Text": "Our hypothesis stipulates that the contribution of the parse tree to establishing a relationship is almost exclusively concentrated in the path connecting the two entities, as well as the head children of constituent nodes along this path.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Generation of Dynamic Syntactic Parse.",
        "Entity": "Normal"
    },
    {
        "Text": "Tree Starting from the Minimum Complete Tree (MCT, the complete sub-tree rooted by the nearest common ancestor of the two entities under consideration) as the representation of each relation instance, along the path connecting two entities, the head child of every node is found according to various constituent dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "Then the path nodes and their head children are kept while any other nodes are removed from the tree.",
        "Entity": "Normal"
    },
    {
        "Text": "Eventually we arrive at a tree called Dynamic Syntactic Parse Tree (DSPT), which is dynamically determined by constituent dependencies and only contains necessary information as expected.",
        "Entity": "Normal"
    },
    {
        "Text": "There exist a considerable number of constituent dependencies in CFG as described by Collins (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "However, since our task is to extract the relationship between two named entities, our focus is on how to condense Noun-Phrases (NPs) and other useful constituents for relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore constituent dependencies can be classified according to constituent types of the CFG rules: (1) Modification within base-NPs: base-NPs mean that they do not directly dominate an NP themselves, unless the dominated NP is a possessive NP.",
        "Entity": "Normal"
    },
    {
        "Text": "The noun phrase right above the entity headword, whose mention type is nominal or name, can be categorized into this type.",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, the entity headword is also the headword of the noun phrase, thus all the constituents before the headword are dependent on the headword, and may be removed from the parse tree, while the headword and the constituents right after the headword remain unchanged.",
        "Entity": "Normal"
    },
    {
        "Text": "In this way the parse tree  one of plants  could capture the  DISC  relationship more concisely and precisely.",
        "Entity": "Normal"
    },
    {
        "Text": "For both SPT and CS-SPT, this example would be condensed to  one of town  and therefore easily misclassified as the  DISC  relationship between the two entities.",
        "Entity": "Normal"
    },
    {
        "Text": "In the contrast, our DSPT can avoid this problem by keeping the constituent   s  and the headword  plants .",
        "Entity": "Normal"
    },
    {
        "Text": "(2) Modification to NPs: except base-NPs, other modification to NPs can be classified into this type.",
        "Entity": "Normal"
    },
    {
        "Text": "Usually these NPs are recursive, meaning that they contain another NP as their child.",
        "Entity": "Normal"
    },
    {
        "Text": "The CFG rules corresponding to these modifications may have the following forms: NP   NP SBAR [relative clause] NP   NP VP [reduced relative] NP   NP PP [PP attachment] Here, the NPs in bold mean that the path connecting the two entities passes through them.",
        "Entity": "Normal"
    },
    {
        "Text": "For every right hand side, the NP in bold is modified by the constituent following them.",
        "Entity": "Normal"
    },
    {
        "Text": "That is, the latter is dependent on the former, and may be reduced to a single NP.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Since the reduced relative  nominated for    modifies and is therefore dependent on the  people , they can be removed from the parse tree, that is, the right side ( NP VP ) can be reduced to the left hand side, which is exactly a single NP.",
        "Entity": "Normal"
    },
    {
        "Text": "NP PP NP NP NP NP PP NP NP NP PP NP NP NP NP PP VP NP NP E1FAC E-GPE E1FACE2-FAC E1 PER QP E2-PER E1-PER E2-PER NN DT NN CD JJ NN NN NN IN RB CD NNS NN NNS one the town two meat-packing one plants one of about 500 people one people (a) Removal of constituents before the headword in base-NP (c) Reduction of modification to NP NP E1-PER NP P P N P NP E 2 G P E E-FAC NP E1FAC NP PP NP E2 GPE NP E-FAC NP S B A R S VP PP NP SBAR S NN IN DT NN POS CD JJ NN NN IN NN POS NN NP NP NP NP NP one of the town 's two meat-packing plants one of town 's plants E1FAC E2-PER NP E1FAC E2-PER VP (b) Keeping of constituents after the headword in base-NP JJ NN PRP VBZ IN DT NNS NN PRP VBZ rental NP property he owns in the state property he owns PP NP NP PP (d) Removal of arguments to verb NP NP NP NP NP NP E1-PER E-GPE E-GPE E2GPE E1-PER E2GPE NNS IN NNP , NNP NNP , CC NNP NNS IN NNP governors from connecticut , south dakota , and montana governors from montana (e)                                                     \n\t\t\tRemoval and reduction of constituents using dependencies (3) Arguments/adjuncts to verbs: this type includes the CFG rules in which the left side includes S, SBAR or VP.",
        "Entity": "Normal"
    },
    {
        "Text": "An argument represents the subject or object of a verb, while an adjunct indicates the location, date/time or way of the action corresponding to the verb.",
        "Entity": "Normal"
    },
    {
        "Text": "They depend on the verb and can be removed if they are not included in the path connecting the two entities.",
        "Entity": "Normal"
    },
    {
        "Text": "However, when the parent tag is S or SBAR, and its child VP is not included in the path, this VP should be recovered to indicate the predicate verb.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "While PP can be removed from the rule ( VP  VBZ PP ), the VP should be kept in the rule ( S  NP VP ).",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, the tree span looks more concise and precise for relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "(4) Coordination conjunctions: In coordination constructions, several peer conjuncts may be reduced into a single constituent.",
        "Entity": "Normal"
    },
    {
        "Text": "Although the first conjunct is always considered as the headword (Collins, 2003), actually all the conjuncts play an equal role in relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) further indicates that among these entity features, entity type, subtype, and mention type, as well as the base form of predicate verb, contribute most while the contribution of other features, such as entity class, headword and GPE role, can be ignored.",
        "Entity": "Normal"
    },
    {
        "Text": "In the example sentence  they  re here , which is excerpted from the ACE RDC 2004 corpus, there exists a relationship  Physical.Located  between the entities  they  [PER] and  here  [GPE.Population-Center].",
        "Entity": "Normal"
    },
    {
        "Text": "The features are encoded as  TP ,  ST ,  MT  and  PVB , which denote type, subtype, mention-type of the two entities, and the base form of predicate verb if existing (nearest to the 2nd entity along the path connecting the two entities) respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the tag  TP1  represents the type of the 1st entity, and the tag  ST2  represents the sub- type of the 2nd entity.",
        "Entity": "Normal"
    },
    {
        "Text": "The three entity-related semantic tree setups are depicted as follows: ENT sentence ( governors from connecticut, south TP1 ST1 MT1 TP2 ST2 MT2 PVB dakota, and montana ) can be reduced to a single NP ( governors from montana ) by keeping the conjunct in the path while removing the other conjuncts.",
        "Entity": "Normal"
    },
    {
        "Text": "PER null PRO GPE Pop.",
        "Entity": "Normal"
    },
    {
        "Text": "PRO be (a) Bag Of Features(BOF) ENT (5) Modification to other constituents: except for the above four types, other CFG rules fall into this type, such as modification to PP, ADVP and PRN etc.",
        "Entity": "Normal"
    },
    {
        "Text": "These cases are similar to arguments/adjuncts to verbs, but less frequent than them, so we will not detail this scenario.In fact, SPT (Zhang et al., 2006) can be ar TP ST MT TP1 TP2 ST1 ST2 MT1 MT2 PER GPE null Pop.",
        "Entity": "Normal"
    },
    {
        "Text": "PRO PRO (b) Feature Paired Tree(FPT) ENT E1 E2 PVB be PVBrived at by carrying out part of the above re TP1 ST1 MT1 TP2 ST2 MT2 be moval operations using a single rule (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "all the constituents outside the linking path should be removed) and CS-CSPT (Zhou et al., 2007) further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT.",
        "Entity": "Normal"
    },
    {
        "Text": "Entity semantic features, such as entity headword, entity type and subtype etc., impose a strong constraint on relation types in terms of relation definition by the ACE RDC task.",
        "Entity": "Normal"
    },
    {
        "Text": "Experiments by Zhang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) show that linear kernel using only entity features contributes much when combined with the convolution parse tree kernel.",
        "Entity": "Normal"
    },
    {
        "Text": "PER null PRO GPE Pop.",
        "Entity": "Normal"
    },
    {
        "Text": "Different setups for entity-related se mantic tree (EST) (a) Bag of Features (BOF, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Fig.",
        "Entity": "Normal"
    },
    {
        "Text": "2(a)): all feature nodes uniformly hang under the root node, so the tree kernel simply counts the number of common features between two relation instances.",
        "Entity": "Normal"
    },
    {
        "Text": "This tree setup is similar to linear entity kernel explored by Zhang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006).",
        "Entity": "Normal"
    },
    {
        "Text": "(b) Feature-Paired Tree (FPT, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Fig.",
        "Entity": "Normal"
    },
    {
        "Text": "2(b)): the features of two entities are grouped into different types according to their feature names, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "TP1  and  TP2  are grouped to  TP .",
        "Entity": "Normal"
    },
    {
        "Text": "This tree setup is aimed to capture the additional similarity of the single feature combined from different entities, i.e., the first and the second entities.",
        "Entity": "Normal"
    },
    {
        "Text": "(c) Entity-Paired Tree (EPT, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Fig.",
        "Entity": "Normal"
    },
    {
        "Text": "2(c)): all the features relating to an entity are grouped to nodes  E1  or  E2 , thus this tree kernel can further explore the equivalence of combined entity features only relating to one of the entities between two relation instances.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, the BOF only captures the individual entity features, while the FPT/EPT can additionally capture the bi-gram/tri-gram features respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Rather than constructing a composite kernel, we incorporate the EST into the DSPT to produce a Unified Parse and Semantic Tree (UPST) to investigate the contribution of the EST to relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "However, detailed evaluation (Qian et al., 2007) indicates that the UPST achieves the best performance when the feature nodes are attached under the top node.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, we also attach three kinds of entity-related semantic trees (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "BOF, FPT and EPT) under the top node of the DSPT right after its original children.",
        "Entity": "Normal"
    },
    {
        "Text": "Thereafter, we employ the standard CTK (Collins and Duffy, 2001) to compute the similarity between two (Moschitti, 2004) 2 is selected as our classifier.",
        "Entity": "Normal"
    },
    {
        "Text": "For efficiency, we apply the one vs. others strategy, which builds K classifiers so as to separate one class from all others.",
        "Entity": "Normal"
    },
    {
        "Text": "For comparison purposes, the training parameters C (SVM) and   (tree kernel) are also set to 2.4 and 0.4 respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2 Experimental Results.",
        "Entity": "Normal"
    },
    {
        "Text": "The MCT with only entity-type information is first used as the baseline, and various constituent dependencies are then applied sequentially to dynamically reshaping the tree in two different modes: --[M1] Respective: every constituent dependency is individually applied on MCT.",
        "Entity": "Normal"
    },
    {
        "Text": "--[M2] Accumulative: every constituent dependency is incrementally applied on the previously derived tree span, which begins with the MCT and eventually gives rise to a Dynamic Syntactic Parse Tree (DSPT).",
        "Entity": "Normal"
    },
    {
        "Text": "Dependency types P(%) R(%) F MCT (baseline) 75.1 53.8 62.7 UPSTs, since this CTK and its variations are Modification within 76.5 59.8 67.1successfully applied in syntactic parsing, seman tic role labeling (Moschitti, 2004) and relation base-NPs (59.8) (59.8) (67.1) extraction (Zhang et al., 2006; Zhou et al., 2007) Modification to NPs 77.0 63.2 69.4 as well.",
        "Entity": "Normal"
    },
    {
        "Text": "(76.2) (56.9) (65.1) Arguments/adjuncts to verb 77.1 63.9 69.9\n\t\n\t\n\t\t\t(76.1) (57.5) (65.5) Coordination conjunctions 77.3 65.2 70.8 This section will evaluate the effectiveness of the (77.3) (55.1) (63.8)DSPT and the contribution of entity-related se Other modifications 77.4 65.4 70.9 mantic information through experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Experimental Setting.",
        "Entity": "Normal"
    },
    {
        "Text": "For evaluation, we use the ACE RDC 2004 corpus as the benchmark data.",
        "Entity": "Normal"
    },
    {
        "Text": "This data set contains 451 documents and 5702 relation instances.",
        "Entity": "Normal"
    },
    {
        "Text": "It defines 7 entity types, 7 major relation types and 23 subtypes.",
        "Entity": "Normal"
    },
    {
        "Text": "For comparison with previous work, evaluation is done on 347 (nwire/bnews) documents and 4307 relation instances using 5-fold cross-validation.",
        "Entity": "Normal"
    },
    {
        "Text": "Here, the corpus is parsed using Charniak s parser (Charniak, 2001) and relation instances are generated by iterating over all pairs of entity mentions occurring in the same sentence with given  true  mentions and coreferential information.",
        "Entity": "Normal"
    },
    {
        "Text": "I                                                                                                            .",
        "Entity": "Normal"
    },
    {
        "Text": "This indicates that reshaping the tree by exploiting constituent dependencies may significantly improve extraction accuracy largely due to the increase in recall.",
        "Entity": "Normal"
    },
    {
        "Text": "It further suggests that constituent dependencies knowledge is very effec 2 http://ainlp.info.uniroma2.it/moschitti/ tive and can be fully utilized in tree kernel-based relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "This indicates the local characteristic of semantic relations, which can be effectively captured by NPs near the two involved entities in the DSPT.",
        "Entity": "Normal"
    },
    {
        "Text": "(2) All the other three dependencies show minor contribution to performance enhancement, they improve the F-measure only by 2.8/0.9/-0.1 units in mode M1 and 0.5/0.9/0.1 units in mode M2.",
        "Entity": "Normal"
    },
    {
        "Text": "This may be due to the reason that these dependencies only remove the nodes far from the two entities.",
        "Entity": "Normal"
    },
    {
        "Text": "It shows that: (1) All the three unified parse and semantic tree kernels significantly outperform the DSPT kernel, obtaining an average increase of ~4 units in F-measure.",
        "Entity": "Normal"
    },
    {
        "Text": "This means that they can effectively capture both the structured syntactic information and the entity-related semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "(2) The Unified Parse and Semantic Tree with Feature-Paired Tree achieves the best performance of 80.1/70.7/75.1 in P/R/F respectively, with an increase of F-measure by 0.4/0.3 units over BOF and EPT respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "This suggests that additional bi-gram entity features capturedby FPT are more useful than tri-gram entity fea tures captured by EPT.",
        "Entity": "Normal"
    },
    {
        "Text": "Performance of Unified Parse and Semantic Trees (UPSTs) on the 7 relation types of the ACE RDC 2004 corpus tree spans.",
        "Entity": "Normal"
    },
    {
        "Text": "It also shows that the Unified Parse and Semantic Tree with Feature-Paired Tree perform significantly better than the other two tree setups (i.e., CS-SPT and DSPT) by 6.7/4.2 units in F-measure respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "This implies that the entity-related semantic information is very useful and contributes much when they are incorporated into the parse tree for relation extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "It shows that our UPST outperforms all previous tree setups using one single kernel, and even better than two previous composite kernels (Zhang et al., 2006; Zhao and Grishman, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, when the UPST (FPT) kernel is com bined with a linear state-of-the-state feature- based kernel (Zhou et al., 2005) into a composite one via polynomial interpolation in a setting similar to Zhou et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "polynomial degree d=2 and coefficient  =0.3), we get the so far best performance of 77.1 in F-measure for 7 relation types on the ACE RDC 2004 data set.",
        "Entity": "Normal"
    },
    {
        "Text": "Systems P(%) R(%) F Ours:                                                                                                                                                                                                                                                                                                                                                                          \n\t\t\t                                                                                                                                      \n\t\t\tIt shows that in a similar setting, our DSPT outperforms SPT by 3.8 units in F-measure, while CS-SPT outperforms SPT by 1.3 units in F-measure.",
        "Entity": "Normal"
    },
    {
        "Text": "This suggests that the DSPT performs best among these 3 We arrive at these values by subtracting P/R/F.",
        "Entity": "Normal"
    },
    {
        "Text": "(79.6/5.6/71.9) of                                                                                                                                                           4 There might be some typing errors for the performance.",
        "Entity": "Normal"
    },
    {
        "Text": "reported in Zhao and Grishman (2005) since P, R and F do not match.",
        "Entity": "Normal"
    },
    {
        "Text": "This paper further explores the potential of structured syntactic information for tree kernel-based relation extraction, and proposes a new approach to dynamically determine the tree span (DSPT) for relation instances by exploiting constituent dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "We also investigate different ways of how entity-related semantic features and their combined features can be effectively captured in a Unified Parse and Semantic Tree (UPST).",
        "Entity": "Normal"
    },
    {
        "Text": "Evaluation on the ACE RDC 2004 corpus shows that our DSPT is appropriate for structured representation of relation instances.",
        "Entity": "Normal"
    },
    {
        "Text": "We also find that, in addition to individual entity features, combined entity features (especially bi-gram) contribute much when they are combined with a DPST into a UPST.",
        "Entity": "Normal"
    },
    {
        "Text": "And the composite kernel, combining the UPST kernel and a linear state-of- the-art kernel, yields the so far best performance.",
        "Entity": "Normal"
    },
    {
        "Text": "For the future work, we will focus on improving performance of complex structured parse trees, where the path connecting the two entities involved in a relationship is too long for current kernel methods to take effect.",
        "Entity": "Normal"
    },
    {
        "Text": "Our preliminary experiment of applying certain discourse theory exhibits certain positive results.",
        "Entity": "Normal"
    },
    {
        "Text": "This research is supported by Project 60673041 under the National Natural Science Foundation of China, Project 2006AA01Z147 under the  863  National High-Tech Research and Development of China, and the National Research Foundation for the Doctoral Program of Higher Education of China under Grant No.",
        "Entity": "Normal"
    },
    {
        "Text": "20060285008.",
        "Entity": "Normal"
    },
    {
        "Text": "We would also like to thank the excellent and insightful comments from the three anonymous reviewers.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tIn some societies, internet users have to create information morphs (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Peace West King  to refer to  Bo Xilai ) to avoid active censorship or achieve other communication goals.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we aim to solve a new problem of resolving entity morphs to their real targets.",
        "Entity": "Normal"
    },
    {
        "Text": "We exploit temporal constraints to collect cross- source comparable corpora relevant to any given morph query and identify target candidates.",
        "Entity": "Normal"
    },
    {
        "Text": "Then we propose various novel similarity measurements including surface features, meta-path based semantic features and social correlation features and combine them in a learning-to-rank framework.",
        "Entity": "Normal"
    },
    {
        "Text": "Experimental results on Chinese Sina Weibo data demonstrate that our approach is promising and significantly outperforms baseline methods1.",
        "Entity": "Normal"
    },
    {
        "Text": "Language constantly evolves to maximize communicative success and expressive power in daily social interactions.",
        "Entity": "Normal"
    },
    {
        "Text": "The proliferation of online social media significantly expedites this evolution, as new phrases triggered by social events may be disseminated rapidly in social media.",
        "Entity": "Normal"
    },
    {
        "Text": "To automatically analyze such fast evolving language in social media, new computational models are demanded.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we focus on one particular language evolution that creates new ways to communicate sensitive subjects because of the existence of internet information censorship.",
        "Entity": "Normal"
    },
    {
        "Text": "We call this 1 Some of the resources and open source programs developed in this work are made freely available for research purpose at http://nlp.cs.qc.cuny.edu/Morphing.tar.gz phenomenon information morph.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, when Chinese online users talk about the former politician  Bo Xilai , they use a morph  Peace West King  instead, a historical figure four hundreds years ago who governed the same region as Bo.",
        "Entity": "Normal"
    },
    {
        "Text": "Morph can be considered as a special case of alias used for hiding true entities in malicious environment (Hsiung et al., 2005; Pantel, 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "However, social network plays an important role in generating morphs.",
        "Entity": "Normal"
    },
    {
        "Text": "Usually morphs are generated by harvesting the collective wisdom of the crowd to achieve certain communication goals.",
        "Entity": "Normal"
    },
    {
        "Text": "Aside from the purpose of avoiding censorship, other motivations for using morph include expressing sarcasm/irony, positive/negative sentiment or making descriptions more vivid toward some entities or events.",
        "Entity": "Normal"
    },
    {
        "Text": "We can see that a morph can be either a regular term with new meaning or a newly created term.",
        "Entity": "Normal"
    },
    {
        "Text": "Morph Target Motivation Peace West King Bo Xilai Sensitive Blind Man Chen Guangcheng Sensitive Miracle Brother Wang Yongping Irony Kim Fat Kim Joingil Negative Kimchi Country South Korea Vivid Table 1: Morph Examples and Motivations.",
        "Entity": "Normal"
    },
    {
        "Text": "We believe that successful resolution of morphs is a crucial step for automated understanding of the fast evolving social media language, which is important for social media marketing (Bar- wise and Meehan, 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "Another application is to help common users without enough background/cultural knowledge to understand internet language for their daily use.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, our approaches can also be applied for satire or other implicit meaning recognition, as well as information extraction (Bollegala et al., 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "1083 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1083 1093, Sofia, Bulgaria, August 49 2013.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2013 Association for Computational Linguistics However, morph resolution in social media is challenging due to the following reasons.",
        "Entity": "Normal"
    },
    {
        "Text": "First, the sensitive real targets that exist in the same data source under active censorship are often automatically filtered.",
        "Entity": "Normal"
    },
    {
        "Text": "For example,                                                        .",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, the co-occurrence of a morph and its target is quite low in the vast amount of information in social media.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, most morphs were not created based on pronunciations, spellings or other encryptions of their original targets.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead, they were created according to semantically related entities in historical and cultural narratives (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Peace West King  as morph of  Bo Xilai ) and thus very difficult to capture based on typical lexical features.",
        "Entity": "Normal"
    },
    {
        "Text": "Third, tweets from Twitter/Chinese Weibo are short (only up to the similarity measures to generate global semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "We model social user behaviors and use social correlation to assist in measuring semantic similarities because the users who posted a morph and its corresponding target tend to share similar interests and opinions.",
        "Entity": "Normal"
    },
    {
        "Text": "Our experiments demonstrate that the proposed approach significantly outperforms traditional alias detection methods (Hsiung et al., 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "Morph Query Comparable Data Acquisition 140 characters) and noisy, resulting in difficult extraction of rich and accurate evidences due to the Censored Data Uncensored Data lack of enough contexts.",
        "Entity": "Normal"
    },
    {
        "Text": "Semantic Annotatio n and Target Candidate Identification Target Candidate Ranking Surface Features Semantic Features Learning to Rank Social Features                                          To the best of our knowledge, this is the first work to use NLP and social network analysis techniques to automatically resolve morphed information.",
        "Entity": "Normal"
    },
    {
        "Text": "To address the above challenges, our paper offers the following novel contributions.",
        "Entity": "Normal"
    },
    {
        "Text": "We detect target candidates by exploiting the dynamics of the social media to extract temporal distribution of entities, based on the assumption that the popularity of an individ ual is correlated between censored and uncensored text within a certain time window.",
        "Entity": "Normal"
    },
    {
        "Text": "Our approach builds and analyzes heterogeneous information networks from multiple sources, such as Twitter, Sina Weibo and web documents in formal genre (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "news) be cause a morph and its target tend to appear in similar contexts.",
        "Entity": "Normal"
    },
    {
        "Text": "We propose two new similarity measures, as Target Figure 1: Overview of Morph Resolution Given a morph query m, the goal of morph resolution is to find its real target.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 1 depicts the general procedure of our approach.",
        "Entity": "Normal"
    },
    {
        "Text": "It consists of two main sub-tasks:   Target Candidate Identification: For each m, discover a list of target candidates E = {e1, e2, ..., eN }.",
        "Entity": "Normal"
    },
    {
        "Text": "First, relevant comparable data sets that include m are retrieved.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we collect comparable censored data from Weibo and uncensored data from Twitter and Web documents such as news articles.",
        "Entity": "Normal"
    },
    {
        "Text": "We then apply various annotations such as word segmentation, part-of-speech tagging, noun phrase chunking, name tagging and event extraction to these data sets.",
        "Entity": "Normal"
    },
    {
        "Text": "Target Candidate Ranking: Rank the target candidates in E. We explore various features including surface, semantic and social fea rank framework.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the top ranked candidate is produced as the resolved target.",
        "Entity": "Normal"
    },
    {
        "Text": "The general goal of the first step is to identify a list of target candidates for each morph query from the comparable corpora including Sina Weibo, Chinese News websites and English Twitter.",
        "Entity": "Normal"
    },
    {
        "Text": "However, obviously we cannot consider all of the named entities in these sources as target candidates due to the sheer volume of information.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, morphs are not limited to named entity forms.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to narrow down the scope of target candidates, we propose a Temporal Distribution Assumption as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "The intuition is that a morph m and its real target e should have similar temporal distributions in terms of their occurrences.",
        "Entity": "Normal"
    },
    {
        "Text": "Suppose the data sets are separated into Z temporal slots (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "by day), the assumption can 4.2 Semantic Features.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.1 Motivations Fortunately, although a morph and its target may have very different orthographic forms, they tend to be embedded in similar semantic contexts which involve similar topics and events.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 2 presents some example messages under censorship (Weibo) and not under censorship (Twitter and Chinese Daily).",
        "Entity": "Normal"
    },
    {
        "Text": "We can see that they include similar topics, events (e.g.,  fell from power ,  gang crackdown ,  sing red songs ), and semantic relations (e.g., family relations with  Bo Guagua ).",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore if we can automatically extract and exploit these indicative semantic contexts, we can narrow down the real targets effectively.",
        "Entity": "Normal"
    },
    {
        "Text": "Peace West King from Chongqing   Bo Xilai: ten thousand letters of accusation have been received during be stated as: fell from power, still need to sing red songs?",
        "Entity": "Normal"
    },
    {
        "Text": "Chongqing gang crackdown.",
        "Entity": "Normal"
    },
    {
        "Text": "There is no difference between that   The webpage of  Tianze Economic Let Tm = {tm1, tm2, ..., tmZm } be the set of temporal slots each morph m occurs, and Te ={te1, te2, ..., teZe } be the set of slots a target can didate e occurs.",
        "Entity": "Normal"
    },
    {
        "Text": "Then e is considered as a target candidate of m if and only if, for each tmi   Tm (i = 1, 2, ..., Zm), there exist a j   {1, 2, ..., Ze} guy s plagiarism and Buhou s gang crackdown.",
        "Entity": "Normal"
    },
    {
        "Text": "Remember that Buhou said that his family was not rich at the press conference a few days before he fell from power.",
        "Entity": "Normal"
    },
    {
        "Text": "His son Bo Guagua is supported by his scholarship.",
        "Entity": "Normal"
    },
    {
        "Text": "Study Institute  owned by the liberal party has been closed.",
        "Entity": "Normal"
    },
    {
        "Text": "This is the first affected website of the liberal party after Bo Xilai fell from power.",
        "Entity": "Normal"
    },
    {
        "Text": "Bo Xilai gave an explanation about the source of his son, Bo Guagua s tuition.",
        "Entity": "Normal"
    },
    {
        "Text": "Bo Xilai led Chongqing city leaders and 40 district and county party and government leaders to sing red songs.",
        "Entity": "Normal"
    },
    {
        "Text": "such that tmi   tej    , where   is a threshold value (in this paper we set the threshold to 7 days, which is optimized from a development set).",
        "Entity": "Normal"
    },
    {
        "Text": "For comparison we also attempted topic modeling approach to detect target candidates, as shown in section 5.3.",
        "Entity": "Normal"
    },
    {
        "Text": "Next, we propose a learning-to-rank framework to rank target candidates based on various levels of novel features based on surface, semantic and social analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Surface Features.",
        "Entity": "Normal"
    },
    {
        "Text": "We first extract surface features between the morph and the candidate based on measuring orthographic similarity measures which were commonly used in entity coreference resolution (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "(Ng, 2010; Hsiung et al., 2005)).",
        "Entity": "Normal"
    },
    {
        "Text": "The measures we use include  string edit distance ,  normalized string edit distance  (Wagner and Fischer, 1974) and  longest common subsequence  (Hirschberg, 1977).",
        "Entity": "Normal"
    },
    {
        "Text": "Weibo (censored) Twitter and Chinese News (uncensored) Figure 2: Cross-source Comparable Data Example (each morph and target pair is shown in the same color) 4.2.2 Information Network Construction We define an information network as a directed graph G = (V, E ) with an object type mapping function   : V   A and a link type mapping function   : E   R, where each object v   V belongs to one particular object type   (v)   A, each link e   E belongs to a particular relation  (e)   R. If two links belong to the same relation type, then they share the same starting object type as well as the same ending object type.",
        "Entity": "Normal"
    },
    {
        "Text": "An information network is homogeneous if and only if there is only one type for both objects and links, and an information network is heterogeneous when the objects are from multiple distinct types or there exist more than one type of links.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to construct the information networks for morphs, we apply the Standford Chinese word segmenter with Chinese Penn Treebank segmentation standard (Chang et al., 2008) and Stanford part-of-speech tagger (Toutanova et al., 2003) to process each sentence in the comparable data sets.",
        "Entity": "Normal"
    },
    {
        "Text": "Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al., 2003) to extract named entities, noun phrases and events.",
        "Entity": "Normal"
    },
    {
        "Text": "We have also attempted using the results from Dependency Parsing, Relation Extraction and Event Extraction tools (Ji and Grishman, 2008) Buhou Morph Peace West King Morph Bo Guagua Entity Chongqing Entity Gang Crackdown Event Fell From Power Event Sing Red Songs Event Bo Xilai Entity to enrich the link types.",
        "Entity": "Normal"
    },
    {
        "Text": "Unfortunately the state- of-the-art techniques for these tasks still perform poorly on social media in terms of both accuracy and coverage of important information, these sophisticated semantic links all produced negative impact on the target ranking performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore we limited the types of vertices into: Morph (M), Entity(E), which includes target candidates, Event (EV), and NonEntity Noun Phrases (NP); and used co-occurrence as the edge type.",
        "Entity": "Normal"
    },
    {
        "Text": "We extract entities, events, and nonentity noun phrases that occur in more than one tweet as neighbors.",
        "Entity": "Normal"
    },
    {
        "Text": "And for two vertices xi and xj , the weight wij of their edge is the frequency they co-occur together within the tweets.",
        "Entity": "Normal"
    },
    {
        "Text": "A network schema of such networks is shown in Figure 3.",
        "Entity": "Normal"
    },
    {
        "Text": "Figure 4 M E EV NP Figure 3: Network Schema of Morph-Related Heterogeneous Information Network presents an example of a heterogeneous information network from the motivation examples following the above network schema, which connects the morphs  Peace West King ,  Buhou  and their corresponding target  Bo Xilai .",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.3 Meta-Path-Based Semantic Similarity Measurements Given the constructed network, a straightforward solution for finding the target for a morph is to use link-based similarity search.",
        "Entity": "Normal"
    },
    {
        "Text": "However, now objects are linked to different types of neighbors, if all neighbors are treated as the same, it may cause information loss problems.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the en tity     (Chongqing)  is a very important aspect Figure 4: Example of Morph-Related Heterogeneous Information Network since he governed it, and if a morph m which is also highly correlated with     (Chongqing) , it is very likely that  Bo Xilai  is the real target of m. Therefore, the semantic features generated from neighbors such as the entity     (Chongqing)  should be treated differently from other types of neighbors such as    (talented people)  .",
        "Entity": "Normal"
    },
    {
        "Text": "In this work, we propose to measure the similarity of two nodes over heterogeneous networks as shown in Figure 3, by distinguishing neighbors into three types according to the network schema (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "entities, events, nonentity noun phrases).",
        "Entity": "Normal"
    },
    {
        "Text": "We then adopt meta-path-based similarity measures (Sun et al., 2011a; Sun et al., 2011b), which are defined over heterogeneous networks to extract semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "A meta-path is a path defined over a network, and composed of a sequence of relations between different object types.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, as shown in Figure 3, a morph and its target candidate can be connected by three meta-paths, including  ME - E ,  MEV - E , and  M - NP - E .",
        "Entity": "Normal"
    },
    {
        "Text": "Intuitively, each meta-path provides a unique angle to measure how similar two objects are.",
        "Entity": "Normal"
    },
    {
        "Text": "For the determined meta-paths, we extract semantic features using the similarity measures proposed in (Sun et al., 2011a; Hsiung et al., 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "We denote the neighbor sets of certain type for a morph m and a target candidate e as  (m) and  (e), and a meta-path as P. We now list several meta-path-based similarity measures below.",
        "Entity": "Normal"
    },
    {
        "Text": "Common neighbors (CN).",
        "Entity": "Normal"
    },
    {
        "Text": "It measures the number of common neighbors that m and e share as | (m)    (e)|.",
        "Entity": "Normal"
    },
    {
        "Text": "Path count (PC).",
        "Entity": "Normal"
    },
    {
        "Text": "It measures the number of path instances between m and e following meta-path P.Pairwise random walk (PRW).",
        "Entity": "Normal"
    },
    {
        "Text": "For a meta meta-paths with the same length P = (P1P2),pairwise random walk measures the probabil ity of the pairwise random walk starting from both m and e and reaching the same middle object.",
        "Entity": "Normal"
    },
    {
        "Text": "More formally, it is computed as into similarity measures to generate global semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "Let T = t1   t2   ...   tN be a set of temporal slots (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "by day), E be the set of target candidates for each morph m. Then for each ti   T , and each  1  1 (p1 p2 ) (P1 P2 ) prob(p1)prob(p2 ), where p2 is the inverse of p2.",
        "Entity": "Normal"
    },
    {
        "Text": "KullbackLeibler distance (KLD).",
        "Entity": "Normal"
    },
    {
        "Text": "For m and e, the pairwise random walk probability of their neighbors can be represented as two probability vectors, then KullbackLeibler distance (Hsiung et al., 2005) can be used to compute sim(m, e).",
        "Entity": "Normal"
    },
    {
        "Text": "Beyond the above similarity measures, we also propose to use cosine-similarity-style normalization method to modify common neighbor and pair e   E, the local semantic features simti (m, e) is extracted based only on the information posted within ti using one of the similarity measures introduced in Section 4.2.3.",
        "Entity": "Normal"
    },
    {
        "Text": "Then we propose two approaches to generate global semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "The first approach is adding the similarity score between m and e in each temporal slot to attain the first set of global features: simglobal sum(m, e) = ) simt wise random walk measures so that we can ensure ti  T i (m, e).",
        "Entity": "Normal"
    },
    {
        "Text": "the morph node and the target candidate node are strongly connected and also have similar popularity.",
        "Entity": "Normal"
    },
    {
        "Text": "The modified algorithms penalize features involved with the highly popular objects, since they are more likely to have accidental interactions with each other.",
        "Entity": "Normal"
    },
    {
        "Text": "The second method first normalizes the similarity score in each temporal slot ti, them sum the normalized scores to generate the second set of global features, which can be calculated as simglobal norm(m, e) = ) normt (m, e).Normalized common neighbors (NCN).",
        "Entity": "Normal"
    },
    {
        "Text": "Nor malized common neighbors can be measured as ti  T sim(m, e) =  | (m)  (e)| .",
        "Entity": "Normal"
    },
    {
        "Text": "It refines the simple.",
        "Entity": "Normal"
    },
    {
        "Text": "where normt (m, e) = si mti (m,e) .",
        "Entity": "Normal"
    },
    {
        "Text": "| (m)| | (e)| i e E simti (m,e) counting of common neighbors by avoiding bias to highly visible or concentrated objects.",
        "Entity": "Normal"
    },
    {
        "Text": "Pairwise random walk/cosine (PRW/cosine).",
        "Entity": "Normal"
    },
    {
        "Text": "Pairwise random walk measures linkage weights disproportionately with their visibility to their neighbors, which may be too strong.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead, we propose to use a tamer normalization method as 4.2.5 Integrate Cross Source/Cross Genre Information Due to internet information censorship or surveillance, users may need to use morphs to post sensitive information.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the Chinese Weibo message         ,              (Already (p1 p2 ) (P1 P2 ) f (p1)f (p2 ), where.",
        "Entity": "Normal"
    },
    {
        "Text": "count(m, x) put in prison, still need to serve Buhou?",
        "Entity": "Normal"
    },
    {
        "Text": "include a morph    (Buhou).",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, users are less restricted in some other uncensored social media f (p1) = f (p2) = , x   count(m, x) count(e, x) , x   count(e, x) such as Twitter.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the tweet from Twitter  ...                          ...\n\t\t\t(...call Bo Xilai peace west king  or  buhou ...)  contains both the morph and the real target    and   is the set of middle objects connecting the decomposed meta-paths p1 and p 1, count(y, x) is the total number of paths between y and the middle object x, y could be m or e. The above similarity measures can also be applied to homogeneous networks that do not differentiate the neighbor types.",
        "Entity": "Normal"
    },
    {
        "Text": "4.2.4 Global Semantic Feafure Generation A morph tends to have higher temporal correlation with its real target, and share more similar topics compared to other irrelevant targets.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we propose to incorporate temporal information   (Bo Xilai).",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we propose to integrate information from another source (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Twitter) to help resolution of sensitive morphs in Weibo.",
        "Entity": "Normal"
    },
    {
        "Text": "Another difficulty from morph resolution in micro-blogging is that tweets are only allowed to contain maximum 140 characters with a lot of noise and diverse topics.",
        "Entity": "Normal"
    },
    {
        "Text": "The shortness and diversity of tweets may limit the power of content analysis for semantic feature extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "However, formal genres such as web documents are cleaner and contain richer contexts, thus can provide more topically related information.",
        "Entity": "Normal"
    },
    {
        "Text": "In this work, we also exploit the background web documents from the embedded URLs in tweets to enrich information network construction.",
        "Entity": "Normal"
    },
    {
        "Text": "After applying the same annotation techniques as tweets for uncensored data sets, sentence-level co-occurrence relations are extracted and integrated into the network as shown in Figure 3.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Social Features.",
        "Entity": "Normal"
    },
    {
        "Text": "It has been shown that there exist correlation between neighbors in social networks (Anagnostopoulos et al., 2008; Wen and Lin, 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "Because of such social correlation, close social neighbors in social media such as Twitter and Weibo may post similar information, or share similar opinion.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we can utilize social correlation to assist in resolving morphs.",
        "Entity": "Normal"
    },
    {
        "Text": "As social correlation can be defined as a function of social distance between a pair of users, we use social distance as a proxy to social correlation in our approach.",
        "Entity": "Normal"
    },
    {
        "Text": "The social distance between user i and j is defined by considering the degree of separation in their interaction (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "retweeting and mentioning) and the amount of the interaction.",
        "Entity": "Normal"
    },
    {
        "Text": "Similar definition has been shown effective in characterizing social distance in social networks extracted from communication data (Lin et al., 2012; Wen and Lin, 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "Specifically, it is dist(i, j) = K  1 1 , where 4.4 Learning-to-Rank.",
        "Entity": "Normal"
    },
    {
        "Text": "Similar to (Hsiung et al., 2005; Sun et al., 2011a), we then model the probability of linkage prediction between a morph m and its target candidate e as a function incorporating the surface, semantic and social features.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a training pair (m, e), we choose the standard logistic regression model to learn weights for the features defined above.",
        "Entity": "Normal"
    },
    {
        "Text": "The learnt model is used to predict the probability of linking an unseen morph and its target candidate.",
        "Entity": "Normal"
    },
    {
        "Text": "Based on the descending ranking order of the probability, we select top k candidates as the final answers based on the answer size k.\n\t\n\t\n\t\t\tNext, we present the experiment under various settings shown in Table 3, and the impacts of cross source and cross genre information.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Data and Evaluation Metric.",
        "Entity": "Normal"
    },
    {
        "Text": "We collected 1, 553, 347 tweets from Chinese Sina Weibo from May 1 to June 30 to construct the censored data set, and retrieved 66, 559 web documents from the embedded URLs in tweets as the initial uncensored data set.",
        "Entity": "Normal"
    },
    {
        "Text": "Retweets and redun k=1 strength(vk ,vk+1 ) v1, ..., vk are the nodes on the shortest path from user i to user j, and strength(vk , vk+1) measures the strength of interactions between vk and vk+1 dant web documents are filtered to ensure more reliable frequency counting of co-occurrence relations.",
        "Entity": "Normal"
    },
    {
        "Text": "We asked two native Chinese annotators to as: strength(i, j) = log(Xij ) j ij , where Xij is analyze the data, and construct a test set consisted of 107 morph entities (81 persons and 26 locathe total interactions between user i and j, includ ing both retweeting and mentioning (If Xij < 10, we set strength(i, j) = 0).",
        "Entity": "Normal"
    },
    {
        "Text": "We integrate social correlation and temporal information to define our social features.",
        "Entity": "Normal"
    },
    {
        "Text": "The intuition is that when a morph is used by an user, the real target may also in the posts by the user or his/her close friends within a certain time period.",
        "Entity": "Normal"
    },
    {
        "Text": "Let T be the set of temporal slots a morph m occurs, Ut be the set of users whose posts include m in slot t where t   T , and Uc be the set of close friends (i.e., social distance < 0.5) for Ut.",
        "Entity": "Normal"
    },
    {
        "Text": "The social features are defined as s(m, e) = t T f (e, t, Ut, Uc) .",
        "Entity": "Normal"
    },
    {
        "Text": "|T | where f (e, t, Ut, Uc) is a indicator function which return 1 if one of the users in Ut or Uc posts tweets tions) and their real targets as our references.",
        "Entity": "Normal"
    },
    {
        "Text": "We verified the references by Web resources including the summary of popular morphs in Wikipedia 2.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we used 23 sensitive morphs and.",
        "Entity": "Normal"
    },
    {
        "Text": "the entities that appear in the tweets as queries and retrieved 25, 128 Chinese tweets from 10% Twitter feeds within the same time period, as well as 7, 473 web documents from the embedded URLs and added them into the uncensored data set.",
        "Entity": "Normal"
    },
    {
        "Text": "To evaluate the system performance, we use leave-one-out cross validation by computing accuracy as Acc@k = Ck , where Ck is the total number of correctly resolved morphs at top k ranked answers, and Q is the total number of morph queries.",
        "Entity": "Normal"
    },
    {
        "Text": "We consider a morph as correctly resolved at the top k answers if the top k answer set contains the real target of the morph.",
        "Entity": "Normal"
    },
    {
        "Text": "include the target candidate e within 7 days before t. 2 http://zh.wikipedia.org/wiki/           Fe atu re set s De scr ipti on s Su rf Sur fac e fea tur es Ho m B Se ma ntic fea tur es ext rac ted fro m ho mo ge ne ou s CN , PC , PR W, an d KL D Ho m E Ho m B + se ma ntic fea tur es ext rac ted fro m ho mo ge ne ous N C N an d PR W/ co sin e He tB Se ma ntic fea tur es ext rac ted fro m het ero ge ne ous CN , PC , PR W an d KL D He tE He tB + Se ma ntic fea tur es ext rac ted fro m het ero ge ne ous N C N an d PR W/ co sin e Gl ob   Glo bal se ma ntic fea tur es So cia l So cial net wo rk fea tur es Table 3: Description of feature sets.",
        "Entity": "Normal"
    },
    {
        "Text": "Glob only uses the same set of similarity measures when combined with other semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2 Resolution Performance.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2.1 Single Genre Information We first study the contributions of each set of surface and semantic features, as shown in the first five rows in Table 4.",
        "Entity": "Normal"
    },
    {
        "Text": "The poor performance based on surface features shows that morph resolution task is very challenging since 70% of morphs are not orthographically similar to their real targets.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, capturing a morph s semantic meaning is crucial.",
        "Entity": "Normal"
    },
    {
        "Text": "Overall, the results demonstrate the effectiveness of our proposed methods.",
        "Entity": "Normal"
    },
    {
        "Text": "Specifically, comparing  HomB  and  HetB ,  HomE  and  HetE , we can see that the semantic features based on heterogeneous networks have advantages over those based on homogeneous networks.",
        "Entity": "Normal"
    },
    {
        "Text": "This corroborates that different neighbor sets contribute differently, and such discrepancies should be captured.",
        "Entity": "Normal"
    },
    {
        "Text": "And comparisions of  HomB  and  HomE ,  HetB  and  HetE demonstrate the effectiveness of our two new proposed measures.",
        "Entity": "Normal"
    },
    {
        "Text": "To evaluate the importance of each similarity measures, we delete the semantic features obtained from each measure in  HetE  and reevaluate the system.",
        "Entity": "Normal"
    },
    {
        "Text": "We find that NCN is the most effective measure, while KLD is the least important one.",
        "Entity": "Normal"
    },
    {
        "Text": "Further adding the global semantic features significantly improves the performance.",
        "Entity": "Normal"
    },
    {
        "Text": "This indicates that capturing both temporal correlations and semantics of morphing simultaneously are important for morph resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 5 shows that combination of surface and semantic features further improves the performance, showing that they are complementary.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, using only surface features, the real tar get       Steve Jobs   of the morph       (Qiao Boss)  is not top ranked since some othercandidates such as     (George)  are more or thographically similar.",
        "Entity": "Normal"
    },
    {
        "Text": "However,  Steve Jobs  is ranked top when combined with semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 4: The System Performance Based on Each Single Feature Set.",
        "Entity": "Normal"
    },
    {
        "Text": "Fe atu res Su rf + Ho m B Su rf + Ho m E Su rf + He tB Su rf + He tE Ac c @ 1 0.2 34 0.2 38 0.2 62 0.2 76 Ac c @ 5 0.4 16 0.4 44 0.4 81 0.5 19 Ac c @ 10 0.4 77 0.5 05 0.5 33 0.5 70 Ac c @ 20 0.5 19 0.5 61 0.5 65 0.5 98 Fe atu res + Gl ob + Gl ob + Gl ob + Gl ob Ac c @ 1 0.2 90 0.3 41 0.3 22 0.3 46 Ac c @ 5 0.5 05 0.4 95 0.5 28 0.5 33 Ac c @ 10 0.5 51 0.5 51 0.5 79 0.5 84 Ac c @ 20 0.5 94 0.6 03 0.6 36 0.6 31 Table 5: The System Performance Based on Combinations of Surface and Semantic Features.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2.2 Cross Source and Cross Genre Information We integrate the cross source information from Twitter, and the cross genre information from web documents into Weibo tweets for information network construction, and extract a new set of semantic features.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 6 shows that further gains can be achieved.",
        "Entity": "Normal"
    },
    {
        "Text": "Notice that integrating tweets from Twitter mainly improves the ranking for top k where k > 1.",
        "Entity": "Normal"
    },
    {
        "Text": "This is because Weibo dominates our dataset, and in Weibo many of these sensitive morphs are mostly used with their traditional meanings instead of the morph senses.",
        "Entity": "Normal"
    },
    {
        "Text": "Further performance improvement is achieved by integrating information from background formal web documents which can provide richer context and relations.",
        "Entity": "Normal"
    },
    {
        "Text": "speed up the system 5 times, while retain 98.5% of the morph candidates that can be detected.",
        "Entity": "Normal"
    },
    {
        "Text": "Sy ste m Ac c @ 1 Ac c @ 5 Ac c @ 10 Ac c @ 20 Wit ho ut 0.",
        "Entity": "Normal"
    },
    {
        "Text": "3 6 5 0.",
        "Entity": "Normal"
    },
    {
        "Text": "5 7 9 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 4 5 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 9 6 Wit h 0.",
        "Entity": "Normal"
    },
    {
        "Text": "3 7 9 0.",
        "Entity": "Normal"
    },
    {
        "Text": "5 9 4 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "6 5 9 0 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 0 1 Table 6: The System Performance of Integrating Cross Source and Cross Genre Information.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2.3 Effects of Social Features Table 7 shows that adding social features can improve the best performance achieved so far.",
        "Entity": "Normal"
    },
    {
        "Text": "This is because a group of people with close relationships may share similar opinion.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, two tweets  ...of course the reputation of Buhou is a little too high!",
        "Entity": "Normal"
    },
    {
        "Text": "//@User1: //@User2: Chongqing event tells us...)  and  ...do not follow Bo Xilai...@User1...)\n\t\t\tare from two users in the same social group.One includes a morph  Buhou  and the other includes its target  Bo Xilai .",
        "Entity": "Normal"
    },
    {
        "Text": "Table 8: The Effects of Temporal Constraint We also attempted using topic modeling approach to detect target candidates.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to the large amount of data, we first split the data set on a daily basis, then applied Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "Named entities which co-occur at least   times with a morph query in the same topic are selected as its target candidates.",
        "Entity": "Normal"
    },
    {
        "Text": "As shown in Table9 (K is the number of predefined topics), PLSA is not quite effective mainly because traditional topic modeling approaches do not perform well on short texts from social media.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, in this paper we choose a simple method based on temporal distribution to detect target candidates.",
        "Entity": "Normal"
    },
    {
        "Text": "Table 9: Accuracy of Target Candidate Detection Table 7: The Effects of Social Features.",
        "Entity": "Normal"
    },
    {
        "Text": "5.3 Effects of Candidate Detection.",
        "Entity": "Normal"
    },
    {
        "Text": "The performance with and without candidate detection step (using all features) is shown in Table 8.",
        "Entity": "Normal"
    },
    {
        "Text": "The gain is small since the combination of all features in the learning to rank framework can already well capture the relationship between a morph and a target candidate.",
        "Entity": "Normal"
    },
    {
        "Text": "Nevertheless, the temporal distribution assumption is effective.",
        "Entity": "Normal"
    },
    {
        "Text": "It helps to filter out 80% of unrelated targets and 5.4 Discussions.",
        "Entity": "Normal"
    },
    {
        "Text": "Compared with the standard alias detection ( Surf+HomB ) approach (Hsiung et al., 2005), our proposed approach achieves significantly better performance (99.9% confidence level by the Wilcoxon Matched-Pairs Signed-Ranks Test for Acc@1).",
        "Entity": "Normal"
    },
    {
        "Text": "We further explore two types of factors which may affect the system performance as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "One important aspect affecting the resolution performance is the morph & non-morph ambiguity.",
        "Entity": "Normal"
    },
    {
        "Text": "We categorize a morph query as  Unique  if the string is mainly used as a morph when it occurs, such as     (Bodu)  which is used to re fer to  Bo Xilai ; otherwise as  Common  (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "(Baby)  ,     (President)  ).",
        "Entity": "Normal"
    },
    {
        "Text": "Table 10 presents the separate scores for these two categories.",
        "Entity": "Normal"
    },
    {
        "Text": "We can see that the morphs in  Unique  category have much better resolution performance than those in  Common  category.",
        "Entity": "Normal"
    },
    {
        "Text": "Cat eg ory Nu mb er Ac c @ 1 Ac c @ 5 Acc @1 0 Acc @2 0 Un iqu e 72 0.4 79 0.7 15 0.7 71 0.8 19 Co mm on 35 0.1 71 0.3 43 0.4 0 0.4 29 Table 10: Performance of Two Categories We also investigate the effects of popularity of morphs on the resolution performance.",
        "Entity": "Normal"
    },
    {
        "Text": "We split the queries into 5 bins with equal size based on the non-descending frequency, and evaluate Acc@1 separately.",
        "Entity": "Normal"
    },
    {
        "Text": "As shown in Table11, we can see that the popularity is not highly correlated with the performance.",
        "Entity": "Normal"
    },
    {
        "Text": "Ra nk 0   20 % 20 %   40 % 40 %   60 % 60 %   80 % 80 %   10 0 % All 0.3 33 0.4 76 0.3 41 0.4 29 0.3 18 Un iqu e 0.3 21 0.6 79 0.3 79 0.5 71 0.4 83 Co mm on 0.2 14 0.2 14 0.0 71 0.0 71 0.2 86 Table 11: Effects of Popularity of Morphs\n\t\n\t\n\t\t\tTo analyze social media behavior under active censorship, (Bamman et al., 2012) automatically discovered politically sensitive terms from Chinese tweets based on message deletion analysis.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, our work goes beyond target idendification by resolving implicit morphs to their real targets.",
        "Entity": "Normal"
    },
    {
        "Text": "Our work is closely related to alias detection (Hsiung et al., 2005; Pantel, 2006; Bollegala et al., 2011; Holzer et al., 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "We demonstrated that state-of-the-art alias detection methods did not perform well on morph resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we exploit cross-genre information and social correlation to measure semantic similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "(Yang et al., 2011; Huang et al., 2012) also showed the effectiveness of exploiting information from formal web documents to enhance tweet summarization and tweet ranking.",
        "Entity": "Normal"
    },
    {
        "Text": "Other similar research lines are the TACKBP Entity Linking (EL) (Ji et al., 2010; Ji et al., 2011), which links a named entity in news and web documents to an appropriate knowledge base (KB) entry, the task of mining name translation pairs from comparable corpora (Udupa et al., 2009; Ji, 2009; Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Hassan et al., 2007) and the link prediction problem (Adamic and Adar, 2001; LibenNowell and Kleinberg, 2003; Sun et al., 2011b; Hasan et al., 2006; Wang et al., 2007; Sun et al., 2011a).",
        "Entity": "Normal"
    },
    {
        "Text": "Most of the work focused on unstructured or structured data with clean and rich relations (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "DBLP).",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, our work constructs heterogeneous information networks from unstructured, noisy multi-genre text without explicit entity attributes.",
        "Entity": "Normal"
    },
    {
        "Text": "To the best of our knowledge, this is the first work of resolving implicit information morphs from the data under active censorship.",
        "Entity": "Normal"
    },
    {
        "Text": "Our promising results can well serve as a benchmark for this new problem.",
        "Entity": "Normal"
    },
    {
        "Text": "Both of the Meta-path based and social correlation based semantic similarity measurements are proven powerful and complementary.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we have focused on entity morphs.",
        "Entity": "Normal"
    },
    {
        "Text": "In the future we will extend our method to discover other types of information morphs, such as events and nominal mentions.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, automatic identification of candidate morphs is another challenging task, especially when the mentions are ambiguous and can also refer to other real entities.",
        "Entity": "Normal"
    },
    {
        "Text": "Our ongoing work includes identifying candidate morphs from scratch, as well as discovering morphs for a given target based on anomaly analysis and textual coherence modeling.",
        "Entity": "Normal"
    },
    {
        "Text": "Thanks to the three anonymous reviewers for their insightful comments.",
        "Entity": "Normal"
    },
    {
        "Text": "This work was supported by the U.S. Army Research Laboratory under Cooperative Agreement No.",
        "Entity": "Normal"
    },
    {
        "Text": "W911NF09-20053 (NSCTA), the U.S. NSF CAREER Award under Grant IIS0953149, the U.S. NSF EAGER Award under Grant No.",
        "Entity": "Normal"
    },
    {
        "Text": "IIS1144111, the U.S. DARPA FA875013-20041 - Deep Exploration and Filtering of Text (DEFT) Program, the U.S. DARPA under Agreement No.",
        "Entity": "Normal"
    },
    {
        "Text": "W911NF12-C-0028, CUNY Junior Faculty Award, NSF IIS0905215, CNS 0931975, CCF0905014, and MIAS, a DHS-IDS Center for Multimodal Information Access and Synthesis at UIUC.",
        "Entity": "Normal"
    },
    {
        "Text": "The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government.",
        "Entity": "Normal"
    },
    {
        "Text": "The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.",
        "Entity": "Normal"
    },
    {
        "Text": "\nA Fast Fertility Hidden Markov Model forWord Alignment Using MCMC\n\t\n\t\tA word in one language can be translated to zero, one, or several words in other languages.",
        "Entity": "Normal"
    },
    {
        "Text": "Using word fertility features has been shown to be useful in building word alignment models for statistical machine translation.",
        "Entity": "Normal"
    },
    {
        "Text": "We built a fertility hidden Markov model by adding fertility to the hidden Markov model.",
        "Entity": "Normal"
    },
    {
        "Text": "This model not only achieves lower alignment error rate than the hidden Markov model, but also runs faster.",
        "Entity": "Normal"
    },
    {
        "Text": "It is similar in some ways to IBM Model 4, but is much easier to understand.",
        "Entity": "Normal"
    },
    {
        "Text": "We use Gibbs sampling for parameter estimation, which is more principled than the neighborhood method used in IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "IBM models and the hidden Markov model (HMM) for word alignment are the most influential statistical word alignment models (Brown et al., 1993; Vogel et al., 1996; Och and Ney, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "There are three kinds of important information for word alignment models: lexicality, locality and fertility.",
        "Entity": "Normal"
    },
    {
        "Text": "IBM Model 1 uses only lexical information; IBM Model 2 and the hidden Markov model take advantage of both lexical and locality information; IBM Models 4 and 5 use all three kinds of information, and they remain the state of the art despite the fact that they were developed almost two decades ago.",
        "Entity": "Normal"
    },
    {
        "Text": "Recent experiments on large datasets have shown that the performance of the hidden Markov model is very close to IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Nevertheless, we believe that IBM Model 4 is essentially a better model because it exploits the fertility of words in the tar get language.",
        "Entity": "Normal"
    },
    {
        "Text": "However, IBM Model 4 is so complex that most researches use the GIZA++ software package (Och and Ney, 2003), and IBM Model 4 itself is treated as a black box.",
        "Entity": "Normal"
    },
    {
        "Text": "The complexity in IBM Model 4 makes it hard to understand and to improve.",
        "Entity": "Normal"
    },
    {
        "Text": "Our goal is to build a model that includes lexicality, locality, and fertility; and, at the same time, to make it easy to understand.",
        "Entity": "Normal"
    },
    {
        "Text": "We also want it to be accurate and computationally efficient.",
        "Entity": "Normal"
    },
    {
        "Text": "There have been many years of research on word alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "Our work is different from others in essential ways.",
        "Entity": "Normal"
    },
    {
        "Text": "Most other researchers take either the HMM alignments (Liang et al., 2006) or IBM Model 4 alignments (Cherry and Lin, 2003) as input and perform post-processing, whereas our model is a potential replacement for the HMM and IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Directly modeling fertility makes our model fundamentally different from others.",
        "Entity": "Normal"
    },
    {
        "Text": "Most models have limited ability to model fertility.",
        "Entity": "Normal"
    },
    {
        "Text": "Liang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) learn the alignment in both translation directions jointly, essentially pushing the fertility towards 1.",
        "Entity": "Normal"
    },
    {
        "Text": "ITG models (Wu, 1997) assume the fertility to be either zero or one.",
        "Entity": "Normal"
    },
    {
        "Text": "It can model phrases, but the phrase has to be contiguous.",
        "Entity": "Normal"
    },
    {
        "Text": "There have been works that try to simulate fertility using the hidden Markov model (Toutanova et al., 2002; Deng and Byrne, 2005), but we prefer to model fertility directly.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model is a coherent generative model that combines the HMM and IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "It is easier to understand than IBM Model 4 (see Section 3).",
        "Entity": "Normal"
    },
    {
        "Text": "Our model also removes several undesired properties in IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "We use Gibbs sampling instead of a heuristic-based neighborhood method for parameter 596 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 596\u2013605, MIT, Massachusetts, USA, 911 October 2010.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2010 Association for Computational Linguistics estimation.",
        "Entity": "Normal"
    },
    {
        "Text": "Our distortion parameters are similar to IBM Model 2 and the HMM, while IBM Model 4 uses inverse distortion (Brown et al., 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Our model assumes that fertility follows a Poisson distribution, while IBM Model 4 assumes a multinomial distribution, and has to learn a much larger number of parameters, which makes it slower and less reliable.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model is much faster than IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, we will show that it is also faster than the HMM, and has lower alignment error rate than the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "Parameter estimation for word alignment models that model fertility is more difficult than for models without fertility.",
        "Entity": "Normal"
    },
    {
        "Text": "Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) and Och and Ney (2003) first compute the Viterbi alignments for simpler models, then consider only some neighbors of the Viterbi alignments for modeling fertility.",
        "Entity": "Normal"
    },
    {
        "Text": "If the optimal alignment is not in those neighbors, this method will not be able find the opti total of I + 1 empty words for the HMM model1.",
        "Entity": "Normal"
    },
    {
        "Text": "Moore (2004) also suggested adding multiple empty words to the target sentence for IBM Model 1.",
        "Entity": "Normal"
    },
    {
        "Text": "After we add I + 1 empty words to the target sentence, the alignment is a mapping from source to target word positions: a : j \u2192 i, i = aj where j = 1, 2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", J and i = 1, 2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", 2I + 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Words from position I + 1 to 2I + 1 in the target sentence are all empty words.",
        "Entity": "Normal"
    },
    {
        "Text": "We allow each source word to align with exactly one target word, but each target word may align with multiple source words.",
        "Entity": "Normal"
    },
    {
        "Text": "The fertility \u03c6i of a word ei at position i is defined as the number of aligned source words: J mal alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the Markov Chain Monte Carlo (MCMC) method for training and decoding, \u03c6i = j=1 \u03b4(aj , i) which has nice probabilistic guarantees.",
        "Entity": "Normal"
    },
    {
        "Text": "DeNero et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2008) applied the Markov Chain Monte Carlo method to word alignment for machine translation; they do not model word fertility.",
        "Entity": "Normal"
    },
    {
        "Text": "where \u03b4 is the Kronecker delta function: ( 1 if x = y \u03b4(x, y) = 0 otherwise In particular, the fertility of all empty words in 2.1 Alignment and Fertility.",
        "Entity": "Normal"
    },
    {
        "Text": "the target sentence is \"\u00a32I +1 \"\u00a32I +1 \u03c6i.",
        "Entity": "Normal"
    },
    {
        "Text": "We define \u03c6\u01eb \u2261 2I +1 i=I +1 \u03c6i.",
        "Entity": "Normal"
    },
    {
        "Text": "For a bilingual sentence pair e1 and Given a source sentence f J = f1, f2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", fJ and a f J , we have \"\u00a3I \u03c6i + \u03c6\u01eb = J .",
        "Entity": "Normal"
    },
    {
        "Text": "target sentence eI 1 = e1, e2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", eI , we define the 1 i=1 The inverted alignments for position i in the tar alignments between the two sentences as a subset of the Cartesian product of the word positions.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993), we assume that each source word is aligned to exactly one target word.",
        "Entity": "Normal"
    },
    {
        "Text": "get sentence are a set Bi, such that each element in Bi is aligned with i, and all alignments of i are in Bi.",
        "Entity": "Normal"
    },
    {
        "Text": "Inverted alignments are explicitly used in IBM Models 3, 4 and 5, but not in our model, which is We denote as aJ = a1, a2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", aJ the alignments one reason that our model is easier to understand.",
        "Entity": "Normal"
    },
    {
        "Text": "between f J and eI .",
        "Entity": "Normal"
    },
    {
        "Text": "When a word fj is not aligned 1 1 with any word e, aj is 0.",
        "Entity": "Normal"
    },
    {
        "Text": "For convenience, we add an empty word \u01eb to the target sentence at position 0 (i.e., e0 = \u01eb).",
        "Entity": "Normal"
    },
    {
        "Text": "However, as we will see, we have to add more than one empty word for the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 IBM Model 1 and HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "IBM Model 1 and the HMM are both generative models, and both start by defining the probability of alignments and source sentence given the In order to compute the \u201cjump probability\u201d in the target sentence: P (aJJ 1 ); the data likeli HMM model, we need to know the position of the 1 , f1 |e2I +1 hood can be computed by summing over alignments: aligned target word for the previous source word.",
        "Entity": "Normal"
    },
    {
        "Text": "If the previous source word aligns to an empty word, 1 If fj.",
        "Entity": "Normal"
    },
    {
        "Text": "\u22121 does not align with an empty word and fj alignswe could use the position of the empty word to indi with an empty word, we want to record the position of the target word that fj\u22121 aligns with.",
        "Entity": "Normal"
    },
    {
        "Text": "There are I + 1 possibilities: fj is cate the nearest previous source word that does not align to an empty word.",
        "Entity": "Normal"
    },
    {
        "Text": "For this reason, we use a the first word in the source sentence, or fj the target word.",
        "Entity": "Normal"
    },
    {
        "Text": "\u22121 aligns with one ofP (f J |e2I +1) = \"\u00a3 J P (aJ , f J |e2I +1).",
        "Entity": "Normal"
    },
    {
        "Text": "The alignwhere the first two equations imply that the proba 1 1 a1 1 1 1 ments aJ are the hidden variables.",
        "Entity": "Normal"
    },
    {
        "Text": "The expectation maximization algorithm is used to learn the parameters such that the data likelihood is maximized.",
        "Entity": "Normal"
    },
    {
        "Text": "Without loss of generality, P (aJ , f J |e2I +1) can bility of jumping to an empty word is either 0 or p0, and the third equation implies that the probability of jumping from a nonempty word is the same as the probability of jumping from the corespondent empty 1 1 1 be decomposed into length probabilities, distortion probabilities (also called alignment probabilities), and lexical probabilities (also called translation probabilities): P (aJ , f J |e2I +1) 1 1 1 J word.",
        "Entity": "Normal"
    },
    {
        "Text": "The absolute position in the HMM is not important, because we re-parametrize the distortion probability in terms of the distance between adjacent alignment points (Vogel et al., 1996; Och and Ney, 2003): = P (J |e2I +1) n P (aj , fj |f j\u22121, aj\u22121, e2I +1) c(i \u2212 i\u2032) 1 j=1 1 1 1 P (i|i\u2032, I ) = \"\u00a3 i\u2032\u2032 c(i\u2032\u2032 \u2212 i\u2032) J = P (J |e2I +1) n P (aj |f j\u22121, aj\u22121, e2I +1) \u00d7 where c( ) is the count of jumps of a given distance.",
        "Entity": "Normal"
    },
    {
        "Text": "1 j=1 1 1 1 In IBM Model 1, the word order does not mat ter.",
        "Entity": "Normal"
    },
    {
        "Text": "The HMM is more likely to align a source P (fj |f j\u22121, aj , e2I +1)l 1 1 1 where P (J |e2I +1) is a length probability, word to a target word that is adjacent to the previous aligned target word, which is more suitable than IBM Model 1 because adjacent words tend to form (aj |f j\u22121, aj\u22121 2I +1P 1 1 , e1 ) is a distortion prob phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "ability and P (fj |f j probability.",
        "Entity": "Normal"
    },
    {
        "Text": "\u22121, aj , e 2I +1 1 ) is a lexical For these two models, in theory, the fertility for a target word can be as large as the length of the IBM Model 1 assumes a uniform distortion probability, a length probability that depends only on the length of the target sentence, and a lexical probability that depends only on the aligned target word: J source sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "In practice, the fertility for a target word in IBM Model 1 is not very big except for rare target words, which can become a garbage collector, and align to many source words (Brown et al., 1993; Och and Ney, 2003; Moore, 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "The HMM is P (aJ , f J |e2I +1) = P (J |I ) n P (f |e ) less likely to have this garbage collector problem be 1 1 1 (2I + 1)J j=1 j aj cause of the alignment probability constraint.",
        "Entity": "Normal"
    },
    {
        "Text": "However, fertility is an inherent cross language propertyThe hidden Markov model assumes a length prob ability that depends only on the length of the target sentence, a distortion probability that depends only on the previous alignment and the length of the target sentence, and a lexical probability that depends only on the aligned target word: P (aJ , f J |e2I +1) = 1 1 1 J P (J |I ) n P (aj |aj\u22121, I )P (fj |ea ) j=1 In order to make the HMM work correctly, we enforce the following constraints (Och and Ney, 2003): and these two models cannot assign consistent fertility to words.",
        "Entity": "Normal"
    },
    {
        "Text": "This is our motivation for adding fertility to these two models, and we expect that the resulting models will perform better than the baseline models.",
        "Entity": "Normal"
    },
    {
        "Text": "Because the HMM performs much better than IBM Model 1, we expect that the fertility hidden Markov model will perform much better than the fertility IBM Model 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Throughout the paper, \u201cour model\u201d refers to the fertility hidden Markov model.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to space constraints, we are unable to provide details for IBM Models 3, 4 and 5; see Brown et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(1993) and Och and Ney (2003).",
        "Entity": "Normal"
    },
    {
        "Text": "But we want to point out that the locality property modeled in the HMM is missing in IBM Model 3, and is modeled invertedly in IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "IBM Model 5 removes deficiency (Brown et al., 1993; Och and Ney, 2003) from IBM Model 4, but it is computationally very expensive due to the larger number of parameters than IBM Model 4, and IBM Model 5 often provides no improvement on alignment accuracy.",
        "Entity": "Normal"
    },
    {
        "Text": "Our fertility IBM Model 1 and fertility HMM are both generative models and start by defining the probability of fertilities (for each nonempty target word and all empty words), alignments, and the source sentence given the target sentence: P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1); 1 1 1 1 are further away from the mean have low probability.",
        "Entity": "Normal"
    },
    {
        "Text": "IBM Models 3, 4, and 5 use a multinomial distribution for fertility, which has a much larger number of parameters to learn.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model has only one parameter for each target word, which can be learned more reliably.",
        "Entity": "Normal"
    },
    {
        "Text": "In the fertility IBM Model 1, we assume that the distortion probability is uniform, and the lexical probability depends only on the aligned target word: P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1) the data likelihood can be computed by 1 1 1 I \u03c6i 1 \u03bb(ei ) summing over fertilities and alignments: n \u03bb(ei) e\u2212 \u00d7 P (f J |e2I +1) = \"\u00a3 I J P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1).",
        "Entity": "Normal"
    },
    {
        "Text": "i=1 \u03c6i!",
        "Entity": "Normal"
    },
    {
        "Text": "1 1 \u03c61 ,\u03c6\u01eb ,a1 1 1 1 1 The fertility for a nonempty word ei is a random variable \u03c6i, and we assume \u03c6i follows a Poisson distribution Poisson(\u03c6i; \u03bb(ei)).",
        "Entity": "Normal"
    },
    {
        "Text": "The sum of the fer (I \u03bb(\u01eb))\u03c6\u01eb e\u2212(I \u03bb(\u01eb)) \u03c6\u01eb!",
        "Entity": "Normal"
    },
    {
        "Text": "\u00d7 J tilities of all the empty words (\u03c6\u01eb) grows with the length of the target sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we assume that \u03c6\u01eb follows a Poisson distribution with parameter I \u03bb(\u01eb).",
        "Entity": "Normal"
    },
    {
        "Text": "Now P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1) can be decomposed 1 (2I + 1)J n P (fj | j=1 eaj ) (1) 1 1 1 1 in the following way: P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1) In the fertility HMM, we assume that the distor tion probability depends only on the previous alignment and the length of the target sentence, and that 1 1 1 1 = P (\u03c6I |e2I +1)P (\u03c6\u01eb|\u03c6I , e2I +1) \u00d7 1 1 1 1 J the lexical probability depends only on the aligned target word: n P (aj , fj |f j\u22121, aj\u22121, e2I +1, \u03c6I , \u03c6\u01eb) j=1 1 1 1 1 P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1) = n \u03bb(ei) e\u2212\u03bb(ei ) 1 1 1 I \u03c6 1 \u03bb(e ) \u03c6i!",
        "Entity": "Normal"
    },
    {
        "Text": "\u00d7 = n \u03bb(ei) i e\u2212 i i=1 (I \u03bb(\u01eb))\u03c6\u01eb e\u2212I \u03bb(\u01eb) \u03c6\u01eb!",
        "Entity": "Normal"
    },
    {
        "Text": "\u00d7 \u03c6 i=1 (I \u03bb(\u01eb))\u03c6\u01eb !",
        "Entity": "Normal"
    },
    {
        "Text": "\u00d7 e\u2212(I \u03bb(\u01eb)) J n P (aj |f j\u22121, aj\u22121, e2I +1 I \u03c6\u01eb!",
        "Entity": "Normal"
    },
    {
        "Text": "\u00d7 J j=1 1 1 1 , \u03c61 , \u03c6\u01eb) \u00d7 n P (aj | j=1 aj\u22121 , I )P (fj | eaj ) (2) P (fj |f j\u22121, aj , e2I +1, \u03c6I , \u03c6\u01eb)l 1 1 1 1 Superficially, we only try to model the length 1 |e2I +1probability more accurately.",
        "Entity": "Normal"
    },
    {
        "Text": "However, we also en When we compute P (f J 1 ), we only sum force the fertility for the same target word across the corpus to be consistent.",
        "Entity": "Normal"
    },
    {
        "Text": "The expected fertility for a nonempty word ei is \u03bb(ei), and the expected fertil over fertilities that agree with the alignments: ity for all empty words is I \u03bb(\u01eb).",
        "Entity": "Normal"
    },
    {
        "Text": "Any fertility value P (f J |e2I +1) = P (aJ , f J |e2I +1) has a nonzero probability, but fertility values that 1 1 1 1 1 J 1 where P (aJ , f J |e2I +1) auxiliar y functio n is: L(P (f |e), P (a|a ), \u03bb(e), \u03be1(e) , \u03be2(a )) 1 1 1 = P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1) = P\u02dc \u2032 aJ e 2I +1, f J ) log \u2032 P (aJ , f J | e2I +1) 1 1 ,\u03c6\u01eb 1 1 1 1 1 1 J 1 1 1 1 \u2248 P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1) \u00d7 \u2212 \u03be1(e)( P (f |e) \u2212 1) 1 1 1 1 I \uf8eb J \uf8f6 e f n \u03b4 \uf8ed i=1 j=1 \u03b4(aj , i), \u03c6i\uf8f8 \u00d7 \u2212 \u03be2(a\u2032)( a\u2032 a P (a|a\u2032) \u2212 1) \uf8eb 2I +1 J \uf8f6 Because P (aJ , f J |e2I +1) is in the exponential 1 1 1 \u03b4 \uf8ed i=I +1 j=1 \u03b4(aj , i), \u03c6\u01eb\uf8f8 (3) family, we get a closed form for the parameters from expected counts:                                                                                                                                                                                        \n\t\t\tBecause we only sum over fer tilities that are consistent with the alignments, we P (a|a\u2032) = \"\u00a3s c (a|a\u2032; f (s), e(s)) (5)have \"\u00a3f J P (f J |e2I +1) < 1, and our model is de \"\u00a3 \"\u00a3 a s c(a|a\u2032; f (s), e(s)) 1 1 1 \"\u00a3 (s) (s) ficient, similar to IBM Models 3 and 4 (Brown et al., 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "We can remove the deficiency for fertility IBM Model 1 by assuming a different distortion \u03bb(e) = s c(\u03c6| e; f , e ) s c(k|e; f (s), e(s)) (6) probability: the distortion probability is 0 if fertility where s is the number of bilingual sentences, andis not consistent with alignments, and uniform oth c(f |e; f J 2I +1 \u02dc J J 2I +1 erwise.",
        "Entity": "Normal"
    },
    {
        "Text": "The total number of consistent fertility and 1 , e1 ) = P (a1 |f1 , e1 ) \u00d7 J alignments is J !",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "Replacing 1 with a1 \u03c6\u01eb !",
        "Entity": "Normal"
    },
    {
        "Text": "J i !",
        "Entity": "Normal"
    },
    {
        "Text": "\u03c6\u01eb !",
        "Entity": "Normal"
    },
    {
        "Text": "J i !",
        "Entity": "Normal"
    },
    {
        "Text": "(2I +1)J \u03b4(fj , f )\u03b4(ei, e) J !",
        "Entity": "Normal"
    },
    {
        "Text": ", we have: c(a|a\u2032; f J , e2I +1) = j P\u02dc(aJ |f J , e2I +1) \u00d7 P (\u03c6I , \u03c6\u01eb, aJ , f J |e2I +1) 1 1 1 1 1 J 1 1 1 1 a1 I = n \u03bb(ei)\u03c6i e\u2212\u03bb(ei ) \u00d7 i=1 (I \u03bb(\u01eb))\u03c6\u01eb e\u2212(I \u03bb(\u01eb)) \u00d7 c(\u03c6|e; f1 , e1 ) = \u03b4(aj , a)\u03b4(aj\u22121, a\u2032) j P\u02dc(a1 |f1 , e1 ) \u00d7 J 2I +1 J J 2I +1 J n P (fj |ea ) J 1 \u03c6 \u03b4(e , e) J !",
        "Entity": "Normal"
    },
    {
        "Text": "j i i j=1 i c(k|e; f J , e2I +1) = k(ei)\u03b4(ei, e) In our experiments, we did not find a noticeable 1 1 change in terms of alignment accuracy by removing the deficiency.",
        "Entity": "Normal"
    },
    {
        "Text": "We estimate the parameters by maximizing P (f J |e2I +1) using the expectation maximization These equations are for the fertility hidden Markov model.",
        "Entity": "Normal"
    },
    {
        "Text": "For the fertility IBM Model 1, we do not need to estimate the distortion probability.",
        "Entity": "Normal"
    },
    {
        "Text": "Although we can estimate the parameters by using 1 1 (EM) algorithm (Dempster et al., 1977).",
        "Entity": "Normal"
    },
    {
        "Text": "The the EM algorithm, in order to compute the expected counts, we have to sum over all possible alignments1 , which is, unfortunately, exponential.",
        "Entity": "Normal"
    },
    {
        "Text": "We devel Algorithm 1: One iteration of E-step: draw t samples for each aj for each sentence pairoped a Gibbs sampling algorithm (Geman and Ge (f J 1 ) in the corpus man, 1984) to compute the expected counts.",
        "Entity": "Normal"
    },
    {
        "Text": "1 , e2I +1 J 2I +1 For each target sentence e2I +1 and source sentence f J , we initialize the alignment aj for each source word fj using the Viterbi alignments from IBM Model 1.",
        "Entity": "Normal"
    },
    {
        "Text": "During the training stage, we try all 2I + 1 possible alignments for aj but fix all other alignments.2 We choose alignment aj with probabil J 2I +1 for (f1 , e1 ) in the corpus do Initialize aJ with IBM Model 1; for t do for j do for i do aj = i; Compute P (aJ , f J |e2I +1); ity P (aj |a1, \u00b7 \u00b7 \u00b7 aj\u22121, aj+1 \u00b7 \u00b7 \u00b7 aJ , f1 , e1 ), which can be computed in the following way: end 1 1 1 P (aj |a1, \u00b7 \u00b7 \u00b7 , aj 1, a , \u00b7 \u00b7 \u00b7 , a , f J , e2I +1) \u2212 j+1 J 1 1 J J 2I +1 Draw a sample for aj using Equation 7; Update counts; = P (a1 , f1 |e1 ) (7) end \"\u00a3 J J 2I +1 aj P (a1 , f1 |e1 ) For each alignment variable aj , we choose t samples.",
        "Entity": "Normal"
    },
    {
        "Text": "This Gibbs sampling method updates parameters constantly, so it is an \u201conline learning\u201d algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this sampling method needs a large amount of communication between machines in order to keep the parameters up to date if we compute the expected counts in parallel.",
        "Entity": "Normal"
    },
    {
        "Text": "Instead, we do \u201cbatch learning\u201d: we fix the parameters, scan through the entire corpus and compute expected counts in parallel (E-step); then combine all the counts together and update the parameters (M- step).",
        "Entity": "Normal"
    },
    {
        "Text": "This is analogous to what IBM models and end end We also consider initializing the alignments using the HMM Viterbi algorithm in the E-step.",
        "Entity": "Normal"
    },
    {
        "Text": "In this case, the fertility hidden Markov model is not faster than the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "Fortunately, initializing using IBM Model 1 Viterbi does not decrease the accuracy in any noticeable way, and reduces the complexity of the Gibbs sampling algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "In the testing stage, the sampling algorithm is the same as above except that we keep the alignments 1 that maximize P (a1 , f1 |e2I +1).",
        "Entity": "Normal"
    },
    {
        "Text": "We need more the HMM do in the EM algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm aJ J J 1 for the E-step on one machine (all machines are independent) is in Algorithm 1.",
        "Entity": "Normal"
    },
    {
        "Text": "For the fertility hidden Markov model, updating P (aJ , f J |e2I +1) whenever we change the alignment 1 1 1 aj can be done in constant time, so the complexity of choosing t samples for all aj (j = 1, 2, .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ", J ) is O(tI J ).",
        "Entity": "Normal"
    },
    {
        "Text": "This is the same complexity as the HMM if t is O(I ), and it has lower complexity if t is a constant.",
        "Entity": "Normal"
    },
    {
        "Text": "Surprisingly, we can achieve better results than the HMM by computing as few as 1 sample for each alignment, so the fertility hidden Markov model is much faster than the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "Even when choosing t such that our model is 5 times faster than the HMM, we achieve better results.",
        "Entity": "Normal"
    },
    {
        "Text": "2 For fertility IBM Model 1, we only need to compute I + 1.\n\t\t\tvalues because e2I +1 are identical empty words.",
        "Entity": "Normal"
    },
    {
        "Text": "samples in the testing stage because it is unlikely to get to the optimal alignments by sampling a few times for each alignment.",
        "Entity": "Normal"
    },
    {
        "Text": "Interestingly, we found that throwing away the fertility and using the HMM Viterbi decoding achieves same results as the sampling approach (we can ignore the difference because it is tiny), but is faster.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we use Gibbs sampling for learning and the HMM Viterbi decoder for testing.",
        "Entity": "Normal"
    },
    {
        "Text": "Gibbs sampling for the fertility IBM Model 1 is similar but simpler.",
        "Entity": "Normal"
    },
    {
        "Text": "We omit the details here.",
        "Entity": "Normal"
    },
    {
        "Text": "Al ig n m en t M o d e l P R A E R e n \u2192 c n I B M 1 I B M 1 F H M M H M M F 1 H M M F 5 H M MF 3 0 I B M 4 49 .6 55 .4 62 .6 65 .4 66 .8 67 .8 66 .8 55 .3 57 .1 59 .5 59 .1 60 .8 62 .3 64 .1 4 7.",
        "Entity": "Normal"
    },
    {
        "Text": "8 4 3.",
        "Entity": "Normal"
    },
    {
        "Text": "8 3 9.",
        "Entity": "Normal"
    },
    {
        "Text": "0 3 7.",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 6.",
        "Entity": "Normal"
    },
    {
        "Text": "2 3 4.",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 4.",
        "Entity": "Normal"
    },
    {
        "Text": "5 c n \u2192 e n I B M 1 I B M 1 F H M M H M M F 1 H M M F 5 H M MF 3 0 I B M 4 52 .6 55 .9 66 .1 68 .6 71 .1 71 .1 69 .3 53 .7 56 .4 62 .1 60 .2 62 .2 62 .7 68 .5 4 6.",
        "Entity": "Normal"
    },
    {
        "Text": "9 4 3.",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 5.",
        "Entity": "Normal"
    },
    {
        "Text": "9 3 5.",
        "Entity": "Normal"
    },
    {
        "Text": "7 3 3.",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 3.",
        "Entity": "Normal"
    },
    {
        "Text": "2 3 1.",
        "Entity": "Normal"
    },
    {
        "Text": "1                     .",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "0.48 0.46 0.44 I B M 1 I B M 1 F H M M H M M F 1 H M M F 5 H M M F 3 0 I B M 4 0.42 0.4 0.38 0.36 0.34 0.32                                  0.48 0.46 0.44 I B M 1 I B M 1 F H M M H M M F 1 H M M F 5 H M M F 3 0 I B M 4 0.42 0.4 0.38 0.36 0.34 0.32                                   5000 4000 I B M 1 I B M 1 F H M M H M M F 1 H M M F 5 H M M F 3 0 I B M 4 3000 2000 1000 0 Figure 3:                          \n\t\t\tThe training time for each model is calculated from scratch.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the training time of IBM Model 4 includes the training time of IBM Model 1, the HMM, and IBM Model 3.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated our model by computing the word alignment and machine translation quality.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the alignment error rate (AER) as the word alignment evaluation criterion.",
        "Entity": "Normal"
    },
    {
        "Text": "Let A be the alignments output by word alignment system, P be a set of possible alignments, and S be a set of sure alignments both labeled by human beings.",
        "Entity": "Normal"
    },
    {
        "Text": "S is a subset of P .",
        "Entity": "Normal"
    },
    {
        "Text": "Precision, recall, and AER are defined as follows: recall = |A \u2229 S| |S| precision = |A \u2229 P | |A| AER(S, P, A) = 1 |A \u2229 S| + |A \u2229 P | |A| + |S| AER is an extension to F-score.",
        "Entity": "Normal"
    },
    {
        "Text": "Lower AER is better.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluate our fertility models on a ChineseEnglish corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The ChineseEnglish data taken from FBIS newswire data, and has 380K sentence pairs, and we use the first 100K sentence pairs as our training data.",
        "Entity": "Normal"
    },
    {
        "Text": "We used hand-aligned data as reference.",
        "Entity": "Normal"
    },
    {
        "Text": "The ChineseEnglish data has 491 sentence pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "We initialize IBM Model 1 and the fertility IBM Model 1 with a uniform distribution.",
        "Entity": "Normal"
    },
    {
        "Text": "We smooth all parameters (\u03bb(e) and P (f |e)) by adding a small value (10\u22128), so they never become too small.",
        "Entity": "Normal"
    },
    {
        "Text": "We run both models for 5 iterations.",
        "Entity": "Normal"
    },
    {
        "Text": "AER results are computed using the IBM Model 1 Viterbi alignments, and the Viterbi alignments obtained from the Gibbs sampling algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "We initialize the HMM and the fertility HMM with the parameters learned in the 5th iteration of IBM Model 1.",
        "Entity": "Normal"
    },
    {
        "Text": "We smooth all parameters (\u03bb(e), P (a|a\u2032) and P (f |e)) by adding a small value (10\u22128).",
        "Entity": "Normal"
    },
    {
        "Text": "We run both models for 5 iterations.",
        "Entity": "Normal"
    },
    {
        "Text": "AER results are computed using traditional HMM Viterbi decoding for both models.",
        "Entity": "Normal"
    },
    {
        "Text": "It is always difficult to determine how many samples are enough for sampling algorithms.",
        "Entity": "Normal"
    },
    {
        "Text": "However, both fertility models achieve better results than their baseline models using a small amount of samples.",
        "Entity": "Normal"
    },
    {
        "Text": "For the fertility IBM Model 1, we sample 10 times for each aj , and restart 3 times in the training stage; we sample 100 times and restart 12 times in the testing stage.",
        "Entity": "Normal"
    },
    {
        "Text": "For the fertility HMM, we sample 30 times for each aj with no restarting in the training stage; no sampling in the testing stage because we use traditional HMM Viterbi decoding for testing.",
        "Entity": "Normal"
    },
    {
        "Text": "More samples give no further improvement.",
        "Entity": "Normal"
    },
    {
        "Text": "Initially, the fertility IBM Model 1 and fertility HMM did not perform well.",
        "Entity": "Normal"
    },
    {
        "Text": "If a target word e only appeared a few times in the training corpus, our model cannot reliably estimate the parameter \u03bb(e).",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, smoothing is needed.",
        "Entity": "Normal"
    },
    {
        "Text": "One may try to solve it by forcing all these words to share a same parameter \u03bb(einfrequent).",
        "Entity": "Normal"
    },
    {
        "Text": "Unfortunately, this does not solve the problem because all infrequent words tend to have larger fertility than they should.",
        "Entity": "Normal"
    },
    {
        "Text": "We solve the problem in the following way: estimate the parameter \u03bb(enon empty ) for all nonempty words, all infrequent words share this parameter.",
        "Entity": "Normal"
    },
    {
        "Text": "We consider words that appear less than 10 times as infrequent words.",
        "Entity": "Normal"
    },
    {
        "Text": "We can see that the fertility IBM Model 1 consistently outperforms IBM Model 1, and the fertility HMM consistently outperforms the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "The fertility HMM not only has lower AER than the HMM, it also runs faster than the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "In fact, with just 1 sample for each alignment, our model archives lower AER than the HMM, and runs more than 5 times faster than the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "It is possible to use sampling instead of dynamic programming in the HMM to reduce the training time with no decrease in AER (often an increase).",
        "Entity": "Normal"
    },
    {
        "Text": "We conclude that the fertility HMM not only has better AER results, but also runs faster than the hidden Markov model.",
        "Entity": "Normal"
    },
    {
        "Text": "We also evaluate our model by computing the machine translation BLEU score (Papineni et al., 2002) using the Moses system (Koehn et al., 2007).",
        "Entity": "Normal"
    },
    {
        "Text": "The training data is the same as the above word alignment evaluation bitexts, with alignments for each model symmetrized using the grow-diag-final heuristic.",
        "Entity": "Normal"
    },
    {
        "Text": "Our test is 633 sentences of up to length 50, with four references.",
        "Entity": "Normal"
    },
    {
        "Text": "Model BLEU HMM 19.55 HMMF30 19.26 IBM4 18.77                      \n\t\n\t\n\t\t\tWe developed a fertility hidden Markov model that runs faster and has lower AER than the HMM.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model is thus much faster than IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Our model is also easier to understand than IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "The Markov Chain Monte Carlo method used in our model is more principled than the heuristic-based neighborhood method in IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "While better word alignment results do not necessarily correspond to better translation quality, our translation results are comparable in translation quality to both the HMM and IBM Model 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Acknowledgments We would like to thank Tagyoung Chung, Matt Post, and the anonymous reviewers for helpful comments.",
        "Entity": "Normal"
    },
    {
        "Text": "This work was supported by NSF grants IIS0546554 and IIS0910611.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tWe present a novel approach to automatic metaphor identification, that discovers both metaphorical associations and metaphorical expressions in unrestricted text.",
        "Entity": "Normal"
    },
    {
        "Text": "Our system first performs hierarchical graph factorization clustering (HGFC) of nouns and then searches the resulting graph for metaphorical connections between concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "It then makes use of the salient features of the metaphorically connected clusters to identify the actual metaphorical expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast to previous work, our method is fully unsupervised.",
        "Entity": "Normal"
    },
    {
        "Text": "Despite this fact, it operates with an encouraging precision (0.69) and recall (0.61).",
        "Entity": "Normal"
    },
    {
        "Text": "Our approach is also the first one in NLP to exploit the cognitive findings on the differences in or- ganisation of abstract and concrete concepts in the human brain.",
        "Entity": "Normal"
    },
    {
        "Text": "Metaphor has traditionally been viewed as a form of linguistic creativity, that gives our expression more vividness, distinction and artistism.",
        "Entity": "Normal"
    },
    {
        "Text": "While this is true on the surface, the mechanisms of metaphor have a much deeper origin in our reasoning.",
        "Entity": "Normal"
    },
    {
        "Text": "Today metaphor is widely understood as a cognitive phenomenon operating at the level of mental processes, whereby one concept or domain is systematically viewed in terms of the properties of another (Lakoff and Johnson, 1980).",
        "Entity": "Normal"
    },
    {
        "Text": "Consider the examples (1)  He shot down all of my arguments  and (2)  He attacked every weak point in my argument .",
        "Entity": "Normal"
    },
    {
        "Text": "They demonstrate a metaphorical mapping of the concept of argument to that of war.",
        "Entity": "Normal"
    },
    {
        "Text": "The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept.",
        "Entity": "Normal"
    },
    {
        "Text": "The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "Lakoff and Johnson call such generalisations a source target domain mapping, or conceptual metaphor.",
        "Entity": "Normal"
    },
    {
        "Text": "The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semantics- oriented NLP application.",
        "Entity": "Normal"
    },
    {
        "Text": "The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012).",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust.",
        "Entity": "Normal"
    },
    {
        "Text": "However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing sub- tasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we present the first computational method 978 Proceedings of NAACLHLT 2013, pages 978 988, Atlanta, Georgia, 9 14 June 2013.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2013 Association for Computational Linguistics that identifies the generalisations that govern the production of metaphorical expressions, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "conceptual metaphors, and then uses these generalisations to identify metaphorical expressions in unrestricted text.",
        "Entity": "Normal"
    },
    {
        "Text": "As opposed to previous works on statistical metaphor processing that were supervised or semi-supervised, and thus required training data, our method is fully unsupervised.",
        "Entity": "Normal"
    },
    {
        "Text": "It relies on building a hierarchical graph of concepts connected by their association strength (using hierarchical clustering) and then searching for metaphorical links in this graph.",
        "Entity": "Normal"
    },
    {
        "Text": "Shutova et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) introduced the hypothesis of  clustering by association  and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "We share this intuition, but take this idea a significant step further.",
        "Entity": "Normal"
    },
    {
        "Text": "Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; WiemerHastings and Xu, 2005; Huang et al., 2010; Crutch and Warring- ton, 2010; Adorni and Proverbio, 2012).",
        "Entity": "Normal"
    },
    {
        "Text": "According to Crutch and Warrington (2005), these differences emerge from their general patterns of relation with other concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "However, most NLP systems to date treat abstract and concrete concepts as identical.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, we incorporate this distinction into our model by creating a network (or a graph) of concepts, and automatically learning the different patterns of association of abstract and concrete concepts with other concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "We expect that, while concrete concepts would tend to naturally organise into a tree-like structure (with more specific terms descending from the more general terms), abstract concepts would exhibit a more complex pattern of associations.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "One can see from this graph that if concrete concepts, such as bike or engine tend to be connected to only one concept at the higher level in the hierarchy (mechanism), abstract concepts may have multiple higher-level associates: the literal ones and the metaphorical ones.",
        "Entity": "Normal"
    },
    {
        "Text": "For ex ample, the abstract concept of democracy is literally associated with a more general concept of political system, as well as metaphorically associated with the concept of mechanism.",
        "Entity": "Normal"
    },
    {
        "Text": "Such multiple associations are due to the fact that political systems are metaphorically viewed as mechanisms, they can function, break, they can be oiled etc.",
        "Entity": "Normal"
    },
    {
        "Text": "We often discuss them using mechanism terminology, and thus a corpus-based distributional learning approach would learn that they share features with political systems (from their literal uses), as well as with mechanisms (from their metaphorical uses, as shown next to the respective graph edges in the        .",
        "Entity": "Normal"
    },
    {
        "Text": "Our system discovers such association patterns within the graph and uses them to identify metaphorical connections between the concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "To the best of our knowledge, our method is the first one to use a hierarchical clustering model for the metaphor processing task.",
        "Entity": "Normal"
    },
    {
        "Text": "The original graph of concepts is built using hierarchical graph factorization clustering (HGFC) (Yu et al., 2006) of nouns, yielding a network of clusters with different levels of generality.",
        "Entity": "Normal"
    },
    {
        "Text": "The weights on the edges of the graph indicate association between the clusters (concepts).",
        "Entity": "Normal"
    },
    {
        "Text": "HGFC has not been previously employed for noun clustering in NLP, but showed successful results in the verb clustering task (Sun and Korhonen, 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "In summary, our system (1) builds a graph of concepts using HGFC, (2) traverses it to find metaphorical associations between clusters using weights on the edges of the graph, (3) generates lists of salient features for the metaphorically connected clusters and (4) searches the British National Corpus (BNC) (Burnard, 2007) for metaphorical expressions describing the target domain concepts using the verbs from the set of salient features.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated the performance of the system with the aid of human judges in precision- and recall-oriented settings.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we compared its performance to that of two baselines, an unsupervised baseline using agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN).",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 Dataset and Feature Extraction.",
        "Entity": "Normal"
    },
    {
        "Text": "Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007).",
        "Entity": "Normal"
    },
    {
        "Text": "We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "The verb lemmas in VERB SUBJECT, VERB DIRECT OBJECT and VERB INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser.",
        "Entity": "Normal"
    },
    {
        "Text": "The feature values were the relative frequencies of the features.",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 Hierarchical Graph Factorization.",
        "Entity": "Normal"
    },
    {
        "Text": "Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005).",
        "Entity": "Normal"
    },
    {
        "Text": "The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one.",
        "Entity": "Normal"
    },
    {
        "Text": "The cluster similarity is measured using linkage criteria (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Ward (1963) measures the decrease in variance for the clusters being merged).",
        "Entity": "Normal"
    },
    {
        "Text": "As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "In a tree, each word can only erarchical clustering tasks (Yu et al., 2006; Sun and Korhonen, 2011), but its hierarchical graph output is also a more suitable representation of the concept graph.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, HGFC can detect the number of levels and the number of clusters on each level of the hierarchical graph automatically.",
        "Entity": "Normal"
    },
    {
        "Text": "This is essential for our task as these settings are difficult to pre- define for a general-purpose concept graph.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a set of nouns, V = {vn}N , the similarity matrix for HGFC is constructed using Jensen Shannon Divergence.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The graph G and the cluster structure can be represented by a bipartite graph K (V, U ).",
        "Entity": "Normal"
    },
    {
        "Text": "V are the vertices on G. U = {up mrepresent the hidden m clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "The matrix B denotes then   m adjacency matrix, with bip being the connec tion weight between the vertex vi and the cluster up.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, B represents the connections between clusters at an upper and lower level of clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "A flat clustering algorithm can be induced by assigning a lower level node to the parent node that has the largest connection weight.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of clusters at any level can be determined by only counting the number of nonempty nodes (namely the nodes that have at least one lower level node associated).",
        "Entity": "Normal"
    },
    {
        "Text": "The bipartite graph K also induces a similarityhave a unique parent cluster at each level.",
        "Entity": "Normal"
    },
    {
        "Text": "Our con (W t) between vi and vj : wt m bip bjp ij = 2:p=1  p = cept graph does not have this constraint: at any level a word can be associated with an arbitrary number of parent clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, not only HGFC outperformed agglomerative clustering methods in hi (B  1BT )ij where   = diag( 1, ...,  m).",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, B can be found by minimizing the divergence distance (  ) between the similarity matrices W and W t: v 1 u 1 2 v v v v 1 2 1 2 1 v v v v v 3 7\n\t\n\t\n\t\t\tv u v 8 v 8 5 2 9 9 v 1 v 2 u 1 v u u 3 q 1 2 v 1 4 u 5 2 v 2 6 6 6 v 3 6 v v 5 v 5 7 4 7 4 u 3 u 2 v 3 v 3 8 8 v v 9 9 (a) (b) (c) (d) (e)         : (a) An undirected graph G representing the similarity matrix; (b) The bipartite graph showing three clusters on G; (c) The induced clusters U ; (d) The new graph G1 over clusters U ; (e) The new bipartite graph over G1 n min   (W, H  H T ), s.t.",
        "Entity": "Normal"
    },
    {
        "Text": "hip = 1 (1) H,  i=1 value of m0 to 800.",
        "Entity": "Normal"
    },
    {
        "Text": "For the subsequent levels, ml is set to the number of nonempty clusters (bipartite H = B  1 ;   (X, Y ) = (xij log ij xij yij   xij + yij ) graph nodes) on the parent level.",
        "Entity": "Normal"
    },
    {
        "Text": "The matrices B and   are initialized randomly.",
        "Entity": "Normal"
    },
    {
        "Text": "We found that the Yu et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) showed that this cost function is non-increasing under the update rule: wij actual initialization values have little impact on the final result.",
        "Entity": "Normal"
    },
    {
        "Text": "The rows in B are normalized after the initialization so the values in each row add up to one.",
        "Entity": "Normal"
    },
    {
        "Text": "For a word vi, the probability of assigning it to clus h ip   hip j (H  H T )ij  p hjp s.t.",
        "Entity": "Normal"
    },
    {
        "Text": "h ip = 1 (2) i ter x(l)   X at level l is given by:   p    p wij (H  H T )ij hip hjp s.t.",
        "Entity": "Normal"
    },
    {
        "Text": "p = wij (3) p(x(l) |vi ) = ... p(x(l) |x(l 1) )...p(x(1) |vi ) j p ij p Xl 1 p x(1)  X1 The cost function can thus be optimized by updating h and   alternately.",
        "Entity": "Normal"
    },
    {
        "Text": "The similarity between clusters p(up, uq ) can be induced from B, as follows: p(up , uq ) = p(up )p(up |uq ) = (BT D 1 B)pq (4) m D = diag(d1 , ..., dn ) where di = bip p=0 We can then construct a new graph G1 (        (d)) with the clusters U as vertices, and the cluster similarity p as the connection weight.",
        "Entity": "Normal"
    },
    {
        "Text": "The clustering algorithm can now be applied again          (e)).",
        "Entity": "Normal"
    },
    {
        "Text": "This process can go on iteratively, leading to a hierarchical graph.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of levels (L) and the number of clusters (ml ) are detected automatically, using the method of Sun and Korhonen (2011).",
        "Entity": "Normal"
    },
    {
        "Text": "Clustering starts with an initial setting of number of clusters (m0) for the first level.",
        "Entity": "Normal"
    },
    {
        "Text": "In our experiment, we set the = (D( 1)  1  1 1 B1 D2 B2 ...Dl Bl )ip (5) Due to the random walk property of the graph, ml is non-increasing for higher levels (Sun and Korhonen, 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "The algorithm can thus terminate when all nouns are assigned to one cluster.",
        "Entity": "Normal"
    },
    {
        "Text": "We run 1000 iterations of updates of h and                    ) for each two adjacent levels.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting graph is composed of a set of bipartite graphs defined by Bl , Bl 1, ..., B1.",
        "Entity": "Normal"
    },
    {
        "Text": "A bipartite graph has a similar structure as in          \n\t\t\tFor a given noun, we can rank the clusters at any level according to the soft assignment probability (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "5).",
        "Entity": "Normal"
    },
    {
        "Text": "The clusters that have no member noun were hidden from the ranking since they do not explicitly represent any concept.",
        "Entity": "Normal"
    },
    {
        "Text": "However, these clusters are still part of the organisation of conceptual space within the model and they contribute to the probability for the clusters on upper levels (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "5).",
        "Entity": "Normal"
    },
    {
        "Text": "We call the view of the hierarchical graph where these empty clusters are hidden an explicit graph.",
        "Entity": "Normal"
    },
    {
        "Text": "The whole algorithm can be summarized as follows: SOURCE: fire TARGET 1: sense hatred emotion passion enthusiasm sentiment hope interest feeling resentment optimism Require: N nouns V , initial number of clusters m1 Compute the similarity matrix W0 from V Build the graph G0 from W0 , l   1 while ml > 1 do Factorize Gl 1 to obtain bipartite graph Kl with the adjacency matrix Bl (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "1, 2 and 3) Build a graph Gl with similarity matrix Wl = hostility excitement anger TARGET 2: coup violence fight resistance clash rebellion battle drive fighting riot revolt war confrontation volcano row revolution struggle TARGET 3: alien immigrant TARGET 4: prisoner hostage inmate BT  1 l Dl Bl according to            l   l + 1 ; ml   No.",
        "Entity": "Normal"
    },
    {
        "Text": "nonempty clusters (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "5) end while return Bl , Bl 1 ...B1 2.3 Identification of Metaphorical Associations.",
        "Entity": "Normal"
    },
    {
        "Text": "Once we obtained the explicit graph of concepts, we can now identify metaphorical associations based on the weights connecting the clusters at different levels (eq.",
        "Entity": "Normal"
    },
    {
        "Text": "5).",
        "Entity": "Normal"
    },
    {
        "Text": "Taking a single noun (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "fire) as input, the system computes the probability of its cluster membership for each cluster at each level, using these weights.",
        "Entity": "Normal"
    },
    {
        "Text": "We expect the cluster membership probabilities to indicate the level of association of the input noun with the clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "The system can then rank the clusters at each level based on these probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "We chose level 3 as the optimal level of generality for our experiments, based on our qualitative analysis of the graph.",
        "Entity": "Normal"
    },
    {
        "Text": "The system selects 6 top- ranked clusters from this level (we expect an average source concept to have no more than 5 typical target associates) and excludes the literal cluster containing the input concept (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "fire flame blaze ).",
        "Entity": "Normal"
    },
    {
        "Text": "The remaining clusters represent the target concepts associated with the input source concept.",
        "Entity": "Normal"
    },
    {
        "Text": "Example output for the input concepts of fire and disease is shown in          \n\t\t\tOne can see from the        that each of the noun-to-cluster mappings represents a new conceptual metaphor, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "EMOTION is FIRE, VIOLENCE is FIRE, CRIME is a DISEASE etc.",
        "Entity": "Normal"
    },
    {
        "Text": "These mappings are exemplified in language by a number of metaphorical expressions (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "His anger will burn him ,  violence flared again ,  it s time they found a cure for corruption ).",
        "Entity": "Normal"
    },
    {
        "Text": "2.4 Identification of Salient Features and.",
        "Entity": "Normal"
    },
    {
        "Text": "Metaphorical Expressions After extracting the source target domain mappings, we now move on to the identification of the cor SOURCE: disease TARGET 1: fraud outbreak offense connection leak count crime violation abuse conspiracy corruption terrorism suicide TARGET 2: opponent critic rival TARGET 3: execution destruction signing TARGET 4: refusal absence fact failure lack delay           Discovered metaphorical associations rage-ncsubj engulf -ncsubj erupt-ncsubj burn-ncsubj light-dobj consume-ncsubj flare-ncsubj sweep-ncsubj spark-dobj battle-dobj gut-idobj smolder-ncsubj ignite-dobj destroy-idobj spread-ncsubj damage-idobj light-ncsubj ravage-ncsubj crackle-ncsubj open-dobj fuel-dobj spray-idobj roar-ncsubj perish-idobj destroy- ncsubj wound-idobj start-dobj ignite-ncsubj injure- idobj fight-dobj rock-ncsubj retaliate-idobj devastate- idobj blaze-ncsubj ravage-idobj rip-ncsubj burn-idobj spark-ncsubj warm-idobj suppress-dobj rekindle-dobj         : Salient features for fire and the violence cluster responding metaphorical expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "The system does this by harvesting the salient features that lead to the input noun being strongly associated with the extracted clusters.",
        "Entity": "Normal"
    },
    {
        "Text": "The salient features are selected by ranking the features according to the joint probability of the feature (f ) occurring both with the input noun (w) and the cluster (c).",
        "Entity": "Normal"
    },
    {
        "Text": "Under a simplified independence assumption, p(w, c|f ) = p(w|f )  p(c|f ).",
        "Entity": "Normal"
    },
    {
        "Text": "p(w|f ) and p(c|f ) are calculated as the ra tio of the frequency of the feature f to the total frequency of the input noun and the cluster respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "The features ranked higher are expected to represent the source domain vocabulary that can be used to metaphorically describe the target concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "We selected the top 50 features from the ranked list.",
        "Entity": "Normal"
    },
    {
        "Text": "Example features (verbs and their grammatical relations) extracted for the source domain noun fire and the violence cluster are shown in          \n\t\t\tWe then refined the lists of features by means of selectional preference (SP) filtering.",
        "Entity": "Normal"
    },
    {
        "Text": "We use SPs to FEELING IS FIRE hope lit (Subj), anger blazed (Subj), optimism raged (Subj), enthusiasm engulfed them (Subj), hatred flared (Subj), passion flared (Subj), interest lit (Subj), fuel resentment (Dobj), anger crackled (Subj), feelings roared (Subj), hostility blazed (Subj), light with hope (Iobj) CRIME IS A DISEASE cure crime (Dobj), abuse transmitted (Subj), eradicate terrorism (Dobj), suffer from corruption (Iobj), diagnose abuse (Dobj), combat fraud (Dobj), cope with crime (Iobj), cure abuse (Dobj), eradicate corruption           Identified metaphorical expressions for the mappings FEELING IS FIRE and CRIME IS A DISEASE quantify how well the extracted features describe the source domain (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "fire).",
        "Entity": "Normal"
    },
    {
        "Text": "We extracted nominal argument distributions of the verbs in our feature lists for VERB SUBJECT, VERB DIRECT OBJECT and VERB INDIRECT OBJECT relations.",
        "Entity": "Normal"
    },
    {
        "Text": "We used the algorithm of Sun and Korhonen (2009) to create SP classes and the measure of Resnik (1993) to quantify how well a particular argument class fits the verb.",
        "Entity": "Normal"
    },
    {
        "Text": "Resnik measures selectional preference strength SR(v) of a predicate as a KullbackLeibler distance between two distributions: the prior probability of the noun class P (c) and the posterior probability of the noun class given the verb P (c|v).",
        "Entity": "Normal"
    },
    {
        "Text": "SR(v) = P (c|v) 3 Evaluation and Discussion.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Baselines.",
        "Entity": "Normal"
    },
    {
        "Text": "AGG: the agglomerative clustering baseline is constructed using SciPy implementation (Oliphant, 2007) of Ward s linkage method (Ward, 1963).",
        "Entity": "Normal"
    },
    {
        "Text": "The output tree is cut according to the number of levels and the number of clusters of the explicit graph detected by HGFC.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting tree is converted into a graph by adding connections from each cluster to all the clusters one level above.",
        "Entity": "Normal"
    },
    {
        "Text": "The connection weight (the cluster distance) is measured using JensenShannon Divergence between the cluster centroids.",
        "Entity": "Normal"
    },
    {
        "Text": "This graph is used in place of the HGFC graph in the metaphor identification experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "WN: in the WN baseline, the WordNet hierarchy is used as the underlying graph of concepts, to which the metaphor extraction method is applied.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a source concept, the system extracts all its sense 1 hypernyms two levels above and subsequently all of their sister terms.",
        "Entity": "Normal"
    },
    {
        "Text": "The hypernyms themselves are considered to represent the literal sense of the source noun and are, therefore, removed.",
        "Entity": "Normal"
    },
    {
        "Text": "The sister terms are kept as potential target domains.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Evaluation of Metaphorical Associations.",
        "Entity": "Normal"
    },
    {
        "Text": "To create our dataset, we extracted 10 common D(P (c|v)||P (c)) = 2:c P (c|v) log P (c) .",
        "Entity": "Normal"
    },
    {
        "Text": "In order source concepts that map to multiple targets from to quantify how well a particular argument class fits the verb, Resnik defines selectional association as AR(v, c) = 1 P (c|v) log P (c|v) .",
        "Entity": "Normal"
    },
    {
        "Text": "We rank the the Master Metaphor List (Lakoff et al., 1991) and linguistic analyses of metaphor (Lakoff and Johnson, 1980; Shutova and Teufel, 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "These SR (v) P (c) nominal arguments of the verbs in our feature lists using their selectional association with the verb, and then only retain the features whose top 5 arguments contain the source concept.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the verb start, that is a common feature for both fire and the violence cluster (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "start a war ,  start a fire ), would be filtered out in this way, whereas the verbs flare or blaze would be retained as descriptive source domain vocabulary.",
        "Entity": "Normal"
    },
    {
        "Text": "We then search the RASP-parsed BNC for grammatical relations, in which the nouns from the target domain cluster appear with the verbs from the source domain vocabulary (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "war blazed  (subj),  to fuel violence  (dobj) for the mapping VIOLENCE is FIRE).",
        "Entity": "Normal"
    },
    {
        "Text": "The system thus annotates metaphorical expressions in text, as well as the corresponding conceptual metaphors, as shown in          \n\t\t\tincluded FIRE, CHILD, SPEED, WAR, DISEASE, BREAKDOWN, CONSTRUCTION, VEHICLE, SYSTEM, BUSINESS.",
        "Entity": "Normal"
    },
    {
        "Text": "Each of the three systems identified 50 source target domain mappings for the given source domains, resulting in a set of 150 conceptual metaphors (each representing a number of submappings since all the target concepts are clusters or synsets).",
        "Entity": "Normal"
    },
    {
        "Text": "These were then evaluated against human judgements in two different experimental settings.",
        "Entity": "Normal"
    },
    {
        "Text": "Setting 1: The judges were presented with a set of conceptual metaphors identified by the three systems, randomized.",
        "Entity": "Normal"
    },
    {
        "Text": "They were asked to annotate the mappings they considered valid.",
        "Entity": "Normal"
    },
    {
        "Text": "In all our experiments, the judges were encouraged to rely on their own intuition of metaphor, but they also reviewed the metaphor annotation guidelines of Shutova and Teufel (2010).",
        "Entity": "Normal"
    },
    {
        "Text": "Two independent judges, both na tive speakers of English, participated in this experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "Their agreement on the task was   = 0.60 (n = 2, N = 150, k = 2) (Siegel and Castellan, 1988).",
        "Entity": "Normal"
    },
    {
        "Text": "The main differences in the annotators  judgements stem from the fact that some metaphorical associations are less obvious and common than others, and thus need more context (or imaginative effort) to establish.",
        "Entity": "Normal"
    },
    {
        "Text": "Such examples, where the judges disagreed included metaphorical mappings such as INTENSITY is SPEED, GOAL is a CHILD, COLLECTION is a SYSTEM, ILLNESS is a BREAKDOWN.",
        "Entity": "Normal"
    },
    {
        "Text": "The system performance was then evaluated against these judgements in terms of precision (P ), i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "the proportion of the valid metaphorical mappings among those identified.",
        "Entity": "Normal"
    },
    {
        "Text": "We calculated system precision (in all experiments) as an average over both annotations.",
        "Entity": "Normal"
    },
    {
        "Text": "HGFC operates with a precision of P = 0.69, whereas the baselines attain P = 0.36 (AGG) and P = 0.29 (WN).",
        "Entity": "Normal"
    },
    {
        "Text": "The precision of an- notator judgements against each other (the human ceiling) is P = 0.80, suggesting that this is a challenging task.",
        "Entity": "Normal"
    },
    {
        "Text": "Setting 2: To measure recall, R, of the systems we asked two annotators (both native speakers with a background in metaphor, different from Setting 1) to write down up to 5 target concepts they strongly associated with each of the 10 source concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "Their annotations were then aggregated into a single metaphor association gold standard, consisting of 63 mappings in total.",
        "Entity": "Normal"
    },
    {
        "Text": "The recall of the systems was measured against this gold standard, resulting in HGFC R = 0.61, AGG R = 0.11 and WN R = 0.03.",
        "Entity": "Normal"
    },
    {
        "Text": "As expected, HGFC outperforms both AGG and WN baselines in both settings.",
        "Entity": "Normal"
    },
    {
        "Text": "AGG has been previously shown to be less accurate than HGFC in the verb clustering task (Sun and Korhonen, 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "Our analysis of the noun clusters indicated that HGFC tends to produce more pure and complete clusters than AGG.",
        "Entity": "Normal"
    },
    {
        "Text": "Another important reason AGG fails is that it by definition organises all concepts into tree and optimises its solution locally, taking into account a small number of clusters at a time.",
        "Entity": "Normal"
    },
    {
        "Text": "However, being able to discover connections between more distant domains and optimising globally over all concepts is crucial for metaphor identification.",
        "Entity": "Normal"
    },
    {
        "Text": "This makes AGG less suitable for the task, as demonstrated by our results.",
        "Entity": "Normal"
    },
    {
        "Text": "However, AGG identified a number of interesting mappings missed by HGFC, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "CAREER IS A CHILD, LANGUAGE IS A SYSTEM, CORRUPTION IS A VEHICLE, EMPIRE IS A CONSTRUCTION, as well as a number of mappings in common with HGFC, e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "DEBATE IS A WAR, DESTRUCTION IS A DISEASE.",
        "Entity": "Normal"
    },
    {
        "Text": "The WN system also identified a few interesting metaphorical mappings (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "COGNITION IS FIRE, EDUCATION IS CONSTRUCTION), but its output is largely dominated by the concepts similar to the source noun and contains some unrelated concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "The comparison of HGFC to WN shows that HGFC identifies meaningful properties and relations of abstract concepts that can not be captured in a tree-like classification (even an accurate, manually created one).",
        "Entity": "Normal"
    },
    {
        "Text": "The latter is more appropriate for concrete concepts, and a more flexible representation is needed to model abstract concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "The fact that both baselines identified some valid metaphorical associations, relying on less suitable conceptual graphs, suggests that our way of traversing the graph is a viable approach in principle.",
        "Entity": "Normal"
    },
    {
        "Text": "HGFC identifies valid metaphorical associations for a range of source concepts.",
        "Entity": "Normal"
    },
    {
        "Text": "On of them (CRIME IS A VIRUS) happened to have been already validated in psychological experiments (Thibodeau and Boroditsky, 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "The most frequent type of error of HGFC is the presence of target clusters similar or closely related to the source noun (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the parent cluster for child).",
        "Entity": "Normal"
    },
    {
        "Text": "The clusters from the same domain can, however, be filtered out if their nouns frequently occur in the same documents with the source noun (in a large corpus), i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "by topical similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "The latter is less likely for the metaphorically connected nouns.",
        "Entity": "Normal"
    },
    {
        "Text": "We intend to implement this improvement in the future version of the system.",
        "Entity": "Normal"
    },
    {
        "Text": "3.3 Evaluation of Metaphorical Expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "For each of the identified conceptual metaphors, the three systems extracted a number of metaphorical expressions from the corpus (average of 430 for HGFC, 148 for AGG, and 855 for WN).",
        "Entity": "Normal"
    },
    {
        "Text": "The expressions were also evaluated against human judgements.",
        "Entity": "Normal"
    },
    {
        "Text": "The judges were presented with a set of randomly sampled sentences containing metaphorical expressions as annotated by the system and by the baselines (200 each), randomized.",
        "Entity": "Normal"
    },
    {
        "Text": "They were asked to mark the tagged expressions that were metaphorical in their judgement as correct.",
        "Entity": "Normal"
    },
    {
        "Text": "Their agreement on the task was   = 0.56 (n = 2, N = 600, k = 2), HLJ 26 [..]\n\t\t\t effective action  was needed to eradicate terrorism, drug-trafficking and corruption.",
        "Entity": "Normal"
    },
    {
        "Text": "EG0 275 In the 1930s the words  means test  was a curse, fuelling the resistance against it both among the unemployed and some of its administrators.",
        "Entity": "Normal"
    },
    {
        "Text": "CRX 1054 [..]\n\t\t\tif the rehabilitative approach were demonstrably successful in curing crime.",
        "Entity": "Normal"
    },
    {
        "Text": "HL3 1206 [..]\n\t\t\the would strive to accelerate progress towards the economic integration of the Caribbean.",
        "Entity": "Normal"
    },
    {
        "Text": "HXJ 121 [..]\n\t\t\tit is likely that some industries will flourish in certain countries as the market widens.",
        "Entity": "Normal"
    },
    {
        "Text": "The system performance against these annotations is P = 0.65 (HGFC), P = 0.47 (AGG) and P = 0.12 (WN).",
        "Entity": "Normal"
    },
    {
        "Text": "The human ceiling for this task was measured at P = 0.79.",
        "Entity": "Normal"
    },
    {
        "Text": "The performance of our unsupervised approach is close to the previous supervised systems of Mason (2004) (accuracy of 0.73) and Shutova et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) (precision of 0.79), however, the results are not directly comparable due to different experimental settings.",
        "Entity": "Normal"
    },
    {
        "Text": "The system errors in this task stem from multiple word senses of the salient features or the source and target sharing some physical properties (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "one can  die from crime  and  die from a disease ).",
        "Entity": "Normal"
    },
    {
        "Text": "Some identified expressions invoke a chain of mappings (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "ABUSE IS A DISEASE, DISEASE IS AN ENEMY for  combat abuse ), however, such chains are not yet incorporated into the system.",
        "Entity": "Normal"
    },
    {
        "Text": "The performance of AGG is higher than in the mappings identification task, since it outputs only few expressions for the incorrect mappings.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, WN tagged a large number of literal expressions due to the incorrect prior identification of the underlying associations.",
        "Entity": "Normal"
    },
    {
        "Text": "Since there is no large metaphor-annotated corpus available, it was impossible for us to reliably evaluate the recall of metaphorical expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "However, we estimated it as a recall of salient features.",
        "Entity": "Normal"
    },
    {
        "Text": "We manually compiled sets of typical features for the 10 source domains, and measured their recall among the top 50 HGFC features at R = 0.70.",
        "Entity": "Normal"
    },
    {
        "Text": "However, in practice the coverage in this task would directly depend on that of the metaphorical associations.",
        "Entity": "Normal"
    },
    {
        "Text": "One of the first attempts to identify and interpret metaphorical expressions in text is the met* system of Fass (1991), that utilizes hand-coded knowledge and detects non-literalness via selectional preference violation.",
        "Entity": "Normal"
    },
    {
        "Text": "In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "CONTAINER-FOR- CONTENT).",
        "Entity": "Normal"
    },
    {
        "Text": "If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones.",
        "Entity": "Normal"
    },
    {
        "Text": "The system of Krishnakumaran and Zhu (2007) uses WordNet (the hyponymy relation) and word bigram counts to predict verbal, nominal and adjectival metaphors at the sentence level.",
        "Entity": "Normal"
    },
    {
        "Text": "The authors discriminate between conventional metaphors (included in WordNet) and novel metaphors.",
        "Entity": "Normal"
    },
    {
        "Text": "Birke and Sarkar (2006) present a sentence clustering approach that employs a set of seed sentences annotated for literalness and computes similarity between the new input sentence and all of the seed sentences.",
        "Entity": "Normal"
    },
    {
        "Text": "The system then tags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%.",
        "Entity": "Normal"
    },
    {
        "Text": "The first system to discover source target domain mappings automatically is CorMet (Mason, 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "It does this by searching for systematic variations in domain-specific verb selectional preferences.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, pour is a characteristic verb in both LAB and FINANCE domains.",
        "Entity": "Normal"
    },
    {
        "Text": "In the LAB domain it has a strong preference for liquids and in the FINANCE domain for money.",
        "Entity": "Normal"
    },
    {
        "Text": "From this the system infers the domain mapping FINANCE   LAB and the concept mapping money   liquid.",
        "Entity": "Normal"
    },
    {
        "Text": "Gedigian et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use.",
        "Entity": "Normal"
    },
    {
        "Text": "They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE for metaphoricity.",
        "Entity": "Normal"
    },
    {
        "Text": "They used PropBank annotation (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%).",
        "Entity": "Normal"
    },
    {
        "Text": "The metaphor identification system of Shutova et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analogies by means of verb and noun clustering.",
        "Entity": "Normal"
    },
    {
        "Text": "As a result, the system can recognize new metaphorical expressions in unrestricted text (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "from the seed  stir excitement  it infers that  swallow anger  is also a metaphor), achieving a precision of 79%.",
        "Entity": "Normal"
    },
    {
        "Text": "Turney et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011) classify verbs and adjectives as literal or metaphorical based on their level of concreteness or abstractness in relation to a noun they appear with.",
        "Entity": "Normal"
    },
    {
        "Text": "They learn concreteness rankings for words automatically (starting from a set of examples) and then search for expressions where a concrete adjective or verb is used with an abstract noun (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "dark humour  is tagged as a metaphor and  dark hair  is not).",
        "Entity": "Normal"
    },
    {
        "Text": "They report an accuracy of 73%.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous research on metaphor addressed a number of different aspects of the phenomenon, and has shown that these aspects can be successfully modeled using statistical techniques.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the methods often focused on a limited domain and needed manually-labeled training data.",
        "Entity": "Normal"
    },
    {
        "Text": "This made them difficult to apply in a real-world setting with the goal of improving semantic interpretation in NLP at large.",
        "Entity": "Normal"
    },
    {
        "Text": "Our method takes a step towards this direction.",
        "Entity": "Normal"
    },
    {
        "Text": "It is fully unsupervised, and thus more robust, and can perform accurate metaphor identification in unrestricted text.",
        "Entity": "Normal"
    },
    {
        "Text": "It identifies metaphor with a precision of 69% and a recall of 61%, which is a very encouraging result for an unsupervised method.",
        "Entity": "Normal"
    },
    {
        "Text": "We believe that this work has important implications for computational and cognitive modeling of metaphor, but is also applicable to a range of other semantic tasks within NLP.",
        "Entity": "Normal"
    },
    {
        "Text": "Integrating different representations of abstract and concrete concepts into NLP systems may improve their performance, as well as make the models more cognitively plausible.",
        "Entity": "Normal"
    },
    {
        "Text": "One of our key future research objectives is to investigate the use and adaptation of the created conceptual graph to perform metaphor interpretation.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we plan to extend this work to cover nominal and adjectival metaphors, by harvesting salient nominal and adjectival features.",
        "Entity": "Normal"
    },
    {
        "Text": "This work was funded by the MetaNet project (grant number W911NF12-C-0022) and the Dorothy Hodgkin Postgraduate Award.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tWe propose the first joint model for word segmentation, POS tagging, and dependency parsing for Chinese.",
        "Entity": "Normal"
    },
    {
        "Text": "Based on an extension of the incremental joint model for POS tagging and dependency parsing (Hatori et al., 2011), we propose an efficient character-based decoding method that can combine features from state-of-the-art segmentation, POS tagging, and dependency parsing models.",
        "Entity": "Normal"
    },
    {
        "Text": "We also describe our method to align comparable states in the beam, and how we can combine features of different characteristics in our incremental framework.",
        "Entity": "Normal"
    },
    {
        "Text": "In experiments using the Chinese Treebank (CTB), we show that the accuracies of the three tasks can be improved significantly over the baseline models, particularly by 0.6% for POS tagging and 2.4% for dependency parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "We also perform comparison experiments with the partially joint models.",
        "Entity": "Normal"
    },
    {
        "Text": "In processing natural languages that do not include delimiters (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "spaces) between words, word segmentation is the crucial first step that is necessary to perform virtually all NLP tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, the word-level information is often augmented with the POS tags, which, along with segmentation, form the basic foundation of statistical NLP.",
        "Entity": "Normal"
    },
    {
        "Text": "Because the tasks of word segmentation and POS tagging have strong interactions, many studies have been devoted to the task of joint word segmentation and POS tagging for languages such as Chinese (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "Kruengkrai et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2009)).",
        "Entity": "Normal"
    },
    {
        "Text": "This is because some of the segmentation ambiguities cannot be resolved without considering the surrounding grammatical constructions encoded in a sequence of POS tags.",
        "Entity": "Normal"
    },
    {
        "Text": "The joint approach to word segmentation and POS tagging has been reported to improve word segmentation and POS tagging accuracies by more than 1% in Chinese (Zhang and Clark, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, some researchers recently proposed a joint approach to Chinese POS tagging and dependency parsing (Li et al., 2011; Hatori et al., 2011); particularly, Ha- tori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011) proposed an incremental approach to this joint task, and showed that the joint approach improves the accuracies of these two tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "In this context, it is natural to consider further a question regarding the joint framework: how strongly do the tasks of word segmentation and dependency parsing interact?",
        "Entity": "Normal"
    },
    {
        "Text": "In the following Chinese sentences:               current peace-prize and peace operation related The current peace prize and peace operations are related.",
        "Entity": "Normal"
    },
    {
        "Text": "current peace award peace operation related group The current peace is awarded to peace-operation-related groups.",
        "Entity": "Normal"
    },
    {
        "Text": "the only difference is the existence of the last word  ; however, whether or not this word existschanges the whole syntactic structure and segmen tation of the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "This is an example in which word segmentation cannot be handled properly without considering long-range syntactic information.",
        "Entity": "Normal"
    },
    {
        "Text": "Syntactic information is also considered beneficial to improve the segmentation of out of- vocabulary (OOV) words.",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike languages such as Japanese that use a distinct character set (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "katakana) for foreign words, the transliterated words in Chinese, many of which are OOV words, frequently include characters that are also used as common or function words.",
        "Entity": "Normal"
    },
    {
        "Text": "In the current systems, the existence of these characters causes numerous over- segmentation errors for OOV words.",
        "Entity": "Normal"
    },
    {
        "Text": "Based on these observations, we aim at building a joint model that simultaneously processes word segmentation, POS tagging, and dependency parsing, trying to capture global interaction among 1045 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1045 1053, Jeju, Republic of Korea, 814 July 2012.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2012 Association for Computational Linguistics these three tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "To handle the increased computational complexity, we adopt the incremental parsing framework with dynamic programming (Huang and Sagae, 2010), and propose an efficient method of character-based decoding over candidate structures.",
        "Entity": "Normal"
    },
    {
        "Text": "Two major challenges exist in formalizing the joint segmentation and dependency parsing task in the character-based incremental framework.",
        "Entity": "Normal"
    },
    {
        "Text": "First, we must address the problem of how to align comparable states effectively in the beam.",
        "Entity": "Normal"
    },
    {
        "Text": "Because the number of dependency arcs varies depending on how words are segmented, we devise a step alignment scheme using the number of character-based arcs, which enables effective joint decoding for the three tasks.",
        "Entity": "Normal"
    },
    {
        "Text": "Second, although the feature set is fundamentally a combination of those used in previous works (Zhang and Clark, 2010; Huang and Sagae, 2010), to integrate them in a single incremental framework is not straightforward.",
        "Entity": "Normal"
    },
    {
        "Text": "Because we must perform decisions of three kinds (segmentation, tagging, and parsing) in an incremental framework, we must adjust which features are to be activated when, and how they are combined with which action labels.",
        "Entity": "Normal"
    },
    {
        "Text": "We have also found that we must balance the learning rate between features for segmentation and tagging decisions, and those for dependency parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "We perform experiments using the Chinese Tree- bank (CTB) corpora, demonstrating that the accuracies of the three tasks can be improved significantly over the pipeline combination of the state-of-the-art joint segmentation and POS tagging model, and the dependency parser.",
        "Entity": "Normal"
    },
    {
        "Text": "We also perform comparison experiments with partially joint models, and investigate the tradeoff between the running speed and the model performance.",
        "Entity": "Normal"
    },
    {
        "Text": "In Chinese, Luo (2003) proposed a joint constituency parser that performs segmentation, POS tagging, and parsing within a single character-based framework.",
        "Entity": "Normal"
    },
    {
        "Text": "They reported that the POS tags contribute to segmentation accuracies by more than 1%, but the syntactic information has no substantial effect on the segmentation accuracies.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, we built a joint model based on a dependency-based framework, with a rich set of structural features.",
        "Entity": "Normal"
    },
    {
        "Text": "Using it, we show the first positive result in Chinese that the segmentation accuracies can be improved using the syntactic information.",
        "Entity": "Normal"
    },
    {
        "Text": "Another line of work exists on lattice-based parsing for Semitic languages (Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008).",
        "Entity": "Normal"
    },
    {
        "Text": "These methods first convert an input sentence into a lattice encoding the morphological ambiguities, and then conduct joint morphological segmentation and PCFG parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the segmentation possibilities considered in those studies are limited to those output by an existing morphological analyzer.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, the lattice does not include word segmentation ambiguities crossing boundaries of space-delimited tokens.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, because the Chinese language does not have spaces between words, we fundamentally need to consider the lattice structure of the whole sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we place no restriction on the segmentation possibilities to consider, and we assess the full potential of the joint segmentation and dependency parsing model.",
        "Entity": "Normal"
    },
    {
        "Text": "Among the many recent works on joint segmentation and POS tagging for Chinese, the linear-time incremental models by Zhang and Clark (2008) and Zhang and Clark (2010) largely inspired our model.",
        "Entity": "Normal"
    },
    {
        "Text": "Zhang and Clark (2008) proposed an incremental joint segmentation and POS tagging model, with an effective feature set for Chinese.",
        "Entity": "Normal"
    },
    {
        "Text": "However, it requires to computationally expensive multiple beams to compare words of different lengths using beam search.",
        "Entity": "Normal"
    },
    {
        "Text": "More recently, Zhang and Clark (2010) proposed an efficient character-based decoder for their word-based model.",
        "Entity": "Normal"
    },
    {
        "Text": "In their new model, a single beam suffices for decoding; hence, they reported that their model is practically ten times as fast as their original model.",
        "Entity": "Normal"
    },
    {
        "Text": "To incorporate the word-level features into the character-based decoder, the features are decomposed into substring-level features, which are effective for incomplete words to have comparable scores to complete words in the beam.",
        "Entity": "Normal"
    },
    {
        "Text": "Because we found that even an incremental approach with beam search is intractable if we perform the word- based decoding, we take a character-based approach to produce our joint model.",
        "Entity": "Normal"
    },
    {
        "Text": "The incremental framework of our model is based on the joint POS tagging and dependency parsing model for Chinese (Hatori et al., 2011), which is an extension of the shift-reduce dependency parser with dynamic programming (Huang and Sagae, 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "They specifically modified the shift action so that it assigns the POS tag when a word is shifted onto the stack.",
        "Entity": "Normal"
    },
    {
        "Text": "However, because they regarded word segmentation as given, their model did not consider the interaction between segmentation and POS tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Incremental Joint Segmentation, POS.",
        "Entity": "Normal"
    },
    {
        "Text": "Tagging, and Dependency Parsing Based on the joint POS tagging and dependency parsing model by Hatori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011), we build our joint model to solve word segmentation, POS tagging, and dependency parsing within a single framework.",
        "Entity": "Normal"
    },
    {
        "Text": "Particularly, we change the role of the shift action and additionally use the append action, inspired by the character-based actions used in the joint segmentation and POS tagging model by Zhang and Clark (2010).",
        "Entity": "Normal"
    },
    {
        "Text": "The list of actions used is the following:   A: append the first character in the queue to the word on top of the stack.",
        "Entity": "Normal"
    },
    {
        "Text": "SH(t): shift the first character in the input queue as a new word onto the stack, with POS tag t.   RL/RR: reduce the top two trees on the stack, (s0, s1), into a subtree s0s1 / s s1, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "We can first think of using the number of shifted characters as the step index, as Zhang and Clark (2010) does.",
        "Entity": "Normal"
    },
    {
        "Text": "However, because RL/RR actions can be performed without incrementing the step index, the decoder tends to prefer states with more dependency arcs, resulting more likely in premature choice of  reduce  actions or oversegmentation of words.",
        "Entity": "Normal"
    },
    {
        "Text": "Alternatively, we can consider using the number of actions that have been applied as the step index, as Hatori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011) does.",
        "Entity": "Normal"
    },
    {
        "Text": "However, this results in inconsistent numbers of actions to reach the terminal states: some states that segment words into larger chunks reach a terminal state earlier than other states with smaller chunks.",
        "Entity": "Normal"
    },
    {
        "Text": "For these reasons, we have found that both approaches yield poor models that are not at all competitive with the baseline (pipeline) models1.",
        "Entity": "Normal"
    },
    {
        "Text": "To address this issue, we propose an indexing scheme using the number of character-based arcs.",
        "Entity": "Normal"
    },
    {
        "Text": "We presume that in addition to the word-to-word dependency arcs, each word (of length M ) implicitly has M   1 inter-character arcs, as in: A B C , 0 0 Although SH(t) is similar to the one used in Hatori A B C , and A BC (each rectangle de et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011), now it shifts the first character in the queue as a new word, instead of shifting a word.",
        "Entity": "Normal"
    },
    {
        "Text": "Following Zhang and Clark (2010), the POS tag is assigned to the word when its first character is shifted, and the word tag pairs observed in the training data and the closed-set tags (Xia, 2000) are used to prune unlikely derivations.",
        "Entity": "Normal"
    },
    {
        "Text": "Because 33 tags are defined in the CTB tag set (Xia, 2000), our model exploits a total of 36 actions.",
        "Entity": "Normal"
    },
    {
        "Text": "To train the model, we use the averaged perceptron with the early update (Collins and Roark, 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "In our joint model, the early update is invoked by mistakes in any of word segmentation, POS tagging, or dependency parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Alignment of States.",
        "Entity": "Normal"
    },
    {
        "Text": "When dependency parsing is integrated into the task of joint word segmentation and POS tagging, it is not straightforward to define a scheme to align (synchronize) the states in the beam.",
        "Entity": "Normal"
    },
    {
        "Text": "In beam search, we use the step index that is associated with each state: the parser states in process are aligned according to the index, and the beam search pruning is applied to those states with the same index.",
        "Entity": "Normal"
    },
    {
        "Text": "Consequently, for the beam search to function effectively, all states with the same index must be comparable, and all terminal states should have the same step index.",
        "Entity": "Normal"
    },
    {
        "Text": "notes a word).",
        "Entity": "Normal"
    },
    {
        "Text": "Then we can define the step index as the sum of the number of shifted characters and the total number of (inter-word and intra-word) dependency arcs, which thereby meets all the following conditions: (1) All subtrees spanning M consecutive characters have the same index 2M   1.",
        "Entity": "Normal"
    },
    {
        "Text": "(2) All terminal states have the same step index 2N (including the root arc), where N is the number of characters in the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "(3) Every action increases the index.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that the number of shifted characters is also necessary to meet condition (3).",
        "Entity": "Normal"
    },
    {
        "Text": "Otherwise, it allows an unlimited number of SH(t) actions without incrementing the step index.",
        "Entity": "Normal"
    },
    {
        "Text": "In our framework, because an action increases the step index by 1 (for SH(t) or RL/RR) or 2 (for A), we need to use two beams to store new states at each step.",
        "Entity": "Normal"
    },
    {
        "Text": "The computational complexity of the entire process is O(B(T + 3)   2N ), where B is the beam 1 For example, in our preliminary experiment on CTB5, the step indexing according to the number of actions underperforms the baseline model by 0.2 0.3% in segmentation accuracy.",
        "Entity": "Normal"
    },
    {
        "Text": "step 1 step 2 1 1 1 step 3 1 1 1 3 step 5 denote the  reduce  actions that determine the word boundary2, whereas RL1/RR1 denote those  reduce  actions that are applied when the word boundary has already been fixed.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, to capture the shared step 6 step 7 step 8 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 nature of boundary determination actions (SH(t), 3 1 1 1 3 1 1 1 1 3 1 1 1 1 1 RL0/RR0), we use a generalized action label SH  to 3 3 3 3 1 5 1 5 1 1 7 3 3 1 1 5 1 1 1 5 3 7 1 represent any of them when combined with W01  W21.",
        "Entity": "Normal"
    },
    {
        "Text": "size, T is the number of POS tags (= 33), and N is the number of characters in the sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Theoretically, the computational time is greater than that with the character-based joint segmentation and tagging model by Zhang and Clark (2010) by a factor of T +3 2N T +1   N ,..\n\t\t\t2.1, when the same beam size is used.",
        "Entity": "Normal"
    },
    {
        "Text": "3.3 Features.",
        "Entity": "Normal"
    },
    {
        "Text": "The feature set of our model is fundamentally a combination of the features used in the state-of-the-art joint segmentation and POS tagging model (Zhang and Clark, 2010) and dependency parser (Huang and Sagae, 2010), both of which are used as baseline models in our experiment.",
        "Entity": "Normal"
    },
    {
        "Text": "However, we must carefully adjust which features are to be activated and when, and how they are combined with which action labels, depending on the type of the features because we intend to perform three tasks in a single incremental framework.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that not all features are always considered: each feature is only considered if the action to be performed is included in the list of actions in the  When to apply  column.",
        "Entity": "Normal"
    },
    {
        "Text": "Because S01  S05 are used to represent the likelihood score of substring sequences, they are only used for A and SH(t) without being combined with any action label.",
        "Entity": "Normal"
    },
    {
        "Text": "Because T01 T05 are used to determine the POS tag of the word being shifted, they are only applied for SH(t).",
        "Entity": "Normal"
    },
    {
        "Text": "Because W01 W21 are used to determine whether to segment at the current position or not, they are only used for those actions involved in boundary determination decisions (A, SH(t), RL0, and RR0).",
        "Entity": "Normal"
    },
    {
        "Text": "The action labels RL0/RR0 are used to level and substring-level scores.",
        "Entity": "Normal"
    },
    {
        "Text": "Regarding the parsing features P01 P28, because we found that P01 P17 are also useful for segmentation decisions, these features are applied to all actions including A, with an explicit distinction of action labels RL0/RR0 from RL1/RR1.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, P18 P28 are only used when one of the parser actions (SH(t), RL, or RR) is applied.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that P07  P09 and P18 P21 (look-ahead features) require the look-ahead information of the next word form and POS tags, which cannot be incorporated straightforwardly in an incremental framework.",
        "Entity": "Normal"
    },
    {
        "Text": "Although we have found that these features can be incorporated using the delayed features proposed by Hatori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011), we did not use them in our current model because it results in the significant increase of computational time.",
        "Entity": "Normal"
    },
    {
        "Text": "3.3.1 Dictionary features Because segmentation using a dictionary alone can serve as a strong baseline in Chinese word segmentation (Sproat et al., 1996), the use of dictionaries is expected to make our joint model more robust and enables us to investigate the contribution of the syntactic dependency in a more realistic setting.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we optionally use four features D01 D04 associated with external dictionaries.",
        "Entity": "Normal"
    },
    {
        "Text": "These features distinguish each dictionary source, reflecting the fact that different dictionaries have different characteristics.",
        "Entity": "Normal"
    },
    {
        "Text": "These features will also be used in our reimplementation of the model by Zhang and Clark (2010).",
        "Entity": "Normal"
    },
    {
        "Text": "3.4 Adjusting the Learning Rate of Features.",
        "Entity": "Normal"
    },
    {
        "Text": "In formulating the three tasks in the incremental framework, we found that adjusting the update rate depending on the type of the features (segmentation/tagging vs. parsing) crucially impacts the final performance of the model.",
        "Entity": "Normal"
    },
    {
        "Text": "To investigate this point, we define the feature vector    and score   of the 2 A reduce action has an additional effect of fixing the boundary of the top word on the stack if the last action was A or SH(t).",
        "Entity": "Normal"
    },
    {
        "Text": "Id Feature template Label When to apply U01 q 1 .e   q 1 .t   A, SH(t) Training Development Test #snt #wrd #snt #wrd #oov #snt #wrd #oov U02,03 q 1 .e q 1 .e   q 1 .t as-is any S01 q 1 .e   c0   A S02 q 1 .t   c0   A, SH(t) S03 q 1 .t   q 1 .b   c0   A S04 q 1 .t   c0   C(q 1 .b)   A S05 q 1 .t   c0   c1   A D01 len(q 1 .w)   i A,SH  A, SH(t), RR/RL0 D02 len(q 1 .w)   q 1 .t   i A,SH  A, SH(t), RR/RL0 D03 len(q 1 .w)   i A,SH  A, SH(t), RR/RL0 D04 len(q 1 .w)   q 1 .t   i A,SH  A, SH(t), RR/RL0 (D01,02: if q 1 .w   Di ; D03,04: if q 1 .w  / Di ) W01,02 q 1 .w q 2 .w   q 1 .w A,SH  A, SH(t), RR/RL0 W03 q 1 .w (for single-char word) A,SH  A, SH(t), RR/RL0 W04 q 1 .b   len(q 1 .w) A,SH  A, SH(t), RR/RL0 CTB5d 16k 438k 804 21k 1.2k 1.9k 50k 3.1k CTB5j 18k 494k 352 6.8k 553 348 8.0k 278 CTB5c 15k 423k - - - - - - CTB6 23k 641k 2.1k 60k 3.3k 2.8k 82k 4.6k CTB7 31k 718k 10k 237k 13k 10k 245k 13k                                 \n\t\t\taction a being applied to the state   as W05 q 1 .e   len(q 1 .w) A,SH  A, SH(t), RR/RL0     W06,07 q 1 .e   c0 q 1 .b   q 1 .e A,SH  A, SH(t), RR/RL0 W08,09 q 1 .w   c0 q 2 .e   q 1 .w A,SH  A, SH(t), RR/RL0  ( , a) =        ( , a) =       st( , a) +  p p( , a) , W10,11 q 1 .b   c0 q 2 .e   q 1 .e A,SH  A, SH(t), RR/RL0 W12 q 2 .w   len(q 1 .w) A,SH  A, SH(t), RR/RL0 W13 len(q 2 .w)   q 1 .w A,SH  A, SH(t), RR/RL0 W14 q 1 .w   q 1 .t A,SH  A, SH(t), RR/RL0 W15 q 2 .t   q 1 .w A,SH  A, SH(t), RR/RL0 W16 q 1 .t   q 1 .w   q 2 .e A,SH  A, SH(t), RR/RL0 W17 q 1 .t   q 1 .w   c0 A,SH  A, SH(t), RR/RL0 W18 q 2 .e   q 1 .w   c0   q1 .t A,SH  A, SH(t), RR/RL0 W19 q 1 .t   q 1 .e A,SH  A, SH(t), RR/RL0 W20 q 1 .t   q 1 .e   c A,SH  A, SH(t), RR/RL0where   st corresponds to the segmentation and tag ging features (those starting with  U ,  S ,  T , or D ), and   p is the set of the parsing features (start ing with  P ).",
        "Entity": "Normal"
    },
    {
        "Text": "Then, if we set  p to a number smaller than 1, perceptron updates for the parsing features will be kept small at the early stage of training because the update is proportional to the values of the W21 q 1 .t   c   cat(q 1 .e) A,SH  A, SH(t), RR/RL0 (W20, W21: c   q 1 .w\\e) feature vector.",
        "Entity": "Normal"
    },
    {
        "Text": "However, even if  p is initially small, T01,02 q 1 .t q 2 .t   q 1 .t SH(t) SH(t) T03,04 q 1 .w c0 SH(t) SH(t) T05 c0   q 1 .t   q 1 .e SH(t) SH(t) P01,02 s0 .w s0 .t A, SH(t), RR/RL0/1 any P03,04 s0 .w   s0 .t s1 .w A, SH(t), RR/RL0/1 any P05,06 s1 .t s1 .w   s1 .t A, SH(t), RR/RL0/1 any P07,08 q0 .w q0 .t A, SH(t), RR/RL0/1 any P09,10 q0 .w   q0 .t s0 .w   s1 .w A, SH(t), RR/RL0/1 any P11,12 s0 .t   s1 .t s0 .t   q0 .t A, SH(t), RR/RL0/1 any P13 s0 .w   s0 .t   s1 .t A, SH(t), RR/RL0/1 any P14 s0 .t   s1 .w   s1 .t A, SH(t), RR/RL0/1 any P15 s0 .w   s1 .w   s1 .t A, SH(t), RR/RL0/1 any P16 s0 .w   s0 .t   s1 .w A, SH(t), RR/RL0/1 any P17 s0 .w   s0 .t   s1 .w   s1 .t A, SH(t), RR/RL0/1 any P18 s0 .t   q0 .t   q1 .t as-is SH(t), RR, RL P19 s1 .t   s0 .t   q0 .t as-is SH(t), RR, RL P20 s0 .w   q0 .t   q1 .t as-is SH(t), RR, RL P21 s1 .t   s0 .w   q0 .t as-is SH(t), RR, RL P22 s1 .t   s1 .rc.t   s0 .t as-is SH(t), RR, RL P23 s1 .t   s1 .lc.t   s0 .t as-is SH(t), RR, RL P24 s1 .t   s1 .rc.t   s0 .w as-is SH(t), RR, RL P25 s1 .t   s1 .lc.t   s0 .w as-is SH(t), RR, RL P26 s1 .t   s0 .t   s0 .rc.t as-is SH(t), RR, RL P27 s1 .t   s0 .w   s0 .lc.t as-is SH(t), RR, RL P28 s2 .t   s1 .t   s0 .t as-is SH(t), RR, RL * q 1 and q 2 respectively denote the last-shifted word and the word shifted before q 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "q.w and q.t respectively denote the (root) word form and POS tag of a subtree (word) q, and q.b and q.e the beginning and ending characters of q.w.",
        "Entity": "Normal"
    },
    {
        "Text": "c0 and c1 are the first and second characters in the queue.",
        "Entity": "Normal"
    },
    {
        "Text": "q.w\\e denotes the set of characters excluding the ending character of q.w.",
        "Entity": "Normal"
    },
    {
        "Text": "len( )denotes the length of the word, capped at 16 if longer.",
        "Entity": "Normal"
    },
    {
        "Text": "cat( ) de notes the category of the character, which is the set of POS tags observed in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Di is a dictionary, a set of words.",
        "Entity": "Normal"
    },
    {
        "Text": "The action label   means that the feature is not combined with any label;  as-is  denotes the use of the default action set  A, SH(t), and RR/RL  as is.",
        "Entity": "Normal"
    },
    {
        "Text": "the global weights for the parsing features will in crease as needed and compensate for the small  p as the training proceeds.",
        "Entity": "Normal"
    },
    {
        "Text": "In this way, we can control the contribution of syntactic dependencies at the early stage of training.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4.3 shows that the best setting we found is  p = 0.5: this result suggests that we probably should resolve remaining errors by preferentially using the local n-gram based features at the early stage of training.",
        "Entity": "Normal"
    },
    {
        "Text": "Otherwise, the premature incorporation of the non-local syntactic dependencies might engender overfitting to the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "4 Experiment 4.1 Experimental.",
        "Entity": "Normal"
    },
    {
        "Text": "Settings We use the Chinese Penn Treebank ver.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1, 6.0, and 7.0 (hereinafter CTB5, CTB6, and CTB7) for evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "These corpora are split into training, development, and test sets, according to previous works.",
        "Entity": "Normal"
    },
    {
        "Text": "For CTB5, we refer to the split by Duan et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) as CTB 5d, and to the split by Jiang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2008) as CTB5j.",
        "Entity": "Normal"
    },
    {
        "Text": "We also prepare a dataset for cross validation: the dataset CTB5c consists of sentences from CTB5 excluding the development and test sets of CTB5d and CTB5j.",
        "Entity": "Normal"
    },
    {
        "Text": "We split CTB 5c into five sets (CTB5c-n), and alternatively use four of these as the training set and the rest as the test set.",
        "Entity": "Normal"
    },
    {
        "Text": "CTB6 is split according to the official split described in the documentation, and CTB7 is split according to Wang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011).",
        "Entity": "Normal"
    },
    {
        "Text": "As external dic94 tionaries, we use the HowNet Word List3, consist ing of 91,015 words, and page names from the Chi- 92 nese Wikipedia4 as of Oct 26, 2011, consisting of 709,352 words.",
        "Entity": "Normal"
    },
    {
        "Text": "These dictionaries only consist of 90 word forms with no frequency or POS information.",
        "Entity": "Normal"
    },
    {
        "Text": "88We use standard measures of word-level preci 76 74 72 70 68 66 Seg ( _p=0.1) Seg ( _p=0.2) Seg ( _p=0.5) 64 Seg ( _p=1.0) Tag ( _p=0.1) Tag ( _p=0.2) 62 Tag ( _p=0.5) Dep ( _p=0.1) Dep ( _p=0.2) Dep ( _p=0.5) sion, recall, and F1 score, for evaluating each task.",
        "Entity": "Normal"
    },
    {
        "Text": "The output of dependencies cannot be correct unless Tag ( _p=1.0) 86 60 0 10 20 30 40 50 60 70 80 Dep ( _p=1.0) 0 10 20 30 40 50 60 70 80 the syntactic head and dependent of the dependency relation are both segmented correctly.",
        "Entity": "Normal"
    },
    {
        "Text": "Following the standard setting in dependency parsing works, we evaluate the task of dependency parsing with the unlabeled attachment scores excluding punctuations.",
        "Entity": "Normal"
    },
    {
        "Text": "Statistical significance is tested by McNemar s test (  : p < 0.05,   : p < 0.01).",
        "Entity": "Normal"
    },
    {
        "Text": "4.2 Baseline and Proposed Models.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the following baseline and proposed models for evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "SegTag: our reimplementation of the joint segmentation and POS tagging model by Zhang and Clark (2010).",
        "Entity": "Normal"
    },
    {
        "Text": "We used the beam of 16, which they reported to achieve the best accuracies.",
        "Entity": "Normal"
    },
    {
        "Text": "Dep : the state-of-the-art dependency parser by Huang and Sagae (2010).",
        "Entity": "Normal"
    },
    {
        "Text": "We used our reimplementation, which is used in Hatori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011).",
        "Entity": "Normal"
    },
    {
        "Text": "Dep: Dep  without look-ahead features.",
        "Entity": "Normal"
    },
    {
        "Text": "TagDep: the joint POS tagging and dependency parsing model (Hatori et al., 2011), where the look-ahead features are omitted.5   SegTag+Dep/SegTag+Dep : a pipeline combination of SegTag and Dep or Dep .",
        "Entity": "Normal"
    },
    {
        "Text": "SegTag+TagDep: a pipeline combination of Seg- Tag and TagDep, where only the segmentation output of SegTag is used as input to TagDep; the output tags of TagDep are used for evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "SegTagDep: the proposed full joint model.",
        "Entity": "Normal"
    },
    {
        "Text": "All of the models described above except Dep  are based on the same feature sets for segmentation and 3 http://www.keenage.com/html/e index.html 4 http://zh.wikipedia.org/wiki 5 We used the original implementation used in Hatori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011).",
        "Entity": "Normal"
    },
    {
        "Text": "In Hatori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "tagging (Zhang and Clark, 2008; Zhang and Clark, 2010) and dependency parsing (Huang and Sagae, 2010).",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, we can investigate the contribution of the joint approach through comparison with the pipeline and joint models.",
        "Entity": "Normal"
    },
    {
        "Text": "4.3 Development Results.",
        "Entity": "Normal"
    },
    {
        "Text": "We have some parameters to tune: parsing feature weight  p, beam size, and training epoch.",
        "Entity": "Normal"
    },
    {
        "Text": "All these parameters are set based on experiments on CTB5c.",
        "Entity": "Normal"
    },
    {
        "Text": "For experiments on CTB5j, CTB6, and CTB7, the training epoch is set using the development set.",
        "Entity": "Normal"
    },
    {
        "Text": "In this experiment, the external dictionaries are not used, and the beam size of 32 is used.",
        "Entity": "Normal"
    },
    {
        "Text": "Interestingly, if we simply set  p to 1, the accuracies seem to converge at lower levels.",
        "Entity": "Normal"
    },
    {
        "Text": "The  p = 0.2 setting seems to reach almost identical segmentation and tagging accuracies as the best setting  p = 0.5, but the convergence occurs more slowly.",
        "Entity": "Normal"
    },
    {
        "Text": "Based on this experiment, we set  p to 0.5 throughout the experiments in this paper.",
        "Entity": "Normal"
    },
    {
        "Text": "Although even the beam size of 32 results in competitive accuracies for word segmentation and POS tagging, the dependency accuracy is affected most by the increase of the beam size.",
        "Entity": "Normal"
    },
    {
        "Text": "of SegTagDep on CTB5c1 w.r.t.",
        "Entity": "Normal"
    },
    {
        "Text": "the beam size.",
        "Entity": "Normal"
    },
    {
        "Text": "iments in this paper, unless otherwise noted.",
        "Entity": "Normal"
    },
    {
        "Text": "97 4.4 Main Results 96.",
        "Entity": "Normal"
    },
    {
        "Text": "In this section, we present experimentally obtained 95results using the proposed and baseline models.",
        "Entity": "Normal"
    },
    {
        "Text": "Irrespective of the existence of the dictionary features, the joint model SegTagDep largely increases the POS tagging and dependency parsing accuracies (by 0.56 0.63% and 2.34 2.44%); the improvements in parsing accuracies are still 94 SegTag (Seg).",
        "Entity": "Normal"
    },
    {
        "Text": "SegTagDep (Seg) SegTag (Tag) SegTag+TagDep (Tag) SegTagDep (Tag) 92 91 90 0.05 0.1 0.2 0.5 1 2 73 72 71 70 SegTag+Dep (Dep) SegTag+TagDep (Dep) SegTagDep (Dep).",
        "Entity": "Normal"
    },
    {
        "Text": "69 0.05 0.1 0.2 0.5 1 2 significant even compared with SegTag+Dep  (the pipeline model with the look-ahead features).",
        "Entity": "Normal"
    },
    {
        "Text": "However, when the external dictionaries are not used ( wo/dict ), no substantial improvements for segmentation accuracies were observed.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, when the dictionaries are used ( w/dict ), the segmentation accuracies are now improved over the baseline model SegTag consistently (on every trial).",
        "Entity": "Normal"
    },
    {
        "Text": "Although the overall improvement in segmentation is only around 0.1%, more than 1% improvement is observed if we specifically examine OOV6 words.",
        "Entity": "Normal"
    },
    {
        "Text": "The difference between  wo/dict  and  w/dict  results suggests that the syntactic dependencies might work as a noise when the segmentation model is insufficiently stable, but the model does improve when it is stable, not receiving negative effects from the syntactic dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "The partially joint model SegTag+TagDep is shown to perform reasonably well in dependency parsing: with dictionaries, it achieved the 2.02% improvement over SegTag+Dep, which is only 0.32% lower than SegTagDep.",
        "Entity": "Normal"
    },
    {
        "Text": "However, whereas Seg- Tag+TagDep showed no substantial improvement in tagging accuracies over SegTag (when the dictionaries are used), SegTagDep achieved consistent improvements of 0.46% and 0.58% (without/with dic 6 We define the OOV words as the words that have not seen in the training data, even when the external dictionaries are used.",
        "Entity": "Normal"
    },
    {
        "Text": "per sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "Each point corresponds to the beam size of 4, 8, 16, 32, (64).",
        "Entity": "Normal"
    },
    {
        "Text": "The beam size of 16 is used for SegTag in SegTag+Dep and SegTag+TagDep.",
        "Entity": "Normal"
    },
    {
        "Text": "tionaries); these differences can be attributed to the combination of the relieved error propagation and the incorporation of the syntactic dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, SegTag+TagDep has OOV tagging accuracies consistently lower than SegTag, suggesting that the syntactic dependency has a negative effect on the POS tagging accuracy of OOV words7.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, this negative effect is not observed for SegTagDep: both the overall tagging accuracy and the OOV accuracy are improved, demonstrating the effectiveness of the proposed model.",
        "Entity": "Normal"
    },
    {
        "Text": "Although SegTagDep takes a few times longer to achieve accuracies comparable to those of SegTag+Dep/TagDep, it seems to present potential 7 This is consistent with Hatori et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011) s observation that although the joint POS tagging and dependency parsing improves the accuracy of syntactically influential POS tags, it has a slight side effect of increasing the confusion between general and proper nouns (NN vs. NR).",
        "Entity": "Normal"
    },
    {
        "Text": "Model Segmentation POS Tagging Dependency wo /di ct S e g T a g + D e p S e g T a g + D e p  S e g T a g + T a g D e p S e g T a g D e p 9 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 2 7 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "2 4 9 1 .",
        "Entity": "Normal"
    },
    {
        "Text": "7 4 5 9 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 2 7 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 8 72.",
        "Entity": "Normal"
    },
    {
        "Text": "94 (+0 .36   ) 74.",
        "Entity": "Normal"
    },
    {
        "Text": "60 (+2 .02   ) 74.",
        "Entity": "Normal"
    },
    {
        "Text": "92 (+2 .34   ) 91.",
        "Entity": "Normal"
    },
    {
        "Text": "86 (+0 .12   ) 58.",
        "Entity": "Normal"
    },
    {
        "Text": "89 ( 0.9 3  ) 92.",
        "Entity": "Normal"
    },
    {
        "Text": "30 (+0 .56   ) 61.",
        "Entity": "Normal"
    },
    {
        "Text": "03 (+1 .21   ) 96.",
        "Entity": "Normal"
    },
    {
        "Text": "19 ( 0.0 3) 72.24 (+0.00) w/ dic t S e g T a g + D e p S e g T a g + D e p  S e g T a g + T a g D e p S e g T a g D e p 9 6 .",
        "Entity": "Normal"
    },
    {
        "Text": "8 2 7 8 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 2 9 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "3 4 6 5 .",
        "Entity": "Normal"
    },
    {
        "Text": "4 4 7 3 .",
        "Entity": "Normal"
    },
    {
        "Text": "5 3 73.",
        "Entity": "Normal"
    },
    {
        "Text": "90 (+0 .37   ) 75.",
        "Entity": "Normal"
    },
    {
        "Text": "45 (+1 .92   ) 75.",
        "Entity": "Normal"
    },
    {
        "Text": "97 (+2 .44   ) 92.",
        "Entity": "Normal"
    },
    {
        "Text": "35 (+0 .01 ) 63.",
        "Entity": "Normal"
    },
    {
        "Text": "20 ( 2.2 4  ) 92.",
        "Entity": "Normal"
    },
    {
        "Text": "97 (+0 .63   ) 67.",
        "Entity": "Normal"
    },
    {
        "Text": "40 (+1 .96   ) 96.",
        "Entity": "Normal"
    },
    {
        "Text": "90 (+0 .08   ) 79.",
        "Entity": "Normal"
    },
    {
        "Text": "38 (+1 .06   )                                                                                                                        \n\t\t\tFigures in parentheses show the differences over SegTag+Dep (  : p < 0.01).",
        "Entity": "Normal"
    },
    {
        "Text": "for greater improvement, especially for tagging and Model CTB6 Test Se CTB7 Test Se parsing accuracies, when a larger beam can be used.",
        "Entity": "Normal"
    },
    {
        "Text": "4.5 Comparison with Other Systems.",
        "Entity": "Normal"
    },
    {
        "Text": "Kruengkrai+  09  is a lattice-based model by Kruengkrai et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2009).",
        "Entity": "Normal"
    },
    {
        "Text": "Zhang  10  is the incremental model by Zhang and Clark (2010).",
        "Entity": "Normal"
    },
    {
        "Text": "These two systems use no external resources other than the CTB corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "Sun+  11  is a CRF-based model (Sun, 2011) that uses a combination of several models, with a dictionary of idioms.",
        "Entity": "Normal"
    },
    {
        "Text": "Wang+  11  is a semi-supervised model by Wang et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2011), which additionally uses the Chinese Gigaword Corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Our models with dictionaries (those marked with  (d) ) have competitive accuracies to other state-of- the-art systems, and SegTagDep(d) achieved the best reported segmentation and POS tagging accuracies, using no additional corpora other than the dictionaries.",
        "Entity": "Normal"
    },
    {
        "Text": "Particularly, the POS tagging accuracy is more than 0.4% higher than the previous best system thanks to the contribution of syntactic dependencies.",
        "Entity": "Normal"
    },
    {
        "Text": "These results also suggest that the use of readily available dictionaries can be more effective than semi-supervised approaches.",
        "Entity": "Normal"
    },
    {
        "Text": "5 Conclusion.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we proposed the first joint model for word segmentation, POS tagging, and dependency parsing in Chinese.",
        "Entity": "Normal"
    },
    {
        "Text": "The model demonstrated substantial improvements on the three tasks over the pipeline combination of the state-of-the-art joint segmentation and POS tagging model, and dependency parser.",
        "Entity": "Normal"
    },
    {
        "Text": "Particularly, results showed that the g Tag Dep g Tag Dep Kruengkrai  09 95.50 90.5095.40 89.86 Wang  11 95.79 91.1295.65 90.46SegTag+Dep 95.46 90.64 72.57 95.49 90.11 71.25 SegTagDep 95.45 91.27 74.88 95.42 90.62 73.58 (diff.)",
        "Entity": "Normal"
    },
    {
        "Text": "-0.01 +0.63   +2.31  -0.07 +0.51   +2.33   SegTag+Dep(d) 96.13 91.38 73.62 95.98 90.68 72.06 SegTagDep(d) 96.18 91.95 75.76 96.07 91.28 74.58 (diff.)",
        "Entity": "Normal"
    },
    {
        "Text": "+0.05 +0.57  +2.14  +0.09  +0.60  +2.52                                                                                                                                                                                                   \n\t\t\tFor word segmentation, although the overall improvement was only around 0.1%, greater than 1% improvements was observed for OOV words.",
        "Entity": "Normal"
    },
    {
        "Text": "We conducted some comparison experiments of the partially joint and full joint models.",
        "Entity": "Normal"
    },
    {
        "Text": "Compared to SegTagDep, SegTag+TagDep performs reasonably well in terms of dependency parsing accuracy, whereas the POS tagging accuracies are more than 0.5% lower.",
        "Entity": "Normal"
    },
    {
        "Text": "In future work, probabilistic pruning techniques such as the one based on a maximum entropy model are expected to improve the efficiency of the joint model further because the accuracies are apparently still improved if a larger beam can be used.",
        "Entity": "Normal"
    },
    {
        "Text": "More efficient decoding would also allow the use of the look-ahead features (Hatori et al., 2011) and richer parsing features (Zhang and Nivre, 2011).",
        "Entity": "Normal"
    },
    {
        "Text": "Acknowledgement We are grateful to the anonymous reviewers for their comments and suggestions, and to Xianchao Wu, Kun Yu, Pontus Stenetorp, and Shin- suke Mori for their helpful feedback.",
        "Entity": "Normal"
    },
    {
        "Text": "\n\t\n\t\tIn this paper we present a new, multi  lingual data-driven method for coreference resolution as implemented in the SWIZZLE system.",
        "Entity": "Normal"
    },
    {
        "Text": "The results obtained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the indi  vidual languages.",
        "Entity": "Normal"
    },
    {
        "Text": "The recent availability of large bilingual corpora has spawned interest in several areas of multilingual text processing.",
        "Entity": "Normal"
    },
    {
        "Text": "Most of the research has focused on bilingual terminology identification, either as par  allel multiwords forms (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the Champollion sys  tem (Smadja et al.1996)), technical terminology (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the Termight system (Dagan and Church, 1994) or broad-coverage translation lexicons (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the SABLE system (Resnik and Melamed, 1997)).",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, the Multilingual Entity Task (MET) from the TIP  STER program1 (http://wwwnlpir.nist.govjrelated  projectsjtipsterjmet.htm) challenged the partici  pants in the Message Understanding Conference (MUC) to extract named entities across several for  eign language corpora, such as Chinese, Japanese and Spanish.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper we present a new application of aligned multilingual texts.",
        "Entity": "Normal"
    },
    {
        "Text": "Since coreference reso  lution is a pervasive discourse phenomenon causing performance impediments in current IE systems, we considered a corpus of aligned English and Roma  nian texts to identify coreferring expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "Our task focused on the same kind of coreference as considered in the past MUC competitions, namely 1The TIPSTER Text Program was a DARPA-led government effort to advance the state of the art in text processing technologies.",
        "Entity": "Normal"
    },
    {
        "Text": "Steven J. Maiorano IPO Washington, D.C. 20505 maiorano cais.com the identity coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Identity coreference links nouns, pronouns and noun phrases (including proper names) to their corresponding antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "We created our bilingual collection by translating the MUC6 and MUC7 coreference training texts into Romanian using native speakers.",
        "Entity": "Normal"
    },
    {
        "Text": "The train  ing data set for Romanian coreference used, wher  ever possible, the same coreference identifiers as the English data and incorporated additional tags as needed.",
        "Entity": "Normal"
    },
    {
        "Text": "Our claim is that by adding the wealth of coreferential features provided by multilingual data, new powerful heuristics for coreference resolu  tion can be developed that outperform monolingual coreference resolution systems.",
        "Entity": "Normal"
    },
    {
        "Text": "For both languages, we resolved coreference by using SWIZZLE, our implementation of a bilingual coreference resolver.",
        "Entity": "Normal"
    },
    {
        "Text": "SWIZZLE is a multilingual en  hancement of COCKTAIL (Harabagiu and Maiorano, 1999), a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information2   When COCKTAIL was applied separately on the English and the Ro  manian texts, coreferring links were identified for each English and Romanian document respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "When aligned referential expressions corefer with nonaligned anaphors, SWIZZLE derived new heuris  tics for coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Our experiments show that SWIZZLE outperformed COCKTAIL on both English and Romanian test documents.",
        "Entity": "Normal"
    },
    {
        "Text": "The rest of the paper is organized as follows.",
        "Entity": "Normal"
    },
    {
        "Text": "Sec  tion 2 presents COCKTAIL, a monolingual coreference resolution system used separately on both the En  glish and Romanian texts.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 3 details the data-driven approach used in SWIZZLE and presents some of its resources.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 4 reports and discusses the experimental results.",
        "Entity": "Normal"
    },
    {
        "Text": "Section 5 summarizes the 2 The name of COCKTAIL is a pun on CogNIAC be  cause COCKTAIL combines a larger number of heuristics than those reported in (Baldwin, 1997).",
        "Entity": "Normal"
    },
    {
        "Text": "SWIZZLE, more  over, adds new heuristics, discovered from the bilingual aligned corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "conclusions.",
        "Entity": "Normal"
    },
    {
        "Text": "Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques.",
        "Entity": "Normal"
    },
    {
        "Text": "Traditionally, these techniques have combined extensive syntactic, se  mantic, and discourse knowledge.",
        "Entity": "Normal"
    },
    {
        "Text": "The acquisition of such knowledge is time-consuming, difficult, and error-prone.",
        "Entity": "Normal"
    },
    {
        "Text": "Nevertheless, recent results show that knowledge-poor methods perform with amazing ac  curacy (cf.",
        "Entity": "Normal"
    },
    {
        "Text": "(Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).",
        "Entity": "Normal"
    },
    {
        "Text": "For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference.",
        "Entity": "Normal"
    },
    {
        "Text": "For this research, we used a coreference resolution sys  tem ((Harabagiu and Maiorano, 1999)) that imple  ments different sets of heuristics corresponding to various forms of coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "term repetition) combined with lexical and textual coherence cues (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "subjects of communication verbs are more likely to refer to the last person mentioned in the text).",
        "Entity": "Normal"
    },
    {
        "Text": "These constraints are implemented as a set of heuristics ordered by their priority.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, the COCKTAIL framework uniformly addresses the prob  lem of interaction between different forms of coref  erence, thus making the extension to multilingual coreference very natural.",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 Data-Driven Coreference Resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "In general, we define a data-driven methodology as a sequence of actions that captures the data pat  terns capable of resolving a problem with both a high degree of precision and recall.",
        "Entity": "Normal"
    },
    {
        "Text": "Our data-driven methodology reported here generated sets of heuris  tics for the coreference resolution problem.",
        "Entity": "Normal"
    },
    {
        "Text": "Precision is the number of correct references out of the total number of coreferences resolved, whereas the recall measures the number of resolved references out of the total number of keys, i.e., the annotated coref  erence data.",
        "Entity": "Normal"
    },
    {
        "Text": "The data-driven methodology used in COCKTAIL is centered around the notion of a coreference chain.",
        "Entity": "Normal"
    },
    {
        "Text": "Due to the transitivity of coreference relations, k coreference relations having at least one common ar  gument generate k + 1 core/erring expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "The text position induces an order among coreferring ex  pressions.",
        "Entity": "Normal"
    },
    {
        "Text": "A coreference structure is created when a set of coreferring expressions are connected in an oriented graph such that each node is related only to one of its preceding nodes.",
        "Entity": "Normal"
    },
    {
        "Text": "In turn, a corefer ence chain is the coreference structure in which ev  ery node is connected to its immediately preceding node.",
        "Entity": "Normal"
    },
    {
        "Text": "Clearly, multiple coreference structures for the same set of coreferring expressions can be mapped to a single coreference chain.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, both coreference structures illustrated in         (a) and (c) are cast into the coreference chain illustrated in         (b).",
        "Entity": "Normal"
    },
    {
        "Text": "TEXT TEXT TEXT         : Three coreference structures.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a corpus annotated with coreference data, the data-driven methodology first generates all coreference chains in the data set and then con  siders all possible combinations of coreference re  lations that would generate the same coreference chains.",
        "Entity": "Normal"
    },
    {
        "Text": "For a coreference chain of length l with nodes n1, n2, ... nl+1 , each node nk (1 k l) can be connected to any of the l - k nodes preceding it.",
        "Entity": "Normal"
    },
    {
        "Text": "From this observation, we find that a number of 1 x 2 x ... x (l - k)... x l = l!",
        "Entity": "Normal"
    },
    {
        "Text": "coreference struc  tures can generate the same coreference chain.",
        "Entity": "Normal"
    },
    {
        "Text": "This result is very important, since it allows for the auto  matic generation of coreference data.",
        "Entity": "Normal"
    },
    {
        "Text": "For each coref  erence relation n from an annotated corpus we cre  ated a median of (l- 1)!",
        "Entity": "Normal"
    },
    {
        "Text": "new coreference relations, where l is the length of the coreference chain contain  ing relation n. This observation gave us the possi  bility of expanding the test data provided by the coreference keys available in the MUC6 and MUC 7 competitions (MUC6 1996), (MUC7 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "The MUC6 coreference annotated corpus contains 1626 coreference relations, while the MUC7 corpus has 2245 relations.",
        "Entity": "Normal"
    },
    {
        "Text": "The average length of a coreference chain is 7.21 for the MUC6 data, and 8.57 for the MUC7 data.",
        "Entity": "Normal"
    },
    {
        "Text": "We were able to expand the number of annotated coreference relations to 6,095,142 for the MUC6 corpus and to 8,269,403 relations for the MUC7 corpus; this represents an expansion factor of 3,710.",
        "Entity": "Normal"
    },
    {
        "Text": "We are not aware of any other automated way of creating coreference annotated data, and we believe that much of the COCKTAIL's impressive per  formance is due to the plethora of data provided by this method.",
        "Entity": "Normal"
    },
    {
        "Text": "He uri sti cs for 3r d pe rs on pr on ou ns He uri sti cs for no mi na l ref er en ce oH eu ris tic 1 Pr on ou n( Hl Pr on ) Se ar ch in the sa me se nte nc e for the sa m e 3 r d p e r s o n p r o n o u n P r o n ' i f ( P r o n ' b e l o n g s t o c o r e f e r e n c e c h a i n C C ) a n d t h e r e i s a n e l e m e n t f r o m C C w h i c h i s c l o s e s t t o P r o n i n T e x t , P i c k t h a t e l e m e n t .",
        "Entity": "Normal"
    },
    {
        "Text": "e l s e P i c k P r o n ' .",
        "Entity": "Normal"
    },
    {
        "Text": "oH eur isti c 2 Pr on ou n( H2 Pr on ) Se ar ch for PN , the clo ses t pr op er na me fro m Pr on if (P N agr ees in nu mb er an d ge nd er wit h Pr on ) i f ( P N b e l o n g s t o c o r e f e r e n c e c h a i n C C ) t h e n P i c k t h e e l e m e n t f r o m C C w h i c h i s c l o s e s t t o P r o n i n T e x t .",
        "Entity": "Normal"
    },
    {
        "Text": "e l s e P i c k P N .",
        "Entity": "Normal"
    },
    {
        "Text": "o He uri sti c 3 Pr on ou n( H3 Pr on ) Se arc h for No un, the clo ses t no un fro m Pr on if (N ou n agr ees in nu mb er an d ge nd er wit h Pr on) i f ( N o u n b e l o n g s t o c o r e f e r e n c e c h a i n C C ) a n d t h e r e i s a n e l e m e n t f r o m C C w h i c h i s c l o s e s t t o P r o n i n T e x t , P i c k t h a t e l e m e n t .",
        "Entity": "Normal"
    },
    {
        "Text": "e l s e P i c k N o u n oH eu ris tic 1 No mi na lC Hl No m) if (N ou n is the he ad of an ap po siti ve ) t h e n P i c k t h e p r e c e d i n g N P .",
        "Entity": "Normal"
    },
    {
        "Text": "o He uri sti c 2 No mi nal (H 2N o m) if (N ou n bel on gs to an NP , Se ar ch for N P' s u c h t h a t N o u n ' = s a m e _ n a m e ( h e a d ( N P ) , h e a d ( N P ' ) ) o r N o u n ' = s a m e _ n a m e ( a d j u n c t ( N P ) , a d j u n c t ( N P ' ) ) ) t h e n i f ( N o u n ' b e l o n g s t o c o r e f e r e n c e c h a i n C C ) t h e n P i c k t h e e l e m e n t f r o m C C w h i c h i s c l o s e s t t o N o u n i n T e x t .",
        "Entity": "Normal"
    },
    {
        "Text": "e l s e P i c k N o u n ' .",
        "Entity": "Normal"
    },
    {
        "Text": "oH eu ris tic 3 No mi na l( H3 No m) if No un is the he ad of an N P t h e n S e a r c h f o r p r o p e r n a m e P N s u c h t h a t h e a d ( P N ) = N o u n i f ( P N b e l o n g s t o c o r e f e r e n c e c h a i n C C ) a n d t h e r e i s a n e l e m e n t f r o m C C w h i c h i s c l o s e s t t o N o u n i n T e x t , P i c k t h a t e l e m e n t .",
        "Entity": "Normal"
    },
    {
        "Text": "e l s e P i c k P N .",
        "Entity": "Normal"
    },
    {
        "Text": ": Best performing heuristics implemented in COCKTAIL 2.2 Knowledge-Poor Coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Resolution The result of our data-driven methodology is the set of heuristics implemented in COCKTAIL which cover both nominal and pronoun coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Each heuristic represents a pattern of coreference that was mined from the large set of coreference data.",
        "Entity": "Normal"
    },
    {
        "Text": "COCKTAIL uses knowledge-poor methods because (a) it is based only on a limited number of heuristics and (b) text processing is limited to part-of-speech tagging, named-entity recognition, and approximate phrasal parsing.",
        "Entity": "Normal"
    },
    {
        "Text": "The heuristics from COCKTAIL can be classified along two directions.",
        "Entity": "Normal"
    },
    {
        "Text": "First of all, they can be grouped according to the type of corefer  ence they resolve, e.g., heuristics that resolve the anaphors of reflexive pronouns operate differently than those resolving bare nominals.",
        "Entity": "Normal"
    },
    {
        "Text": "Currently, in COCKTAIL there are heuristics that resolve five types of pronouns (personal, possessive, reflexive, demon  strative and relative) and three forms of nominals (definite, bare and indefinite).",
        "Entity": "Normal"
    },
    {
        "Text": "Secondly, for each type of coreference, there are three classes of heuristics categorized according to their suitability to resolve coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "The first class is comprised of strong indicators of coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "This class resulted from the analysis of the distribu  tion of the antecedents in the MUC annotated data.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, repetitions of named entities and ap  positives account for the majority of the nominal coreferences, and, therefore, represent anchors for the first class of heuristics.",
        "Entity": "Normal"
    },
    {
        "Text": "The second class of coreference covers cases in which the arguments are recognized to be seman  tically consistent.",
        "Entity": "Normal"
    },
    {
        "Text": "COCKTAIL's test of semantic con  sistency blends together information available from WordNet and statistics gathered from Treebank.",
        "Entity": "Normal"
    },
    {
        "Text": "Different consistency checks are modeled for each of the heuristics.",
        "Entity": "Normal"
    },
    {
        "Text": "Ex a m pl e of th e ap pli ca tio n of he ur ist ic H 2 Pr on M r. A da m s 1 , 69 ye ar s ol d, is th e re tir ed ch ai r m an o f C a n a d ia n b a s e d E m c o L t d ., a m a k e r o f p l u m b i n g a n d p et r o le u m e q u i p m e n t; h e 1 h a s s e r v e d o n t h e W o o l w o rt h b o a r d si n c e 1 9 8 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Ex a m pl e of th e ap pli ca tio n of he ur ist ic H 3 Pr on \" W e ha ve go t to st op po in ti ng ou r fi ng er s at th es e k i d s 2 w h o h a v e n o f u t u r e , \" h e s a i d , \" a n d r e a c h o u r h a n d s o u t t o t h e m 2 .",
        "Entity": "Normal"
    },
    {
        "Text": "Ex a m pl e of th e ap pli ca tio n of he ur ist ic H 2 N o m T he ch air m an an d th e ch ief ex ec uti ve of fi ce r3 o f W o o l w o r t h C o r p .",
        "Entity": "Normal"
    },
    {
        "Text": "h a v e t e m p o r a r i l y r e l i n q u i s h e d t h e i r p o s t s w h i l e t h e r e t a i l e r c o n d u c t s i t s i n v e s t i g a t i o n i n t o a l l e g e d a c c o u n t i n g i r r e g u l a r i t i e s 4 .",
        "Entity": "Normal"
    },
    {
        "Text": "W o o l w o rt h' s b o a r d n a m e d J o h n W .",
        "Entity": "Normal"
    },
    {
        "Text": "A d a m s, a n o u ts i d e r, t o s e r v e a s i n t e ri m c h a ir m a n a n d e x e c u ti v e o ff i c e r 3 , w h il e a s p e c i a l c o m m it t e e, a p p o i n t e d b y t h e b o a r d l a st w e e k a n d l e d b y M r. A d a m s, i n v e st i g a t e s t h e al le g e d ir r e g u l a ri ti e s 4 .",
        "Entity": "Normal"
    },
    {
        "Text": ": Examples of coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "The same annotated index indicates coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "The third class of heuristics resolves coreference by coercing nominals.",
        "Entity": "Normal"
    },
    {
        "Text": "Sometimes coercions involve only derivational morphology - linking verbs with their nominalizations.",
        "Entity": "Normal"
    },
    {
        "Text": "On other occasions, coercions are obtained as paths of meronyms (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "is-part re  lations) and hypernyms (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "is-a relations).",
        "Entity": "Normal"
    },
    {
        "Text": "Con sistency checks implemented for this class of coref  erence are conservative: either the adjuncts must be identical or the adjunct of the referent must be less specific than the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "lists the top performing heuristics of COCKTAIL for pronominal and nominal coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Examples of the heuristics operation on the MUC data are presented presented in         \n\t\t\tDetails of the top performing heuris  tics of COCKTAIL were reported in (Harabagiu and Maiorano, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "2.3 Bootstrapping for Coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Resolution One of the major drawbacks of existing corefer  ence resolution systems is their inability to recog  nize many forms of coreference displayed by many real-world texts.",
        "Entity": "Normal"
    },
    {
        "Text": "Recall measures of current systems range between 36% and 59% for both knowledge  based and statistical techniques.",
        "Entity": "Normal"
    },
    {
        "Text": "Knowledge based  systems would perform better if more coreference constraints were available whereas statistical meth  ods would be improved if more annotated data were available.",
        "Entity": "Normal"
    },
    {
        "Text": "Since knowledge-based techniques out  perform inductive methods, we used high-precision coreference heuristics as knowledge seeds for ma  chine learning techniques that operate on large amounts of unlabeled data.",
        "Entity": "Normal"
    },
    {
        "Text": "One such technique is bootstrapping, which was recently presented in (Riloff and Jones 1999), (Jones et al.1999) as an ideal framework for text learning tasks that have knowledge seeds.",
        "Entity": "Normal"
    },
    {
        "Text": "The method does not require large training sets.",
        "Entity": "Normal"
    },
    {
        "Text": "We extended COCKTAIL by using meta  bootstrapping of both new heuristics and clusters of nouns that display semantic consistency for corefer  ence.",
        "Entity": "Normal"
    },
    {
        "Text": "The coreference heuristics are the seeds of our bootstrapping framework for coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "When applied to large collections of texts, the heuristics determine classes of coreferring expres  sions.",
        "Entity": "Normal"
    },
    {
        "Text": "By generating coreference chains out of all these coreferring expressions, often new heuristics are uncovered.",
        "Entity": "Normal"
    },
    {
        "Text": "For example,          illustrates the application of three heuristics and the generation of data for a new heuristic rule.",
        "Entity": "Normal"
    },
    {
        "Text": "In COCKTAIL, after a heuristic is applied, a new coreference chain is cal  culated.",
        "Entity": "Normal"
    },
    {
        "Text": "For the example illustrated in         , if the reference of expression A is sought, heuristic Hl the FOIL-Gain measure, as introduced by the FOIL inductive algorithm (CameronJones and Quinlan 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Let H0 be the new heuristic and H1 a heuris  tic that is already in the seed set.",
        "Entity": "Normal"
    },
    {
        "Text": "Let Po be the num  ber of positive coreference examples of Hnew (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "the number of coreference relations produced by the heuristic that can be found in the test data) and n0 the number of negative examples of Hnew (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "the number of relations generated by the heuristic which cannot be found in the test data).",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, P1 and n1 are the positive and negative examples of H1   The new heuristics are scored by their FOJL_Gain distance to the existing set of heuristics, and the best scoring one is added to the COCKTAIL system.",
        "Entity": "Normal"
    },
    {
        "Text": "The FOILGain formula is: FOILGain(H1,Ho) = k(log2 Pl log2 Po ) P1 + n1 Po+ no where k is the number of positive examples cov  ered by both H1 and Ho.",
        "Entity": "Normal"
    },
    {
        "Text": "Heuristic Ho is added to the seed set if there is no other heuristic providing larger FOILGain to any of the seed heuristics.",
        "Entity": "Normal"
    },
    {
        "Text": "Since in COCKTAIL, semantic consistency of core  ferring expressions is checked by comparing the sim  ilarity of noun classes, each new heuristic deter  mines the adjustment of the similarity threshold of all known coreferring noun classes.",
        "Entity": "Normal"
    },
    {
        "Text": "The steps of the bootstrapping algorithm that learns both new heuristics and adjusts the similarity threshold of coreferential expressions is: MUTUAL BOOTSTRAPPING LOOP 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Score all candidate heuristics with FOIL-.",
        "Entity": "Normal"
    },
    {
        "Text": "Gain 2.",
        "Entity": "Normal"
    },
    {
        "Text": "BesLh=closest candidate to.",
        "Entity": "Normal"
    },
    {
        "Text": "heuristics(COCKTAIL)\n\t\n\t\n\t\t\theuristics(COCKTAIL)\n\t\n\t\n\t\t\tsemantic consistency of core/erring nouns\n\t\n\t\n\t\t\tnot degrade under minimal performance.",
        "Entity": "Normal"
    },
    {
        "Text": "indicates expression B to be the antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "When the coreference chain is built, expression A is di  rectly linked to expression D, thus uncovering a new heuristic HO.",
        "Entity": "Normal"
    },
    {
        "Text": "As a rule of thumb, we do not consider a new heuristic unless there is massive evidence of its cov  erage in the data.",
        "Entity": "Normal"
    },
    {
        "Text": "To measure the coverage we use (Riloff and Jones 1999) note that the bootstrap  ping algorithm works well but its performance can deteriorate rapidly when non coreferring data enter as candidate heuristics.",
        "Entity": "Normal"
    },
    {
        "Text": "To make the algorithm more robust, a second level of bootstrapping can be intro  duced.",
        "Entity": "Normal"
    },
    {
        "Text": "The outer bootstrapping mechanism, called metabootstrapping compiles the results of the inner (mutual) bootstrapping process and identifies the k most reliable heuristics, where k is a number de  termined experimentally.",
        "Entity": "Normal"
    },
    {
        "Text": "These k heuristics are re  tained and the rest of them are discarded.",
        "Entity": "Normal"
    },
    {
        "Text": "3 SWIZZLE.",
        "Entity": "Normal"
    },
    {
        "Text": "3.1 Multilingual Coreference Data.",
        "Entity": "Normal"
    },
    {
        "Text": "To study the performance of a data-driven multi  lingual coreference resolution system, we prepared a corpus of Romanian texts by translating the MUC6 and MUC7 coreference training texts.",
        "Entity": "Normal"
    },
    {
        "Text": "The transla  tions were performed by a group of four Romanian native speakers, and were checked for style by a cer  tified translator from Romania.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, the Ro  manian texts were annotated with coreference keys.",
        "Entity": "Normal"
    },
    {
        "Text": "Two rules were followed when the annotations were done: o1: Whenever an expression ER represents a trans  lation of an expression EE from the corresponding English text, if EE is tagged as a coreference key with identification number ID, then the Romanian expression ER is also tagged with the same ID num  ber.",
        "Entity": "Normal"
    },
    {
        "Text": "This rule allows for translations in which the textual position of the referent and the antecedent have been swapped.",
        "Entity": "Normal"
    },
    {
        "Text": "o2: Since the translations often introduce new coreferring expressions in the same chain, the new expressions are given new, unused ID numbers.",
        "Entity": "Normal"
    },
    {
        "Text": "For example,         lists corresponding English and Romanian fragments of coreference chains from the original MUC6 Wall Street Journal document DOCNO: 9307290143.\n\t\t\t        also shows the original MUC coreference SGML annotations.",
        "Entity": "Normal"
    },
    {
        "Text": "Whenever present, the REF tag indicates the ID of the antecedent, whereas the MIN tag indicates the minimal reference expression.",
        "Entity": "Normal"
    },
    {
        "Text": "3.2 Lexical Resources.",
        "Entity": "Normal"
    },
    {
        "Text": "The multilingual coreference resolution method im  plemented in SWIZZLE incorporates the heuristics de  rived from COKCTAIL's monolingual coreference res  olution processing in both languages.",
        "Entity": "Normal"
    },
    {
        "Text": "To this end, COCKTAIL required both sets of texts to be tagged for part-of-speech and to recognize the noun phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "The English texts were parsed with Brill's part-of  speech tagger (Brill1992) and the noun phrases were identified by the grammar rules implemented in the phrasal parser of FASTUS (Appelt et al., 1993).",
        "Entity": "Normal"
    },
    {
        "Text": "Cor  responding resources are not available in Romanian.",
        "Entity": "Normal"
    },
    {
        "Text": "To minimize COCKTAIL's configuration for process  ing Romanian texts, we implemented a Romanian part-of-speech rule-based tagger that used the same Economic adviser Gene Sperling described <COREF ID=\"29\" TYPE=\"IDENT\" REF=\"30\"> it< /COREF> as \"a true full-court press\" to pass <COREF ID=\"31\" TYPE=\"IDENT\" REF=\"26\" MIN=\"bill\">the <COREF ID=\"32\" TYPE=\"IDENT\" REF=\"lO\" MIN=\"reduction\"> <COREF ID=\"33\" TYPE=\"IDENT\" REF=\"12\"> deficit< /COREF>-reduction< /COREF> bill, the final version of which is now being hammered out by <COREF ID=\"43\">House < /COREF> and <COREF ID=\"41\" >Senate < JCOREF>negotiators< /COREF>.",
        "Entity": "Normal"
    },
    {
        "Text": "<COREF ID=\"34\" TYPE=\"IDENT\" REF=\"2\"> The executives< /COREF>' backing- however tepid - gives the administration a way to counter <COREF ID=\"35\" TYPE=\"IDENT\" REF=\"36\"> business< /COREF> critics of <COREF ID=\"500\" TYPE=\"IDENT\" REF=\"31\" MIN=\"package\" STATUS=\"OPT\">the overall package < JCOREF>,...\n\t\t\tConsilierul cu probleme economice Gene Sperling a descris-<COREF ID=\"29\" TYPE=\"IDENT\" REF=\"30\">o< /COREF> cape un efort de avengura menit sa promoveze <COREF ID=\"1125\" TYPE=\"IDENT\" REF=\"26\" MIN=\"legea\">legea < JCOREF> pentru <COREF TYPE=\"IDENT\" REF=\"10\" MIN=\"reducerea\" > reducerea < /COREF><COREF ID=\"33\" TYPE=\"IDENT\" REF=\"12\"> deficitului in bugetul SUA< /COREF>.",
        "Entity": "Normal"
    },
    {
        "Text": "Versiunea finala a acestei <COREF ID=\"1126\" TYPE=\"IDENT\" REF=\"1125\" MIN=\"legi\">legi < JCOREF> este desfiin ata chiar in aceste zile in cadrul dezbaterilor ce au loc in <COREF ID=\"43\" >Camera Reprezentativilor < /COREF>  i in <COREF ID=\" 41\" > Senat< /COREF>< /COREF>.",
        "Entity": "Normal"
    },
    {
        "Text": "Sprijinirea <COREF ID=\"127\" TYPE=\"IDENT\" REF=\"ll26\" MIN=\"legii\">legii> /COREF> de catre speciali ti ineconomiede i in maniera moderataofera administratiei o modalitate de a contrabalansa criticile aduse <COREF ID=\"500\" TYPE=\"IDENT\" REF=\"31\" MIN=\"legii\" STATUS=\"OPT\">legii< /COREF> de catre companiile americane,...\n\t\t\t       : Example of parallel English and Romanian text annotated for coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "The elements from a coreference chain in the respective texts are under  lined.",
        "Entity": "Normal"
    },
    {
        "Text": "The English text has only two elements in the coreference chain, whereas the Romanian text con  tains four different elements.",
        "Entity": "Normal"
    },
    {
        "Text": "The two additional ele  ments of the Romanian coreference chain are derived due to (1) the need to translate the relative clause from the English fragment into a separate sentence in Romanian; and (2) the reordering of words in the second sentence.",
        "Entity": "Normal"
    },
    {
        "Text": "146 tags as generated by the Brill tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition, we implemented rules that identify noun phrases in Romanian.",
        "Entity": "Normal"
    },
    {
        "Text": "To take advantage of the aligned corpus, SWIZZLE also relied on bilingual lexical resources that help translate the referential expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "For this purpose, we used a core Romanian WordNet (Harabagiu, 1999) which encoded, wherever possi  ble, links between the English synsets and their Ro  manian counterparts.",
        "Entity": "Normal"
    },
    {
        "Text": "This resource also incorpo  rated knowledge derived from several bilingual dic  tionaries (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "(Banta , 1969)).",
        "Entity": "Normal"
    },
    {
        "Text": "Having the parallel coreference annotations, we can easily identify their translations because they have the same identification coreference key.",
        "Entity": "Normal"
    },
    {
        "Text": "Look  ing at the example given in        , the expres  sion \"legii\", with ID=500 is the translation of the implemented, several other principles were applied.",
        "Entity": "Normal"
    },
    {
        "Text": "In our experiment, we were satisfied with the qual  ity of the translations recognized by following only these two principles.",
        "Entity": "Normal"
    },
    {
        "Text": "3.3 Multilingual Coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "Resolution The SWIZZLE system was run on a corpus of 2335 referential expressions in English (927 from MUC 6 and 1408 from MUC7) and 2851 Romanian ex  pressions (1219 from MUC6 and 1632 from MUC 7).",
        "Entity": "Normal"
    },
    {
        "Text": "Initially, the heuristics implemented in COCKTAIL were applied separately to the two textual collec  tions.",
        "Entity": "Normal"
    },
    {
        "Text": "Several special cases arose.",
        "Entity": "Normal"
    },
    {
        "Text": "English Text Romanian Text expression \"package\", having the same ID in the English text.",
        "Entity": "Normal"
    },
    {
        "Text": "However, in the test set, the REF fields are intentionally voided, entrusting COCKTAIL to identify the antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "The bilingual corefer  Reference ' '  - f onre Translation ence resolution performed in SWIZZLE, however, re  quires the translations of the English and Romanian antecedents.",
        "Entity": "Normal"
    },
    {
        "Text": "The principles guiding the translations of the English and Romanian antecedents (AE-R and ARE, respectively) are:   Circularity: Given an English antecedent, due to semantic ambiguity, it can belong to several English WordNet sysnsets.",
        "Entity": "Normal"
    },
    {
        "Text": "For each such sysnset Sf we con  sider the Romanian corresponding sysnet(s) Sf.",
        "Entity": "Normal"
    },
    {
        "Text": "We filter out all Sf that do not contain AE-R.",
        "Entity": "Normal"
    },
    {
        "Text": "If only one Romanian sysnset is left, then we identified a translation.",
        "Entity": "Normal"
    },
    {
        "Text": "Otherwise, we start from the Roma  nian antecedent, find all synsets Sf!",
        "Entity": "Normal"
    },
    {
        "Text": "to which it be  longs, and obtain the corresponding English sysnets Sf.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, all English synsets not containing the English antecedent are filtered out.",
        "Entity": "Normal"
    },
    {
        "Text": "If only one synset remains, we have again identified a transla  tion.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, in the last case, the intersection of the multiple synsets in either language generates a legal translation.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the English synset sE ={bill, measure} translates into the Romanian synset sR ={lege}.",
        "Entity": "Normal"
    },
    {
        "Text": "First, none of the dictionary translations of bill into Romanian (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "politif., hac  nota, afi ) translate back into any of the elements of sE.",
        "Entity": "Normal"
    },
    {
        "Text": "However the translation of measure into the Romanian lege translates back into bill, its synonym.",
        "Entity": "Normal"
    },
    {
        "Text": "Semantic density: Given an English and a Roma  nian antecedent, to establish whether they are trans  lations of one another, we disambiguate them by first collapsing all sysnsets that have common elements.",
        "Entity": "Normal"
    },
    {
        "Text": "Then we apply the circularity principle, relying on the semantic alignment encoded in the Romanian WordNet.",
        "Entity": "Normal"
    },
    {
        "Text": "When this core lexical database was first         : Case 1 of multilingual coreference Case 1, which is the ideal case, is shown in Fig  ure 3.",
        "Entity": "Normal"
    },
    {
        "Text": "It occurs when two referential expressions have antecedents that are translations of one an  other.",
        "Entity": "Normal"
    },
    {
        "Text": "This situation occurred in 63.3% of the refer  ential expressions from MUC6 and in 58.7% of the MUC7 references.",
        "Entity": "Normal"
    },
    {
        "Text": "Over 50% of these are pronouns or named entities.",
        "Entity": "Normal"
    },
    {
        "Text": "However, all the non-ideal cases are more interesting for SWIZZLE, since they port knowledge that enhances system performance.",
        "Entity": "Normal"
    },
    {
        "Text": "RA H4 R R Translation ER: English reference RR: Romanian reference EA: English antecedent RA: Romanian antecedent ET: English translation RT: Romanian translation of Romanian antecedent of English antecedent         : Case 2 of multilingual coreference Case 2 occurs when the antecedents are not trans  lations, but belong to or corefer with elements of some coreference chains that were already estab  lished.",
        "Entity": "Normal"
    },
    {
        "Text": "Moreover, one of the antecedents is textually 147 closer to its referent.",
        "Entity": "Normal"
    },
    {
        "Text": "illustrates the case when the English antecedent is closer to the referent than the Romanian one.",
        "Entity": "Normal"
    },
    {
        "Text": "SWIZZLE Solutions: (1) If the heuristic H(E) used to resolve the reference in the English text has higher priority than H(R), which was used to resolve the reference from the Romanian text, then we first search for RT, the Romanian translation of EA, the English antecedent.",
        "Entity": "Normal"
    },
    {
        "Text": "In the next step, we add heuris  tic Hl that resolves RR into RT, and give it a higher priority than H(R).",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, we also add heuristic H2 that links RT to RA when there is at least one trans  lation between the elements of the coreference chains containing EA and ET respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "(2) If H(R) has higher priority than H(E), heuris  tic H3 is added while H(E) is removed.",
        "Entity": "Normal"
    },
    {
        "Text": "We also add H4 that relates ER to ET, the English translation of RA.",
        "Entity": "Normal"
    },
    {
        "Text": "Case 3 occurs when at least one of the antecedents starts a new coreference chain (i.e., no coreferring antecedent can be found in the current chains).",
        "Entity": "Normal"
    },
    {
        "Text": "SWIZZLE Solution: If one of the antecedents corefers with an element from a coreference chain, then the antecedent in the opposite language is its translation.",
        "Entity": "Normal"
    },
    {
        "Text": "Otherwise, SWIZZLE chooses the an  tecedent returned by the heuristic with highest pri  ority.",
        "Entity": "Normal"
    },
    {
        "Text": "4 Results.",
        "Entity": "Normal"
    },
    {
        "Text": "The foremost contribution of SWIZZLE was that it improved coreference resolution over both English and Romanian texts when compared to monolingual coreference resolution performance in terms of preci  sion and recall.",
        "Entity": "Normal"
    },
    {
        "Text": "Also relevant was the contribution of SWIZZLE to the process of understanding the cultural differences expressed in language and the way these differences influence coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Because we do not have sufficient space to discuss this issue in detail here, let us state, in short, that English is more economical than Romanian in terms of referen  tial expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "However the referential expressions in Romanian contribute to the resolution of some of the most difficult forms of coreference in English.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Precision and Recall.",
        "Entity": "Normal"
    },
    {
        "Text": "summarizes the precision results for both English and Romanian coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "The results in  dicate that the English coreference is more pre  cise than the Romanian coreference, but SWIZZLE improves coreference resolution in both languages.",
        "Entity": "Normal"
    },
    {
        "Text": "There were 64% cases when the English coreference was resolved by a heuristic with higher priority than the corresponding heuristic for the Romanian coun terpart.",
        "Entity": "Normal"
    },
    {
        "Text": "This result explains why there is better pre  cision enhancement for the English coreference.",
        "Entity": "Normal"
    },
    {
        "Text": "N o mi na l Pr on om ina l To tal E ng lis h 7 3 % 8 9 % 84 % R o m an ia n 6 6 % 7 8 % 72 % S W IZ Z L E on E ng lis h 7 6 % 9 3 % 87 % S W IZ Z L E on R o m an ia n 7 1 % 8 2 % 76 %        : Coreference precision N o mi na l Pr on o mi nal To tal E ng lis h 6 9 % 8 9 78 % R o m an ia n 6 3 % 8 3 % 72 % S W IZ Z L E on E ng lis h 6 6 % 8 7 % 77 % S W IZ Z L E on R o m an ia n 6 1 % 8 0 % 70 %        : Coreference recall         also illustrates the recall results.",
        "Entity": "Normal"
    },
    {
        "Text": "The advantage of the data-driven coreference resolution over other methods is based on its better recall per  formance.",
        "Entity": "Normal"
    },
    {
        "Text": "This is explained by the fact that this method captures a larger variety of coreference pat  terns.",
        "Entity": "Normal"
    },
    {
        "Text": "Even though other coreference resolution sys  tems perform better for some specific forms of refer  ence, their recall results are surpassed by the data  driven approach.",
        "Entity": "Normal"
    },
    {
        "Text": "Multilingual coreference in turn improves more the precision than the recall of the monolingual data-driven coreference systems.",
        "Entity": "Normal"
    },
    {
        "Text": "In addition,         shows that the English coref  erence results in better recall than Romanian coref  erence.",
        "Entity": "Normal"
    },
    {
        "Text": "However, the recall shows a decrease for both languages for SWIZZLE because imprecise coreference links are deleted.",
        "Entity": "Normal"
    },
    {
        "Text": "As is usually the case, deleting data lowers the recall.",
        "Entity": "Normal"
    },
    {
        "Text": "All results were obtained by using the automatic scorer program developed for the MUC evaluations.",
        "Entity": "Normal"
    },
    {
        "Text": "5 Conclusions.",
        "Entity": "Normal"
    },
    {
        "Text": "We have introduced a new data-driven method for multilingual coreference resolution, implemented in the SWIZZLE system.",
        "Entity": "Normal"
    },
    {
        "Text": "The results of this method are encouraging since they show clear improvements over monolingual coreference resolution.",
        "Entity": "Normal"
    },
    {
        "Text": "Currently, we are also considering the effects of a bootstrap  ping algorithm for multilingual coreference resolu  tion.",
        "Entity": "Normal"
    },
    {
        "Text": "Through this procedure we would learn con  currently semantic consistency knowledge and bet  ter performing heuristic rules.",
        "Entity": "Normal"
    },
    {
        "Text": "To be able to de  velop such a learning approach, we must first develop a method for automatic recognition of multilingual referential expressions.",
        "Entity": "Normal"
    },
    {
        "Text": "148 We also believe that a better performance evalu  ation of SWIZZLE can be achieved by measuring its impact on several complex applications.",
        "Entity": "Normal"
    },
    {
        "Text": "We intend to analyze the performance of SWIZZLE when it is used as a module in an IE system, and separately in a Question/ Answering system.",
        "Entity": "Normal"
    },
    {
        "Text": "Acknowledgements This paper is dedicated to the memory of our friend Megumi Kameyama, who in  spired this work.",
        "Entity": "Normal"
    },
    {
        "Text": "\nMining New Word Translations from Comparable Corpora\n\t\n\t\tNew words such as names, technical terms, etc appear frequently.",
        "Entity": "Normal"
    },
    {
        "Text": "As such, the bilingual lexicon of a machine translation system has to be constantly updated with these new word translations.",
        "Entity": "Normal"
    },
    {
        "Text": "Comparable corpora such as news documents of the same period from different news agencies are readily available.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we present a new approach to mining new word translations from comparable corpora, by using context information to complement transliteration information.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated our approach on six months of Chinese and English Gigaword corpora, with encouraging results.",
        "Entity": "Normal"
    },
    {
        "Text": "New words such as person names, organization names, technical terms, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "appear frequently.",
        "Entity": "Normal"
    },
    {
        "Text": "In order for a machine translation system to translate these new words correctly, its bilingual lexicon needs to be constantly updated with new word translations.",
        "Entity": "Normal"
    },
    {
        "Text": "Much research has been done on using parallel corpora to learn bilingual lexicons (Melamed, 1997; Moore, 2003).",
        "Entity": "Normal"
    },
    {
        "Text": "But parallel corpora are scarce resources, especially for uncommon lan guage pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "Comparable corpora refer to texts that are not direct translation but are about the same topic.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, various news agencies report major world events in different languages, and such news documents form a readily available source of comparable corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "Being more readily available, comparable corpora are thus more suitable than parallel corpora for the task of acquiring new word translations, although relatively less research has been done in the past on comparable corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "Previous research efforts on acquiring translations from comparable corpora include (Fung and Yee, 1998; Rapp, 1995; Rapp, 1999).",
        "Entity": "Normal"
    },
    {
        "Text": "When translating a word w, two sources of information can be used to determine its translation: the word w itself and the surrounding words in the neighborhood (i.e., the context) of w. Most previous research only considers one of the two sources of information, but not both.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the work of (AlOnaizan and Knight, 2002a; AlOnaizan and Knight, 2002b; Knight and Graehl, 1998) used the pronunciation of w in translation.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, the work of (Cao and Li, 2002; Fung and Yee, 1998; Koehn and Knight, 2002; Rapp, 1995; Rapp, 1999) used the context of w to locate its translation in a second language.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we propose a new approach for the task of mining new word translations from comparable corpora, by combining both context and transliteration information.",
        "Entity": "Normal"
    },
    {
        "Text": "Since both sources of information are complementary, the accuracy of our combined approach is better than the accuracy of using just context or transliteration information alone.",
        "Entity": "Normal"
    },
    {
        "Text": "We fully implemented our method and tested it on ChineseEnglish comparable corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "We translated Chinese words into English.",
        "Entity": "Normal"
    },
    {
        "Text": "That is, Chinese is the source language and English is the target language.",
        "Entity": "Normal"
    },
    {
        "Text": "We achieved encouraging results.",
        "Entity": "Normal"
    },
    {
        "Text": "While we have only tested our method on Chinese-English comparable corpora, our method is general and applicable to other language pairs.",
        "Entity": "Normal"
    },
    {
        "Text": "The work of (Fung and Yee, 1998; Rapp, 1995; Rapp, 1999) noted that if an English word e is the translation of a Chinese word c , then the contexts of the two words are similar.",
        "Entity": "Normal"
    },
    {
        "Text": "We could view this as a document retrieval problem.",
        "Entity": "Normal"
    },
    {
        "Text": "The context (i.e., the surrounding words) of c is viewed as a query.",
        "Entity": "Normal"
    },
    {
        "Text": "The context of each candidate translation e' is viewed as a document.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the context of the correct translation e is similar to e , is considered as a document in IR.",
        "Entity": "Normal"
    },
    {
        "Text": "If an English word e is the translation of a Chinese word c , they will have similar contexts.",
        "Entity": "Normal"
    },
    {
        "Text": "So we use the the context of c , we are likely to retrieve the context of e when we use the context of c as query C(c) to retrieve a document C (e* ) that * the query and try to retrieve the most similar best matches the query.",
        "Entity": "Normal"
    },
    {
        "Text": "The English word e document.",
        "Entity": "Normal"
    },
    {
        "Text": "We employ the language modeling approach (Ng, 2000; Ponte and Croft, 1998) for corresponding to that document translation of c .",
        "Entity": "Normal"
    },
    {
        "Text": "C (e* ) is the this retrieval problem.",
        "Entity": "Normal"
    },
    {
        "Text": "More details are given in Section 3.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, when we only look at the word w itself, we can rely on the pronunciation of w to locate its translation.",
        "Entity": "Normal"
    },
    {
        "Text": "We use a variant of Within IR, there is a new approach to document retrieval called the language modeling approach (Ponte & Croft, 98).",
        "Entity": "Normal"
    },
    {
        "Text": "In this approach, a language model is derived from each document D .",
        "Entity": "Normal"
    },
    {
        "Text": "Then the probability of generating the query the machine transliteration method proposed by Q according to that language model, P(Q | D) , (Knight and Graehl, 1998).",
        "Entity": "Normal"
    },
    {
        "Text": "More details are is estimated.",
        "Entity": "Normal"
    },
    {
        "Text": "The document with the highest given in Section 4.",
        "Entity": "Normal"
    },
    {
        "Text": "Each of the two individual methods provides a P(Q | D) is the one that best matches the query.",
        "Entity": "Normal"
    },
    {
        "Text": "ranked list of candidate words, associating with each candidate a score estimated by the particular method.",
        "Entity": "Normal"
    },
    {
        "Text": "If a word e in English is indeed the translation of a word c in Chinese, then we would expect e to be ranked very high in both lists in general.",
        "Entity": "Normal"
    },
    {
        "Text": "Specifically, our combination method is as follows: we examine the top M The language modeling approach to IR has been shown to give superior retrieval performance (Ponte & Croft, 98; Ng, 2000), compared with traditional vector space model, and we adopt this approach in our current work.",
        "Entity": "Normal"
    },
    {
        "Text": "To estimate P(Q | D) , we use the approach of (Ng, 2000).",
        "Entity": "Normal"
    },
    {
        "Text": "We view the document D as a multinomial distribution of terms and assume that words in both lists and finde1 , e2 ,..., ek that ap query Q is generated by this model: pear in top M positions in both lists.",
        "Entity": "Normal"
    },
    {
        "Text": "We then n!",
        "Entity": "Normal"
    },
    {
        "Text": "rank these words e1 , e2 ,..., ek according to the P (Q | D ) = \u220f P (t | D ) c t average of their rank positions in the two lists.",
        "Entity": "Normal"
    },
    {
        "Text": "\u220f t c t !",
        "Entity": "Normal"
    },
    {
        "Text": "t The candidate ei that is ranked the highest according to the average rank is taken to be the cor where t is a term in the corpus, ct is the number rect translation and is output.",
        "Entity": "Normal"
    },
    {
        "Text": "If no words appear within the top M positions in both lists, then no translation is output.",
        "Entity": "Normal"
    },
    {
        "Text": "Since we are using comparable corpora, it is possible that the translation of a new word does not exist in the target corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "In particular, our experiment was conducted on comparable corpora that are not very closely related and as such, most of the Chinese words have no translations of times term t occurs in the query Q , n = \u2211t ct is the total number of terms in query Q .",
        "Entity": "Normal"
    },
    {
        "Text": "For ranking purpose, the first fraction n!",
        "Entity": "Normal"
    },
    {
        "Text": "/ \u220ft ct !",
        "Entity": "Normal"
    },
    {
        "Text": "can be omitted as this part depends on the query only and thus is the same for all the documents.",
        "Entity": "Normal"
    },
    {
        "Text": "in the English target corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "In our translation problem, C(c) is viewed as the query and C(e) is viewed as a document.",
        "Entity": "Normal"
    },
    {
        "Text": "So\n\t\n\t\n\t\t\tour task is to compute P(C (c) | C (e)) for each In a typical information retrieval (IR) problem, a query is given and a ranked list of documents English word e and find the e that gives the highest P(C (c) | C (e)) , estimated as: most relevant to the query is returned from a document collection.",
        "Entity": "Normal"
    },
    {
        "Text": "\u220f P(tc tc\u2208C ( c ) | T (C (e)))q (tc ) For our task, the query is C (c) , the context Term tc is a Chinese word.",
        "Entity": "Normal"
    },
    {
        "Text": "q(tc ) is the number (i.e., the surrounding words) of a Chinese word c .",
        "Entity": "Normal"
    },
    {
        "Text": "Each C (e) , the context of an English word of occurrenc es of tc in C (c) .",
        "Entity": "Normal"
    },
    {
        "Text": "Tc (C (e)) is the bag of Chinese words obtained by translating the First, each Chinese character in a Chinese English words in C(e) , as determined by a bi word c is converted to pinyin form.",
        "Entity": "Normal"
    },
    {
        "Text": "Then we sum lingual dictionary.",
        "Entity": "Normal"
    },
    {
        "Text": "If an English word is ambiguous and has K translated Chinese words listed in the bilingual dictionary, then each of the K trans over all the alignments that this pinyin form of c can map to an English word e. For each possible alignment, we calculate the probability by taking lated Chinese words is counted as occurring 1/K times in Tc (C (e)) for the purpose of probability the product of each mapping.",
        "Entity": "Normal"
    },
    {
        "Text": "ble of pinyin, api is the ith sylla li is the English letter sequence estimation.",
        "Entity": "Normal"
    },
    {
        "Text": "We use backoff and linear interpolation for probability estimation: P(tc | Tc (C (e))) = \u03b1 \u22c5 Pml (tc | Tc (C (e))) + (1 \u2212\u03b1 ) \u22c5 Pml (tc ) that the ith pinyin syllable maps to in the particular alignment a.",
        "Entity": "Normal"
    },
    {
        "Text": "Since most Chinese characters have only one pronunciation and hence one pinyin form, we assume that Chinese character-to-pinyin mapping is one-to-one to simplify the problem.",
        "Entity": "Normal"
    },
    {
        "Text": "We use the Pml (tc | Tc (C (e))) = dT (C (e )) (tc ) \u2211dT (C ( e )) (t ) expect ation maxi mizati on (EM) algorit hm to genera te mappi ng proba bilitie s from pinyin syl c t\u2208Tc (C ( e )) lables to English letter sequences.",
        "Entity": "Normal"
    },
    {
        "Text": "To reduce the search space, we limit the number of English letters that each pinyin syllable can map to as 0, where Pml (\u2022) are the maximu m likelihood esti 1, or 2.",
        "Entity": "Normal"
    },
    {
        "Text": "Also.",
        "Entity": "Normal"
    },
    {
        "Text": "we do not allow cross mappin gs.",
        "Entity": "Normal"
    },
    {
        "Text": "mates, dT (C ( e)) (tc ) is the number of occurre nces That is, if an English letter sequenc e e1 precede s of the term tc in Tc (C(e)) , andPml (tc ) is esti another English letter sequence e2 in an English mated similarly by counting the occurrences of word, then the pinyin syllable mapped to e1 tc in the Chinese translation of the whole English corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "\u03b1 is set to 0.6 in our experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "must precede the pinyin syllable mapped to e2 .",
        "Entity": "Normal"
    },
    {
        "Text": "Our method differs from (Knight and Graehl, 1998) and (AlOnaizan and Knight, 2002b) in that our method does not generate candidates but For the transliteration model, we use a modified only estimatesP(e | c) for candidates e appearmodel of (Knight and Graehl, 1998) and (Al ing in the English corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Another difference is Onaizan and Knight, 2002b).",
        "Entity": "Normal"
    },
    {
        "Text": "Knight and Graehl (1998) proposed a probabilistic model for machine transliteration.",
        "Entity": "Normal"
    },
    {
        "Text": "In this model, a word in the target language (i.e., English in our task) is written and pronounced.",
        "Entity": "Normal"
    },
    {
        "Text": "This pronunciation is converted to source language pronunciation and then to source language word that our method estimates stead of P(c | e) and P(e) .",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Resources.",
        "Entity": "Normal"
    },
    {
        "Text": "P(e | c)directly, in (i.e., Chinese in our task).",
        "Entity": "Normal"
    },
    {
        "Text": "AlOnaizan and Knight (2002b) suggested that pronunciation can be skipped and the target language letters can be mapped directly to source language letters.",
        "Entity": "Normal"
    },
    {
        "Text": "Pinyin is the standard Romanization system of Chinese characters.",
        "Entity": "Normal"
    },
    {
        "Text": "It is phonetic-based.",
        "Entity": "Normal"
    },
    {
        "Text": "For transliteration, we estimate P(e | c) as follows: P(e | c) = P(e | pinyin) = \u2211 P(e, a | pinyin) a For the Chinese corpus, we used the Linguistic Data Consortium (LDC) Chinese Gigaword Corpus from Jan 1995 to Dec 1995.",
        "Entity": "Normal"
    },
    {
        "Text": "The corpus of the period Jul to Dec 1995 was used to come up with new Chinese words c for translation into English.",
        "Entity": "Normal"
    },
    {
        "Text": "The corpus of the period Jan to Jun 1995 was just used to determine if a Chinese word c from Jul to Dec 1995 was new, i.e., not occurring from Jan to Jun 1995.",
        "Entity": "Normal"
    },
    {
        "Text": "Chinese Giga- word corpus consists of news from two agencies: = \u2211\u220f P(l a a i | pi ) Xinhua News Agency and Central News Agency.",
        "Entity": "Normal"
    },
    {
        "Text": "As for English corpus, we used the LDC English Gigaword Corpus from Jul to Dec 1995.",
        "Entity": "Normal"
    },
    {
        "Text": "The English Gigaword corpus consists of news from four newswire services: Agence France Press English Service, Associated Press Worldstream English Service, New York Times Newswire Service, and Xinhua News Agency English Service.",
        "Entity": "Normal"
    },
    {
        "Text": "To avoid accidentally using parallel texts, we did not use the texts of Xinhua News Agency them English translation candidate words.",
        "Entity": "Normal"
    },
    {
        "Text": "For a Chinese source word occurring within a half- month period p, we looked for its English translation candidate words occurring in news documents in the same period p. 5.3 Translation candidates.",
        "Entity": "Normal"
    },
    {
        "Text": "English Service.",
        "Entity": "Normal"
    },
    {
        "Text": "The size of the English corpus from Jul to Dec The context C(c)of a Chinese word c was col 1995 was about 730M bytes, and the size of the Chinese corpus from Jul to Dec 1995 was about 120M bytes.",
        "Entity": "Normal"
    },
    {
        "Text": "We used a ChineseEnglish dictionary which contained about 10,000 entries for translating the words in the context.",
        "Entity": "Normal"
    },
    {
        "Text": "For the training of transliteration probability, we required a ChineseEnglish name list.",
        "Entity": "Normal"
    },
    {
        "Text": "We used a list of 1,580 ChineseEnglish name pairs as training data for the EM algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "lected as follows: For each occurrence of c, we set a window of size 50 characters centered at c. We discarded all the Chinese words in the context that were not in the dictionary we used.",
        "Entity": "Normal"
    },
    {
        "Text": "The contexts of all occurrences of a word c were then concatenated together to form C(c) .",
        "Entity": "Normal"
    },
    {
        "Text": "The context of an English translation candidate word e, C (e) , was similarly collected.",
        "Entity": "Normal"
    },
    {
        "Text": "The window size of English context was 100 words.After all the counts were collected, we esti mated P(C (c) | C (e)) as described in Section 3, 5.2 Preprocessing.",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike English, Chinese text is composed of Chinese characters with no demarcation for words.",
        "Entity": "Normal"
    },
    {
        "Text": "So we first segmented Chinese text with a Chinese word segmenter that was based on maximum entropy modeling (Ng and Low, 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "for each pair of Chinese source word and English translation candidate word.",
        "Entity": "Normal"
    },
    {
        "Text": "For each Chinese source word, we ranked all its English translation candidate words according to the estimated P(C (c) | C (e)) .",
        "Entity": "Normal"
    },
    {
        "Text": "For each Chinese source word c and an English translation candidate word e , we also calcu We then divided the Chinese corpus from Jul to Dec 1995 into 12 periods, each containing text lated the probability P(e | c) (as described in from a half-month period.",
        "Entity": "Normal"
    },
    {
        "Text": "Then we determined the new Chinese words in each half-month period p. By new Chinese words, we refer to those words that appeared in this period p but not from Jan to Jun 1995 or any other periods that preceded p. Among all these new words, we selected those occurring at least 5 times.",
        "Entity": "Normal"
    },
    {
        "Text": "These words made up our test set.",
        "Entity": "Normal"
    },
    {
        "Text": "We call these words Chinese source words.",
        "Entity": "Normal"
    },
    {
        "Text": "They were the words that we were supposed to find translations from the English corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "For the English corpus, we performed sentence segmentation and converted each word to its morphological root form and to lower case.",
        "Entity": "Normal"
    },
    {
        "Text": "We also divided the English corpus into 12 periods, each containing text from a half-month period.",
        "Entity": "Normal"
    },
    {
        "Text": "For each period, we selected those English words occurring at least 10 times and were not present in the 10,000-word ChineseEnglish dictionary we used and were not stop words.",
        "Entity": "Normal"
    },
    {
        "Text": "We considered these English words as potential translations of the Chinese source words.",
        "Entity": "Normal"
    },
    {
        "Text": "We call Section 4), which was used to rank the English candidate words based on transliteration.",
        "Entity": "Normal"
    },
    {
        "Text": "Finally, the English candidate word with the smallest average rank position and that appears within the top M positions of both ranked lists is the chosen English translation (as described in Section 2).",
        "Entity": "Normal"
    },
    {
        "Text": "If no words appear within the top M positions in both ranked lists, then no translation is output.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that for many Chinese words, only one English word e appeared within the top M positions for both lists.",
        "Entity": "Normal"
    },
    {
        "Text": "And among those cases where more than one English words appeared within the top M positions for both lists, many were multiple translations of a Chinese word.",
        "Entity": "Normal"
    },
    {
        "Text": "This happened for example when a Chinese word was a non-English person name.",
        "Entity": "Normal"
    },
    {
        "Text": "The name could have multiple translations in English.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, \u7c73 \u6d1b\u897f\u5a1c was a Russian name.",
        "Entity": "Normal"
    },
    {
        "Text": "Mirochina and Miroshina both appeared in top 10 positions of both lists.",
        "Entity": "Normal"
    },
    {
        "Text": "Both were correct.",
        "Entity": "Normal"
    },
    {
        "Text": "5.4 Evaluation.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated our method on each of the 12 half- month periods.",
        "Entity": "Normal"
    },
    {
        "Text": ".",
        "Entity": "Normal"
    },
    {
        "Text": "The correctness of the English translations was manually checked.",
        "Entity": "Normal"
    },
    {
        "Text": "We attempted to estimate recall by manually finding the English translations for all the Chinese source words for the two periods Dec 01 \u2013 Dec 15 and Dec 16 \u2013 Dec 31 in the English part of the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "During the whole December period, we only managed to find English translations which were present in the English side of the comparable corpora for 43 Chinese words.",
        "Entity": "Normal"
    },
    {
        "Text": "Precision and recall for different values of M The past research of (Fung and Yee, 1998; Rapp, 1995; Rapp, 1999) utilized context information alone and was evaluated on different corpora from ours, so it is difficult to directly compare our current results with theirs.",
        "Entity": "Normal"
    },
    {
        "Text": "Similarly, AlOnaizan and Knight (2002a; 2002b) only made use of transliteration information alone and so was not directly comparable.",
        "Entity": "Normal"
    },
    {
        "Text": "To investigate the effect of the two individual sources of information (context and transliteration), we checked how many translations could be found using only one source of information (i.e., context alone or transliteration alone), on those Chinese words that have translations in the English part of the comparable corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "As mentioned earlier, for the month of Dec 1995, there are altogether 43 Chinese words that have their translations in the English part of the corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "Since our method currently only considers unigram English words, we are not able to find translations for these words.",
        "Entity": "Normal"
    },
    {
        "Text": "But it is not difficult to extend our method to handle this problem.",
        "Entity": "Normal"
    },
    {
        "Text": "We can first use a named entity recognizer and noun phrase chunker to extract English names and noun phrases.",
        "Entity": "Normal"
    },
    {
        "Text": "Our method is not able to find 43 (329 + 205) \u00d7 4499 = 362words in all 12 pe these translations.",
        "Entity": "Normal"
    },
    {
        "Text": "But this is due to search space riods.",
        "Entity": "Normal"
    },
    {
        "Text": "And our program finds correct translations for 115 words.",
        "Entity": "Normal"
    },
    {
        "Text": "So we estimate that recall (for M = 10) is approximately 115 / 362 = 31.8% .",
        "Entity": "Normal"
    },
    {
        "Text": "pruning.",
        "Entity": "Normal"
    },
    {
        "Text": "If we are willing to spend more time on searching, then in principle we can find these translations.",
        "Entity": "Normal"
    },
    {
        "Text": "And using just transliteration information alone, 9 Chinese words have their correct English translations at rank one position.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence, our method of using both sources of information outperforms using either information source alone.",
        "Entity": "Normal"
    },
    {
        "Text": "As pointed out earlier, most previous research only considers either transliteration or context information in determining the translation of a source language word w, but not both sources of information.",
        "Entity": "Normal"
    },
    {
        "Text": "For example, the work of (AlOnaizan and Knight, 2002a; AlOnaizan and Knight, 2002b; Knight and Graehl, 1998) used only the pronunciation or spelling of w in translation.",
        "Entity": "Normal"
    },
    {
        "Text": "On the other hand, the work of (Cao and Li, 2002; Fung and Yee, 1998; Rapp, 1995; Rapp, 1999) used only the context of w to locate its translation in a second language.",
        "Entity": "Normal"
    },
    {
        "Text": "In contrast, our current work attempts to combine both complementary sources of information, yielding higher accuracy than using either source of information alone.",
        "Entity": "Normal"
    },
    {
        "Text": "Koehn and Knight (2002) attempted to combine multiple clues, including similar context and spelling.",
        "Entity": "Normal"
    },
    {
        "Text": "But their similar spelling clue uses the longest common subsequence ratio and works only for cognates (words with a very similar spelling).",
        "Entity": "Normal"
    },
    {
        "Text": "The work that is most similar to ours is the recent research of (Huang et al., 2004).",
        "Entity": "Normal"
    },
    {
        "Text": "They attempted to improve named entity translation by combining phonetic and semantic information.",
        "Entity": "Normal"
    },
    {
        "Text": "Their contextual semantic similarity model is different from our language modeling approach to measuring context similarity.",
        "Entity": "Normal"
    },
    {
        "Text": "It also made use of part-of-speech tag information, whereas our method is simpler and does not require part-of- speech tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "They combined the two sources of information by weighting the two individual scores, whereas we made use of the average rank for combination.",
        "Entity": "Normal"
    },
    {
        "Text": "In this paper, we proposed a new method to mine new word translations from comparable corpora, by combining context and transliteration information, which are complementary sources of information.",
        "Entity": "Normal"
    },
    {
        "Text": "We evaluated our approach on six months of Chinese and English Gigaword corpora, with encouraging results.",
        "Entity": "Normal"
    },
    {
        "Text": "We thank Jia Li for implementing the EM algorithm to train transliteration probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "This research is partially supported by a research grant R252000-125112 from National University of Singapore Academic Research Fund.",
        "Entity": "Normal"
    },
    {
        "Text": "\nEstimation of Conditional ProbabilitiesWith Decision Trees and an Application to Fine-Grained POS Tagging\n\t\n\t\tWe present a HMM part-of-speech tagging method which is particularly suited for POS tagsets with a large number of fine-grained tags.",
        "Entity": "Normal"
    },
    {
        "Text": "It is based on three ideas: (1) splitting of the POS tags into attribute vectors and decomposition of the contextual POS probabilities of the HMM into a product of attribute probabilities, (2) estimation of the contextual probabilities with decision trees, and (3) use of high-order HMMs.",
        "Entity": "Normal"
    },
    {
        "Text": "In experiments on German and Czech data, our tagger outperformed state- of-the-art POS taggers.",
        "Entity": "Normal"
    },
    {
        "Text": "A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.)",
        "Entity": "Normal"
    },
    {
        "Text": "computes the most probable POS tag sequence t\u02c6N = t\u02c61, ..., t\u02c6N for a given word sequence wN .",
        "Entity": "Normal"
    },
    {
        "Text": "POS taggers are usually trained on corpora with between 50 and 150 different POS tags.",
        "Entity": "Normal"
    },
    {
        "Text": "Tagsets of this size contain little or no information about number, gender, case and similar morphosyntac- tic features.",
        "Entity": "Normal"
    },
    {
        "Text": "For languages with a rich morphology such as German or Czech, more fine-grained tagsets are often considered more appropriate.",
        "Entity": "Normal"
    },
    {
        "Text": "The additional information may also help to disambiguate the (base) part of speech.",
        "Entity": "Normal"
    },
    {
        "Text": "Without gender information, for instance, it is difficult for a tagger to correctly disambiguate the German sentence Ist das Realita\u00a8 t?",
        "Entity": "Normal"
    },
    {
        "Text": "(Is that reality?).",
        "Entity": "Normal"
    },
    {
        "Text": "The word das is ambiguous between an article and a demonstrative.",
        "Entity": "Normal"
    },
    {
        "Text": "Because of the lack of gender agreement between das (neuter) and the noun Realita\u00a8 t (feminine), the article reading must be wrong.",
        "Entity": "Normal"
    },
    {
        "Text": "The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).",
        "Entity": "Normal"
    },
    {
        "Text": "Large tagsets aggravate sparse data problems.",
        "Entity": "Normal"
    },
    {
        "Text": "As an example, take the German sentence Das zu versteuernde Einkommen sinkt (\u201cThe to be taxed income decreases\u201d; The t\u02c6N N N 1 = arg max p(t1 , w1 ) 1                                                                                                                                            N taxable income decreases).",
        "Entity": "Normal"
    },
    {
        "Text": "Das ART.Def.Nom.Sg.Neut zu PART.Zu versteuernde ADJA.Pos.Nom.Sg.Neut Einkommen N.Reg.Nom.Sg.Neut p(tN , wN ) = n 1 1 i=1 p(ti|ti\u22121 ) i\u2212k p(wi|ti) le .",
        "Entity": "Normal"
    },
    {
        "Text": "(1) context prob.",
        "Entity": "Normal"
    },
    {
        "Text": "xical prob HMM taggers are fast and were successfully applied to a wide range of languages and training corpora.",
        "Entity": "Normal"
    },
    {
        "Text": "Qc 2008.",
        "Entity": "Normal"
    },
    {
        "Text": "Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).",
        "Entity": "Normal"
    },
    {
        "Text": "Some rights reserved.",
        "Entity": "Normal"
    },
    {
        "Text": "Unfortunately, the POS trigram consisting of the tags of the first three words does not occur in the Tiger corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "(Neither does the pair consisting of the first two tags.)",
        "Entity": "Normal"
    },
    {
        "Text": "The unsmoothed 777 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 777\u2013784 Manchester, August 2008 context probability of the third POS tag is therefore 0.",
        "Entity": "Normal"
    },
    {
        "Text": "If the probability is smoothed with the backoff distribution p(\u2022|P ART .Z u), the most probable tag is ADJA.Pos.Acc.Sg.Fem rather than ADJA.Pos.Nom.Sg.Neut.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, the agreement between the article and the adjective is not checked anymore.",
        "Entity": "Normal"
    },
    {
        "Text": "A closer inspection of the Tiger corpus reveals that it actually contains all the information needed to completely disambiguate each component of the POS tag ADJA.Pos.Nom.Sg.Neut: \u2022 All words appearing after an article (ART) and the infinitive particle zu (PART.zu) are attributive adjectives (ADJA) (10 of 10 cases).",
        "Entity": "Normal"
    },
    {
        "Text": "\u2022 All adjectives appearing after an article and a particle (PART) have the degree positive (Pos) (39 of 39 cases).",
        "Entity": "Normal"
    },
    {
        "Text": "\u2022 All adjectives appearing after a nominative article and a particle have nominative case (11 of 11 cases).",
        "Entity": "Normal"
    },
    {
        "Text": "\u2022 All adjectives appearing after a singular article and a particle are singular (32 of 32 cases).",
        "Entity": "Normal"
    },
    {
        "Text": "\u2022 All adjectives appearing after a neuter article and a particle are neuter (4 of 4 cases).",
        "Entity": "Normal"
    },
    {
        "Text": "By (1) decomposing the context probability of ADJA.Pos.Nom.Sg.Neut into a product of attribute probabilities p(ADJA | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu) \u2217 p(Pos| 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA) \u2217 p(Nom | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA, 0:ADJA.Pos) \u2217 p(Sg | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA, 0:ADJA.Pos, 0:ADJA.Nom) \u2217 p(Neut | 2:ART, 2:ART.Def, 2:ART.Nom, 2:ART.Sg, 2:ART.Neut, 1:PART, 1:PART.Zu, 0:ADJA, 0:ADJA.Pos, 0:ADJA.Nom, 0:ADJA.Sg) and (2) selecting the relevant context attributes for the prediction of each attribute, we obtain the \u2217 p(Sg | 2:ART.Sg, 1:PART.Zu, 0:ADJA) \u2217 p(Neut | 2:ART.Neut, 1:PART.Zu, 0:ADJA) The conditional probability of each attribute is 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence the context probability of the whole tag is.",
        "Entity": "Normal"
    },
    {
        "Text": "also 1.",
        "Entity": "Normal"
    },
    {
        "Text": "Without having observed the given context, it is possible to deduce that the observed POS tag is the only possible tag in this context.",
        "Entity": "Normal"
    },
    {
        "Text": "These considerations motivate an HMM tagging approach which decomposes the POS tags into a set of simple attributes, and uses decision trees to estimate the probability of each attribute.",
        "Entity": "Normal"
    },
    {
        "Text": "Decision trees are ideal for this task because the identification of relevant attribute combinations is at the heart of this method.",
        "Entity": "Normal"
    },
    {
        "Text": "The backoff smoothing methods of traditional n-gram POS taggers require an ordering of the reduced contexts which is not available, here.",
        "Entity": "Normal"
    },
    {
        "Text": "Discriminatively trained taggers, on the other hand, have difficulties to handle the huge number of features which are active at the same time if any possible combination of context attributes defines a separate feature.",
        "Entity": "Normal"
    },
    {
        "Text": "Decision trees (Breiman et al., 1984; Quinlan, 1993) are normally used as classifiers, i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "they assign classes to objects which are represented as attribute vectors.",
        "Entity": "Normal"
    },
    {
        "Text": "The non-terminal nodes are labeled with attribute tests, the edges with the possible outcomes of a test, and the terminal nodes are labeled with classes.",
        "Entity": "Normal"
    },
    {
        "Text": "An object is classified by evaluating the test of the top node on the object, following the respective edge to a daughter node, evaluating the test of the daughter node, and so on until a terminal node is reached whose class is assigned to the object.",
        "Entity": "Normal"
    },
    {
        "Text": "Decision Trees are turned into probability estimation trees by storing a probability for each possible class at the terminal nodes instead of a single result class.",
        "Entity": "Normal"
    },
    {
        "Text": "2.1 Induction of Decision Trees.",
        "Entity": "Normal"
    },
    {
        "Text": "Decision trees are incrementally built by first selecting the test which splits the manually annotated training sample into the most homogeneous subsets with respect to the class.",
        "Entity": "Normal"
    },
    {
        "Text": "This test, which maximizes the information gain1 wrt.",
        "Entity": "Normal"
    },
    {
        "Text": "the class, is following expression for the context probability: 1 The information gain measures how much the test de-.",
        "Entity": "Normal"
    },
    {
        "Text": "p(ADJA | ART, PART.Zu) \u2217 p(Pos | 2:ART, 1:PART, 0:ADJA) \u2217 p(Nom | 2:ART.Nom, 1:PART.Zu, 0:ADJA) creases the uncertainty about the class.",
        "Entity": "Normal"
    },
    {
        "Text": "It is the difference between the entropy of the empirical distribution of the class variable in the training set and the weighted average entropy yes 0:N.Name yes no 1:ART.Nom no 1:ADJA.Nom yes no which returns a probability of 0.3.",
        "Entity": "Normal"
    },
    {
        "Text": "The third tree for neuter has one non terminal and two terminal nodes returning a probability of 0.3 and 0.5, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "The sum of probabilities is therefore either 0.9 or 1.1, but never exactly 1.",
        "Entity": "Normal"
    },
    {
        "Text": "This problem 2:N.Reg p=0.999 0:N.Name 0:N.Name yes no p=0.571 p=0.938 yes no p=0.948 p=0.998 .... is solved by renormalizing the probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "The probability of an attribute (such as \u201cNom\u201d) is always conditioned on the respective base POS (such as \u201cN\u201d) (unless the predicted attribute is the                                                                        \n\t\t\t                                                                        \n\t\t\tassigned to the top node.",
        "Entity": "Normal"
    },
    {
        "Text": "The tree is recursively expanded by selecting the best test for each subset and so on, until all objects of the current subset belong to the same class.",
        "Entity": "Normal"
    },
    {
        "Text": "In a second step, the decision tree may be pruned in order to avoid overfit- ting to the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "Our tagger generates a predictor for each feature (such as base POS, number, gender etc.)",
        "Entity": "Normal"
    },
    {
        "Text": "Instead of using a single tree for the prediction of all possible values of a feature (such as noun, article, etc.",
        "Entity": "Normal"
    },
    {
        "Text": "for base POS), the tagger builds a separate decision tree for each value.",
        "Entity": "Normal"
    },
    {
        "Text": "The motivation was that a tree which predicts a single value (say verb) does not fragment the data with tests which are only relevant for the distinction of two other values (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "article and possessive pronoun).2 Furthermore, we observed that such two-class decision trees require no optimization of the pruning threshold (see also section 2.2.)",
        "Entity": "Normal"
    },
    {
        "Text": "The tree induction algorithm only considers binary tests, which check whether some particular attribute is present or not.",
        "Entity": "Normal"
    },
    {
        "Text": "The best test for each node is selected with the standard information gain criterion.",
        "Entity": "Normal"
    },
    {
        "Text": "The recursive tree building process terminates if the information gain is 0.",
        "Entity": "Normal"
    },
    {
        "Text": "The decision tree is pruned with the pruning criterion described below.",
        "Entity": "Normal"
    },
    {
        "Text": "Since the tagger creates a separate tree for each attribute, the probabilities of a set of competing attributes such as masculine, feminine, and neuter will not exactly sum up to 1.",
        "Entity": "Normal"
    },
    {
        "Text": "To understand why, assume that there are three trees for the gender attributes.",
        "Entity": "Normal"
    },
    {
        "Text": "Two of them (say the trees for masculine and feminine) consist of a single terminal node base POS) in order to make sure that the probability of an attribute is 0 if it never appeared with the respective base POS.",
        "Entity": "Normal"
    },
    {
        "Text": "All context attributes other than the base POS are always used in combination with the base POS.",
        "Entity": "Normal"
    },
    {
        "Text": "A typical context attribute is \u201c1:ART.Nom\u201d which states that the preceding tag is an article with the attribute \u201cNom\u201d.",
        "Entity": "Normal"
    },
    {
        "Text": "\u201c1:ART\u201d is also a valid attribute specification, but \u201c1:Nom\u201d is not.",
        "Entity": "Normal"
    },
    {
        "Text": "The tagger further restricts the set of possible test attributes by requiring that some attribute of the POS tag at position i-k (i=position of the predicted POS tag, k \u2265 1) must have been used be fore an attribute of the POS tag at position i-(k+1) may be examined.",
        "Entity": "Normal"
    },
    {
        "Text": "This restriction improved the tagging accuracy for large contexts.",
        "Entity": "Normal"
    },
    {
        "Text": "2.2 Pruning Criterion.",
        "Entity": "Normal"
    },
    {
        "Text": "The tagger applies3 the critical-value pruning strategy proposed by (Mingers, 1989).",
        "Entity": "Normal"
    },
    {
        "Text": "A node is pruned if the information gain of the best test multiplied by the size of the data subsample is below a given threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "To illustrate the pruning, assume that D is the data of the current node with 50 positive and 25 negative elements, and that D1 (with 20 positive and 20 negative elements) and D2 (with 30 positive and 5 negative elements) are the two subsets induced by the best test.",
        "Entity": "Normal"
    },
    {
        "Text": "The entropy of D is \u22122/3 log22/3 \u2212 1/3 log21/3 = 0.92, the entropy of D1 is \u22121/2 log21/2\u22121/2 log21/2 = 1, and the entropy of D2 is \u22126/7 log26/7 \u2212 1/7 log21/7 = 0.59.",
        "Entity": "Normal"
    },
    {
        "Text": "The information gain is therefore 0.92 \u2212 (8/15 \u2217 1 \u2212 7/15 \u2217 0.59) = 0.11.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting score is 75 \u2217 0.11 = 8.25.",
        "Entity": "Normal"
    },
    {
        "Text": "Given a threshold of 6, the node is therefore not pruned.",
        "Entity": "Normal"
    },
    {
        "Text": "We experimented with pre-pruning (where a node is always pruned if the gain is below the in the two subsets.",
        "Entity": "Normal"
    },
    {
        "Text": "The weight of each subset is proportional to its size.",
        "Entity": "Normal"
    },
    {
        "Text": "2 We did not directly compare the two alternatives (two- valued vs. multi-valued tests), because the implementational effort required would have been too large.",
        "Entity": "Normal"
    },
    {
        "Text": "3 We also experimented with a pruning criterion based on binomial tests, which returned smaller trees with a slightly lower accuracy, although the difference in accuracy was never larger than 0.1% for any context size.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, the simpler pruning strategy presented here was chosen.",
        "Entity": "Normal"
    },
    {
        "Text": "threshold) as well as post-pruning (where a node is only pruned if its sub-nodes are terminal nodes or pruned nodes).",
        "Entity": "Normal"
    },
    {
        "Text": "The performance of pre-pruning was slightly better and it was less dependent on the choice of the pruning threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "A threshold of 6 consistently produced optimal or near optimal results for pre-pruning.",
        "Entity": "Normal"
    },
    {
        "Text": "Thus, pre-pruning with a threshold of 6 was used in the experiments.",
        "Entity": "Normal"
    },
    {
        "Text": "The tagger treats dots in POS tag labels as attribute separators.",
        "Entity": "Normal"
    },
    {
        "Text": "The first attribute of a POS tag is the main category.",
        "Entity": "Normal"
    },
    {
        "Text": "The number of additional attributes is fixed for each main category.",
        "Entity": "Normal"
    },
    {
        "Text": "The additional attributes are category-specific.",
        "Entity": "Normal"
    },
    {
        "Text": "The singular attribute of a noun and an adjective POS tag are therefore two different attributes.4 Each position in the POS tags of a given category corresponds to a feature.",
        "Entity": "Normal"
    },
    {
        "Text": "The attributes occurring at a certain position constitute the value set of the feature.",
        "Entity": "Normal"
    },
    {
        "Text": "Our tagger is a HMM tagger which decomposes the context probabilities into a product of attribute probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "The probability of an attribute given the attributes of the preceding POS tags as well asand that the context probability p(ti|ti\u22121 ) is internally computed as a product of attribute probabili ties.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to increase the speed, the tagger also applies a beam-search strategy which prunes all search paths whose probability is below the probability of the best path times a threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "With athreshold of 10\u22123 or lower, the influence of prun ing on the tagging accuracy was negligible.",
        "Entity": "Normal"
    },
    {
        "Text": "4.1 Supplementary Lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "The tagger may use an external lexicon which supplies entries for additional words which are not found in the training corpus, and additional tags for words which did occur in the training data.",
        "Entity": "Normal"
    },
    {
        "Text": "If an external lexicon is provided, the lexical probabilities are smoothed as follows: The tagger computes the average tag probabilities of all words with the same set of possible POS tags.",
        "Entity": "Normal"
    },
    {
        "Text": "The Witten-Bell method is then applied to smooth the lexical probabilities with the average probabilities.",
        "Entity": "Normal"
    },
    {
        "Text": "If the word w was observed with N different tags, and f (w, t) is the joint frequency of w and POS tag t, and p(t|[w]) is the average probability of t among words with the same set of possible tags as w, then the smoothed probability of t given w is defined as follows: f (w, t) + N p(t|[w]) the preceding attributes of the predicted POS tag is estimated with a decision tree as described be p(t|w) = f (w) + N fore.",
        "Entity": "Normal"
    },
    {
        "Text": "The probabilities at the terminal nodes of the decision trees are smoothed with the parent node probabilities (which themselves were smoothed in the same way).",
        "Entity": "Normal"
    },
    {
        "Text": "The smoothing is implemented by adding the weighted class probabilities pp(c) of the parent node to the frequencies f (c) before normalizing them to probabilities: p(c) = f (c) + \u03b1pp(c) \u03b1 + \ufffdc f (c) The weight \u03b1 was fixed to 1 after a few experiments on development data.",
        "Entity": "Normal"
    },
    {
        "Text": "This smoothing strategy is closely related to Witten-Bell smoothing.",
        "Entity": "Normal"
    },
    {
        "Text": "The probabilities are normalized by dividing them by the total probability of all attribute values of the respective feature (see section 2.1).",
        "Entity": "Normal"
    },
    {
        "Text": "The best tag sequence is computed with the Viterbi algorithm.",
        "Entity": "Normal"
    },
    {
        "Text": "The main differences of our tag- ger to a standard trigram tagger are that the order of the Markov model (the k in equation 1) is not fixed 4 This is the reason why the attribute tests in figure 1 used complex attributes such as ART.Nom rather than Nom.The smoothed estimates of p(tag|word) are di vided by the prior probability p(tag) of the tag and used instead of p(word|tag).5 4.2 Unknown Words.",
        "Entity": "Normal"
    },
    {
        "Text": "The lexical probabilities of unknown words are obtained as follows: The unknown words are divided into four disjoint classes6 with numeric expressions, words starting with an uppercase letter, words starting with a lowercase letter, and a fourth class for the other words.",
        "Entity": "Normal"
    },
    {
        "Text": "The tagger builds a suffix trie for each class of unknown words using the known word types from that class.",
        "Entity": "Normal"
    },
    {
        "Text": "The maximal length of the suffixes is 7.",
        "Entity": "Normal"
    },
    {
        "Text": "The suffix tries are pruned until (i) all suffixes have a frequency of at least 5 and (ii) the information gain multiplied by the suffix frequency and di 5 p(word|tag) is equal to p(tag|word)p(word)/p(tag) and p(word) is a constant if the tokenization is unambiguous.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore dropping the factor p(word) has no influence on the ranking of the different tag sequences.",
        "Entity": "Normal"
    },
    {
        "Text": "6 In earlier experiments, we had used a much larger number of word classes.",
        "Entity": "Normal"
    },
    {
        "Text": "Decreasing their number to 4 turned out to be better.",
        "Entity": "Normal"
    },
    {
        "Text": "a threshold of 1.",
        "Entity": "Normal"
    },
    {
        "Text": "More precisely, if T\u03b1 is the set of POS tags that occurred with suffix \u03b1, |T | is the size of the set T , f\u03b1 is the frequency of suffix \u03b1, and p\u03b1(t) is the probability of POS tag t among the words with suffix \u03b1, then the following condition must hold: tion between definite and indefinite articles, and the distinction between hyphens, slashes, left and right parentheses, quotation marks, and other symbols which the Tiger treebank annotates with \u201c$(\u201d.",
        "Entity": "Normal"
    },
    {
        "Text": "A supplementary lexicon was created by analyzing a word list which included all words from the fa\u03b1 pa\u03b1 (t) log pa\u03b1(t) < 1 training, development, and test data with a German computationa l morphology.",
        "Entity": "Normal"
    },
    {
        "Text": "The analyses gener |Ta\u03b1| t\u2208Ta\u03b1 p\u03b1(t) ated by the morphology were mapped to the Tiger The POS probabilities are recursively smoothed with the POS probabilities of shorter suffixes using Witten-Bell smoothing.",
        "Entity": "Normal"
    },
    {
        "Text": "Our tagger was first evaluated on data from the German Tiger treebank.",
        "Entity": "Normal"
    },
    {
        "Text": "The results were compared to those obtained with the TnT tagger (Brants, 2000) and the SVMTool (Gime\u00b4nez and Ma`rquez, 2004), which is based on support vector machines.7 The training of the SVMTool took more than a day.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore it was not possible to optimize the parameters systematically.",
        "Entity": "Normal"
    },
    {
        "Text": "We took standard features from a 5 word window and M4LRL training without optimization of the regular- ization parameter C. In a second experiment, our tagger was also evaluated on the Czech Academic corpus 1.0 (Hladka\u00b4 et al., 2007) and compared to the TnT tag- ger.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1 Tiger Corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "The German Tiger treebank (Brants et al., 2002) contains over 888,000 tokens.",
        "Entity": "Normal"
    },
    {
        "Text": "It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.",
        "Entity": "Normal"
    },
    {
        "Text": "After deleting problematic sentences (e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "with an incomplete annotation) and automatically correcting some easily detectable errors, 885,707 tokens were left.",
        "Entity": "Normal"
    },
    {
        "Text": "The first 80% were used as training data, the first half of the rest as development data, and the last 10% as test data.",
        "Entity": "Normal"
    },
    {
        "Text": "Some of the 54 STTS labels were mapped to new labels with dots, which reduced the number of main categories to 23.",
        "Entity": "Normal"
    },
    {
        "Text": "Examples are the nominal POS tags NN and NE which were mapped to N.Reg and N.Name.",
        "Entity": "Normal"
    },
    {
        "Text": "Some lexically decidable distinctions missing in the Tiger corpus have been tagset.",
        "Entity": "Normal"
    },
    {
        "Text": "Note that only the words, but not the POS tags from the test and development data were used, here.",
        "Entity": "Normal"
    },
    {
        "Text": "Therefore, it is always possible to create a supplementary lexicon for the corpus to be processed.",
        "Entity": "Normal"
    },
    {
        "Text": "In case of the TnT tagger, the entries of the supplementary lexicon were added to the regular lexicon with a default frequency of 1 if the word/tag- pair was unknown, and with a frequency proportional to the prior probability of the tag if the word was unknown.",
        "Entity": "Normal"
    },
    {
        "Text": "This strategy returned the best results on the development data.",
        "Entity": "Normal"
    },
    {
        "Text": "In case of the SVM- Tool, we were not able to successfully integrate the supplementary lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1.1 Refined Tagset Prepositions are not annotated with case in the Tiger treebank, although this information is important for the disambiguation of the case of the next noun phrase.",
        "Entity": "Normal"
    },
    {
        "Text": "In order to provide the tagger with some information about the case of prepositions, a second training corpus was created in which prepositions which always select the same case, such as durch (through), were annotated with this case (APPR.Acc).",
        "Entity": "Normal"
    },
    {
        "Text": "Prepositions which select genitive case, but also occur with dative case8, were tagged with APPR.Gen.",
        "Entity": "Normal"
    },
    {
        "Text": "The more frequent ones of the remaining prepositions, such as in (in), were lexicalized (APPR.in).",
        "Entity": "Normal"
    },
    {
        "Text": "The refined tagset also distinguished between the auxiliaries sein, haben, and werden, and used lexicalized tags for the coordinating conjunctions aber, doch, denn, wie, bis, noch, and als whose distribution differs from the distribution of prototypical coordinating conjunctions such as und (and) or oder (or).",
        "Entity": "Normal"
    },
    {
        "Text": "For evaluation purposes, the refined tags are mapped back to the original tags.",
        "Entity": "Normal"
    },
    {
        "Text": "This mapping is unambiguous.",
        "Entity": "Normal"
    },
    {
        "Text": "7 It was planned to include also the Stanford tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "(Toutanova et al., 2003) in this comparison, but it was not possible to train it on the Tiger data.",
        "Entity": "Normal"
    },
    {
        "Text": "8 In German, the genitive case of arguments is more and.",
        "Entity": "Normal"
    },
    {
        "Text": "more replaced by the dative.",
        "Entity": "Normal"
    },
    {
        "Text": "much smaller.",
        "Entity": "Normal"
    },
    {
        "Text": "The first result was obtained with TnT trained on Tiger data which was mapped to STTS before.",
        "Entity": "Normal"
    },
    {
        "Text": "The second row contains the results for the TnT tagger when it is trained on the Tiger data and the output is mapped to STTS.",
        "Entity": "Normal"
    },
    {
        "Text": "The third row gives the corresponding figures for our tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "5.1.2 Results                                                                                                    \n\t\t\t                                                                                                                                                                                                                          \n\t\t\t                                                             \n\t\t\tA tag is considered correct if all attributes are correct.",
        "Entity": "Normal"
    },
    {
        "Text": "The SVMTool is slightly better than the TnT tagger on the default tagset, but shows little improvement from the tagset refinement.",
        "Entity": "Normal"
    },
    {
        "Text": "Apparently, the lexical features used by the SVMTool encode most of the information of the tagset refinement.",
        "Entity": "Normal"
    },
    {
        "Text": "With a context of two preceding POS tags (similar to the trigram tagger TnT), our tagger outperforms TnT by 0.7% on the default tagset, by 1% on the refined tagset, and by 1.1% on the refined tagset plus the additional lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "A larger context of up to 10 preceding POS tags further increased the accuracy by 0.6, 0.6, and 0.7%, respectively.",
        "Entity": "Normal"
    },
    {
        "Text": "de fa ult refined ref.+lexicon T n T S T T S T n T Ti g e r 1 0 t a g s 9 7.",
        "Entity": "Normal"
    },
    {
        "Text": "2 8 9 7.",
        "Entity": "Normal"
    },
    {
        "Text": "1 7 97.26 97.51 9 7.",
        "Entity": "Normal"
    },
    {
        "Text": "3 9 97.57 97.97                                                                                                                                                               \n\t\t\tThese figures are considerably lower than e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "the 96.7% accuracy reported in Brants (2000) for the Negra treebank which is annotated with STTS tags without agreement features.",
        "Entity": "Normal"
    },
    {
        "Text": "This is to 9 Unknown words are tagged by choosing the most frequent tag of words with the same capitalization.",
        "Entity": "Normal"
    },
    {
        "Text": "The best results are obtained with a context size of 10.",
        "Entity": "Normal"
    },
    {
        "Text": "What type of information is relevant across a distance of ten words?",
        "Entity": "Normal"
    },
    {
        "Text": "A good example is the decision tree for the attribute first person of finite verbs, which looks for a first person pronoun at positions -1 through -10 (relative to the position of the current word) in this order.",
        "Entity": "Normal"
    },
    {
        "Text": "Since German is a verb-final language, these tests clearly make sense.",
        "Entity": "Normal"
    },
    {
        "Text": "Our tagger was used with a context size of 10.",
        "Entity": "Normal"
    },
    {
        "Text": "The suffix length parameter of the TnT tagger was set to 6 without lexicon and to 3 with lexicon.",
        "Entity": "Normal"
    },
    {
        "Text": "These values were optimal on the development data.",
        "Entity": "Normal"
    },
    {
        "Text": "The accuracy of our tagger is lower than on the development data.",
        "Entity": "Normal"
    },
    {
        "Text": "This could be due to the higher rate of unknown words (10.0% vs. 7.7%).",
        "Entity": "Normal"
    },
    {
        "Text": "Relative to the TnT tagger, however, the accuracy is quite similar for test and development data.",
        "Entity": "Normal"
    },
    {
        "Text": "The differences between the two taggers are significant.10 ta gg er de fa ult refined ref.+lexicon Tn T ou r ta gg er 8 3.",
        "Entity": "Normal"
    },
    {
        "Text": "4 5 84.11 89.14 8 5.",
        "Entity": "Normal"
    },
    {
        "Text": "0 0 85.92 91.07                                          \n\t\t\t                                                                                           \n\t\t\tIf 10 726 sentences were better tagged by TnT (i.e.",
        "Entity": "Normal"
    },
    {
        "Text": "with few errors), 1450 sentences were better tagged by our tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "The resulting score of a binomial test is below 0.001.",
        "Entity": "Normal"
    },
    {
        "Text": "Our tagger is quite fast, although not as fast as the TnT tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "With a context size of 3 (10), it annotates 7000 (2000) tokens per second on a computer with an Athlon X2 4600 CPU.",
        "Entity": "Normal"
    },
    {
        "Text": "The training with a context size of 10 took about 4 minutes.",
        "Entity": "Normal"
    },
    {
        "Text": "5.2 Czech Academic Corpus.",
        "Entity": "Normal"
    },
    {
        "Text": "We also evaluated our tagger on the Czech Academic corpus (Hladka\u00b4 et al., 2007) which contains 652.131 tokens and about 1200 different POS tags.",
        "Entity": "Normal"
    },
    {
        "Text": "The data was divided into 80% training data, 10% development data and 10% test data.",
        "Entity": "Normal"
    },
    {
        "Text": "89 88.9 88.8 Provost & Domingos (2003) noted that well- known decision tree induction algorithms such as C4.5 (Quinlan, 1993) or CART (Breiman et al., 1984) fail to produce accurate probability estimates.",
        "Entity": "Normal"
    },
    {
        "Text": "They proposed to grow the decision trees to their maximal size without pruning, and to smooth the probability estimates with add-1 smoothing (also known as the Laplace correction).",
        "Entity": "Normal"
    },
    {
        "Text": "Ferri et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2003) describe a more complex backoff smoothing method.",
        "Entity": "Normal"
    },
    {
        "Text": "Contrary to them, we applied pruning and found that some pruning (threshold=6) gives better results than no pruning (threshold=0).",
        "Entity": "Normal"
    },
    {
        "Text": "Another difference is that we used N two- class trees with normalization to predict the probabilities of N classes.",
        "Entity": "Normal"
    },
    {
        "Text": "These two-class trees can be pruned with a fixed pruning threshold.",
        "Entity": "Normal"
    },
    {
        "Text": "Hence there is no need to put aside training data for parameter tuning.",
        "Entity": "Normal"
    },
    {
        "Text": "88.7 88.6 88.5 \u2019 c o n t e x t d a t a 2 \u2019 2 3 4 5 6 7 8 9 10 A n ope n que stio n is wh eth er the SV MT ool (or oth er dis cri min ativ ely trai ned tag ger s) cou ld out - perf orm the pre sen ted tag ger if the sa me dec om positi on of PO S tag s and the sa me con text size was                                                                  The best accuracy of our tagger on the development set was 88.9% obtained with a context of 4 preceding POS tags.",
        "Entity": "Normal"
    },
    {
        "Text": "The best accuracy of the TnT tagger was 88.2% with a maximal suffix length of 5.",
        "Entity": "Normal"
    },
    {
        "Text": "The difference is significant.",
        "Entity": "Normal"
    },
    {
        "Text": "Our tagger combines two ideas, the decomposition of the probability of complex POS tags into a product of feature probabilities, and the estimation of the conditional probabilities with decision trees.",
        "Entity": "Normal"
    },
    {
        "Text": "A similar idea was previously presented in Kempe (1994), but apparently never applied again.",
        "Entity": "Normal"
    },
    {
        "Text": "The tagging accuracy reported by Kempe was below that of a traditional trigram tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "Unlike him, we found that our tagging method outperformed state-of-the-art POS taggers on fine-grained POS tagging even if only a trigram context was used.",
        "Entity": "Normal"
    },
    {
        "Text": "Schmid (1994) and Ma`rquez (1999) used decision trees for the estimation of contextual tag probabilities, but without a decomposition of the tag probability.",
        "Entity": "Normal"
    },
    {
        "Text": "Magerman (1994) applied probabilistic decision trees to parsing, but not with a generative model.",
        "Entity": "Normal"
    },
    {
        "Text": "used.",
        "Entity": "Normal"
    },
    {
        "Text": "We think that this might be the case if the SVM features are restricted to the set of relevant attribute combinations discovered by the decision tree, but we doubt that it is possible to train the SVMTool (or other discriminatively trained tag- gers) without such a restriction given the difficulties to train it with the standard context size.",
        "Entity": "Normal"
    },
    {
        "Text": "Czech POS tagging has been extensively studied in the past (Hajic\u02c7 and Vidova\u00b4-Hladka\u00b4, 1998; Hajic\u02c7 et al., 2001; Votrubec, 2006).",
        "Entity": "Normal"
    },
    {
        "Text": "Spoustov et al.",
        "Entity": "Normal"
    },
    {
        "Text": "(2007) compared several POS taggers including an n-gram tagger and a discriminatively trained tagger (Morc\u02c7e), and evaluated them on the Prague Dependency Treebank (PDT 2.0).",
        "Entity": "Normal"
    },
    {
        "Text": "Morc\u02c7e\u2019s tagging accuracy was 95.12%, 0.3% better than the n-gram tagger.",
        "Entity": "Normal"
    },
    {
        "Text": "A hybrid system based on four different tagging methods reached an accuracy of 95.68%.",
        "Entity": "Normal"
    },
    {
        "Text": "Because of the different corpora used and the different amounts of lexical information available, a direct comparison to our results is difficult.",
        "Entity": "Normal"
    },
    {
        "Text": "Furthermore, our tagger uses no corpus-specific heuristics, whereas Morc\u02c7e e.g.",
        "Entity": "Normal"
    },
    {
        "Text": "is optimized for Czech POS tagging.",
        "Entity": "Normal"
    },
    {
        "Text": "The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.",
        "Entity": "Normal"
    },
    {
        "Text": "We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.",
        "Entity": "Normal"
    },
    {
        "Text": "In experiments with German and Czech corpora, this method achieved a higher tagging accuracy than two state-of-the-art general-purpose POS taggers (TnT and SVMTool).",
        "Entity": "Normal"
    }
]