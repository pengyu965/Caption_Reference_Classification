[
    {
        "Text": "Figure 1: Effect of model parameters on performance.",
        "Entity": "Reference"
    },
    {
        "Text": "The algorithm takes into account possibly unaligned words at the boundaries of the source or target language phrases.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows the effect of the length of the language model history on translation quality.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Number of recall errors according to mention type (rows anaphor, columns antecedent).",
        "Entity": "Reference"
    },
    {
        "Text": "E.g., the city Fez, Mo rocco (figure 1) was tagged as a single LOCATION by one annotator and as two by the other.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the labeled dependency graph of example (2), taken from Talbanken05.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the distribution of character type sequences that constitute the infrequent words in the EDR corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "W can be encoded by an undirected graph G (Figure 2(a)), where the nouns are mapped to vertices and Wij is the edge weight between vertices i and j",
        "Entity": "Reference"
    },
    {
        "Text": "The results for French to English and for English to French are shown in Table 10",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows a constituent headed by a process nominal with an embedded adjective phrase.",
        "Entity": "Reference"
    },
    {
        "Text": "The TnT tagger achieves 86.3% accuracy on the default tagset.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 reports experimental results using lexical features only; we observe that the stemming n-gram features boost the performance by one point (64.7 vs. 65.8).",
        "Entity": "Reference"
    },
    {
        "Text": "We obtain the following decision rule: eI = argmax Pr(eI | f J ) 1 1 1 I 1 M ) = argmax m hm (eI , f J ) 1 1 I m=1",
        "Entity": "Reference"
    },
    {
        "Text": "Probabilities We find that Equation (7) assigns too little proba bilities to long words (5 or more characters).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Distributions of Morph Examples",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6 shows example sentences annotated by HGFC.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6: Sample targets for meta alternations with high AP and mid-coherence values.",
        "Entity": "Reference"
    },
    {
        "Text": "If it starts with a lower case letter, and contains both upper and lower case letters, then (mixedCaps, zone) is set to 1.",
        "Entity": "Reference"
    },
    {
        "Text": "he largest effect seems to come from taking into account the bigram dependence, which achieves an mWER of 32.9%",
        "Entity": "Reference"
    },
    {
        "Text": "The renormalization needed in equation (3) requires a sum over manypossible sentences, for which we do not know of an efficient algorithm",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering.",
        "Entity": "Reference"
    },
    {
        "Text": "alignment models Pr(f J , aJ | eI ),",
        "Entity": "Reference"
    },
    {
        "Text": "So we estimate that English translations are present in the English part of the corpus for Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "and 8 show word accuracy for Chasen, Juman, and our algorithm for parameter settings optimizing word precision, recall, and F-measure rates.",
        "Entity": "Reference"
    },
    {
        "Text": "An extract of the results is listed in table 1",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: Metaphors tagged by the system (in bold) whereby the main source of disagreement was the presence of lexicalized metaphors, e.g. verbs such as impose, decline etc.",
        "Entity": "Reference"
    },
    {
        "Text": "and ap plied to an Arabic sentence in figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Approximate times in seconds to generate predictions of maximum word sequence length M , on a 1.2GHz processor, for the MEMD model.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows a comparison with some existing toolkits that build deterministic, minimized automata/transducers.",
        "Entity": "Reference"
    },
    {
        "Text": "Tree setups P(%) R(%) F CS-SPT over SPT3 1.5 1.1 1.3 DSPT over SPT 1.1 5.6 3.8 UPST (FPT) over SPT 3.8 10.9 8.0 Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Examples of word bigrams including un known word tags example",
        "Entity": "Reference"
    },
    {
        "Text": "The bipartite graph K also induces a similarityagain (Figure 1(e)).",
        "Entity": "Reference"
    },
    {
        "Text": "W can be encoded by an undirected graph G (Figure 2(a)), where the nouns are mapped to vertices and Wij is the edge weight between vertices i and j",
        "Entity": "Reference"
    },
    {
        "Text": "In MUC6, the best result is achieved by SRA (Krupka, 1995).",
        "Entity": "Reference"
    },
    {
        "Text": "For MUC6, the reduction in error due to global features is 27%, and for MUC7,14%.",
        "Entity": "Reference"
    },
    {
        "Text": "(2004) makes use of a coding manual designed for a project studying genitive modification (Garretson et al., 2004) and presents an explicit annotation scheme for an _ Samma _ PO _ KP erfarenhet NN _ gjorde VV PT engelsmannen NN DD|HH imacy, illustrated by figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5: Meta alternations and their average precision values for the task.",
        "Entity": "Reference"
    },
    {
        "Text": "#e is the total number of English translation candidates in the period.",
        "Entity": "Reference"
    },
    {
        "Text": "An abridged version of the grammatical representation produced by the implemented grammar for this sentence is presented in Figure 1, where the feature structures below the tree correspond to partial grammatical representations of the constituents 16 See Kamp and Reyle (1993) for a comprehensive rendering of DRT, and Branco (2000, Chapter 5) for an.",
        "Entity": "Reference"
    },
    {
        "Text": "The unknown parameters are determined by maximizing the likelihood on the parallel training corpus:",
        "Entity": "Reference"
    },
    {
        "Text": "Equation (12), which is a set of word models trained for each part of speech (POS + Poisson + bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paa and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2",
        "Entity": "Reference"
    },
    {
        "Text": "Thus,we have crafted more specific explanations, sum marized for nouns in figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Reduction of conjuncts for NP coordination Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "An abridged version of the grammatical representation produced by the implemented grammar for this sentence is presented in Figure 1, where the feature structures below the tree correspond to partial grammatical representations of the constituents 16 See Kamp and Reyle (1993) for a comprehensive rendering of DRT, and Branco (2000, Chapter 5) for an.",
        "Entity": "Reference"
    },
    {
        "Text": "The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).",
        "Entity": "Reference"
    },
    {
        "Text": "An extract of the results is listed in table 1",
        "Entity": "Reference"
    },
    {
        "Text": "On the contrary, in the above training stage, although the samples are not accurate enough to represent the distribution defined by Equation 7 for each alignment aj , it is accurate enough for computing the expected counts, which are defined at the corpus level.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Scores for CityU corpus",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5: Meta alternations and their average precision values for the task.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in Figure 8, relative word performance was not degraded and sometimes even slightly better.",
        "Entity": "Reference"
    },
    {
        "Text": "First, the source sentence words f J are grouped into phrases f K . For each phrase f an 1 1 alignment template z is chosen and the sequence of chosen alignment templates is reordered (according to K ).",
        "Entity": "Reference"
    },
    {
        "Text": "Among all possible target sentences, we will choose the sentence with the highest probability",
        "Entity": "Reference"
    },
    {
        "Text": "However, if we remove the mouse-node from its local graph illustrated in figure 1, the graph decomposes into two parts, one representing the electronic device meaning of mouse and the other one representing its animal sense.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the experimental results with and without the stem n-grams features.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, look ing at Figure 2(b), V on G can be grouped into three clusters u1, u2 and u3.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the distribution of SSTs in the corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "In fact, from the last column of Figure 8 we see that even if our algorithm has access to only five anno tated sequences when Juman has access to ten times as many, we still achieve better precision and better F measure.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Accuracy of part of speech estimation each part of speech and word type (POS + WT + Poisson + bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "If we compare the error rates in Table 7, which correspond to about 55 search errors in Table 6, we obtain an mWER of 36.7% (53 search errors) using no heuristic function and an mWER of 32.6% (57 search errors) using the combined heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "The unknown parameters are determined by maximizing the likelihood on the parallel training corpus:",
        "Entity": "Reference"
    },
    {
        "Text": "#Cor is the number of correct English translations output.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, look ing at Figure 2(b), V on G can be grouped into three clusters u1, u2 and u3.",
        "Entity": "Reference"
    },
    {
        "Text": "This sum can be computed efficiently using the algorithm shown in Figure 8",
        "Entity": "Reference"
    },
    {
        "Text": "14http://www.cis.upenn.edu/ dbikel/software.html Gold standard Automatic UAS LAS UAS LAS Baseline 89.87 84.92 89.87 84.92 Anim 89.81 84.94 89.87 84.99 Table 5: Overall results in experiments with automatic features compared to gold standard features, expressed as unlabeled and labeled attachment scores.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 evaluates the contributions of different kinds of constituent dependencies to extraction performance on the 7 relation types of the ACE RDC 2004 corpus",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows the performance on the test data.",
        "Entity": "Reference"
    },
    {
        "Text": "We compare in Table 2 the performance of Unified Parse and Semantic Trees with different kinds of Entity Semantic Tree setups using standard convolution tree kernel, while the SPT and DSPT with only entity-type information are listed for reference.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Performance of the mention detection system including all ACE 04 subtasks",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows an example of calculating the target side SRS based on a complicated TTS template.",
        "Entity": "Reference"
    },
    {
        "Text": "Except our own and MENE + reference resolution, the results in Table 6 are all official MUC7 results.",
        "Entity": "Reference"
    },
    {
        "Text": "We also investigated the effect of varying M . The results are shown in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the correctness evaluation results.",
        "Entity": "Reference"
    },
    {
        "Text": "The statistics of 96 these splits are shown in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "We include a list of per-category results for selected phrasal labels, POS tags, and dependencies in Table 8.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Precision statistics for pronouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Examples of common character bigrams for each part of speech in the infrequent words pa rt of sp ee ch ch ar ac ter bi gr a m fre qu en cy no un nu m be r a dj e ct iv al v er b v er b ad je cti ve ad ve rb < e o w > <b o w > 1 S \" J < e o w > I t < e o w > L < e o w > < e o w > 13 43 4 8 4 3 2 7 2 1 3 69 63 resented all unknown words by one length model.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Number of recall errors according to mention type (rows anaphor, columns antecedent).",
        "Entity": "Reference"
    },
    {
        "Text": "Based on this experiment, we set the beam size of SegTagDep to 64 throughout the exper 64 96.28 92.37 74.96 0.48 Table 3: F1 scores and speed (in sentences per sec.)",
        "Entity": "Reference"
    },
    {
        "Text": "The dataset (table 1) consists of the main text of 28 articles selected from the topical domains of history, sports, science, and technology",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows that this reimplementation almost reproduces the accuracy of their implementation.",
        "Entity": "Reference"
    },
    {
        "Text": "The statistics of 96 these splits are shown in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "As an example, the probability of accepting the prediction in figure 1 is about .25.",
        "Entity": "Reference"
    },
    {
        "Text": "L set of lemmas IL set of (lemma-wise) instances SL set of (lemma-wise) senses inst : L (IL ) mapping lemma instances sns : L (SL ) mapping lemma senses M set of meta senses meta : SL M mapping senses meta senses A M M set of meta alternations (MAs) A set of MA representations score : A S2 R scoring function for MAs repA : A A MA representation function comp : A S2 R compatibility function Table 1: Notation and signatures for our framework.",
        "Entity": "Reference"
    },
    {
        "Text": "See Figure 3 for examples.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the performance and processing time comparison of various models and their combinations.",
        "Entity": "Reference"
    },
    {
        "Text": "The results when we set M = 10 are shown in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "The first model is Equation (5), which is the combina . tion of Poisson distribution and character zerogram",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows a confusion matrix for the classification of the nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 summarizes the results obtained with different taggers and tagsets on the development data.",
        "Entity": "Reference"
    },
    {
        "Text": "Tree setups P(%) R(%) F CS-SPT over SPT3 1.5 1.1 1.3 DSPT over SPT 1.1 5.6 3.8 UPST (FPT) over SPT 3.8 10.9 8.0 Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8a shows that the best model recovers SBAR at only 71.0% F1.",
        "Entity": "Reference"
    },
    {
        "Text": "Our experimental data was drawn from 150 megabytes of 1993 Nikkei newswire (see Figure I).",
        "Entity": "Reference"
    },
    {
        "Text": "By introducing the distinction of word type to the model of Equation(12),we can derive a more sophis ticated unknown word model that reflects both word 3 When a Chinese character is used to represent a seman tically equivalent Japanese verb, its root is written in the Chinese character and its inflectional suffix is written in hi ragana.",
        "Entity": "Reference"
    },
    {
        "Text": "As illus trated in Figure 1(e), the NP coordination in the Qian et al.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 reports experimental results using lexical features only; we observe that the stemming n-gram features boost the performance by one point (64.7 vs. 65.8).",
        "Entity": "Reference"
    },
    {
        "Text": "On the other hand, using our method of combining both sources of information and setting M = \u221e, 19 Chinese words (i.e., the first 22 Chinese words in Table 3 except \u5df4\u4f50\u4e9a,\u5769\u57da,\u666e\u5229\u6cd5) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "MENE has only been tested on MUC7.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Results for different predictor configurations.",
        "Entity": "Reference"
    },
    {
        "Text": ">10 nouns (a) (b) classified as 222 125 (a) class animate 49 3390 (b) class inanimate Table 4: Confusion matrix for the MBLclassifier with a general feature space on the >10 data set on Talbanken05 nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Collecting evidence for a word boundary - are the non-straddling n-grams 8 1 and 82 more frequent than the straddling n-grams t 1, t2, and t3?",
        "Entity": "Reference"
    },
    {
        "Text": "e suggest the use of a log-linear model to incorporate the various knowledge sources into an overall translation system and to perform discriminative training of the free model parameters",
        "Entity": "Reference"
    },
    {
        "Text": "segmentation (Table 2).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 presents the performance in terms of precision, recall, and F- measure of the whole system.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 underscores the virtues of Sentence Recency: In the most recent sentence with antecedents satisfying the filters, there are on aver ble.",
        "Entity": "Reference"
    },
    {
        "Text": "For fair comparison, we have tabulated all results with the size of training data used (Table 5",
        "Entity": "Reference"
    },
    {
        "Text": "(Abbreviations are listed in Table 2.)",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in figure 3, read times are much higher for predictions that get accepted, re B(x, k, a) = R1(x) + T (x, k) E(x, k), a = 1 R0(x), a = 0 flecting both a more careful perusal by the translator and the fact the rejected predictions are often simplywhere Ra(x) is the cost of reading x when it ulignored.2 In both cases there is a weak linear rela timately gets accepted (a = 1) or rejected (a = 0), T (x, k) is the cost of manually typing xk , and E(x, k) is the edit cost of accepting x and erasing to the end of its first k characters.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows a probability estimation tree for the prediction of the probability of the nominative attribute of nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "The breakdown of the different types of words found by ST in the test corpus is given in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6 gives an overview of the decisions made in the alignment template model.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 4 and 5 show the effect of the pruning parameter tp with the histogram pruning parameter Np = 50,000",
        "Entity": "Reference"
    },
    {
        "Text": "For MUC6, the reduction in error due to global features is 27%, and for MUC7,14%.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Feature templates for the full joint model.",
        "Entity": "Reference"
    },
    {
        "Text": "Then, every phrase f produces its translation e (using the corresponding alignment template z).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 The cost as a novel given name (second position) for hanzi from various radical classes.",
        "Entity": "Reference"
    },
    {
        "Text": "The annotation manual (Teleman, 1974) states that a markable should be tagged as human (H H) if it may be replaced by the interrogative pronoun vem who and be referred to by the personal pronouns han he or hon she .There are clear similarities between the anno tation for human reference found in Talbanken05 and the annotation scheme for animacy discussed HUM Other animate Inanimate ORG ANIM CONC NCONC TIME PLACE Figure 1: Animacy classification scheme (Zaenen et al., 2004)",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows examples of the discovered patterns for the merger and acquisition topic.",
        "Entity": "Reference"
    },
    {
        "Text": "As can be seen in Table 4, our training data is a lot less than those used by MENE and IdentiFinder3.",
        "Entity": "Reference"
    },
    {
        "Text": "U = {up}m represent the hidden m struct a new graph G1 (Figure 1(d)) with the clusters U as vertices.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Bootstrapping new heuristics.",
        "Entity": "Reference"
    },
    {
        "Text": "The list of the features used in our joint model is presented in Table 1, where S01 S05, W01 W21, and T01 05 are taken from Zhang and Clark (2010), and P01 P28 are taken from Huang and Sagae (2010).",
        "Entity": "Reference"
    },
    {
        "Text": "As Table 1 shows, word bigrams whose infrequent word bigram",
        "Entity": "Reference"
    },
    {
        "Text": "To illustrate how SRF impacts the translation results, Figure 8 gives 3 examples of the MT outputs with and without the SRFs",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 9 shows that in fact both contribute to producing good segmentations.",
        "Entity": "Reference"
    },
    {
        "Text": "Table (1) and Eq.",
        "Entity": "Reference"
    },
    {
        "Text": "W can be encoded by a undi rected graph G (Figure 1(a)), where the verbs are mapped to vertices and the Wij is the edge weight between vertices i and j.",
        "Entity": "Reference"
    },
    {
        "Text": "The second factor of Equation (13) is estimated from the Poisson distribution whose parameter",
        "Entity": "Reference"
    },
    {
        "Text": "For the Verbmobil task, we train the model parameters M according to the maximum class posterior probability criterion (equation (4)).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 evaluates the contributions of different kinds of constituent dependencies to extraction performance on the 7 relation types of the ACE RDC 2004 corpus",
        "Entity": "Reference"
    },
    {
        "Text": "In the table, Nc indicates the number of clusters in the inferred tree, while Nl indicates the closest match to the number of classes in the gold standard.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, looking at Figure 1(b), V on G can be grouped into three clusters u1, u2 and u3.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Decoding algorithm for the standard Tree-to-String transducer.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 1, period 1 is Jul 01 \u2013 Jul 15, period 2 is Jul 16 \u2013 Jul 31, \u2026, period 12 is Dec 16 \u2013 Dec 31.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Distributions of Morph Examples",
        "Entity": "Reference"
    },
    {
        "Text": "#c is the total number of new Chinese source words in the period",
        "Entity": "Reference"
    },
    {
        "Text": "However, if we remove the mouse-node from its local graph illustrated in figure 1, the graph decomposes into two parts, one representing the electronic device meaning of mouse and the other one representing its animal sense.",
        "Entity": "Reference"
    },
    {
        "Text": "The results when we set M = 10 are shown in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "In these experiments, the input lacks segmentation markers, hence the slightly different dev set baseline than in Table 6.",
        "Entity": "Reference"
    },
    {
        "Text": "The corresponding figures for the test data are. 89.53% for our tagger and 88.88% for the TnT tag- ger.",
        "Entity": "Reference"
    },
    {
        "Text": "Only tokens with initCaps not found in commonWords are tested against each list in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "composite kernel 83.0 72.0 77.1 Zhou et al., (2007): composite kernel 82.2 70.2 75.8 Zhang et al., (2006): composite kernel 76.1 68.4 72.1 Zhao and Grishman, (2005):4 composite kernel 69.2 70.5 70.4 Ours: CTK with UPST 80.1 70.7 75.1Zhou et al., (2007): context sensitive CTK with CS-SPT 81.1 66.7 73.2 Zhang et al., (2006): CTK with SPT 74.1 62.4 67.7 Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the effect of the role-based preference on our data.",
        "Entity": "Reference"
    },
    {
        "Text": "The performance of these systems is shown in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "This approach has been suggested by Papineni, Roukos, and Ward (1997, 1998) for a natural language understanding task.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows the tagging accuracy of unknown words.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the record for the headword orange followed by its collocates",
        "Entity": "Reference"
    },
    {
        "Text": "we directly model the posterior probability Pr(eI| f J )",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 6 and 7 show the effect of the pruning pa rameter Np with the pruning parameter tp = 10 12",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 6 and 7 show the effect of the pruning pa rameter Np with the pruning parameter tp = 10 12",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the absolute frequencies of sen tence recency values when only the most recent antecedent (in the order just stated) is considered.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Illustration of dictionary based segmenta tion finite state transducer 3.1 Bootstrapping.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Above: The complete supersense tagset for nouns; each tag is briefly described by its symbol, NAME, short description, and examples.",
        "Entity": "Reference"
    },
    {
        "Text": "Cik Figure 1: Local graph of the word mouse",
        "Entity": "Reference"
    },
    {
        "Text": "As a result, Arabic sentences are usually long relative to English, especially after",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows a constituent headed by a process nominal with an embedded adjective phrase.",
        "Entity": "Reference"
    },
    {
        "Text": "The accuracy of a baseline tagger which chooses the most probable tag9 ignoring the context is 67.3% without and 69.4% with the supple 92.3 92.2 92.1 92 91.9 91.8 91.7 91.6 91.5 91.4 2 3 4 5 6 7 8 9 10 mentary lexicon.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Effect of Arabic stemming features on coreference resolution.",
        "Entity": "Reference"
    },
    {
        "Text": "The dataset (table 1) consists of the main text of 28 articles selected from the topical domains of history, sports, science, and technology",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in Table 3, using just context information alone, 10 Chinese words (the first 10) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "The tagset refinement increases the accuracy by about 0.6%, and the external lexicon by another 3.5%.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the results of both unconstrained and constrained versions of HGFC and those of AGG on the test set T3 (where singular classes are removed to enable proper evaluation of the constrained method).",
        "Entity": "Reference"
    },
    {
        "Text": "Recall is somewhat difficult to estimate because we do not know whether the English translation of a Chinese word appears in the English part of the corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 Differences in performance between our system and Wang, Li, and Chang (1992).",
        "Entity": "Reference"
    },
    {
        "Text": "able 1 shows the bilingual phrases containing between two and seven words that result from the application of this algorithm to the alignment of Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "The breakdown of the different types of words found by ST in the test corpus is given in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Comparison against Stevenson and Joanis (2003) s result on T1 (using similar features).",
        "Entity": "Reference"
    },
    {
        "Text": "We also investigated the effect of varying M . The results are shown in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "This sum can be computed efficiently using the algorithm shown in Figure 8",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Performance of the mention detection system using lexical features only.",
        "Entity": "Reference"
    },
    {
        "Text": "the time-consuming renormalization in equation (3) is not needed in search",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: CoreLex s basic types with their corresponding WordNet anchors.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Distributions of Morph Examples",
        "Entity": "Reference"
    },
    {
        "Text": "In Figure 1(c) we show a sentence one of about 500 people nominated for , where there exists a DISC relationship between the entities one and people",
        "Entity": "Reference"
    },
    {
        "Text": "Considering that the way the semantic where all(T ) denotes all the possible target strings which can be generated from the source tree T . Given a set of TTS templates, the new partition function can be efficiently computed using the dynamic programming algorithm shown in Figure 7.",
        "Entity": "Reference"
    },
    {
        "Text": "The dataset (table 1) consists of the main text of 28 articles selected from the topical domains of history, sports, science, and technology",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Performance of the mention detection system including all ACE 04 subtasks",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6 gives an overview of the decisions made in the alignment template model.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 7 shows the results.",
        "Entity": "Reference"
    },
    {
        "Text": "The tagset refinement increases the accuracy by about 0.6%, and the external lexicon by another 3.5%.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 gives the mean values for the comparison of troughs placed by the segmentation algorithm to the segmentation points identified by the test subjects for all the texts",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Performance of baseline and joint models w.r.t. the average processing time (in sec.)",
        "Entity": "Reference"
    },
    {
        "Text": "To differentiate between the coordinating and discourse separator functions of conjunctions (Table 3), we mark each CC with the label of its right sister (splitCC).",
        "Entity": "Reference"
    },
    {
        "Text": "The list of the features used in our joint model is presented in Table 1, where S01 S05, W01 W21, and T01 05 are taken from Zhang and Clark (2010), and P01 P28 are taken from Huang and Sagae (2010).",
        "Entity": "Reference"
    },
    {
        "Text": "See Table 1 for details.",
        "Entity": "Reference"
    },
    {
        "Text": "It should be emphasized that this constraint to consecutive phrases limits the expressive power.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the correctness evaluation results.",
        "Entity": "Reference"
    },
    {
        "Text": "#e is the total number of English translation candidates in the period.",
        "Entity": "Reference"
    },
    {
        "Text": "The bipartite graph K also induces a similarityagain (Figure 1(e)).",
        "Entity": "Reference"
    },
    {
        "Text": "W can be encoded by a undi rected graph G (Figure 1(a)), where the verbs are mapped to vertices and the Wij is the edge weight between vertices i and j.",
        "Entity": "Reference"
    },
    {
        "Text": "We compared the ATB5 to tree- banks for Chinese (CTB6), German (Negra), and English (WSJ) (Table 4)",
        "Entity": "Reference"
    },
    {
        "Text": "The baseline system in Table 3 refers to the maximum entropy system that uses only local features.",
        "Entity": "Reference"
    },
    {
        "Text": "As the search space increases expo nentially, it is not possible to explicitly represent it.",
        "Entity": "Reference"
    },
    {
        "Text": "MENE has only been tested on MUC7.",
        "Entity": "Reference"
    },
    {
        "Text": "The results for French to English and for English to French are shown in Table 10",
        "Entity": "Reference"
    },
    {
        "Text": "Cik Figure 1: Local graph of the word mouse",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows that the tagging accuracy tends to increase with the context size.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4: An example showing how to compute the target side position of a semantic role by using the median of its aligning points.",
        "Entity": "Reference"
    },
    {
        "Text": "Another interesting example is shown in Figure 1(b), where the base-NP of the second entity town is a possessive NP and there is no relationship between the entities one and town defined in the ACE corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "This corresponds to maximizing the equivocation or maximizing the likelihood of the direct-translation model",
        "Entity": "Reference"
    },
    {
        "Text": "Probabilities We find that Equation (7) assigns too little proba bilities to long words (5 or more characters).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "able 2 shows the corpus statistics for this task.",
        "Entity": "Reference"
    },
    {
        "Text": "In the last two lines of Equation 3, \u03c6\u01eb and each P (f |e) = \"\u00a3s c (f |e; f (s), e(s)) (4) \u03c6i are not free variables, but are determined by f s c(f |e; f (s), e(s))the alignments.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the manual evaluation results based on the entire test set, and the improvement from SRF is significant at p < 0.005 based on a t-test.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows examples of the discovered patterns for the merger and acquisition topic.",
        "Entity": "Reference"
    },
    {
        "Text": "Fi gure 7 depic ts the comp atible brack ets and all comp atible brack ets rates.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Results for different predictor configurations.",
        "Entity": "Reference"
    },
    {
        "Text": "If the token starts with a capital letter (initCaps), then an additional feature (init- Caps, zone) is set to 1",
        "Entity": "Reference"
    },
    {
        "Text": "The overall architecture of the statistical translation approach is summarized in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "A standard criterion on a parallel training corpus consisting of S sentence pairs {(fs , es ): s = 1, .",
        "Entity": "Reference"
    },
    {
        "Text": "PRO (c) Entity-Paired Tree(EPT)Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "The results are displayed in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 Similarity matrix for segmentation judgments.",
        "Entity": "Reference"
    },
    {
        "Text": "As can be seen in Table 4, our training data is a lot less than those used by MENE and IdentiFinder3.",
        "Entity": "Reference"
    },
    {
        "Text": "U = {up}m represent the hidden m struct a new graph G1 (Figure 1(d)) with the clusters U as vertices.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 Classes of words found by ST for the test corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "This list of 43 words is shown in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "The overall architecture of the log-linear modeling approach is summarized in Figure 1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 Classes of words found by ST for the test corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Although kanji sequences are difficult to seg ment, they can comprise a significant portion of Japanese text, as shown in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "With an absolute frequency threshold of 10, we obtain an accuracy of 95.4%, which constitutes a 50% reduction of error rate.Table 3 presents the experimental results rela tive to class.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows the cross entropy per word and char acter perplexity of three unknown word model.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Illustration of dictionary based segmenta tion finite state transducer 3.1 Bootstrapping.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: An example showing the combination of the semantic role sequences of the states.",
        "Entity": "Reference"
    },
    {
        "Text": "#Cor is the number of correct English translations output.",
        "Entity": "Reference"
    },
    {
        "Text": "The baseline system in Table 3 refers to the maximum entropy system that uses only local features.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 Performance on morphological analysis.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the results of an evaluation based on the plain STTS tagset.",
        "Entity": "Reference"
    },
    {
        "Text": "As can be seen in figure 2, wing \"part of a bird\" is closely related to tail, as is wing \"part of a plane\"",
        "Entity": "Reference"
    },
    {
        "Text": "Results are shown in Table 2; we see that better word alignment results do not lead to better translations.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, no synset covers any combinations of the main words in Figure 2, namely buy , acquire and merger",
        "Entity": "Reference"
    },
    {
        "Text": "For example, in the sentence bought one of town s two meat- packing plants as illustrated in Figure 1(a), the constituents before the headword plants can be removed from the parse tree.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows examples of alignment templates",
        "Entity": "Reference"
    },
    {
        "Text": "using the convolution parse tree kernel as depicted in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "even after removal of the wing-node, the two areas of meaning are still linked via tail",
        "Entity": "Reference"
    },
    {
        "Text": "See Table 1 for details.",
        "Entity": "Reference"
    },
    {
        "Text": "Except our own and MENE + reference resolution, the results in Table 6 are all official MUC7 results.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the absolute frequencies of sen tence recency values when only the most recent antecedent (in the order just stated) is considered.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Precision statistics for pronouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Thetheoretical upper bound of the decoding complex Figure 5: Decoding algorithm using semantic role features.",
        "Entity": "Reference"
    },
    {
        "Text": "In Figure 4 we show an example of variation between the parsing models.",
        "Entity": "Reference"
    },
    {
        "Text": "Finally, Table 4 shows the results for the unconstrained HGFC on T2 and and T3 when the tree structure is not predefined but inferred automatically as described in section 3.2.3.",
        "Entity": "Reference"
    },
    {
        "Text": "The overall architecture of the statistical translation approach is summarized in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7: Computing the partition function of the conditional probability P r(S|T ).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Feature templates for the full joint model.",
        "Entity": "Reference"
    },
    {
        "Text": "This leaves us with 60 meta alternations, shown in Table 5.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the bilingual phrases containing between two and seven words that result from the application of this algorithm to the alignment of Figure 2",
        "Entity": "Reference"
    },
    {
        "Text": "see table 3) as the impact of soft constraints is the weakest for the constrained method at this level.",
        "Entity": "Reference"
    },
    {
        "Text": "We also propose to use the features U01 U03, which we found are effective to adjust the character Figure 1: Illustration of the alignment of steps.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 11 gives an overview on the training and test data.",
        "Entity": "Reference"
    },
    {
        "Text": "The alignment aJ that has the highest probability (under a certain model) is also called the Viterbi alignment (of that model)",
        "Entity": "Reference"
    },
    {
        "Text": "14http://www.cis.upenn.edu/ dbikel/software.html Gold standard Automatic UAS LAS UAS LAS Baseline 89.87 84.92 89.87 84.92 Anim 89.81 84.94 89.87 84.99 Table 5: Overall results in experiments with automatic features compared to gold standard features, expressed as unlabeled and labeled attachment scores.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Examples of word bigrams including un known word tags example",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6: Final results on CTB6 and CTB7 accuracies of POS tagging and dependency parsing were remarkably improved by 0.6% and 2.4%, respectively corresponding to 8.3% and 10.2% error reduction.",
        "Entity": "Reference"
    },
    {
        "Text": "At the morp heme level, stems are divid ed from their affixe s. For exam ple, altho ugh both naga no (Naga no) and shi (city) can appea r as indivi dual words , nagano shi (Nag ano city) is brack eted as [[naga no][s hi]], since here shi Figure 3: Determining word boundaries.",
        "Entity": "Reference"
    },
    {
        "Text": "(prec2 in Table 8)",
        "Entity": "Reference"
    },
    {
        "Text": "For the graph depicted in Figure 1 this algorithm computes the clusters {They, Leaders}, {Paris} and {recent developments}.",
        "Entity": "Reference"
    },
    {
        "Text": "Improvements of different tree setups over SPT on the ACE RDC 2004 corpus Finally, Table 4 compares our system with other state-of-the-art kernel-based systems on the 7 relation types of the ACE RDC 2004 corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 shows the decoding algorithm incorporating the SRR features.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows type- and token-level error rates for each corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "E.g. rat and printer are very different in meaning, but they are both closely related to different meanings of mouse",
        "Entity": "Reference"
    },
    {
        "Text": "Comparison of different systems on the ACE RDC 2004 corpus In Table 3 we summarize the improvements of different tree setups over SPT.",
        "Entity": "Reference"
    },
    {
        "Text": "the time-consuming renormalization in equation (3) is not needed in search",
        "Entity": "Reference"
    },
    {
        "Text": "We choose t = 1, 5, and 30 for the fertility HMM",
        "Entity": "Reference"
    },
    {
        "Text": "For instance, the gain for the prediction in figure 1 would be 2 7 8 = 6.",
        "Entity": "Reference"
    },
    {
        "Text": "The use of the language model feature in equation (18) helps take long-range dependencies better into account",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 underscores the virtues of Sentence Recency: In the most recent sentence with antecedents satisfying the filters, there are on aver ble.",
        "Entity": "Reference"
    },
    {
        "Text": "A natural unit for B(x, k, a) is the number of keystrokes saved, so all elements of the above equation are converted to this measure.",
        "Entity": "Reference"
    },
    {
        "Text": "The entity features can be attached under the top node, the entity nodes, or directly combined with the entity nodes as in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 plots AP by for all meta alternations.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 6 and 7 show the effect of the pruning pa rameter Np with the pruning parameter tp = 10 12",
        "Entity": "Reference"
    },
    {
        "Text": "A natural unit for B(x, k, a) is the number of keystrokes saved, so all elements of the above equation are converted to this measure.",
        "Entity": "Reference"
    },
    {
        "Text": "In these experiments, the input lacks segmentation markers, hence the slightly different dev set baseline than in Table 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 11 gives an overview on the training and test data.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 show the training time for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "#c is the total number of new Chinese source words in the period",
        "Entity": "Reference"
    },
    {
        "Text": "The third model is Equation (11), which is a set of word models trained for each word type (WT +Poisson+ bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "For example, if a token starts with a capital letter and ends with a period (such as Mr.), then the feature InitCapPeriod is set to 1, etc",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 lists new conceptsthat CAM introduces to manipulate vector represen tations.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows an example of calculating the target side SRS based on a complicated TTS template.",
        "Entity": "Reference"
    },
    {
        "Text": "The TnT tagger achieves 86.3% accuracy on the default tagset.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 4 and 5 show the effect of the pruning parameter tp with the histogram pruning parameter Np = 50,000.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows the performance on the test data.",
        "Entity": "Reference"
    },
    {
        "Text": "By introducing the distinction of word type to the model of Equation(12),we can derive a more sophis ticated unknown word model that reflects both word 3 When a Chinese character is used to represent a seman tically equivalent Japanese verb, its root is written in the Chinese character and its inflectional suffix is written in hi ragana.",
        "Entity": "Reference"
    },
    {
        "Text": "If we compare the error rates in Table 7, which correspond to about 55 search errors in Table 6, we obtain an mWER of 36.7% (53 search errors) using no heuristic function and an mWER of 32.6% (57 search errors) using the combined heuristic function",
        "Entity": "Reference"
    },
    {
        "Text": "(Equation (7)) (Poisson + hi gram).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows examples of alignment templates",
        "Entity": "Reference"
    },
    {
        "Text": "Recall is somewhat difficult to estimate because we do not know whether the English translation of a Chinese word appears in the English part of the corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 illustrates the effects of different components of the user model by showing results for simulated users who read infinitely fast and accept only predictions having positive benefit (superman); who read normally but accept like superman (rational); and who match the standard user model (real).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 shows our morpheme accuracy results.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Effect of Factors antecedent is found in the previous context, subsequent sentences are inspected (cataphora), also ordered by proximity to the pronoun.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Illustration of dictionary based segmenta tion finite state transducer 3.1 Bootstrapping.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the performance and speed of the full joint model (with no dictionaries) on CTB5c1 with respect to the beam size.",
        "Entity": "Reference"
    },
    {
        "Text": "see table 3) as the impact of soft constraints is the weakest for the constrained method at this level.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Snapshot of the supersense-annotated data.",
        "Entity": "Reference"
    },
    {
        "Text": "In the table, Nc indicates the number of clusters in the inferred tree, while Nl indicates the closest match to the number of classes in the gold standard.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in figure 1, a similarity matrix W models one-hop transitions that follow the links from vertices to neighbors.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows examples of the feature SRR.",
        "Entity": "Reference"
    },
    {
        "Text": "n all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 presents the distributions of some examples of morphs and their targets in English Twitter and Chinese Sina Weibo.",
        "Entity": "Reference"
    },
    {
        "Text": "The renormalization needed in equation (3) requires a sum over manypossible sentences, for which we do not know of an efficient algorithm",
        "Entity": "Reference"
    },
    {
        "Text": "The second condition is necessary to allow for single-character words (see Figure 3).",
        "Entity": "Reference"
    },
    {
        "Text": "We see that the language model perplexity improves from 4,781 for a unigram model to 29.9 for a trigram model.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows that by using word type and part of speech information, recall is improved from 28.1% to 40.6% and precision is improved from 57.3% to 64.1%.",
        "Entity": "Reference"
    },
    {
        "Text": "The second model is Equa tion (13), which is a set of word models trained for",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the labeled dependency graph of example (2), taken from Talbanken05.",
        "Entity": "Reference"
    },
    {
        "Text": "E.g. rat and printer are very different in meaning, but they are both closely related to different meanings of mouse",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the usefulness evaluation result.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 9 shows the training and test corpus statistics.",
        "Entity": "Reference"
    },
    {
        "Text": "see table 3) as the impact of soft constraints is the weakest for the constrained method at this level.",
        "Entity": "Reference"
    },
    {
        "Text": "But it conflates the coordinating and discourse separator functions of wa (<..4.b \ufffd \ufffd) into one analysis: conjunction(Table 3).",
        "Entity": "Reference"
    },
    {
        "Text": "For the graph depicted in Figure 1 this algorithm computes the clusters {They, Leaders}, {Paris} and {recent developments}.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 presents the performance in terms of precision, recall, and F- measure of the whole system.",
        "Entity": "Reference"
    },
    {
        "Text": "In our segmentation system, a hybrid strategy is applied (Figure 1): First, forward maximum matching (Chen and Liu, 1992), which is a dictionary-based method, is used to generate a segmentation result.",
        "Entity": "Reference"
    },
    {
        "Text": "An extract of the results is listed in table 1",
        "Entity": "Reference"
    },
    {
        "Text": "Contribution of constituent dependencies in respective mode (inside parentheses) and accumulative mode (outside parentheses) The table shows that the final DSPT achieves the best performance of 77.4%/65.4%/70.9 in precision/recall/F-measure respectively after applying all the dependencies, with the increase of F-measure by 8.2 units compared to the baseline MCT.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in Figure 8, relative word performance was not degraded and sometimes even slightly better.",
        "Entity": "Reference"
    },
    {
        "Text": "For the Verbmobil task, we train the model parameters M according to the maximum class posterior probability criterion (equation (4)).",
        "Entity": "Reference"
    },
    {
        "Text": "The translations of 6 of the 43 words are words in the dictionary (denoted as \u201ccomm.\u201d in Table 3) and 4 of the 43 words appear less than 10 times in the English part of the corpus (denoted as \u201cinsuff\u201d).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Example of a prediction for English to French translation.",
        "Entity": "Reference"
    },
    {
        "Text": "However, this information is hard to extract reliably from the available data; and even if were obtainable, many of the 0.3 0.2 0.1 0 60 50 40 30 20 10 0 10 20 30 40 50 60 gain (length of correct prefix length of incorrect suffix) Figure 2: Probability that a prediction will be accepted versus its gain.",
        "Entity": "Reference"
    },
    {
        "Text": "(2011), we confirmed that omission of the look-ahead features results in a 0.26% decrease in the parsing accuracy on CTB5d (dev).Figure 2: F1 scores (in %) of SegTagDep on CTB 5c1 w.r.t. the training epoch (x-axis) and parsing feature weights (in legend).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows the tagging accuracy of unknown words.",
        "Entity": "Reference"
    },
    {
        "Text": "The TnT tagger achieves 86.3% accuracy on the default tagset.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows empirical estimates of p(a = 1|2k l) from the TransType data.",
        "Entity": "Reference"
    },
    {
        "Text": "Also, the CRF model using maximum subword-based tagging (Zhang et al., 2006) and the CRF model using minimum subword-based tagging, both of which are statistical methods, are used individually to solve the Figure 1: Outline of the segmentation process 2.1 Forward Maximum Matching.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 Architecture of the statistical translation approach based on Bayes decision rule.",
        "Entity": "Reference"
    },
    {
        "Text": "As each global feature group is added to the list of features, we see improvements to both MUC6 and",
        "Entity": "Reference"
    },
    {
        "Text": "Another interesting example is shown in Figure 1(b), where the base-NP of the second entity town is a possessive NP and there is no relationship between the entities one and town defined in the ACE corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6: Sample targets for meta alternations with high AP and mid-coherence values.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Scores for MSRA corpus",
        "Entity": "Reference"
    },
    {
        "Text": "Throughout in this paper, we used Equation (9) to compute the word spelling probabilities.",
        "Entity": "Reference"
    },
    {
        "Text": "The points labelled smoothed in figure 2 were obtained using a sliding-average smoother, and the model curve was obtained using two-component Gaussian mixtures to fit the smoothed empirical likelihoods p(gain|a = 0) and p(gain|a = 1).",
        "Entity": "Reference"
    },
    {
        "Text": "igure 1 gives an example.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 The cost as a novel given name (second position) for hanzi from various radical classes.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 shows the decoding algorithm incorporating the SRR features.",
        "Entity": "Reference"
    },
    {
        "Text": "where ECD|S,T (fi), the expected count of a feature over all derivations given a pair of tree and string, can be computed using the modified inside- outside algorithm described in Section 3.2, and ECS |T (fi), the expected count of a feature over all possible target strings given the source tree, can be computed in a similar way to the partition function described in Figure 7.",
        "Entity": "Reference"
    },
    {
        "Text": "The performance of these systems is shown in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "W can be encoded by an undirected graph G (Figure 2(a)), where the nouns are mapped to vertices and Wij is the edge weight between vertices i and j",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Output of word sense clustering.",
        "Entity": "Reference"
    },
    {
        "Text": "E.g. rat and printer are very different in meaning, but they are both closely related to different meanings of mouse",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in figure 3, read times are much higher for predictions that get accepted, re B(x, k, a) = R1(x) + T (x, k) E(x, k), a = 1 R0(x), a = 0 flecting both a more careful perusal by the translator and the fact the rejected predictions are often simplywhere Ra(x) is the cost of reading x when it ulignored.2 In both cases there is a weak linear rela timately gets accepted (a = 1) or rejected (a = 0), T (x, k) is the cost of manually typing xk , and E(x, k) is the edit cost of accepting x and erasing to the end of its first k characters.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7 shows a structogram of the algorithm",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 describes the components and how this system works.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Accuracy of part of speech estimation each part of speech and word type (POS + WT + Poisson + bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "If the token starts with a capital letter (initCaps), then an additional feature (init- Caps, zone) is set to 1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the NA M N O M PR O NA M 34 13 (21 %) 67 (6 6 %) 11 (4 6 %) N O M 43 (67 %) 21 48 (4 9 %) 9 (8 9 %) PR O 86 8 (32 %) 17 71 (5 5 %) 53 08 (2 4 %) Table 2: Number of clustering decisions made according to mention type (rows anaphor, columns antecedent) and percentage of wrong decisions.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows an example of a symmetrized alignment",
        "Entity": "Reference"
    },
    {
        "Text": "this error is not counted, the tagging accuracy on the development data rises from 92.17% to 94.27%.",
        "Entity": "Reference"
    },
    {
        "Text": "A standard criterion on a parallel training corpus consisting of S sentence pairs {(fs , es ): s = 1, .",
        "Entity": "Reference"
    },
    {
        "Text": "To simplify the description, we assume in Figure 2 that a bigram language model is used and all the TTS templates are binarized.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7: Computing the partition function of the conditional probability P r(S|T ).",
        "Entity": "Reference"
    },
    {
        "Text": "For the graph depicted in Figure 1 this algorithm computes the clusters {They, Leaders}, {Paris} and {recent developments}.",
        "Entity": "Reference"
    },
    {
        "Text": "In addition to the basic regular expression operators shown in table 1, the formalism is extended in various ways.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Accuracy for MBL and SVM classifiers on Talbanken05 nouns in accumulated frequency bins by Parole frequency.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 gives the algorithm phrase-extract that computes the phrases",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 7 we give results for several evaluation metrics.",
        "Entity": "Reference"
    },
    {
        "Text": "This approach can be seen as a generalization of the originally suggested source channel modeling framework for statistical machine translation",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "Improvements of different tree setups over SPT on the ACE RDC 2004 corpus Finally, Table 4 compares our system with other state-of-the-art kernel-based systems on the 7 relation types of the ACE RDC 2004 corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "The results for French to English and for English to French are shown in Table 10",
        "Entity": "Reference"
    },
    {
        "Text": "Recall is somewhat difficult to estimate because we do not know whether the English translation of a Chinese word appears in the English part of the corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "The argmax operation denotes the search problem, that is, the generation of the output sentence in the target language",
        "Entity": "Reference"
    },
    {
        "Text": "Our experimental data was drawn from 150 megabytes of 1993 Nikkei newswire (see Figure I).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1(d) shows a sentence maintain rental property he owns in the state , where the ART.User-or-Owner relation holds between the entities property and he",
        "Entity": "Reference"
    },
    {
        "Text": "igure 1 gives an example.",
        "Entity": "Reference"
    },
    {
        "Text": "As we will see from Table 3, not much improvement is derived from this feature.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the F1 scores of the proposed model (SegTagDep) on CTB5c1 with respect to the training epoch and different parsing feature weights, where Seg , Tag , and Dep respectively denote the F1 scores of word segmentation, POS tagging, and dependency parsing.",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "bothmentions are in a parallel construction in adja Figure 1: An example graph modeling relations between mentions.",
        "Entity": "Reference"
    },
    {
        "Text": "The coupling between B and is removed by setting H = B 1: n min (W, H H T ), s.t. hip = 1 (1) H, i=1 BT Dl Bl according to equation 4 l end for return BL , BL 1 ...B1 Additional steps need to be performed in order to extract a tree from the hierarchical graph.",
        "Entity": "Reference"
    },
    {
        "Text": "The third model is Equation (11), which is a set of word models trained for each word type (WT +Poisson+ bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Performance of the mention detection system using lexical, syntactic, gazetteer features as well as features obtained by running other named-entity classifiers named-entity classifiers (with different semantic tag sets).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Snapshot of the supersense-annotated data.",
        "Entity": "Reference"
    },
    {
        "Text": "Among all possible target sentences, we will choose the sentence with the highest probability",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the bilingual phrases containing between two and seven words that result from the application of this algorithm to the alignment of Figure 2",
        "Entity": "Reference"
    },
    {
        "Text": "tion (13) is estimated from the relative frequency of the corresponding events in the training corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 7 we give results for several evaluation metrics.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows empirical estimates of p(a = 1|2k l) from the TransType data.",
        "Entity": "Reference"
    },
    {
        "Text": "We show that noun-noun vs. discourse-level coordination ambiguity in Arabic is a significant source of parsing errors (Table 8c).",
        "Entity": "Reference"
    },
    {
        "Text": "To illustrate the complete user model, in the figure 1 example the benefit of accepting would be7 2 4.2 = .8 keystrokes and the benefit of reject ing would be .2 keystrokes.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Performance of the mention detection system using lexical, syntactic, gazetteer features as well as features obtained by running other named-entity classifiers named-entity classifiers (with different semantic tag sets).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows the number of sentences, words, and characters of the training and test sets.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 7: Word segmentation accuracy of unknown words r e c pr ec F Po iss on + bi gr a m W T + P oi ss o n + b i g r a m P O S + P o is s o n + b i g r a m P O S + W T + P o is s o n + bi g ra m 31 .8 45 .5 39 .7 42.",
        "Entity": "Reference"
    },
    {
        "Text": "This class-based model gives reasonable results: for six radical classes, Table 1 gives the estimated cost for an unseen hanzi in the class occurring as the second hanzi in a double GIVEN name.",
        "Entity": "Reference"
    },
    {
        "Text": "In these experiments, the input lacks segmentation markers, hence the slightly different dev set baseline than in Table 6.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 7 we give results for several evaluation metrics.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Performance of Algorithms switch under different input data.",
        "Entity": "Reference"
    },
    {
        "Text": "The graph displayed in Figure 1 is the graph constructed for the mentions Leaders, Paris, recent developments and They from the example sentence at the beginning of this Section, where R = {P AnaPron, P Subject, N Number}.",
        "Entity": "Reference"
    },
    {
        "Text": "This group consists of 10 features based on the string , as listed in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Our experimental data was drawn from 150 megabytes of 1993 Nikkei newswire (see Figure I).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 9 shows the training and test corpus statistics.",
        "Entity": "Reference"
    },
    {
        "Text": "vecI : IL Rk instance vector computation C : Rk m Rk centroid computation vecL : L Rk lemma (type) vector computation repM : M Rk meta sense representation Table 3: Additional notation and signatures for CAM explicit sense disambiguation, CAM represents lemmas by their type vectors, i.e., the centroid of their instances, and compares their vectors (attributes) to those of the meta alternation hence the name.",
        "Entity": "Reference"
    },
    {
        "Text": "The distribution of errors is displayed in Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "The tagset refinement increases the accuracy by about 0.6%, and the external lexicon by another 3.5%.",
        "Entity": "Reference"
    },
    {
        "Text": "#o is the total number of output English translations.",
        "Entity": "Reference"
    },
    {
        "Text": "The first example in Table 3 shows that words ending in ' -' are likely to be nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 5 we present results from small test cor pora for the productive affixes handled by the current version of the system; as with names, the segmentation of morphologically derived words is generally either right or wrong.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 9 shows that in fact both contribute to producing good segmentations.",
        "Entity": "Reference"
    },
    {
        "Text": "The result is shown in Table 4: the baseline numbers without stem features are listed under Base, and the results of the coreference system with stem features are listed under Base+Stem.",
        "Entity": "Reference"
    },
    {
        "Text": "To compute the third factor of Equation (13), we have to estimate the character bigram probabilities that are classified by word type and part of speech.",
        "Entity": "Reference"
    },
    {
        "Text": "This group consists of 10 features based on the string , as listed in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Evaluation results are listed in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 8: Relative word accuracy as a function of training set size.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6 gives an overview of the decisions made in the alignment template model.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 Performance on morphological analysis.",
        "Entity": "Reference"
    },
    {
        "Text": "To simplify the description, we assume in Figure 2 that a bigram language model is used and all the TTS templates are binarized.",
        "Entity": "Reference"
    },
    {
        "Text": "(prec2 in Table 8)",
        "Entity": "Reference"
    },
    {
        "Text": "Prec. is the precision.",
        "Entity": "Reference"
    },
    {
        "Text": "Preliminary observations show that the different neighbours in Table 1 can be used to indicate with great accuracy which of the senses is being used",
        "Entity": "Reference"
    },
    {
        "Text": "But it conflates the coordinating and discourse separator functions of wa (<..4.b \ufffd \ufffd) into one analysis: conjunction(Table 3).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 7 shows the results.",
        "Entity": "Reference"
    },
    {
        "Text": "If M = 10, 15 Chinese words (i.e., the first 19 Chinese words in Table 3 except \u53f6\u739b\u65af,\u5df4\u4f50\u4e9a,\u5769\u57da,\u666e\u5229\u6cd5) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "The graph displayed in Figure 1 is the graph constructed for the mentions Leaders, Paris, recent developments and They from the example sentence at the beginning of this Section, where R = {P AnaPron, P Subject, N Number}.",
        "Entity": "Reference"
    },
    {
        "Text": "This sentence should be tagged as shown in table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8: Part of speech tagging accuracy of unknown words (the last column represents the percentage of correctly tagged unknown words in the correctly segmented unknown words",
        "Entity": "Reference"
    },
    {
        "Text": "The results are shown in the corr row of table 2, for exact character-probability estimates.",
        "Entity": "Reference"
    },
    {
        "Text": "In our segmentation system, a hybrid strategy is applied (Figure 1): First, forward maximum matching (Chen and Liu, 1992), which is a dictionary-based method, is used to generate a segmentation result.",
        "Entity": "Reference"
    },
    {
        "Text": "The third model is Equation (11), which is a set of word models trained for each word type (WT +Poisson+ bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7 shows a structogram of the algorithm",
        "Entity": "Reference"
    },
    {
        "Text": "This is usually straightforward, with the exception of the case where the words that are aligned to a particular role s span in the source side are not continuous in the target side, as shown in Figure 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Results are shown in Table 2; we see that better word alignment results do not lead to better translations.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 compares the results of the unconstrained version of HGFC against those of AGG on our largest test set T2.",
        "Entity": "Reference"
    },
    {
        "Text": "We obtain the following decision rule: eI = argmax Pr(eI | f J ) 1 1 1 I 1 M ) = argmax m hm (eI , f J ) 1 1 I m=1",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the word length distribution of words consists of only kanji characters and words consists of only katakana characters.",
        "Entity": "Reference"
    },
    {
        "Text": "using the convolution parse tree kernel as depicted in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "The corresponding figures for the test data are. 89.53% for our tagger and 88.88% for the TnT tag- ger.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 illustrates the effects of different components of the user model by showing results for simulated users who read infinitely fast and accept only predictions having positive benefit (superman); who read normally but accept like superman (rational); and who match the standard user model (real).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Dependency representation of example (2) from Talbanken05.",
        "Entity": "Reference"
    },
    {
        "Text": "and 8 show word accuracy for Chasen, Juman, and our algorithm for parameter settings optimizing word precision, recall, and F-measure rates.",
        "Entity": "Reference"
    },
    {
        "Text": "We illustrate its use with an example (see Then, we average the contributions of each n-gram order: Figure 2).",
        "Entity": "Reference"
    },
    {
        "Text": "A natural unit for B(x, k, a) is the number of keystrokes saved, so all elements of the above equation are converted to this measure.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Examples of the semantic role features assuming that the semantic roles have been tagged for the source sentences.",
        "Entity": "Reference"
    },
    {
        "Text": "We show that noun-noun vs. discourse-level coordination ambiguity in Arabic is a significant source of parsing errors (Table 8c).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Examples of the semantic role features assuming that the semantic roles have been tagged for the source sentences.",
        "Entity": "Reference"
    },
    {
        "Text": "E.g., the city Fez, Mo rocco (figure 1) was tagged as a single LOCATION by one annotator and as two by the other.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Effect of Factors antecedent is found in the previous context, subsequent sentences are inspected (cataphora), also ordered by proximity to the pronoun.",
        "Entity": "Reference"
    },
    {
        "Text": "L set of lemmas IL set of (lemma-wise) instances SL set of (lemma-wise) senses inst : L (IL ) mapping lemma instances sns : L (SL ) mapping lemma senses M set of meta senses meta : SL M mapping senses meta senses A M M set of meta alternations (MAs) A set of MA representations score : A S2 R scoring function for MAs repA : A A MA representation function comp : A S2 R compatibility function Table 1: Notation and signatures for our framework.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4: An example showing how to compute the target side position of a semantic role by using the median of its aligning points.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Effect of model parameters on performance.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 lists new conceptsthat CAM introduces to manipulate vector represen tations.",
        "Entity": "Reference"
    },
    {
        "Text": "As we will see from Table 3, not much improvement is derived from this feature.",
        "Entity": "Reference"
    },
    {
        "Text": "This approach can be seen as a generalization of the originally suggested source channel modeling framework for statistical machine translation",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Local graph of the word wing of a graph",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "In MUC6, the best result is achieved by SRA (Krupka, 1995).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: EM Algorithm For Estimating TTS Templates and Semantic Features framework (May and Knight, 2007).",
        "Entity": "Reference"
    },
    {
        "Text": "As an example, the probability of accepting the prediction in figure 1 is about .25.",
        "Entity": "Reference"
    },
    {
        "Text": "The last is exhibited for the first mention in figure 1, where one annotator chose ARTIFACT (referring tothe physical book) while the other chose COMMUNICATION (the content)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows the cross entropy per word and char acter perplexity of three unknown word model.",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "#o is the total number of output English translations.",
        "Entity": "Reference"
    },
    {
        "Text": "The results are shown in the corr row of table 2, for exact character-probability estimates.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows that tagging precision is im proved from 88.2% to 96.6%.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 7: Word segmentation accuracy of unknown words r e c pr ec F Po iss on + bi gr a m W T + P oi ss o n + b i g r a m P O S + P o is s o n + b i g r a m P O S + W T + P o is s o n + bi g ra m 31 .8 45 .5 39 .7 42.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, if x in figure 1 were evenir aux choses, then x14 would map to v1 = evenir, w2 = aux, and u3 = cho.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the NA M N O M PR O NA M 34 13 (21 %) 67 (6 6 %) 11 (4 6 %) N O M 43 (67 %) 21 48 (4 9 %) 9 (8 9 %) PR O 86 8 (32 %) 17 71 (5 5 %) 53 08 (2 4 %) Table 2: Number of clustering decisions made according to mention type (rows anaphor, columns antecedent) and percentage of wrong decisions.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows that by changing the word spelling model from zerogram to bigram, character perplex ity is greatly reduced.",
        "Entity": "Reference"
    },
    {
        "Text": "For MUC7, there are also no published results on systems trained on only the official training data of 200 aviation disaster articles.",
        "Entity": "Reference"
    },
    {
        "Text": "This list of 43 words is shown in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "E.g., the city Fez, Mo rocco (figure 1) was tagged as a single LOCATION by one annotator and as two by the other.",
        "Entity": "Reference"
    },
    {
        "Text": "This table also shows that: (1) Both modification within base-NPs and modification to NPs contribute much to performance improvement, acquiring the increase of F- measure by 4.4/2.4 units in mode M1 and 4.4/2.3 units in mode M2 respectively.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Performance on T3 using a predefined tree structure.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 Differences in performance between our system and Wang, Li, and Chang (1992).",
        "Entity": "Reference"
    },
    {
        "Text": "Shortest-enclosed Path Tree from P/R/F (81.1/6.7/73.2) of Dynamic Context-Sensitive Shortest- enclosed Path Tree according to Table 2 (Zhou et al., 2007)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 presents the performance in terms of precision, recall, and F- measure of the whole system.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows a confusion matrix for the classification of the nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7: Computing the partition function of the conditional probability P r(S|T ).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows an example of a symmetrized alignment",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows that tagging precision is im proved from 88.2% to 96.6%.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the results of an evaluation based on the plain STTS tagset.",
        "Entity": "Reference"
    },
    {
        "Text": "If we compare the error rates in Table 7, which correspond to about 55 search errors in Table 6, we obtain an mWER of 36.7% (53 search errors) using no heuristic function and an mWER of 32.6% (57 search errors) using the combined heuristic function",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: BLEU4 scores of different systems Source Launching1 New2 Diplomatic3 Offensive4 SRF On 1 2 3 4 SRF Off 2 3 4 It1 is2 therefore3 necessary4 to5 speed6 up7 the8 equal better worse With SRF vs. W/O SRF 72% 20.2% 7.8% Source transformation9 of10 traditional11 industries12 with13 high14 technologies15",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the distribution of SSTs in the corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 portrays how the states are aligned using the proposed scheme, where a subtree is denoted as a rectangle with its partial index shown inside it.",
        "Entity": "Reference"
    },
    {
        "Text": "his optimization can be performed using the expectation maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: A sentence from the article Islamic GoldenAge, with the supersense tagging from one of two anno tators.",
        "Entity": "Reference"
    },
    {
        "Text": "As an example, the probability of accepting the prediction in figure 1 is about .25.",
        "Entity": "Reference"
    },
    {
        "Text": "The alignment aJ that has the highest probability (under a certain model) is also called the Viterbi alignment (of that model)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 displays the performance of our model and of the systems that obtained the best (Fernandes et al., 2012) and the median performance in the MUC B3 CEAFe average R P F1 R P F1 R P F1 CoNLL 12 English development data be st 64.",
        "Entity": "Reference"
    },
    {
        "Text": "The corresponding translation quality improves from an mWER of 45.9% to an mWER of 31.8%.",
        "Entity": "Reference"
    },
    {
        "Text": "The argmax operation denotes the search problem, that is, the generation of the output sentence in the target language",
        "Entity": "Reference"
    },
    {
        "Text": "As Figure 3 shows, word type information improves the prediction accuracy significantly.",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "To reduce the memory requirement of the alignment templates, we compute these probabilities only for phrases up to a certain maximal length in the source language.",
        "Entity": "Reference"
    },
    {
        "Text": "For instance, the gain for the prediction in figure 1 would be 2 7 8 = 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: BLEU4 scores of different systems Source Launching1 New2 Diplomatic3 Offensive4 SRF On 1 2 3 4 SRF Off 2 3 4 It1 is2 therefore3 necessary4 to5 speed6 up7 the8 equal better worse With SRF vs. W/O SRF 72% 20.2% 7.8% Source transformation9 of10 traditional11 industries12 with13 high14 technologies15",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows that by using word type and part of speech information, recall is improved from 28.1% to 40.6% and precision is improved from 57.3% to 64.1%.",
        "Entity": "Reference"
    },
    {
        "Text": "The corresponding figures for the test data are. 89.53% for our tagger and 88.88% for the TnT tag- ger.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the labeled dependency graph of example (2), taken from Talbanken05.",
        "Entity": "Reference"
    },
    {
        "Text": "This table also shows that: (1) Both modification within base-NPs and modification to NPs contribute much to performance improvement, acquiring the increase of F- measure by 4.4/2.4 units in mode M1 and 4.4/2.3 units in mode M2 respectively.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in figure 3, read times are much higher for predictions that get accepted, re B(x, k, a) = R1(x) + T (x, k) E(x, k), a = 1 R0(x), a = 0 flecting both a more careful perusal by the translator and the fact the rejected predictions are often simplywhere Ra(x) is the cost of reading x when it ulignored.2 In both cases there is a weak linear rela timately gets accepted (a = 1) or rejected (a = 0), T (x, k) is the cost of manually typing xk , and E(x, k) is the edit cost of accepting x and erasing to the end of its first k characters.",
        "Entity": "Reference"
    },
    {
        "Text": "We illustrate its use with an example (see Then, we average the contributions of each n-gram order: Figure 2).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Effect of model parameters on performance.",
        "Entity": "Reference"
    },
    {
        "Text": "The reordering of the semantic roles from source to target is computed for each TTS template as part of the template extraction process, using the word-level alignments between the LHS/RHS of the TTS template (e.g., Figure 3).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Segmentation, POS tagging, and (unlabeled attachment) dependency F1 scores averaged over five trials on CTB5c.",
        "Entity": "Reference"
    },
    {
        "Text": "Shortest-enclosed Path Tree from P/R/F (81.1/6.7/73.2) of Dynamic Context-Sensitive Shortest- enclosed Path Tree according to Table 2 (Zhou et al., 2007)",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Word length distribution of kanji words and katakana words length model does not reflect the variation of the word length distribution resulting from the Japanese orthography.",
        "Entity": "Reference"
    },
    {
        "Text": "Another interesting example is shown in Figure 1(b), where the base-NP of the second entity town is a possessive NP and there is no relationship between the entities one and town defined in the ACE corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "IBM1F refers to the fertility IBM1 and HMMF refers to the fertility HMM",
        "Entity": "Reference"
    },
    {
        "Text": "At the morp heme level, stems are divid ed from their affixe s. For exam ple, altho ugh both naga no (Naga no) and shi (city) can appea r as indivi dual words , nagano shi (Nag ano city) is brack eted as [[naga no][s hi]], since here shi Figure 3: Determining word boundaries.",
        "Entity": "Reference"
    },
    {
        "Text": "vecI : IL Rk instance vector computation C : Rk m Rk centroid computation vecL : L Rk lemma (type) vector computation repM : M Rk meta sense representation Table 3: Additional notation and signatures for CAM explicit sense disambiguation, CAM represents lemmas by their type vectors, i.e., the centroid of their instances, and compares their vectors (attributes) to those of the meta alternation hence the name.",
        "Entity": "Reference"
    },
    {
        "Text": "If we directly translate the EM algorithm into the log- linear model, the problem becomes maximizing 0 X P r(S, T , D) = X @ Y P r(t) Y 1 P r(f )A the data likelihood represented by feature weights instead of feature probabilities: D D t D f F (S,T .role,D) Though the above formulation, which makes the P r(S, T ) = D exp i i fi (S, T , D) total probability of all the pairs of trees and strings P P exp P f (S , T , D ) St ,T t Dt i i i less than 1, is not a strict generative model, we can still use the EM algorithm (Dempster et al., 1977) to estimate the probability of the TTS templates and the semantic features, as shown in Figure 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Thus,we have crafted more specific explanations, sum marized for nouns in figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "able 1 shows the bilingual phrases containing between two and seven words that result from the application of this algorithm to the alignment of Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 contains results for two different translation models.",
        "Entity": "Reference"
    },
    {
        "Text": "Contribution of constituent dependencies in respective mode (inside parentheses) and accumulative mode (outside parentheses) The table shows that the final DSPT achieves the best performance of 77.4%/65.4%/70.9 in precision/recall/F-measure respectively after applying all the dependencies, with the increase of F-measure by 8.2 units compared to the baseline MCT.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Above: The complete supersense tagset for nouns; each tag is briefly described by its symbol, NAME, short description, and examples.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows an example of calculating the target side SRS based on a complicated TTS template.",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the effect of constraining the maximum length of the alignment templates in the source language.",
        "Entity": "Reference"
    },
    {
        "Text": "As illus trated in Figure 1(e), the NP coordination in the Qian et al.",
        "Entity": "Reference"
    },
    {
        "Text": "The result is shown in Table 4: the baseline numbers without stem features are listed under Base, and the results of the coreference system with stem features are listed under Base+Stem.",
        "Entity": "Reference"
    },
    {
        "Text": "The model 1 The total 74,597 sentence pairs used in experiments are those in the FBIS corpus whose English part can be parsed using Charniak (2000)",
        "Entity": "Reference"
    },
    {
        "Text": "The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).",
        "Entity": "Reference"
    },
    {
        "Text": "To differentiate between the coordinating and discourse separator functions of conjunctions (Table 3), we mark each CC with the label of its right sister (splitCC).",
        "Entity": "Reference"
    },
    {
        "Text": "we directly model the posterior probability Pr(eI| f J )",
        "Entity": "Reference"
    },
    {
        "Text": "A comparison of the lines for grammatical roles and for surface order in Table 1 shows that the same is true in German.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the performance and processing time comparison of various models and their combinations.",
        "Entity": "Reference"
    },
    {
        "Text": "The breakdown of the different types of words found by ST in the test corpus is given in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: NMI of unconstrained HGFC when trees for T2 and T3 are inferred automatically.",
        "Entity": "Reference"
    },
    {
        "Text": "We compared the ATB5 to tree- banks for Chinese (CTB6), German (Negra), and English (WSJ) (Table 4)",
        "Entity": "Reference"
    },
    {
        "Text": "In this section, we try to compare our results with those obtained by IdentiFinder ' 97 (Bikel et al., 1997), IdentiFinder ' 99 (Bikel et al., 1999), and MENE (Borthwick, 1999).",
        "Entity": "Reference"
    },
    {
        "Text": "In the table, Nc indicates the number of clusters in the inferred tree, while Nl indicates the closest match to the number of classes in the gold standard.",
        "Entity": "Reference"
    },
    {
        "Text": "Typically, the translation probability Pr(eI | f J ) is decomposed via additional hid 1 1 den variables",
        "Entity": "Reference"
    },
    {
        "Text": "However, the spelling model, especially the character bigrams in Equation (17) are hard to es timate because of the data sparseness.",
        "Entity": "Reference"
    },
    {
        "Text": "To illustrate the complete user model, in the figure 1 example the benefit of accepting would be7 2 4.2 = .8 keystrokes and the benefit of reject ing would be .2 keystrokes.",
        "Entity": "Reference"
    },
    {
        "Text": "Thus,we have crafted more specific explanations, sum marized for nouns in figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "The direct translation probability is given by",
        "Entity": "Reference"
    },
    {
        "Text": "The last is exhibited for the first mention in figure 1, where one annotator chose ARTIFACT (referring tothe physical book) while the other chose COMMUNICATION (the content)",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Average Precision and Coherence ( ) for each meta alternation.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Precision statistics for pronouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 suggests that the best setup is dependent on the specific meta sense or meta alternation being MACRO MICRO repM gram gramlex lex space type MACRO MICRO repA",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Word length distribution of unknown words and its estimate by Poisson distribution",
        "Entity": "Reference"
    },
    {
        "Text": "The last is exhibited for the first mention in figure 1, where one annotator chose ARTIFACT (referring tothe physical book) while the other chose COMMUNICATION (the content)",
        "Entity": "Reference"
    },
    {
        "Text": "Equation (12), which is a set of word models trained for each part of speech (POS + Poisson + bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "Nc Nl HGFC uncons trained A G G N MI F N M I F 13 0 13 3 57 .3 1 36 .6 5 54 .2 2 32 .6 2 11 4 11 7 54 .6 7 37 .9 6 51 .3 5 32 .4 4 50 51 37 .7 5 40 .0 0 32 .6 1 32 .7 8 Table 2: Performance on T2 using a predefined tree structure.",
        "Entity": "Reference"
    },
    {
        "Text": "Ta SegTag 97.66 93.61 SegTagDep 97.73 94.46 SegTag(d) 98.18 94.08 SegTagDep(d) 98.26 94.64 Table 5: Final results on CTB5j 76 75 74 ble 4 shows the segmentation, POS tagging, and dependency parsing F1 scores of these models on CTB5c.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Performance of Algorithms switch under different input data.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 is, in fact, a weighted sum of these two distributions.",
        "Entity": "Reference"
    },
    {
        "Text": "Based on this experiment, we set the beam size of SegTagDep to 64 throughout the exper 64 96.28 92.37 74.96 0.48 Table 3: F1 scores and speed (in sentences per sec.)",
        "Entity": "Reference"
    },
    {
        "Text": "Letting u1 be the prefix of the word that ends in v1 (eg, r in figure 1), w1 = u1v1, and h = htu1:is less accurate because it ignores the alignment rela tion between s and h, which is captured by even the simplest noisy-channel models.",
        "Entity": "Reference"
    },
    {
        "Text": "The distribution of errors is displayed in Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.",
        "Entity": "Reference"
    },
    {
        "Text": "In Figure 1(c) we show a sentence one of about 500 people nominated for , where there exists a DISC relationship between the entities one and people",
        "Entity": "Reference"
    },
    {
        "Text": "The probabilities P( <U-t>lwi_I) can be esti mated from the relative frequencies in the training corpus whose infrequent words are replaced with their corresponding unknown word tags based on their part of speeches 2 Table 1 shows examples of word bigrams including unknown word tags.",
        "Entity": "Reference"
    },
    {
        "Text": "Collocations were automatically located in a text by looking up pairwise words in this lexicon",
        "Entity": "Reference"
    },
    {
        "Text": "In fact, from the last column of Figure 8 we see that even if our algorithm has access to only five anno tated sequences when Juman has access to ten times as many, we still achieve better precision and better F measure.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Time to read and accept or reject proposals versus their length tion, because the empirical probability of acceptance is very low when it is less than zero and rises rapidly as it increases.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows a probability estimation tree for the prediction of the probability of the nominative attribute of nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "The bottom-up decoding algorithm for the TTS transducer is sketched in Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paa and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 presents an overview of the animacy data Clas s Ani mat e Type s Tok 6 4 4 ens cover ed 6 0 1 0 Inan imat e 691 0 3 4 8 2 2 Tota l 755 4 4 0 8 3 2 Table 1: The animacy data set from Talbanken05; number of noun lemmas (Types) and tokens in each class.",
        "Entity": "Reference"
    },
    {
        "Text": "As for the unknown word model, word-based char acter bigrams are computed from the words with Table 5: Cross entropy (CE) per word and character perplexity (PP) of each unknown word model Part of Speech Estimation Accuracy 0.95 0.9 frequency one (49,653 words).",
        "Entity": "Reference"
    },
    {
        "Text": "The second factor of Equation (13) is estimated from the Poisson distribution whose parameter",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function",
        "Entity": "Reference"
    },
    {
        "Text": "This list of 43 words is shown in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Accuracy of part of speech estimation each part of speech and word type (POS + WT + Poisson + bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows the number of sentences, words, and characters of the training and test sets.",
        "Entity": "Reference"
    },
    {
        "Text": "The entity features can be attached under the top node, the entity nodes, or directly combined with the entity nodes as in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "To reduce the memory requirement of the alignment templates, we compute these probabilities only for phrases up to a certain maximal length in the source language.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Average Precision and Coherence ( ) for each meta alternation.",
        "Entity": "Reference"
    },
    {
        "Text": "segmentation (Table 2).",
        "Entity": "Reference"
    },
    {
        "Text": "The first model is Equation (5), which is the combina . tion of Poisson distribution and character zerogram",
        "Entity": "Reference"
    },
    {
        "Text": "Considering that the way the semantic where all(T ) denotes all the possible target strings which can be generated from the source tree T . Given a set of TTS templates, the new partition function can be efficiently computed using the dynamic programming algorithm shown in Figure 7.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 suggests that the best setup is dependent on the specific meta sense or meta alternation being MACRO MICRO repM gram gramlex lex space type MACRO MICRO repA",
        "Entity": "Reference"
    },
    {
        "Text": "In Figure 1(c) we show a sentence one of about 500 people nominated for , where there exists a DISC relationship between the entities one and people",
        "Entity": "Reference"
    },
    {
        "Text": "Typically, the translation probability Pr(eI | f J ) is decomposed via additional hid 1 1 den variables",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6 lists a sample of targets for the five meta alternations involved.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Feature templates for the full joint model.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, looking at Figure 1(b), V on G can be grouped into three clusters u1, u2 and u3.",
        "Entity": "Reference"
    },
    {
        "Text": "Strube (1998) s centeri ng appro ach (whos e senten ce orderi ng is designate d as SR2 in Table 2) also deals with and even prefer s intrase ntenti al anaph ora, which raises the upper limit to a more accept able 80.2% .",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: (a) An undirected graph G representing the similarity matrix; (b) The bipartite graph showing three clusters on G; (c) The induced clusters U ; (d) The new graph G1 over clusters U ; (e) The new bipartite graph over G1 p |vi ) = Vl 1 ...",
        "Entity": "Reference"
    },
    {
        "Text": "bothmentions are in a parallel construction in adja Figure 1: An example graph modeling relations between mentions.",
        "Entity": "Reference"
    },
    {
        "Text": "The first machine, illustrated in Figure 1 encodes the prefix and suffix expansion rules, producing a lattice of possible segmentations.",
        "Entity": "Reference"
    },
    {
        "Text": "The results are shown in the corr row of table 2, for exact character-probability estimates.",
        "Entity": "Reference"
    },
    {
        "Text": "The second model is the combination of Poisson distribution (Equation (6)) and character bigram",
        "Entity": "Reference"
    },
    {
        "Text": "As column 5 (SVM) in table 2 shows, the classification results are very similar to the results obtained with MBL.12 We furthermore find a very similar set of errors, and in particular, we find that 51.0 % of the errors for the inanimate class are nouns with the gradient animacy properties presented in (9)-(13) above.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the F1 scores of the proposed model (SegTagDep) on CTB5c1 with respect to the training epoch and different parsing feature weights, where Seg , Tag , and Dep respectively denote the F1 scores of word segmentation, POS tagging, and dependency parsing.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 5 we present results from small test cor pora for the productive affixes handled by the current version of the system; as with names, the segmentation of morphologically derived words is generally either right or wrong.",
        "Entity": "Reference"
    },
    {
        "Text": "For the Verbmobil task, we train the model parameters M according to the maximum class posterior probability criterion (equation (4)).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: CoreLex s basic types with their corresponding WordNet anchors.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows examples of common char acter bigrams for each part of speech in the infre quent words of the EDR corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: Examples of word, morpheme, and compatible-bracket errors.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1), i.e., the degree to which a sense pair (s1, s2) matches a meta alternation a.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Results for different user simulations.",
        "Entity": "Reference"
    },
    {
        "Text": "For MUC6, the reduction in error due to global features is 27%, and for MUC7,14%.",
        "Entity": "Reference"
    },
    {
        "Text": "This is because the lefthand side of Equation (7) represents the probability of the string c1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows that this reimplementation almost reproduces the accuracy of their implementation.",
        "Entity": "Reference"
    },
    {
        "Text": "In order to effectively capture entity-related semantic features, and their combined features as well, especially bi-gram or tri-gram features, we build an Entity-related Semantic Tree (EST) in three ways as illustrated in Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows our results and the results of Stevenson and Joanis (2003) on T1 when employing AGG using Ward as the linkage criterion.",
        "Entity": "Reference"
    },
    {
        "Text": "PRO (c) Entity-Paired Tree(EPT)Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows an example of a symmetrized alignment",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6 lists a sample of targets for the five meta alternations involved.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the part of speech prediction accu racy of two unknown word model without context.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the influence of the four parameters.",
        "Entity": "Reference"
    },
    {
        "Text": "and ap plied to an Arabic sentence in figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Probabilities We find that Equation (7) assigns too little proba bilities to long words (5 or more characters).",
        "Entity": "Reference"
    },
    {
        "Text": "#c is the total number of new Chinese source words in the period",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6 shows example sentences annotated by HGFC.",
        "Entity": "Reference"
    },
    {
        "Text": "As Figure 3 shows, word type information improves the prediction accuracy significantly.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Scores for MSRA corpus",
        "Entity": "Reference"
    },
    {
        "Text": "As we will see from Table 3, not much improvement is derived from this feature.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: (a) An undirected graph G representing the similarity matrix; (b) The bipartite graph showing three clusters on G; (c) The induced clusters U ; (d) The new graph G1 over clusters U ; (e) The new bipartite graph over G1 p |vi ) = Vl 1 ...",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1; capital letters designate sets and small letters elements of sets).2 For a lemma l like lamb, we want to knowhow well a meta alternation (such as ANIMAL FOOD) explains a pair of its senses (such as the animal and food senses of lamb).3 This is formalized through the function score, which maps a meta alternation and two senses onto a score.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows a probability estimation tree for the prediction of the probability of the nominative attribute of nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6 shows the word segmentation accuracy of four unknown word models over test set-2.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in figure 1, a similarity matrix W models one-hop transitions that follow the links from vertices to neighbors.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows that the tagging accuracy tends to increase with the context size.",
        "Entity": "Reference"
    },
    {
        "Text": "Examples of the deletion features can be found in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "The bottom-up decoding algorithm for the TTS transducer is sketched in Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 underscores the virtues of Sentence Recency: In the most recent sentence with antecedents satisfying the filters, there are on aver ble.",
        "Entity": "Reference"
    },
    {
        "Text": "the target Chen Guangcheng only appears once in Weibo",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Distribution of the sentences where the semantic role features give no/positive/negative impact to the sentence fluency in terms of the completeness and ordering of the semantic roles.classes in VerbNet (Dang et al., 1998).",
        "Entity": "Reference"
    },
    {
        "Text": "So we estimate that English translations are present in the English part of the corpus for Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Letting u1 be the prefix of the word that ends in v1 (eg, r in figure 1), w1 = u1v1, and h = htu1:is less accurate because it ignores the alignment rela tion between s and h, which is captured by even the simplest noisy-channel models.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 presents the distributions of some examples of morphs and their targets in English Twitter and Chinese Sina Weibo.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 4 and 5 show the effect of the pruning parameter tp with the histogram pruning parameter Np = 50,000.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 summarizes the results obtained with different taggers and tagsets on the development data.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, the pairwise words orange and peel form a collocation.",
        "Entity": "Reference"
    },
    {
        "Text": "vecI : IL Rk instance vector computation C : Rk m Rk centroid computation vecL : L Rk lemma (type) vector computation repM : M Rk meta sense representation Table 3: Additional notation and signatures for CAM explicit sense disambiguation, CAM represents lemmas by their type vectors, i.e., the centroid of their instances, and compares their vectors (attributes) to those of the meta alternation hence the name.",
        "Entity": "Reference"
    },
    {
        "Text": "However, the learning curves in Figure 3 show that the Berkeley parser does not exceed our manual grammar by as wide a margin as has been shown for other languages (Petrov, 2009).",
        "Entity": "Reference"
    },
    {
        "Text": "The graph displayed in Figure 1 is the graph constructed for the mentions Leaders, Paris, recent developments and They from the example sentence at the beginning of this Section, where R = {P AnaPron, P Subject, N Number}.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, look ing at Figure 2(b), V on G can be grouped into three clusters u1, u2 and u3.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 9: Entries indicate whether best performance is achieved using the local maximum condition (M), the threshold condition (T), or both.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 presents the wide range of cases that are used to create the morphs.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the results of an evaluation based on the plain STTS tagset.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: An example showing the combination of the semantic role sequences of the states.",
        "Entity": "Reference"
    },
    {
        "Text": "We include a list of per-category results for selected phrasal labels, POS tags, and dependencies in Table 8.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 breaks down the performance of the best CAM model by meta alternation.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the effect of constraining the maximum length of the alignment templates in the source language.",
        "Entity": "Reference"
    },
    {
        "Text": "We choose t = 1, 5, and 30 for the fertility HMM",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7: Compatible brackets and all-compatible bracket rates when word accuracy is optimized.",
        "Entity": "Reference"
    },
    {
        "Text": "Length Distribution In word segmentation, one of the major problems of the word length model of Equation (6) is the decom position of unknown words.",
        "Entity": "Reference"
    },
    {
        "Text": "Column four (MBL) in table 2 shows the accuracy obtained with all features in the general feature space.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 9: Entries indicate whether best performance is achieved using the local maximum condition (M), the threshold condition (T), or both.",
        "Entity": "Reference"
    },
    {
        "Text": "As Table 1 shows, word bigrams whose infrequent word bigram",
        "Entity": "Reference"
    },
    {
        "Text": "The overall architecture of the statistical translation approach is summarized in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Decoding algorithm for the standard Tree-to-String transducer.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in figure 1, a similarity matrix W models one-hop transitions that follow the links from vertices to neighbors.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the bilingual phrases containing between two and seven words that result from the application of this algorithm to the alignment of Figure 2",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the part of speech prediction accu racy of two unknown word model without context.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, no synset covers any combinations of the main words in Figure 2, namely buy , acquire and merger",
        "Entity": "Reference"
    },
    {
        "Text": "e suggest the use of a log-linear model to incorporate the various knowledge sources into an overall translation system and to perform discriminative training of the free model parameters",
        "Entity": "Reference"
    },
    {
        "Text": "he largest effect seems to come from taking into account the bigram dependence, which achieves an mWER of 32.9%",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Effect of Arabic stemming features on coreference resolution.",
        "Entity": "Reference"
    },
    {
        "Text": "We see that the language model perplexity improves from 4,781 for a unigram model to 29.9 for a trigram model.",
        "Entity": "Reference"
    },
    {
        "Text": "(2011), we confirmed that omission of the look-ahead features results in a 0.26% decrease in the parsing accuracy on CTB5d (dev).Figure 2: F1 scores (in %) of SegTagDep on CTB 5c1 w.r.t. the training epoch (x-axis) and parsing feature weights (in legend).",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "tion (13) is estimated from the relative frequency of the corresponding events in the training corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 8: Relative word accuracy as a function of training set size.",
        "Entity": "Reference"
    },
    {
        "Text": "So we estimate that English translations are present in the English part of the corpus for Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Comparison of segmentation algorithm using different linguistic features.",
        "Entity": "Reference"
    },
    {
        "Text": "We compare in Table 2 the performance of Unified Parse and Semantic Trees with different kinds of Entity Semantic Tree setups using standard convolution tree kernel, while the SPT and DSPT with only entity-type information are listed for reference.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, if a token starts with a capital letter and ends with a period (such as Mr.), then the feature InitCapPeriod is set to 1, etc",
        "Entity": "Reference"
    },
    {
        "Text": "This class-based model gives reasonable results: for six radical classes, Table 1 gives the estimated cost for an unseen hanzi in the class occurring as the second hanzi in a double GIVEN name.",
        "Entity": "Reference"
    },
    {
        "Text": "Prec. is the precision.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Examples of common character bigrams for each part of speech in the infrequent words pa rt of sp ee ch ch ar ac ter bi gr a m fre qu en cy no un nu m be r a dj e ct iv al v er b v er b ad je cti ve ad ve rb < e o w > <b o w > 1 S \" J < e o w > I t < e o w > L < e o w > < e o w > 13 43 4 8 4 3 2 7 2 1 3 69 63 resented all unknown words by one length model.",
        "Entity": "Reference"
    },
    {
        "Text": "Consider the example in Figure 1",
        "Entity": "Reference"
    },
    {
        "Text": "Ta SegTag 97.66 93.61 SegTagDep 97.73 94.46 SegTag(d) 98.18 94.08 SegTagDep(d) 98.26 94.64 Table 5: Final results on CTB5j 76 75 74 ble 4 shows the segmentation, POS tagging, and dependency parsing F1 scores of these models on CTB5c.",
        "Entity": "Reference"
    },
    {
        "Text": "However, the learning curves in Figure 3 show that the Berkeley parser does not exceed our manual grammar by as wide a margin as has been shown for other languages (Petrov, 2009).",
        "Entity": "Reference"
    },
    {
        "Text": "A simple lexicalized PCFG with second order Markovization gives relatively poor performance: 75.95% F1 on the test set.8 But this figure is surprisingly competitive with a recent state-of-the-art baseline (Table 7).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows the number of sentences, words, and characters of the training and test sets.",
        "Entity": "Reference"
    },
    {
        "Text": "and Table 6 show a comparison of the segmentation and POS tagging accuracies with other state-of-the-art models.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 1, period 1 is Jul 01 \u2013 Jul 15, period 2 is Jul 16 \u2013 Jul 31, \u2026, period 12 is Dec 16 \u2013 Dec 31.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 gives the algorithm phrase-extract that computes the phrases",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows a confusion matrix for the classification of the nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Distribution of the sentences where the semantic role features give no/positive/negative impact to the sentence fluency in terms of the completeness and ordering of the semantic roles.classes in VerbNet (Dang et al., 1998).",
        "Entity": "Reference"
    },
    {
        "Text": "tion (13) is estimated from the relative frequency of the corresponding events in the training corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "where ECD|S,T (fi), the expected count of a feature over all derivations given a pair of tree and string, can be computed using the modified inside- outside algorithm described in Section 3.2, and ECS |T (fi), the expected count of a feature over all possible target strings given the source tree, can be computed in a similar way to the partition function described in Figure 7.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 4 and 5 show the effect of the pruning parameter tp with the histogram pruning parameter Np = 50,000",
        "Entity": "Reference"
    },
    {
        "Text": "Although kanji sequences are difficult to seg ment, they can comprise a significant portion of Japanese text, as shown in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 7: Word segmentation accuracy of unknown words r e c pr ec F Po iss on + bi gr a m W T + P oi ss o n + b i g r a m P O S + P o is s o n + b i g r a m P O S + W T + P o is s o n + bi g ra m 31 .8 45 .5 39 .7 42.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Word length distribution of kanji words and katakana words length model does not reflect the variation of the word length distribution resulting from the Japanese orthography.",
        "Entity": "Reference"
    },
    {
        "Text": "The accuracy of a baseline tagger which chooses the most probable tag9 ignoring the context is 67.3% without and 69.4% with the supple 92.3 92.2 92.1 92 91.9 91.8 91.7 91.6 91.5 91.4 2 3 4 5 6 7 8 9 10 mentary lexicon.",
        "Entity": "Reference"
    },
    {
        "Text": "As can be seen in Table 4, our training data is a lot less than those used by MENE and IdentiFinder3.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in Table 3, using just context information alone, 10 Chinese words (the first 10) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "The annotation manual (Teleman, 1974) states that a markable should be tagged as human (H H) if it may be replaced by the interrogative pronoun vem who and be referred to by the personal pronouns han he or hon she .There are clear similarities between the anno tation for human reference found in Talbanken05 and the annotation scheme for animacy discussed HUM Other animate Inanimate ORG ANIM CONC NCONC TIME PLACE Figure 1: Animacy classification scheme (Zaenen et al., 2004)",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 9: Entries indicate whether best performance is achieved using the local maximum condition (M), the threshold condition (T), or both.",
        "Entity": "Reference"
    },
    {
        "Text": "If the token starts with a capital letter (initCaps), then an additional feature (init- Caps, zone) is set to 1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 presents the wide range of cases that are used to create the morphs.",
        "Entity": "Reference"
    },
    {
        "Text": "A standard criterion on a parallel training corpus consisting of S sentence pairs {(fs , es ): s = 1, .",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "A simple lexicalized PCFG with second order Markovization gives relatively poor performance: 75.95% F1 on the test set.8 But this figure is surprisingly competitive with a recent state-of-the-art baseline (Table 7).",
        "Entity": "Reference"
    },
    {
        "Text": "The performance of these systems is shown in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "In this section, we try to compare our results with those obtained by IdentiFinder ' 97 (Bikel et al., 1997), IdentiFinder ' 99 (Bikel et al., 1999), and MENE (Borthwick, 1999).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 shows our morpheme accuracy results.",
        "Entity": "Reference"
    },
    {
        "Text": "Table (1) and Eq.",
        "Entity": "Reference"
    },
    {
        "Text": "As for the unknown word model, word-based char acter bigrams are computed from the words with Table 5: Cross entropy (CE) per word and character perplexity (PP) of each unknown word model Part of Speech Estimation Accuracy 0.95 0.9 frequency one (49,653 words).",
        "Entity": "Reference"
    },
    {
        "Text": "The accuracy of a baseline tagger which chooses the most probable tag9 ignoring the context is 67.3% without and 69.4% with the supple 92.3 92.2 92.1 92 91.9 91.8 91.7 91.6 91.5 91.4 2 3 4 5 6 7 8 9 10 mentary lexicon.",
        "Entity": "Reference"
    },
    {
        "Text": "As a result, Arabic sentences are usually long relative to English, especially after",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows a comparison with some existing toolkits that build deterministic, minimized automata/transducers.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the results of both unconstrained and constrained versions of HGFC and those of AGG on the test set T3 (where singular classes are removed to enable proper evaluation of the constrained method).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Distribution of the sentences where the semantic role features give no/positive/negative impact to the sentence fluency in terms of the completeness and ordering of the semantic roles.classes in VerbNet (Dang et al., 1998).",
        "Entity": "Reference"
    },
    {
        "Text": "Consider the example in Figure 1",
        "Entity": "Reference"
    },
    {
        "Text": "This approach has been suggested by Papineni, Roukos, and Ward (1997, 1998) for a natural language understanding task.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the absolute frequencies of sen tence recency values when only the most recent antecedent (in the order just stated) is considered.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1; capital letters designate sets and small letters elements of sets).2 For a lemma l like lamb, we want to knowhow well a meta alternation (such as ANIMAL FOOD) explains a pair of its senses (such as the animal and food senses of lamb).3 This is formalized through the function score, which maps a meta alternation and two senses onto a score.",
        "Entity": "Reference"
    },
    {
        "Text": "(Equation (7)) (Poisson + hi gram).",
        "Entity": "Reference"
    },
    {
        "Text": "The reordering of the semantic roles from source to target is computed for each TTS template as part of the template extraction process, using the word-level alignments between the LHS/RHS of the TTS template (e.g., Figure 3).",
        "Entity": "Reference"
    },
    {
        "Text": "To compute the third factor of Equation (13), we have to estimate the character bigram probabilities that are classified by word type and part of speech.",
        "Entity": "Reference"
    },
    {
        "Text": "of the 43 words are translated to English multi-word phrases (denoted as \u201cphrase\u201d in Table 3).",
        "Entity": "Reference"
    },
    {
        "Text": "(2004) in figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "bothmentions are in a parallel construction in adja Figure 1: An example graph modeling relations between mentions.",
        "Entity": "Reference"
    },
    {
        "Text": "#Cor is the number of correct English translations output.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows empirical search timings for various values of M , for the MEMD model described in the next section.",
        "Entity": "Reference"
    },
    {
        "Text": "The model 1 The total 74,597 sentence pairs used in experiments are those in the FBIS corpus whose English part can be parsed using Charniak (2000)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows that by changing the word spelling model from zerogram to bigram, character perplex ity is greatly reduced.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 6 and 7 show the effect of the pruning pa rameter Np with the pruning parameter tp = 10 12",
        "Entity": "Reference"
    },
    {
        "Text": ">10 nouns (a) (b) classified as 222 125 (a) class animate 49 3390 (b) class inanimate Table 4: Confusion matrix for the MBLclassifier with a general feature space on the >10 data set on Talbanken05 nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "range free green lemon peel red state yellow",
        "Entity": "Reference"
    },
    {
        "Text": "By far the most frequent tagging error was the confusion of nominative and accusative case.",
        "Entity": "Reference"
    },
    {
        "Text": "To reduce the memory requirement of the alignment templates, we compute these probabilities only for phrases up to a certain maximal length in the source language.",
        "Entity": "Reference"
    },
    {
        "Text": "The coupling between B and is removed by setting H = B 1: n min (W, H H T ), s.t. hip = 1 (1) H, i=1 BT Dl Bl according to equation 4 l end for return BL , BL 1 ...B1 Additional steps need to be performed in order to extract a tree from the hierarchical graph.",
        "Entity": "Reference"
    },
    {
        "Text": "See Fig ure 6 for some examples.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 portrays how the states are aligned using the proposed scheme, where a subtree is denoted as a rectangle with its partial index shown inside it.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 The cost as a novel given name (second position) for hanzi from various radical classes.",
        "Entity": "Reference"
    },
    {
        "Text": "In addition to the basic regular expression operators shown in table 1, the formalism is extended in various ways.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Results of different systems on the CoNLL 12 English data sets.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows examples of the feature SRR.",
        "Entity": "Reference"
    },
    {
        "Text": "We also propose to use the features U01 U03, which we found are effective to adjust the character Figure 1: Illustration of the alignment of steps.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8: Part of speech tagging accuracy of unknown words (the last column represents the percentage of correctly tagged unknown words in the correctly segmented unknown words",
        "Entity": "Reference"
    },
    {
        "Text": "The points labelled smoothed in figure 2 were obtained using a sliding-average smoother, and the model curve was obtained using two-component Gaussian mixtures to fit the smoothed empirical likelihoods p(gain|a = 0) and p(gain|a = 1).",
        "Entity": "Reference"
    },
    {
        "Text": "able 2 shows the corpus statistics for this task.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Sample of experimental items for the meta alternation anmfod.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 presents an overview of the animacy data Clas s Ani mat e Type s Tok 6 4 4 ens cover ed 6 0 1 0 Inan imat e 691 0 3 4 8 2 2 Tota l 755 4 4 0 8 3 2 Table 1: The animacy data set from Talbanken05; number of noun lemmas (Types) and tokens in each class.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 shows the decoding algorithm incorporating the SRR features.",
        "Entity": "Reference"
    },
    {
        "Text": "Tree setups P(%) R(%) F SPT 76.3 59.8 67.1 DSPT 77.4 65.4 70.9 UPST (BOF) 80.4 69.7 74.7 UPST (FPT) 80.1 70.7 75.1 UPST (EPT) 79.9 70.2 74.8 Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 4 and 5 show the effect of the pruning parameter tp with the histogram pruning parameter Np = 50,000.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: NMI of unconstrained HGFC when trees for T2 and T3 are inferred automatically.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows the effect of the length of the language model history on translation quality.",
        "Entity": "Reference"
    },
    {
        "Text": "This is usually straightforward, with the exception of the case where the words that are aligned to a particular role s span in the source side are not continuous in the target side, as shown in Figure 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Snapshot of the supersense-annotated data.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, the pairwise words orange and peel form a collocation.",
        "Entity": "Reference"
    },
    {
        "Text": "In general, as shown in this figure, there may be additional transformations to make the translation task simpler for the algorithm.",
        "Entity": "Reference"
    },
    {
        "Text": "To simplify the description, we assume in Figure 2 that a bigram language model is used and all the TTS templates are binarized.",
        "Entity": "Reference"
    },
    {
        "Text": "In MUC6, the best result is achieved by SRA (Krupka, 1995).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Local graph of the word wing of a graph",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows that by changing the word spelling model from zerogram to bigram, character perplex ity is greatly reduced.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Dependency representation of example (2) from Talbanken05.",
        "Entity": "Reference"
    },
    {
        "Text": "#e is the total number of English translation candidates in the period.",
        "Entity": "Reference"
    },
    {
        "Text": "We establish a corresponding feature function by multiplying the probability of all used alignment templates and taking the logarithm",
        "Entity": "Reference"
    },
    {
        "Text": "(prec2 in Table 8)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 lists both the success rate maximally achievable (broken down according to different types of pronouns) and the average number of antecedents remaining after applying each factor.",
        "Entity": "Reference"
    },
    {
        "Text": "even after removal of the wing-node, the two areas of meaning are still linked via tail",
        "Entity": "Reference"
    },
    {
        "Text": "Column four (MBL) in table 2 shows the accuracy obtained with all features in the general feature space.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows empirical estimates of p(a = 1|2k l) from the TransType data.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 show the training time for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the manual evaluation results based on the entire test set, and the improvement from SRF is significant at p < 0.005 based on a t-test.",
        "Entity": "Reference"
    },
    {
        "Text": "If we directly translate the EM algorithm into the log- linear model, the problem becomes maximizing 0 X P r(S, T , D) = X @ Y P r(t) Y 1 P r(f )A the data likelihood represented by feature weights instead of feature probabilities: D D t D f F (S,T .role,D) Though the above formulation, which makes the P r(S, T ) = D exp i i fi (S, T , D) total probability of all the pairs of trees and strings P P exp P f (S , T , D ) St ,T t Dt i i i less than 1, is not a strict generative model, we can still use the EM algorithm (Dempster et al., 1977) to estimate the probability of the TTS templates and the semantic features, as shown in Figure 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Length Distribution In word segmentation, one of the major problems of the word length model of Equation (6) is the decom position of unknown words.",
        "Entity": "Reference"
    },
    {
        "Text": "equation 2) says that the prob ability of starting a new entity, given the current mention m and the previous entities e1, e2, , et, is simply 1 minus the maximum link probability between the current mention and one of the previous entities.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the effect of constraining the maximum length of the alignment templates in the source language.",
        "Entity": "Reference"
    },
    {
        "Text": "range free green lemon peel red state yellow",
        "Entity": "Reference"
    },
    {
        "Text": "Considering that the way the semantic where all(T ) denotes all the possible target strings which can be generated from the source tree T . Given a set of TTS templates, the new partition function can be efficiently computed using the dynamic programming algorithm shown in Figure 7.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.",
        "Entity": "Reference"
    },
    {
        "Text": "The second factor of Equation (13) is estimated from the Poisson distribution whose parameter",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Local graph of the word wing of a graph",
        "Entity": "Reference"
    },
    {
        "Text": "We establish a corresponding feature function by multiplying the probability of all used alignment templates and taking the logarithm",
        "Entity": "Reference"
    },
    {
        "Text": "In fact, from the last column of Figure 8 we see that even if our algorithm has access to only five anno tated sequences when Juman has access to ten times as many, we still achieve better precision and better F measure.",
        "Entity": "Reference"
    },
    {
        "Text": "The use of the language model feature in equation (18) helps take long-range dependencies better into account",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Performance of baseline and joint models w.r.t. the average processing time (in sec.)",
        "Entity": "Reference"
    },
    {
        "Text": "As column 5 (SVM) in table 2 shows, the classification results are very similar to the results obtained with MBL.12 We furthermore find a very similar set of errors, and in particular, we find that 51.0 % of the errors for the inanimate class are nouns with the gradient animacy properties presented in (9)-(13) above.",
        "Entity": "Reference"
    },
    {
        "Text": "We choose t = 1, 5, and 30 for the fertility HMM",
        "Entity": "Reference"
    },
    {
        "Text": "The overall architecture of the log-linear modeling approach is summarized in Figure 1",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Example of a prediction for English to French translation.",
        "Entity": "Reference"
    },
    {
        "Text": "Tree setups P(%) R(%) F SPT 76.3 59.8 67.1 DSPT 77.4 65.4 70.9 UPST (BOF) 80.4 69.7 74.7 UPST (FPT) 80.1 70.7 75.1 UPST (EPT) 79.9 70.2 74.8 Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows that tagging precision is im proved from 88.2% to 96.6%.",
        "Entity": "Reference"
    },
    {
        "Text": "n our experimentations, SVMlight (Joachims, 1998) with the tree kernel function (75.0) (53.7) (62.6) Table 1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Performance on T3 using a predefined tree structure.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8b shows that verbal nouns are the hardest pre-terminal categories to identify.",
        "Entity": "Reference"
    },
    {
        "Text": "We compare in Table 2 the performance of Unified Parse and Semantic Trees with different kinds of Entity Semantic Tree setups using standard convolution tree kernel, while the SPT and DSPT with only entity-type information are listed for reference.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1shows the word length distribution of in frequent words in the EDR corpus, and the estimate of word length distribution by Equation (6) whose parameter (.A = 4.8) is the average word length of infrequent words.",
        "Entity": "Reference"
    },
    {
        "Text": "Ta SegTag 97.66 93.61 SegTagDep 97.73 94.46 SegTag(d) 98.18 94.08 SegTagDep(d) 98.26 94.64 Table 5: Final results on CTB5j 76 75 74 ble 4 shows the segmentation, POS tagging, and dependency parsing F1 scores of these models on CTB5c.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8a shows that the best model recovers SBAR at only 71.0% F1.",
        "Entity": "Reference"
    },
    {
        "Text": "CoreLex defines a layer of abstraction above WordNet consisting of 39 basic types, coarse- grained ontological classes (Table 2).",
        "Entity": "Reference"
    },
    {
        "Text": "For example, the expressions in Figure 2 are identified as paraphrases by this method; so these three patterns will be placed in the same pattern set.",
        "Entity": "Reference"
    },
    {
        "Text": "n all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 shows our morpheme accuracy results.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Character type configuration of infrequent words in the EDR corpus",
        "Entity": "Reference"
    },
    {
        "Text": "The direct translation probability is given by",
        "Entity": "Reference"
    },
    {
        "Text": "Results: Table I gives the results for the comparison of the troughs placed by the segmentation algorithm to the known subject change points.",
        "Entity": "Reference"
    },
    {
        "Text": "See Table 1 for details.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Examples of the semantic role features assuming that the semantic roles have been tagged for the source sentences.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: The amount of training and test sets The first factor in the righthand side of Equa tion (13) is estimated from the relative frequency of the corresponding events in the training corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "and Table 6 show a comparison of the segmentation and POS tagging accuracies with other state-of-the-art models.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows examples of common char acter bigrams for each part of speech in the infre quent words of the EDR corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "The first machine, illustrated in Figure 1 encodes the prefix and suffix expansion rules, producing a lattice of possible segmentations.",
        "Entity": "Reference"
    },
    {
        "Text": "This is especially true in the case of quotations\u2014which are common in the ATB\u2014where (1) will follow a verb like (2) (Figure 1).",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 6 and 7 show the effect of the pruning pa rameter Np with the pruning parameter tp = 10 12",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6: Final results on CTB6 and CTB7 accuracies of POS tagging and dependency parsing were remarkably improved by 0.6% and 2.4%, respectively corresponding to 8.3% and 10.2% error reduction.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows a comparison with some existing toolkits that build deterministic, minimized automata/transducers.",
        "Entity": "Reference"
    },
    {
        "Text": "(2004) makes use of a coding manual designed for a project studying genitive modification (Garretson et al., 2004) and presents an explicit annotation scheme for an _ Samma _ PO _ KP erfarenhet NN _ gjorde VV PT engelsmannen NN DD|HH imacy, illustrated by figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "The bipartite graph K also induces a similarityagain (Figure 1(e)).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: Examples of word, morpheme, and compatible-bracket errors.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows these similarity measures.",
        "Entity": "Reference"
    },
    {
        "Text": "In Figure 4 we show an example of variation between the parsing models.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 Architecture of the statistical translation approach based on Bayes decision rule.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 Differences in performance between our system and Wang, Li, and Chang (1992).",
        "Entity": "Reference"
    },
    {
        "Text": "With an absolute frequency threshold of 10, we obtain an accuracy of 95.4%, which constitutes a 50% reduction of error rate.Table 3 presents the experimental results rela tive to class.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6 shows example sentences annotated by HGFC.",
        "Entity": "Reference"
    },
    {
        "Text": "Fi gure 7 depic ts the comp atible brack ets and all comp atible brack ets rates.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Output of word sense clustering.",
        "Entity": "Reference"
    },
    {
        "Text": "The results are displayed in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "If it starts with a lower case letter, and contains both upper and lower case letters, then (mixedCaps, zone) is set to 1.",
        "Entity": "Reference"
    },
    {
        "Text": "The figure schematically shows a small portion of the graph describing the concepts of mechanism (concrete), political system and relationship (abstract) at two levels of generality.",
        "Entity": "Reference"
    },
    {
        "Text": "Length Distribution In word segmentation, one of the major problems of the word length model of Equation (6) is the decom position of unknown words.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Scores for UPUC corpusFrom those tables, we can see that a simple ma jority voting algorithm produces accuracy that is higher than each individual system and reasonably high F-scores overall.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the correctness evaluation results.",
        "Entity": "Reference"
    },
    {
        "Text": "By introducing the distinction of word type to the model of Equation(12),we can derive a more sophis ticated unknown word model that reflects both word 3 When a Chinese character is used to represent a seman tically equivalent Japanese verb, its root is written in the Chinese character and its inflectional suffix is written in hi ragana.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Scores for CityU corpus",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Segmentation, POS tagging, and (unlabeled attachment) dependency F1 scores averaged over five trials on CTB5c.",
        "Entity": "Reference"
    },
    {
        "Text": "In the following, we describe the criterion that defines the set of phrases that is consistent with the word alignment matrix",
        "Entity": "Reference"
    },
    {
        "Text": "In the following, we describe the criterion that defines the set of phrases that is consistent with the word alignment matrix",
        "Entity": "Reference"
    },
    {
        "Text": "The baseline system in Table 3 refers to the maximum entropy system that uses only local features.",
        "Entity": "Reference"
    },
    {
        "Text": "Examples of the deletion features can be found in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Evaluation results are listed in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "In addition to the basic regular expression operators shown in table 1, the formalism is extended in various ways.",
        "Entity": "Reference"
    },
    {
        "Text": "Collocation: Collocations were extracted from a seven million word sample of the Longman English Language Corpus using the association ratio (Church and Hanks, 1990) and outputted to a lexicon.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Statistics from 1993 Japanese newswire (NIKKEI), 79,326,406 characters total.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8b shows that verbal nouns are the hardest pre-terminal categories to identify.",
        "Entity": "Reference"
    },
    {
        "Text": "To differentiate between the coordinating and discourse separator functions of conjunctions (Table 3), we mark each CC with the label of its right sister (splitCC).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 Performance on morphological analysis.",
        "Entity": "Reference"
    },
    {
        "Text": "his optimization can be performed using the expectation maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Statistics of datasets.",
        "Entity": "Reference"
    },
    {
        "Text": "Also, the CRF model using maximum subword-based tagging (Zhang et al., 2006) and the CRF model using minimum subword-based tagging, both of which are statistical methods, are used individually to solve the Figure 1: Outline of the segmentation process 2.1 Forward Maximum Matching.",
        "Entity": "Reference"
    },
    {
        "Text": "These semantic features Figure 8: Examples of the MT outputs with and without SRFs",
        "Entity": "Reference"
    },
    {
        "Text": "The probability of using an alignment template to translate a specific source language phrase f is estimated by means of relative frequency",
        "Entity": "Reference"
    },
    {
        "Text": "MENE has only been tested on MUC7.",
        "Entity": "Reference"
    },
    {
        "Text": "In order to effectively capture entity-related semantic features, and their combined features as well, especially bi-gram or tri-gram features, we build an Entity-related Semantic Tree (EST) in three ways as illustrated in Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Examples are given in Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "We obtain the following decision rule: eI = argmax Pr(eI | f J ) 1 1 1 I 1 M ) = argmax m hm (eI , f J ) 1 1 I m=1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Performance of the mention detection system using lexical, syntactic, gazetteer features as well as features obtained by running other named-entity classifiers named-entity classifiers (with different semantic tag sets).",
        "Entity": "Reference"
    },
    {
        "Text": "This class-based model gives reasonable results: for six radical classes, Table 1 gives the estimated cost for an unseen hanzi in the class occurring as the second hanzi in a double GIVEN name.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 summarizes the results obtained with different taggers and tagsets on the development data.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows that this reimplementation almost reproduces the accuracy of their implementation.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Tree setups P(%) R(%) F CS-SPT over SPT3 1.5 1.1 1.3 DSPT over SPT 1.1 5.6 3.8 UPST (FPT) over SPT 3.8 10.9 8.0 Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "(2004) in figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Performance of baseline and joint models w.r.t. the average processing time (in sec.)",
        "Entity": "Reference"
    },
    {
        "Text": "The figure schematically shows a small portion of the graph describing the concepts of mechanism (concrete), political system and relationship (abstract) at two levels of generality.",
        "Entity": "Reference"
    },
    {
        "Text": "If we directly translate the EM algorithm into the log- linear model, the problem becomes maximizing 0 X P r(S, T , D) = X @ Y P r(t) Y 1 P r(f )A the data likelihood represented by feature weights instead of feature probabilities: D D t D f F (S,T .role,D) Though the above formulation, which makes the P r(S, T ) = D exp i i fi (S, T , D) total probability of all the pairs of trees and strings P P exp P f (S , T , D ) St ,T t Dt i i i less than 1, is not a strict generative model, we can still use the EM algorithm (Dempster et al., 1977) to estimate the probability of the TTS templates and the semantic features, as shown in Figure 6.",
        "Entity": "Reference"
    },
    {
        "Text": "As each global feature group is added to the list of features, we see improvements to both MUC6 and",
        "Entity": "Reference"
    },
    {
        "Text": "This is because the lefthand side of Equation (7) represents the probability of the string c1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the experimental results with and without the stem n-grams features.",
        "Entity": "Reference"
    },
    {
        "Text": "The coupling between B and is removed by setting H = B 1: n min (W, H H T ), s.t. hip = 1 (1) H, i=1 BT Dl Bl according to equation 4 l end for return BL , BL 1 ...B1 Additional steps need to be performed in order to extract a tree from the hierarchical graph.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Statistics of datasets.",
        "Entity": "Reference"
    },
    {
        "Text": "Comparison of different systems on the ACE RDC 2004 corpus In Table 3 we summarize the improvements of different tree setups over SPT.",
        "Entity": "Reference"
    },
    {
        "Text": "See Figure 3 for examples.",
        "Entity": "Reference"
    },
    {
        "Text": "where ECD|S,T (fi), the expected count of a feature over all derivations given a pair of tree and string, can be computed using the modified inside- outside algorithm described in Section 3.2, and ECS |T (fi), the expected count of a feature over all possible target strings given the source tree, can be computed in a similar way to the partition function described in Figure 7.",
        "Entity": "Reference"
    },
    {
        "Text": "The unknown parameters are determined by maximizing the likelihood on the parallel training corpus:",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 gives an example of the word alignment and phrase alignment of a German English sentence pair.We describe our model using a log-linear modeling approach",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 9 shows that in fact both contribute to producing good segmentations.",
        "Entity": "Reference"
    },
    {
        "Text": "As Table 1 shows, word bigrams whose infrequent word bigram",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4 shows the performance on the test data.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Statistics from 1993 Japanese newswire (NIKKEI), 79,326,406 characters total.",
        "Entity": "Reference"
    },
    {
        "Text": "alignment models Pr(f J , aJ | eI ),",
        "Entity": "Reference"
    },
    {
        "Text": "Preliminary observations show that the different neighbours in Table 1 can be used to indicate with great accuracy which of the senses is being used",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows examples of the discovered patterns for the merger and acquisition topic.",
        "Entity": "Reference"
    },
    {
        "Text": "If it is made up of all capital letters, then (allCaps, zone) is set to 1",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows a constituent headed by a process nominal with an embedded adjective phrase.",
        "Entity": "Reference"
    },
    {
        "Text": "Results: Table I gives the results for the comparison of the troughs placed by the segmentation algorithm to the known subject change points.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 show the training time for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "This sentence should be tagged as shown in table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Letting u1 be the prefix of the word that ends in v1 (eg, r in figure 1), w1 = u1v1, and h = htu1:is less accurate because it ignores the alignment rela tion between s and h, which is captured by even the simplest noisy-channel models.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 plots AP by for all meta alternations.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows empirical search timings for various values of M , for the MEMD model described in the next section.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1(d) shows a sentence maintain rental property he owns in the state , where the ART.User-or-Owner relation holds between the entities property and he",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Comparison against Stevenson and Joanis (2003) s result on T1 (using similar features).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows the cross entropy per word and char acter perplexity of three unknown word model.",
        "Entity": "Reference"
    },
    {
        "Text": "We establish a corresponding feature function by multiplying the probability of all used alignment templates and taking the logarithm",
        "Entity": "Reference"
    },
    {
        "Text": "If we compare the error rates in Table 7, which correspond to about 55 search errors in Table 6, we obtain an mWER of 36.7% (53 search errors) using no heuristic function and an mWER of 32.6% (57 search errors) using the combined heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "In general, as shown in this figure, there may be additional transformations to make the translation task simpler for the algorithm.",
        "Entity": "Reference"
    },
    {
        "Text": "In the last two lines of Equation 3, \u03c6\u01eb and each P (f |e) = \"\u00a3s c (f |e; f (s), e(s)) (4) \u03c6i are not free variables, but are determined by f s c(f |e; f (s), e(s))the alignments.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1), i.e., the degree to which a sense pair (s1, s2) matches a meta alternation a.",
        "Entity": "Reference"
    },
    {
        "Text": "We show that noun-noun vs. discourse-level coordination ambiguity in Arabic is a significant source of parsing errors (Table 8c).",
        "Entity": "Reference"
    },
    {
        "Text": "Improvements of different tree setups over SPT on the ACE RDC 2004 corpus Finally, Table 4 compares our system with other state-of-the-art kernel-based systems on the 7 relation types of the ACE RDC 2004 corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the results of both unconstrained and constrained versions of HGFC and those of AGG on the test set T3 (where singular classes are removed to enable proper evaluation of the constrained method).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows our results and the results of Stevenson and Joanis (2003) on T1 when employing AGG using Ward as the linkage criterion.",
        "Entity": "Reference"
    },
    {
        "Text": "In our segmentation system, a hybrid strategy is applied (Figure 1): First, forward maximum matching (Chen and Liu, 1992), which is a dictionary-based method, is used to generate a segmentation result.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: A sentence from the article Islamic GoldenAge, with the supersense tagging from one of two anno tators.",
        "Entity": "Reference"
    },
    {
        "Text": "this error is not counted, the tagging accuracy on the development data rises from 92.17% to 94.27%.",
        "Entity": "Reference"
    },
    {
        "Text": "We set Table 6: Word segmentation accuracy of all words r e c pr ec F Po iss on +b igr a m W T +P oi ss on +b igr a m P O S + Po iss on +b igr a m P O S + W T + Po iss on + bi gr a m 94 .5 94 .4 94 .4 94 .6 93 .1 93 .8 93 .6 93 .7 93 .8 94 .1 94 .0 94 .1",
        "Entity": "Reference"
    },
    {
        "Text": "In order to effectively capture entity-related semantic features, and their combined features as well, especially bi-gram or tri-gram features, we build an Entity-related Semantic Tree (EST) in three ways as illustrated in Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "The probability of using an alignment template to translate a specific source language phrase f is estimated by means of relative frequency",
        "Entity": "Reference"
    },
    {
        "Text": "We compared the ATB5 to tree- banks for Chinese (CTB6), German (Negra), and English (WSJ) (Table 4)",
        "Entity": "Reference"
    },
    {
        "Text": "If we compare the error rates in Table 7, which correspond to about 55 search errors in Table 6, we obtain an mWER of 36.7% (53 search errors) using no heuristic function and an mWER of 32.6% (57 search errors) using the combined heuristic function",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 compares the results of the unconstrained version of HGFC against those of AGG on our largest test set T2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 is, in fact, a weighted sum of these two distributions.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 displays the performance of our model and of the systems that obtained the best (Fernandes et al., 2012) and the median performance in the MUC B3 CEAFe average R P F1 R P F1 R P F1 CoNLL 12 English development data be st 64.",
        "Entity": "Reference"
    },
    {
        "Text": "However, this information is hard to extract reliably from the available data; and even if were obtainable, many of the 0.3 0.2 0.1 0 60 50 40 30 20 10 0 10 20 30 40 50 60 gain (length of correct prefix length of incorrect suffix) Figure 2: Probability that a prediction will be accepted versus its gain.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Average Precision and Coherence ( ) for each meta alternation.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, in the sentence bought one of town s two meat- packing plants as illustrated in Figure 1(a), the constituents before the headword plants can be removed from the parse tree.",
        "Entity": "Reference"
    },
    {
        "Text": "For fair comparison, we have tabulated all results with the size of training data used (Table 5",
        "Entity": "Reference"
    },
    {
        "Text": "A token that is allCaps will also be initCaps.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows these similarity measures.",
        "Entity": "Reference"
    },
    {
        "Text": "The first model is Equation (5), which is the combina . tion of Poisson distribution and character zerogram",
        "Entity": "Reference"
    },
    {
        "Text": "Fi gure 7 depic ts the comp atible brack ets and all comp atible brack ets rates.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: Examples of word, morpheme, and compatible-bracket errors.",
        "Entity": "Reference"
    },
    {
        "Text": "of the 43 words are translated to English multi-word phrases (denoted as \u201cphrase\u201d in Table 3).",
        "Entity": "Reference"
    },
    {
        "Text": "even after removal of the wing-node, the two areas of meaning are still linked via tail",
        "Entity": "Reference"
    },
    {
        "Text": "For MUC7, there are also no published results on systems trained on only the official training data of 200 aviation disaster articles.",
        "Entity": "Reference"
    },
    {
        "Text": "The second condition is necessary to allow for single-character words (see Figure 3).",
        "Entity": "Reference"
    },
    {
        "Text": "The algorithm takes into account possibly unaligned words at the boundaries of the source or target language phrases.",
        "Entity": "Reference"
    },
    {
        "Text": "More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paa and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2",
        "Entity": "Reference"
    },
    {
        "Text": "To illustrate how SRF impacts the translation results, Figure 8 gives 3 examples of the MT outputs with and without the SRFs",
        "Entity": "Reference"
    },
    {
        "Text": "The Stanford parser (Klein and Manning, 2002) is unable to recover the verbal reading of the unvocalized surface form 0 an (Table 1).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: Metaphors tagged by the system (in bold) whereby the main source of disagreement was the presence of lexicalized metaphors, e.g. verbs such as impose, decline etc.",
        "Entity": "Reference"
    },
    {
        "Text": "In this section, we try to compare our results with those obtained by IdentiFinder ' 97 (Bikel et al., 1997), IdentiFinder ' 99 (Bikel et al., 1999), and MENE (Borthwick, 1999).",
        "Entity": "Reference"
    },
    {
        "Text": "Then, every phrase f produces its translation e (using the corresponding alignment template z).",
        "Entity": "Reference"
    },
    {
        "Text": "A token that is allCaps will also be initCaps.",
        "Entity": "Reference"
    },
    {
        "Text": "This corresponds to maximizing the equivocation or maximizing the likelihood of the direct-translation model",
        "Entity": "Reference"
    },
    {
        "Text": "See Fig ure 6 for some examples.",
        "Entity": "Reference"
    },
    {
        "Text": "5http://cactus.aistnara.ac.jp/lab/nltlchasen.html 6http://pine.kuee.kyoto-u.ac.jp/nl-resource/juman-e.html Word accuracy 90 CHASEN JUMAN opllnizt oplnuo recall opiJTozt F Figure 4: Word accuracy.",
        "Entity": "Reference"
    },
    {
        "Text": "First, the source sentence words f J are grouped into phrases f K . For each phrase f an 1 1 alignment template z is chosen and the sequence of chosen alignment templates is reordered (according to K ).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 contains results for two different translation models.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 is, in fact, a weighted sum of these two distributions.",
        "Entity": "Reference"
    },
    {
        "Text": "The probabilities P( <U-t>lwi_I) can be esti mated from the relative frequencies in the training corpus whose infrequent words are replaced with their corresponding unknown word tags based on their part of speeches 2 Table 1 shows examples of word bigrams including unknown word tags.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the word length distribution of words consists of only kanji characters and words consists of only katakana characters.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Distribution of supersense mentions by domain (left), and counts for tags occurring over 800 times (below).",
        "Entity": "Reference"
    },
    {
        "Text": "For example, if x in figure 1 were evenir aux choses, then x14 would map to v1 = evenir, w2 = aux, and u3 = cho.",
        "Entity": "Reference"
    },
    {
        "Text": "As the search space increases expo nentially, it is not possible to explicitly represent it.",
        "Entity": "Reference"
    },
    {
        "Text": "If M = 10, 15 Chinese words (i.e., the first 19 Chinese words in Table 3 except \u53f6\u739b\u65af,\u5df4\u4f50\u4e9a,\u5769\u57da,\u666e\u5229\u6cd5) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "segmentation (Table 2).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the NA M N O M PR O NA M 34 13 (21 %) 67 (6 6 %) 11 (4 6 %) N O M 43 (67 %) 21 48 (4 9 %) 9 (8 9 %) PR O 86 8 (32 %) 17 71 (5 5 %) 53 08 (2 4 %) Table 2: Number of clustering decisions made according to mention type (rows anaphor, columns antecedent) and percentage of wrong decisions.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Performance of the mention detection system using lexical features only.",
        "Entity": "Reference"
    },
    {
        "Text": "Comparison of different systems on the ACE RDC 2004 corpus In Table 3 we summarize the improvements of different tree setups over SPT.",
        "Entity": "Reference"
    },
    {
        "Text": "This is especially true in the case of quotations\u2014which are common in the ATB\u2014where (1) will follow a verb like (2) (Figure 1).",
        "Entity": "Reference"
    },
    {
        "Text": "The model is described using a log-linear modeling approach, which is a generalization of the often used source channel approach",
        "Entity": "Reference"
    },
    {
        "Text": "This sentence should be tagged as shown in table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 5 we present results from small test cor pora for the productive affixes handled by the current version of the system; as with names, the segmentation of morphologically derived words is generally either right or wrong.",
        "Entity": "Reference"
    },
    {
        "Text": "To illustrate the complete user model, in the figure 1 example the benefit of accepting would be7 2 4.2 = .8 keystrokes and the benefit of reject ing would be .2 keystrokes.",
        "Entity": "Reference"
    },
    {
        "Text": "This table also shows that: (1) Both modification within base-NPs and modification to NPs contribute much to performance improvement, acquiring the increase of F- measure by 4.4/2.4 units in mode M1 and 4.4/2.3 units in mode M2 respectively.",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in Table 3, using just context information alone, 10 Chinese words (the first 10) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7 shows a structogram of the algorithm",
        "Entity": "Reference"
    },
    {
        "Text": "Thetheoretical upper bound of the decoding complex Figure 5: Decoding algorithm using semantic role features.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Bootstrapping new heuristics.",
        "Entity": "Reference"
    },
    {
        "Text": "Although kanji sequences are difficult to seg ment, they can comprise a significant portion of Japanese text, as shown in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "igure 1 gives an example.",
        "Entity": "Reference"
    },
    {
        "Text": "The bottom-up decoding algorithm for the TTS transducer is sketched in Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: (a) An undirected graph G representing the similarity matrix; (b) The bipartite graph showing three clusters on G; (c) The induced clusters U ; (d) The new graph G1 over clusters U ; (e) The new bipartite graph over G1 p |vi ) = Vl 1 ...",
        "Entity": "Reference"
    },
    {
        "Text": "Table 7 shows the results.",
        "Entity": "Reference"
    },
    {
        "Text": "On the contrary, in the above training stage, although the samples are not accurate enough to represent the distribution defined by Equation 7 for each alignment aj , it is accurate enough for computing the expected counts, which are defined at the corpus level.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6: Sample targets for meta alternations with high AP and mid-coherence values.",
        "Entity": "Reference"
    },
    {
        "Text": "The sources of our dictionaries are listed in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "CoreLex defines a layer of abstraction above WordNet consisting of 39 basic types, coarse- grained ontological classes (Table 2).",
        "Entity": "Reference"
    },
    {
        "Text": "For MUC7, there are also no published results on systems trained on only the official training data of 200 aviation disaster articles.",
        "Entity": "Reference"
    },
    {
        "Text": "Comparison of segmentation algorithm using different linguistic features.",
        "Entity": "Reference"
    },
    {
        "Text": "The overall architecture of the log-linear modeling approach is summarized in Figure 1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: BLEU4 scores of different systems Source Launching1 New2 Diplomatic3 Offensive4 SRF On 1 2 3 4 SRF Off 2 3 4 It1 is2 therefore3 necessary4 to5 speed6 up7 the8 equal better worse With SRF vs. W/O SRF 72% 20.2% 7.8% Source transformation9 of10 traditional11 industries12 with13 high14 technologies15",
        "Entity": "Reference"
    },
    {
        "Text": "Equation (12), which is a set of word models trained for each part of speech (POS + Poisson + bigram).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 Classes of words found by ST for the test corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Output of word sense clustering.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: Metaphors tagged by the system (in bold) whereby the main source of disagreement was the presence of lexicalized metaphors, e.g. verbs such as impose, decline etc.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the performance and processing time comparison of various models and their combinations.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 4 and 5 show the effect of the pruning parameter tp with the histogram pruning parameter Np = 50,000",
        "Entity": "Reference"
    },
    {
        "Text": "For instance, the gain for the prediction in figure 1 would be 2 7 8 = 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Examples are given in Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows type- and token-level error rates for each corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Accuracy for MBL and SVM classifiers on Talbanken05 nouns in accumulated frequency bins by Parole frequency.",
        "Entity": "Reference"
    },
    {
        "Text": "The first machine, illustrated in Figure 1 encodes the prefix and suffix expansion rules, producing a lattice of possible segmentations.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 reports experimental results using lexical features only; we observe that the stemming n-gram features boost the performance by one point (64.7 vs. 65.8).",
        "Entity": "Reference"
    },
    {
        "Text": "#o is the total number of output English translations.",
        "Entity": "Reference"
    },
    {
        "Text": "As a result, Arabic sentences are usually long relative to English, especially after",
        "Entity": "Reference"
    },
    {
        "Text": "We also investigated the effect of varying M . The results are shown in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Strube (1998) s centeri ng appro ach (whos e senten ce orderi ng is designate d as SR2 in Table 2) also deals with and even prefer s intrase ntenti al anaph ora, which raises the upper limit to a more accept able 80.2% .",
        "Entity": "Reference"
    },
    {
        "Text": ">10 nouns (a) (b) classified as 222 125 (a) class animate 49 3390 (b) class inanimate Table 4: Confusion matrix for the MBLclassifier with a general feature space on the >10 data set on Talbanken05 nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Contribution of constituent dependencies in respective mode (inside parentheses) and accumulative mode (outside parentheses) The table shows that the final DSPT achieves the best performance of 77.4%/65.4%/70.9 in precision/recall/F-measure respectively after applying all the dependencies, with the increase of F-measure by 8.2 units compared to the baseline MCT.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8a shows that the best model recovers SBAR at only 71.0% F1.",
        "Entity": "Reference"
    },
    {
        "Text": "The second model is Equa tion (13), which is a set of word models trained for",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Results for different predictor configurations.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the usefulness evaluation result.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1(d) shows a sentence maintain rental property he owns in the state , where the ART.User-or-Owner relation holds between the entities property and he",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 Architecture of the statistical translation approach based on Bayes decision rule.",
        "Entity": "Reference"
    },
    {
        "Text": "Tables 6 and 7 show the effect of the pruning pa rameter Np with the pruning parameter tp = 10 12",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "The reordering of the semantic roles from source to target is computed for each TTS template as part of the template extraction process, using the word-level alignments between the LHS/RHS of the TTS template (e.g., Figure 3).",
        "Entity": "Reference"
    },
    {
        "Text": "See Fig ure 6 for some examples.",
        "Entity": "Reference"
    },
    {
        "Text": "The use of the language model feature in equation (18) helps take long-range dependencies better into account",
        "Entity": "Reference"
    },
    {
        "Text": "We see from Table 5, that the improvement in overall parse results is mainly in terms of dependency labeling, reflected in the LAS score.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the influence of the four parameters.",
        "Entity": "Reference"
    },
    {
        "Text": "If it starts with a lower case letter, and contains both upper and lower case letters, then (mixedCaps, zone) is set to 1.",
        "Entity": "Reference"
    },
    {
        "Text": "If M = 10, 15 Chinese words (i.e., the first 19 Chinese words in Table 3 except \u53f6\u739b\u65af,\u5df4\u4f50\u4e9a,\u5769\u57da,\u666e\u5229\u6cd5) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6: Final results on CTB6 and CTB7 accuracies of POS tagging and dependency parsing were remarkably improved by 0.6% and 2.4%, respectively corresponding to 8.3% and 10.2% error reduction.",
        "Entity": "Reference"
    },
    {
        "Text": "In Table 1, period 1 is Jul 01 \u2013 Jul 15, period 2 is Jul 16 \u2013 Jul 31, \u2026, period 12 is Dec 16 \u2013 Dec 31.",
        "Entity": "Reference"
    },
    {
        "Text": "composite kernel 83.0 72.0 77.1 Zhou et al., (2007): composite kernel 82.2 70.2 75.8 Zhang et al., (2006): composite kernel 76.1 68.4 72.1 Zhao and Grishman, (2005):4 composite kernel 69.2 70.5 70.4 Ours: CTK with UPST 80.1 70.7 75.1Zhou et al., (2007): context sensitive CTK with CS-SPT 81.1 66.7 73.2 Zhang et al., (2006): CTK with SPT 74.1 62.4 67.7 Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: EM Algorithm For Estimating TTS Templates and Semantic Features framework (May and Knight, 2007).",
        "Entity": "Reference"
    },
    {
        "Text": "Reduction of conjuncts for NP coordination Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8: Part of speech tagging accuracy of unknown words (the last column represents the percentage of correctly tagged unknown words in the correctly segmented unknown words",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Approximate times in seconds to generate predictions of maximum word sequence length M , on a 1.2GHz processor, for the MEMD model.",
        "Entity": "Reference"
    },
    {
        "Text": "n our experimentations, SVMlight (Joachims, 1998) with the tree kernel function (75.0) (53.7) (62.6) Table 1",
        "Entity": "Reference"
    },
    {
        "Text": "However, the learning curves in Figure 3 show that the Berkeley parser does not exceed our manual grammar by as wide a margin as has been shown for other languages (Petrov, 2009).",
        "Entity": "Reference"
    },
    {
        "Text": "Throughout in this paper, we used Equation (9) to compute the word spelling probabilities.",
        "Entity": "Reference"
    },
    {
        "Text": "In general, as shown in this figure, there may be additional transformations to make the translation task simpler for the algorithm.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Results of different systems on the CoNLL 12 English data sets.",
        "Entity": "Reference"
    },
    {
        "Text": "the time-consuming renormalization in equation (3) is not needed in search",
        "Entity": "Reference"
    },
    {
        "Text": "The figure schematically shows a small portion of the graph describing the concepts of mechanism (concrete), political system and relationship (abstract) at two levels of generality.",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "The probability of using an alignment template to translate a specific source language phrase f is estimated by means of relative frequency",
        "Entity": "Reference"
    },
    {
        "Text": "However, if we remove the mouse-node from its local graph illustrated in figure 1, the graph decomposes into two parts, one representing the electronic device meaning of mouse and the other one representing its animal sense.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Word length distribution of kanji words and katakana words length model does not reflect the variation of the word length distribution resulting from the Japanese orthography.",
        "Entity": "Reference"
    },
    {
        "Text": "The sources of our dictionaries are listed in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Segmentation, POS tagging, and (unlabeled attachment) dependency F1 scores averaged over five trials on CTB5c.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 gives the mean values for the comparison of troughs placed by the segmentation algorithm to the segmentation points identified by the test subjects for all the texts",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Collecting evidence for a word boundary - are the non-straddling n-grams 8 1 and 82 more frequent than the straddling n-grams t 1, t2, and t3?",
        "Entity": "Reference"
    },
    {
        "Text": "Throughout in this paper, we used Equation (9) to compute the word spelling probabilities.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, if a token starts with a capital letter and ends with a period (such as Mr.), then the feature InitCapPeriod is set to 1, etc",
        "Entity": "Reference"
    },
    {
        "Text": "The list of the features used in our joint model is presented in Table 1, where S01 S05, W01 W21, and T01 05 are taken from Zhang and Clark (2010), and P01 P28 are taken from Huang and Sagae (2010).",
        "Entity": "Reference"
    },
    {
        "Text": "Consider the example in Figure 1",
        "Entity": "Reference"
    },
    {
        "Text": "As shown in Figure 8, relative word performance was not degraded and sometimes even slightly better.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the usefulness evaluation result.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Approximate times in seconds to generate predictions of maximum word sequence length M , on a 1.2GHz processor, for the MEMD model.",
        "Entity": "Reference"
    },
    {
        "Text": "we directly model the posterior probability Pr(eI| f J )",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Character type configuration of infrequent words in the EDR corpus",
        "Entity": "Reference"
    },
    {
        "Text": "Based on this experiment, we set the beam size of SegTagDep to 64 throughout the exper 64 96.28 92.37 74.96 0.48 Table 3: F1 scores and speed (in sentences per sec.)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Performance of Algorithms switch under different input data.",
        "Entity": "Reference"
    },
    {
        "Text": "A comparison of the lines for grammatical roles and for surface order in Table 1 shows that the same is true in German.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 6: EM Algorithm For Estimating TTS Templates and Semantic Features framework (May and Knight, 2007).",
        "Entity": "Reference"
    },
    {
        "Text": "Examples are given in Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Results for different user simulations.",
        "Entity": "Reference"
    },
    {
        "Text": "Cik Figure 1: Local graph of the word mouse",
        "Entity": "Reference"
    },
    {
        "Text": "As for the unknown word model, word-based char acter bigrams are computed from the words with Table 5: Cross entropy (CE) per word and character perplexity (PP) of each unknown word model Part of Speech Estimation Accuracy 0.95 0.9 frequency one (49,653 words).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the performance and speed of the full joint model (with no dictionaries) on CTB5c1 with respect to the beam size.",
        "Entity": "Reference"
    },
    {
        "Text": "alignment models Pr(f J , aJ | eI ),",
        "Entity": "Reference"
    },
    {
        "Text": "where N is role features when combining two children states, and ex amples can be found in Figure 3.",
        "Entity": "Reference"
    },
    {
        "Text": "If it is made up of all capital letters, then (allCaps, zone) is set to 1",
        "Entity": "Reference"
    },
    {
        "Text": "the target Chen Guangcheng only appears once in Weibo",
        "Entity": "Reference"
    },
    {
        "Text": "The entity features can be attached under the top node, the entity nodes, or directly combined with the entity nodes as in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Reduction of conjuncts for NP coordination Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 suggests that the best setup is dependent on the specific meta sense or meta alternation being MACRO MICRO repM gram gramlex lex space type MACRO MICRO repA",
        "Entity": "Reference"
    },
    {
        "Text": "The results when we set M = 10 are shown in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "(2004) in figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "See Figure 3 for examples.",
        "Entity": "Reference"
    },
    {
        "Text": "The probabilities P( <U-t>lwi_I) can be esti mated from the relative frequencies in the training corpus whose infrequent words are replaced with their corresponding unknown word tags based on their part of speeches 2 Table 1 shows examples of word bigrams including unknown word tags.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Statistics of datasets.",
        "Entity": "Reference"
    },
    {
        "Text": "The annotation manual (Teleman, 1974) states that a markable should be tagged as human (H H) if it may be replaced by the interrogative pronoun vem who and be referred to by the personal pronouns han he or hon she .There are clear similarities between the anno tation for human reference found in Talbanken05 and the annotation scheme for animacy discussed HUM Other animate Inanimate ORG ANIM CONC NCONC TIME PLACE Figure 1: Animacy classification scheme (Zaenen et al., 2004)",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4 shows examples of alignment templates",
        "Entity": "Reference"
    },
    {
        "Text": "e suggest the use of a log-linear model to incorporate the various knowledge sources into an overall translation system and to perform discriminative training of the free model parameters",
        "Entity": "Reference"
    },
    {
        "Text": "These semantic features Figure 8: Examples of the MT outputs with and without SRFs",
        "Entity": "Reference"
    },
    {
        "Text": "n our experimentations, SVMlight (Joachims, 1998) with the tree kernel function (75.0) (53.7) (62.6) Table 1",
        "Entity": "Reference"
    },
    {
        "Text": "The first example in Table 3 shows that words ending in ' -' are likely to be nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 gives the algorithm phrase-extract that computes the phrases",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 shows type- and token-level error rates for each corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "he largest effect seems to come from taking into account the bigram dependence, which achieves an mWER of 32.9%",
        "Entity": "Reference"
    },
    {
        "Text": "Evaluation results are listed in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Typically, the translation probability Pr(eI | f J ) is decomposed via additional hid 1 1 den variables",
        "Entity": "Reference"
    },
    {
        "Text": "As illus trated in Figure 1(e), the NP coordination in the Qian et al.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows examples of common char acter bigrams for each part of speech in the infre quent words of the EDR corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "This approach has been suggested by Papineni, Roukos, and Ward (1997, 1998) for a natural language understanding task.",
        "Entity": "Reference"
    },
    {
        "Text": "The graphical structure depicted in Figure 1 models these relations between the four mentions Leaders, Paris, recent developments and They.",
        "Entity": "Reference"
    },
    {
        "Text": "As can be seen in figure 2, wing \"part of a bird\" is closely related to tail, as is wing \"part of a plane\"",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows that the tagging accuracy tends to increase with the context size.",
        "Entity": "Reference"
    },
    {
        "Text": "At the morp heme level, stems are divid ed from their affixe s. For exam ple, altho ugh both naga no (Naga no) and shi (city) can appea r as indivi dual words , nagano shi (Nag ano city) is brack eted as [[naga no][s hi]], since here shi Figure 3: Determining word boundaries.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 evaluates the contributions of different kinds of constituent dependencies to extraction performance on the 7 relation types of the ACE RDC 2004 corpus",
        "Entity": "Reference"
    },
    {
        "Text": "This group consists of 10 features based on the string , as listed in Table 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 presents the wide range of cases that are used to create the morphs.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Examples of common character bigrams for each part of speech in the infrequent words pa rt of sp ee ch ch ar ac ter bi gr a m fre qu en cy no un nu m be r a dj e ct iv al v er b v er b ad je cti ve ad ve rb < e o w > <b o w > 1 S \" J < e o w > I t < e o w > L < e o w > < e o w > 13 43 4 8 4 3 2 7 2 1 3 69 63 resented all unknown words by one length model.",
        "Entity": "Reference"
    },
    {
        "Text": "On the other hand, using our method of combining both sources of information and setting M = \u221e, 19 Chinese words (i.e., the first 22 Chinese words in Table 3 except \u5df4\u4f50\u4e9a,\u5769\u57da,\u666e\u5229\u6cd5) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Scores for CityU corpus",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: The amount of training and test sets The first factor in the righthand side of Equa tion (13) is estimated from the relative frequency of the corresponding events in the training corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "The model is described using a log-linear modeling approach, which is a generalization of the often used source channel approach",
        "Entity": "Reference"
    },
    {
        "Text": "Examples of the deletion features can be found in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Performance on T3 using a predefined tree structure.",
        "Entity": "Reference"
    },
    {
        "Text": "(2011), we confirmed that omission of the look-ahead features results in a 0.26% decrease in the parsing accuracy on CTB5d (dev).Figure 2: F1 scores (in %) of SegTagDep on CTB 5c1 w.r.t. the training epoch (x-axis) and parsing feature weights (in legend).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Above: The complete supersense tagset for nouns; each tag is briefly described by its symbol, NAME, short description, and examples.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 shows the performance and speed of the full joint model (with no dictionaries) on CTB5c1 with respect to the beam size.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1shows the word length distribution of in frequent words in the EDR corpus, and the estimate of word length distribution by Equation (6) whose parameter (.A = 4.8) is the average word length of infrequent words.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 9 shows the training and test corpus statistics.",
        "Entity": "Reference"
    },
    {
        "Text": "The statistics of 96 these splits are shown in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Word length distribution of unknown words and its estimate by Poisson distribution",
        "Entity": "Reference"
    },
    {
        "Text": "A token that is allCaps will also be initCaps.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, the expressions in Figure 2 are identified as paraphrases by this method; so these three patterns will be placed in the same pattern set.",
        "Entity": "Reference"
    },
    {
        "Text": "Prec. is the precision.",
        "Entity": "Reference"
    },
    {
        "Text": "Thetheoretical upper bound of the decoding complex Figure 5: Decoding algorithm using semantic role features.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: CoreLex s basic types with their corresponding WordNet anchors.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, in the sentence bought one of town s two meat- packing plants as illustrated in Figure 1(a), the constituents before the headword plants can be removed from the parse tree.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1; capital letters designate sets and small letters elements of sets).2 For a lemma l like lamb, we want to knowhow well a meta alternation (such as ANIMAL FOOD) explains a pair of its senses (such as the animal and food senses of lamb).3 This is formalized through the function score, which maps a meta alternation and two senses onto a score.",
        "Entity": "Reference"
    },
    {
        "Text": "Shortest-enclosed Path Tree from P/R/F (81.1/6.7/73.2) of Dynamic Context-Sensitive Shortest- enclosed Path Tree according to Table 2 (Zhou et al., 2007)",
        "Entity": "Reference"
    },
    {
        "Text": "The second model is the combination of Poisson distribution (Equation (6)) and character bigram",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Number of recall errors according to mention type (rows anaphor, columns antecedent).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows these similarity measures.",
        "Entity": "Reference"
    },
    {
        "Text": "The graphical structure depicted in Figure 1 models these relations between the four mentions Leaders, Paris, recent developments and They.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 lists both the success rate maximally achievable (broken down according to different types of pronouns) and the average number of antecedents remaining after applying each factor.",
        "Entity": "Reference"
    },
    {
        "Text": "n all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "If it is made up of all capital letters, then (allCaps, zone) is set to 1",
        "Entity": "Reference"
    },
    {
        "Text": "The corresponding translation quality improves from an mWER of 45.9% to an mWER of 31.8%.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the record for the headword orange followed by its collocates",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the distribution of character type sequences that constitute the infrequent words in the EDR corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the experimental results with and without the stem n-grams features.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Performance of the mention detection system using lexical features only.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 Similarity matrix for segmentation judgments.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows that by using word type and part of speech information, recall is improved from 28.1% to 40.6% and precision is improved from 57.3% to 64.1%.",
        "Entity": "Reference"
    },
    {
        "Text": "Results: Table I gives the results for the comparison of the troughs placed by the segmentation algorithm to the known subject change points.",
        "Entity": "Reference"
    },
    {
        "Text": "A simple lexicalized PCFG with second order Markovization gives relatively poor performance: 75.95% F1 on the test set.8 But this figure is surprisingly competitive with a recent state-of-the-art baseline (Table 7).",
        "Entity": "Reference"
    },
    {
        "Text": "Comparison of segmentation algorithm using different linguistic features.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Statistics from 1993 Japanese newswire (NIKKEI), 79,326,406 characters total.",
        "Entity": "Reference"
    },
    {
        "Text": "of the 43 words are translated to English multi-word phrases (denoted as \u201cphrase\u201d in Table 3).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6 shows the word segmentation accuracy of four unknown word models over test set-2.",
        "Entity": "Reference"
    },
    {
        "Text": "However, this information is hard to extract reliably from the available data; and even if were obtainable, many of the 0.3 0.2 0.1 0 60 50 40 30 20 10 0 10 20 30 40 50 60 gain (length of correct prefix length of incorrect suffix) Figure 2: Probability that a prediction will be accepted versus its gain.",
        "Entity": "Reference"
    },
    {
        "Text": "and ap plied to an Arabic sentence in figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "The points labelled smoothed in figure 2 were obtained using a sliding-average smoother, and the model curve was obtained using two-component Gaussian mixtures to fit the smoothed empirical likelihoods p(gain|a = 0) and p(gain|a = 1).",
        "Entity": "Reference"
    },
    {
        "Text": "It should be emphasized that this constraint to consecutive phrases limits the expressive power.",
        "Entity": "Reference"
    },
    {
        "Text": "We see from Table 5, that the improvement in overall parse results is mainly in terms of dependency labeling, reflected in the LAS score.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 breaks down the performance of the best CAM model by meta alternation.",
        "Entity": "Reference"
    },
    {
        "Text": "We illustrate its use with an example (see Then, we average the contributions of each n-gram order: Figure 2).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6 lists a sample of targets for the five meta alternations involved.",
        "Entity": "Reference"
    },
    {
        "Text": "his optimization can be performed using the expectation maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Character type configuration of infrequent words in the EDR corpus",
        "Entity": "Reference"
    },
    {
        "Text": "To illustrate how SRF impacts the translation results, Figure 8 gives 3 examples of the MT outputs with and without the SRFs",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 displays the performance of our model and of the systems that obtained the best (Fernandes et al., 2012) and the median performance in the MUC B3 CEAFe average R P F1 R P F1 R P F1 CoNLL 12 English development data be st 64.",
        "Entity": "Reference"
    },
    {
        "Text": "CoreLex defines a layer of abstraction above WordNet consisting of 39 basic types, coarse- grained ontological classes (Table 2).",
        "Entity": "Reference"
    },
    {
        "Text": "Collocation: Collocations were extracted from a seven million word sample of the Longman English Language Corpus using the association ratio (Church and Hanks, 1990) and outputted to a lexicon.",
        "Entity": "Reference"
    },
    {
        "Text": "The direct translation probability is given by",
        "Entity": "Reference"
    },
    {
        "Text": "where N is role features when combining two children states, and ex amples can be found in Figure 3.",
        "Entity": "Reference"
    },
    {
        "Text": "In the following, we describe the criterion that defines the set of phrases that is consistent with the word alignment matrix",
        "Entity": "Reference"
    },
    {
        "Text": "Again, Table 2 shows that using stem n-grams features gave a small boost to the whole main-type classification system4.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the manual evaluation results based on the entire test set, and the improvement from SRF is significant at p < 0.005 based on a t-test.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, if x in figure 1 were evenir aux choses, then x14 would map to v1 = evenir, w2 = aux, and u3 = cho.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 compares the results of the unconstrained version of HGFC against those of AGG on our largest test set T2.",
        "Entity": "Reference"
    },
    {
        "Text": "Only tokens with initCaps not found in commonWords are tested against each list in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 4: An example showing how to compute the target side position of a semantic role by using the median of its aligning points.",
        "Entity": "Reference"
    },
    {
        "Text": "The model 1 The total 74,597 sentence pairs used in experiments are those in the FBIS corpus whose English part can be parsed using Charniak (2000)",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Time to read and accept or reject proposals versus their length tion, because the empirical probability of acceptance is very low when it is less than zero and rises rapidly as it increases.",
        "Entity": "Reference"
    },
    {
        "Text": "We see that the language model perplexity improves from 4,781 for a unigram model to 29.9 for a trigram model.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Effect of Factors antecedent is found in the previous context, subsequent sentences are inspected (cataphora), also ordered by proximity to the pronoun.",
        "Entity": "Reference"
    },
    {
        "Text": "where N is role features when combining two children states, and ex amples can be found in Figure 3.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 Similarity matrix for segmentation judgments.",
        "Entity": "Reference"
    },
    {
        "Text": "As column 5 (SVM) in table 2 shows, the classification results are very similar to the results obtained with MBL.12 We furthermore find a very similar set of errors, and in particular, we find that 51.0 % of the errors for the inanimate class are nouns with the gradient animacy properties presented in (9)-(13) above.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Distribution of supersense mentions by domain (left), and counts for tags occurring over 800 times (below).",
        "Entity": "Reference"
    },
    {
        "Text": "We set Table 6: Word segmentation accuracy of all words r e c pr ec F Po iss on +b igr a m W T +P oi ss on +b igr a m P O S + Po iss on +b igr a m P O S + W T + Po iss on + bi gr a m 94 .5 94 .4 94 .4 94 .6 93 .1 93 .8 93 .6 93 .7 93 .8 94 .1 94 .0 94 .1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 presents an overview of the animacy data Clas s Ani mat e Type s Tok 6 4 4 ens cover ed 6 0 1 0 Inan imat e 691 0 3 4 8 2 2 Tota l 755 4 4 0 8 3 2 Table 1: The animacy data set from Talbanken05; number of noun lemmas (Types) and tokens in each class.",
        "Entity": "Reference"
    },
    {
        "Text": "The result is shown in Table 4: the baseline numbers without stem features are listed under Base, and the results of the coreference system with stem features are listed under Base+Stem.",
        "Entity": "Reference"
    },
    {
        "Text": "The translations of 6 of the 43 words are words in the dictionary (denoted as \u201ccomm.\u201d in Table 3) and 4 of the 43 words appear less than 10 times in the English part of the corpus (denoted as \u201cinsuff\u201d).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Scores for UPUC corpusFrom those tables, we can see that a simple ma jority voting algorithm produces accuracy that is higher than each individual system and reasonably high F-scores overall.",
        "Entity": "Reference"
    },
    {
        "Text": "We include a list of per-category results for selected phrasal labels, POS tags, and dependencies in Table 8.",
        "Entity": "Reference"
    },
    {
        "Text": "The second model is the combination of Poisson distribution (Equation (6)) and character bigram",
        "Entity": "Reference"
    },
    {
        "Text": "composite kernel 83.0 72.0 77.1 Zhou et al., (2007): composite kernel 82.2 70.2 75.8 Zhang et al., (2006): composite kernel 76.1 68.4 72.1 Zhao and Grishman, (2005):4 composite kernel 69.2 70.5 70.4 Ours: CTK with UPST 80.1 70.7 75.1Zhou et al., (2007): context sensitive CTK with CS-SPT 81.1 66.7 73.2 Zhang et al., (2006): CTK with SPT 74.1 62.4 67.7 Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, no synset covers any combinations of the main words in Figure 2, namely buy , acquire and merger",
        "Entity": "Reference"
    },
    {
        "Text": "Except our own and MENE + reference resolution, the results in Table 6 are all official MUC7 results.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 8: Relative word accuracy as a function of training set size.",
        "Entity": "Reference"
    },
    {
        "Text": "Preliminary observations show that the different neighbours in Table 1 can be used to indicate with great accuracy which of the senses is being used",
        "Entity": "Reference"
    },
    {
        "Text": "Tree setups P(%) R(%) F SPT 76.3 59.8 67.1 DSPT 77.4 65.4 70.9 UPST (BOF) 80.4 69.7 74.7 UPST (FPT) 80.1 70.7 75.1 UPST (EPT) 79.9 70.2 74.8 Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows the tagging accuracy of unknown words.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 illustrates the effects of different components of the user model by showing results for simulated users who read infinitely fast and accept only predictions having positive benefit (superman); who read normally but accept like superman (rational); and who match the standard user model (real).",
        "Entity": "Reference"
    },
    {
        "Text": "This is especially true in the case of quotations\u2014which are common in the ATB\u2014where (1) will follow a verb like (2) (Figure 1).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the effect of the role-based preference on our data.",
        "Entity": "Reference"
    },
    {
        "Text": "Finally, Table 4 shows the results for the unconstrained HGFC on T2 and and T3 when the tree structure is not predefined but inferred automatically as described in section 3.2.3.",
        "Entity": "Reference"
    },
    {
        "Text": "To compute the third factor of Equation (13), we have to estimate the character bigram probabilities that are classified by word type and part of speech.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Distribution of supersense mentions by domain (left), and counts for tags occurring over 800 times (below).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Accuracy for MBL and SVM classifiers on Talbanken05 nouns in accumulated frequency bins by Parole frequency.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5: Meta alternations and their average precision values for the task.",
        "Entity": "Reference"
    },
    {
        "Text": "PRO (c) Entity-Paired Tree(EPT)Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Bootstrapping new heuristics.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the influence of the four parameters.",
        "Entity": "Reference"
    },
    {
        "Text": "The second condition is necessary to allow for single-character words (see Figure 3).",
        "Entity": "Reference"
    },
    {
        "Text": "Again, Table 2 shows that using stem n-grams features gave a small boost to the whole main-type classification system4.",
        "Entity": "Reference"
    },
    {
        "Text": "Also, the CRF model using maximum subword-based tagging (Zhang et al., 2006) and the CRF model using minimum subword-based tagging, both of which are statistical methods, are used individually to solve the Figure 1: Outline of the segmentation process 2.1 Forward Maximum Matching.",
        "Entity": "Reference"
    },
    {
        "Text": "We see from Table 5, that the improvement in overall parse results is mainly in terms of dependency labeling, reflected in the LAS score.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1shows the word length distribution of in frequent words in the EDR corpus, and the estimate of word length distribution by Equation (6) whose parameter (.A = 4.8) is the average word length of infrequent words.",
        "Entity": "Reference"
    },
    {
        "Text": "W can be encoded by a undi rected graph G (Figure 1(a)), where the verbs are mapped to vertices and the Wij is the edge weight between vertices i and j.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Scores for UPUC corpusFrom those tables, we can see that a simple ma jority voting algorithm produces accuracy that is higher than each individual system and reasonably high F-scores overall.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Collecting evidence for a word boundary - are the non-straddling n-grams 8 1 and 82 more frequent than the straddling n-grams t 1, t2, and t3?",
        "Entity": "Reference"
    },
    {
        "Text": "A comparison of the lines for grammatical roles and for surface order in Table 1 shows that the same is true in German.",
        "Entity": "Reference"
    },
    {
        "Text": "(Abbreviations are listed in Table 2.)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows the effect of the role-based preference on our data.",
        "Entity": "Reference"
    },
    {
        "Text": "and 8 show word accuracy for Chasen, Juman, and our algorithm for parameter settings optimizing word precision, recall, and F-measure rates.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Sample of experimental items for the meta alternation anmfod.",
        "Entity": "Reference"
    },
    {
        "Text": "the target Chen Guangcheng only appears once in Weibo",
        "Entity": "Reference"
    },
    {
        "Text": "whose unvocalized surface forms 0 an are indistinguishable.",
        "Entity": "Reference"
    },
    {
        "Text": "This is because the lefthand side of Equation (7) represents the probability of the string c1",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Effect of Arabic stemming features on coreference resolution.",
        "Entity": "Reference"
    },
    {
        "Text": "This is usually straightforward, with the exception of the case where the words that are aligned to a particular role s span in the source side are not continuous in the target side, as shown in Figure 4.",
        "Entity": "Reference"
    },
    {
        "Text": "(Equation (7)) (Poisson + hi gram).",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 contains results for two different translation models.",
        "Entity": "Reference"
    },
    {
        "Text": "We also propose to use the features U01 U03, which we found are effective to adjust the character Figure 1: Illustration of the alignment of steps.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows examples of the feature SRR.",
        "Entity": "Reference"
    },
    {
        "Text": "(2004) makes use of a coding manual designed for a project studying genitive modification (Garretson et al., 2004) and presents an explicit annotation scheme for an _ Samma _ PO _ KP erfarenhet NN _ gjorde VV PT engelsmannen NN DD|HH imacy, illustrated by figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "For fair comparison, we have tabulated all results with the size of training data used (Table 5",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 shows the record for the headword orange followed by its collocates",
        "Entity": "Reference"
    },
    {
        "Text": "whose unvocalized surface forms 0 an are indistinguishable.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: Time to read and accept or reject proposals versus their length tion, because the empirical probability of acceptance is very low when it is less than zero and rises rapidly as it increases.",
        "Entity": "Reference"
    },
    {
        "Text": "On the other hand, using our method of combining both sources of information and setting M = \u221e, 19 Chinese words (i.e., the first 22 Chinese words in Table 3 except \u5df4\u4f50\u4e9a,\u5769\u57da,\u666e\u5229\u6cd5) have their correct English translations at rank one position.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1), i.e., the degree to which a sense pair (s1, s2) matches a meta alternation a.",
        "Entity": "Reference"
    },
    {
        "Text": "If we compare the error rates in Table 7, which correspond to about 55 search errors in Table 6, we obtain an mWER of 36.7% (53 search errors) using no heuristic function and an mWER of 32.6% (57 search errors) using the combined heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "By far the most frequent tagging error was the confusion of nominative and accusative case.",
        "Entity": "Reference"
    },
    {
        "Text": "14http://www.cis.upenn.edu/ dbikel/software.html Gold standard Automatic UAS LAS UAS LAS Baseline 89.87 84.92 89.87 84.92 Anim 89.81 84.94 89.87 84.99 Table 5: Overall results in experiments with automatic features compared to gold standard features, expressed as unlabeled and labeled attachment scores.",
        "Entity": "Reference"
    },
    {
        "Text": "(Abbreviations are listed in Table 2.)",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 gives the mean values for the comparison of troughs placed by the segmentation algorithm to the segmentation points identified by the test subjects for all the texts",
        "Entity": "Reference"
    },
    {
        "Text": "The graphical structure depicted in Figure 1 models these relations between the four mentions Leaders, Paris, recent developments and They.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Results of different systems on the CoNLL 12 English data sets.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: The amount of training and test sets The first factor in the righthand side of Equa tion (13) is estimated from the relative frequency of the corresponding events in the training corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, looking at Figure 1(b), V on G can be grouped into three clusters u1, u2 and u3.",
        "Entity": "Reference"
    },
    {
        "Text": "The model is described using a log-linear modeling approach, which is a generalization of the often used source channel approach",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function",
        "Entity": "Reference"
    },
    {
        "Text": "Finally, Table 4 shows the results for the unconstrained HGFC on T2 and and T3 when the tree structure is not predefined but inferred automatically as described in section 3.2.3.",
        "Entity": "Reference"
    },
    {
        "Text": "The distribution of errors is displayed in Table 4.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: Sample of experimental items for the meta alternation anmfod.",
        "Entity": "Reference"
    },
    {
        "Text": "Nc Nl HGFC uncons trained A G G N MI F N M I F 13 0 13 3 57 .3 1 36 .6 5 54 .2 2 32 .6 2 11 4 11 7 54 .6 7 37 .9 6 51 .3 5 32 .4 4 50 51 37 .7 5 40 .0 0 32 .6 1 32 .7 8 Table 2: Performance on T2 using a predefined tree structure.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Decoding algorithm for the standard Tree-to-String transducer.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the F1 scores of the proposed model (SegTagDep) on CTB5c1 with respect to the training epoch and different parsing feature weights, where Seg , Tag , and Dep respectively denote the F1 scores of word segmentation, POS tagging, and dependency parsing.",
        "Entity": "Reference"
    },
    {
        "Text": "The translations of 6 of the 43 words are words in the dictionary (denoted as \u201ccomm.\u201d in Table 3) and 4 of the 43 words appear less than 10 times in the English part of the corpus (denoted as \u201cinsuff\u201d).",
        "Entity": "Reference"
    },
    {
        "Text": "Strube (1998) s centeri ng appro ach (whos e senten ce orderi ng is designate d as SR2 in Table 2) also deals with and even prefer s intrase ntenti al anaph ora, which raises the upper limit to a more accept able 80.2% .",
        "Entity": "Reference"
    },
    {
        "Text": "able 2 shows the corpus statistics for this task.",
        "Entity": "Reference"
    },
    {
        "Text": "range free green lemon peel red state yellow",
        "Entity": "Reference"
    },
    {
        "Text": "As Figure 3 shows, word type information improves the prediction accuracy significantly.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 describes the components and how this system works.",
        "Entity": "Reference"
    },
    {
        "Text": "It should be emphasized that this constraint to consecutive phrases limits the expressive power.",
        "Entity": "Reference"
    },
    {
        "Text": "In Figure 4 we show an example of variation between the parsing models.",
        "Entity": "Reference"
    },
    {
        "Text": "Nc Nl HGFC uncons trained A G G N MI F N M I F 13 0 13 3 57 .3 1 36 .6 5 54 .2 2 32 .6 2 11 4 11 7 54 .6 7 37 .9 6 51 .3 5 32 .4 4 50 51 37 .7 5 40 .0 0 32 .6 1 32 .7 8 Table 2: Performance on T2 using a predefined tree structure.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3: An example showing the combination of the semantic role sequences of the states.",
        "Entity": "Reference"
    },
    {
        "Text": "Then, every phrase f produces its translation e (using the corresponding alignment template z).",
        "Entity": "Reference"
    },
    {
        "Text": "This leaves us with 60 meta alternations, shown in Table 5.",
        "Entity": "Reference"
    },
    {
        "Text": "This corresponds to maximizing the equivocation or maximizing the likelihood of the direct-translation model",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 plots AP by for all meta alternations.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8 shows the effect of the length of the language model history on translation quality.",
        "Entity": "Reference"
    },
    {
        "Text": "IBM1F refers to the fertility IBM1 and HMMF refers to the fertility HMM",
        "Entity": "Reference"
    },
    {
        "Text": "Again, Table 2 shows that using stem n-grams features gave a small boost to the whole main-type classification system4.",
        "Entity": "Reference"
    },
    {
        "Text": "This leaves us with 60 meta alternations, shown in Table 5.",
        "Entity": "Reference"
    },
    {
        "Text": "this error is not counted, the tagging accuracy on the development data rises from 92.17% to 94.27%.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Word length distribution of unknown words and its estimate by Poisson distribution",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 portrays how the states are aligned using the proposed scheme, where a subtree is denoted as a rectangle with its partial index shown inside it.",
        "Entity": "Reference"
    },
    {
        "Text": "We set Table 6: Word segmentation accuracy of all words r e c pr ec F Po iss on +b igr a m W T +P oi ss on +b igr a m P O S + Po iss on +b igr a m P O S + W T + Po iss on + bi gr a m 94 .5 94 .4 94 .4 94 .6 93 .1 93 .8 93 .6 93 .7 93 .8 94 .1 94 .0 94 .1",
        "Entity": "Reference"
    },
    {
        "Text": "equation 2) says that the prob ability of starting a new entity, given the current mention m and the previous entities e1, e2, , et, is simply 1 minus the maximum link probability between the current mention and one of the previous entities.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows empirical search timings for various values of M , for the MEMD model described in the next section.",
        "Entity": "Reference"
    },
    {
        "Text": "Only tokens with initCaps not found in commonWords are tested against each list in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Example of a prediction for English to French translation.",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "U = {up}m represent the hidden m struct a new graph G1 (Figure 1(d)) with the clusters U as vertices.",
        "Entity": "Reference"
    },
    {
        "Text": "As each global feature group is added to the list of features, we see improvements to both MUC6 and",
        "Entity": "Reference"
    },
    {
        "Text": "Table 5 breaks down the performance of the best CAM model by meta alternation.",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "This approach can be seen as a generalization of the originally suggested source channel modeling framework for statistical machine translation",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 gives an example of the word alignment and phrase alignment of a German English sentence pair.We describe our model using a log-linear modeling approach",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 lists both the success rate maximally achievable (broken down according to different types of pronouns) and the average number of antecedents remaining after applying each factor.",
        "Entity": "Reference"
    },
    {
        "Text": "Results are shown in Table 2; we see that better word alignment results do not lead to better translations.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, the pairwise words orange and peel form a collocation.",
        "Entity": "Reference"
    },
    {
        "Text": "This sum can be computed efficiently using the algorithm shown in Figure 8",
        "Entity": "Reference"
    },
    {
        "Text": "As the search space increases expo nentially, it is not possible to explicitly represent it.",
        "Entity": "Reference"
    },
    {
        "Text": "However, the spelling model, especially the character bigrams in Equation (17) are hard to es timate because of the data sparseness.",
        "Entity": "Reference"
    },
    {
        "Text": "Among all possible target sentences, we will choose the sentence with the highest probability",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2 shows the word length distribution of words consists of only kanji characters and words consists of only katakana characters.",
        "Entity": "Reference"
    },
    {
        "Text": "5http://cactus.aistnara.ac.jp/lab/nltlchasen.html 6http://pine.kuee.kyoto-u.ac.jp/nl-resource/juman-e.html Word accuracy 90 CHASEN JUMAN opllnizt oplnuo recall opiJTozt F Figure 4: Word accuracy.",
        "Entity": "Reference"
    },
    {
        "Text": "5http://cactus.aistnara.ac.jp/lab/nltlchasen.html 6http://pine.kuee.kyoto-u.ac.jp/nl-resource/juman-e.html Word accuracy 90 CHASEN JUMAN opllnizt oplnuo recall opiJTozt F Figure 4: Word accuracy.",
        "Entity": "Reference"
    },
    {
        "Text": "The argmax operation denotes the search problem, that is, the generation of the output sentence in the target language",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: A sentence from the article Islamic GoldenAge, with the supersense tagging from one of two anno tators.",
        "Entity": "Reference"
    },
    {
        "Text": "The sources of our dictionaries are listed in Table 2.",
        "Entity": "Reference"
    },
    {
        "Text": "whose unvocalized surface forms 0 an are indistinguishable.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Examples of word bigrams including un known word tags example",
        "Entity": "Reference"
    },
    {
        "Text": "Column four (MBL) in table 2 shows the accuracy obtained with all features in the general feature space.",
        "Entity": "Reference"
    },
    {
        "Text": "The alignment aJ that has the highest probability (under a certain model) is also called the Viterbi alignment (of that model)",
        "Entity": "Reference"
    },
    {
        "Text": "The renormalization needed in equation (3) requires a sum over manypossible sentences, for which we do not know of an efficient algorithm",
        "Entity": "Reference"
    },
    {
        "Text": "and Table 6 show a comparison of the segmentation and POS tagging accuracies with other state-of-the-art models.",
        "Entity": "Reference"
    },
    {
        "Text": "The first example in Table 3 shows that words ending in ' -' are likely to be nouns.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Results for different user simulations.",
        "Entity": "Reference"
    },
    {
        "Text": "In the last two lines of Equation 3, \u03c6\u01eb and each P (f |e) = \"\u00a3s c (f |e; f (s), e(s)) (4) \u03c6i are not free variables, but are determined by f s c(f |e; f (s), e(s))the alignments.",
        "Entity": "Reference"
    },
    {
        "Text": "In all four tables, we provide theresults for using no heuristic functions and three variants of an increasingly infor mative heuristic function.",
        "Entity": "Reference"
    },
    {
        "Text": "As can be seen in figure 2, wing \"part of a bird\" is closely related to tail, as is wing \"part of a plane\"",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 presents the distributions of some examples of morphs and their targets in English Twitter and Chinese Sina Weibo.",
        "Entity": "Reference"
    },
    {
        "Text": "But it conflates the coordinating and discourse separator functions of wa (<..4.b \ufffd \ufffd) into one analysis: conjunction(Table 3).",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the distribution of SSTs in the corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "The algorithm takes into account possibly unaligned words at the boundaries of the source or target language phrases.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3 lists new conceptsthat CAM introduces to manipulate vector represen tations.",
        "Entity": "Reference"
    },
    {
        "Text": "These semantic features Figure 8: Examples of the MT outputs with and without SRFs",
        "Entity": "Reference"
    },
    {
        "Text": "The corresponding translation quality improves from an mWER of 45.9% to an mWER of 31.8%.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 11 gives an overview on the training and test data.",
        "Entity": "Reference"
    },
    {
        "Text": "L set of lemmas IL set of (lemma-wise) instances SL set of (lemma-wise) senses inst : L (IL ) mapping lemma instances sns : L (SL ) mapping lemma senses M set of meta senses meta : SL M mapping senses meta senses A M M set of meta alternations (MAs) A set of MA representations score : A S2 R scoring function for MAs repA : A A MA representation function comp : A S2 R compatibility function Table 1: Notation and signatures for our framework.",
        "Entity": "Reference"
    },
    {
        "Text": "IBM1F refers to the fertility IBM1 and HMMF refers to the fertility HMM",
        "Entity": "Reference"
    },
    {
        "Text": "With an absolute frequency threshold of 10, we obtain an accuracy of 95.4%, which constitutes a 50% reduction of error rate.Table 3 presents the experimental results rela tive to class.",
        "Entity": "Reference"
    },
    {
        "Text": "However, the spelling model, especially the character bigrams in Equation (17) are hard to es timate because of the data sparseness.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1 shows our results and the results of Stevenson and Joanis (2003) on T1 when employing AGG using Ward as the linkage criterion.",
        "Entity": "Reference"
    },
    {
        "Text": "On the contrary, in the above training stage, although the samples are not accurate enough to represent the distribution defined by Equation 7 for each alignment aj , it is accurate enough for computing the expected counts, which are defined at the corpus level.",
        "Entity": "Reference"
    },
    {
        "Text": "We scan through the corpus many times until we are satisfied with the parameters we learned using Equations 4, 5, and 6.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 8b shows that verbal nouns are the hardest pre-terminal categories to identify.",
        "Entity": "Reference"
    },
    {
        "Text": "Collocation: Collocations were extracted from a seven million word sample of the Longman English Language Corpus using the association ratio (Church and Hanks, 1990) and outputted to a lexicon.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1: Comparison against Stevenson and Joanis (2003) s result on T1 (using similar features).",
        "Entity": "Reference"
    },
    {
        "Text": "The second model is Equa tion (13), which is a set of word models trained for",
        "Entity": "Reference"
    },
    {
        "Text": "Collocations were automatically located in a text by looking up pairwise words in this lexicon",
        "Entity": "Reference"
    },
    {
        "Text": "Table 3: Performance of the mention detection system including all ACE 04 subtasks",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 2: Dependency representation of example (2) from Talbanken05.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 1 describes the components and how this system works.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2: Scores for MSRA corpus",
        "Entity": "Reference"
    },
    {
        "Text": "Table 4: NMI of unconstrained HGFC when trees for T2 and T3 are inferred automatically.",
        "Entity": "Reference"
    },
    {
        "Text": "using the convolution parse tree kernel as depicted in Figure 1.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 1, Figure 1, and Figure 2 shows the AER results for different models.",
        "Entity": "Reference"
    },
    {
        "Text": "Collocations were automatically located in a text by looking up pairwise words in this lexicon",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7: Compatible brackets and all-compatible bracket rates when word accuracy is optimized.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 6 shows the word segmentation accuracy of four unknown word models over test set-2.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 3 shows the part of speech prediction accu racy of two unknown word model without context.",
        "Entity": "Reference"
    },
    {
        "Text": "able 1 shows the bilingual phrases containing between two and seven words that result from the application of this algorithm to the alignment of Figure 2.",
        "Entity": "Reference"
    },
    {
        "Text": "An abridged version of the grammatical representation produced by the implemented grammar for this sentence is presented in Figure 1, where the feature structures below the tree correspond to partial grammatical representations of the constituents 16 See Kamp and Reyle (1993) for a comprehensive rendering of DRT, and Branco (2000, Chapter 5) for an.",
        "Entity": "Reference"
    },
    {
        "Text": "For example, the expressions in Figure 2 are identified as paraphrases by this method; so these three patterns will be placed in the same pattern set.",
        "Entity": "Reference"
    },
    {
        "Text": "Table 2 shows the distribution of character type sequences that constitute the infrequent words in the EDR corpus.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 7: Compatible brackets and all-compatible bracket rates when word accuracy is optimized.",
        "Entity": "Reference"
    },
    {
        "Text": "The results are displayed in Table 3.",
        "Entity": "Reference"
    },
    {
        "Text": "First, the source sentence words f J are grouped into phrases f K . For each phrase f an 1 1 alignment template z is chosen and the sequence of chosen alignment templates is reordered (according to K ).",
        "Entity": "Reference"
    },
    {
        "Text": "Table (1) and Eq.",
        "Entity": "Reference"
    },
    {
        "Text": "equation 2) says that the prob ability of starting a new entity, given the current mention m and the previous entities e1, e2, , et, is simply 1 minus the maximum link probability between the current mention and one of the previous entities.",
        "Entity": "Reference"
    },
    {
        "Text": "Figure 5 gives an example of the word alignment and phrase alignment of a German English sentence pair.We describe our model using a log-linear modeling approach",
        "Entity": "Reference"
    },
    {
        "Text": "By far the most frequent tagging error was the confusion of nominative and accusative case.",
        "Entity": "Reference"
    }
]